{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import related package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import tensorflow package for modeling\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "## Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Min-max normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "## Plot the graph\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## Initializing module\n",
    "from sklearn.linear_model import LinearRegression\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "## Copy module\n",
    "import copy\n",
    "\n",
    "## Used to calculate the training time\n",
    "import time\n",
    "\n",
    "## Set the GUP environment\n",
    "import os\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the display\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 編寫結果在note中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Setup logging.\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%m/%d/%Y %I:%M:%S %p',\n",
    "    level=logging.DEBUG,\n",
    "    filename='log.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control memory usage space for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前設備： 0\n",
      "目前設備名： GeForce GTX 1070 Ti\n"
     ]
    }
   ],
   "source": [
    "## 查詢有無可用 GPU\n",
    "torch.cuda.is_available()\n",
    "## 查詢可用 GPU 的數量\n",
    "torch.cuda.device_count()\n",
    "##目前設備\n",
    "print(\"目前設備：\",torch.cuda.current_device())\n",
    "## 目前設備名\n",
    "print(\"目前設備名：\",torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices(device_type='GPU')\n",
    "\n",
    "# tf.config.set_logical_device_configuration(\n",
    "#     gpus[0],\n",
    "#     [tf.config.LogicalDeviceConfiguration(memory_limit=2048),\n",
    "#      tf.config.LogicalDeviceConfiguration(memory_limit=2048)]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = tf.compat.v1.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction =0.1\n",
    "# tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "# tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out some info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_cacl(pred_value, actual_value):\n",
    "    \n",
    "#     yo, loss, tape = network.forward()\n",
    "    accuracy = []\n",
    "\n",
    "    for i in range(pred_value.shape[1]):\n",
    "        \n",
    "        correct_times = torch.nonzero(torch.abs(pred_value[:,i] - actual_value[:,i]) < 3000)\n",
    "        accuracy.append(correct_times.shape[0]/pred_value.shape[0])   \n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(name, pred_value, actual_value,block_index):\n",
    "    \n",
    "    fig, ax = plt.subplots(2,2,figsize=(20,10), sharex=True, sharey=True)\n",
    "#     ax.set_xlim(0,pred_value.shape[0])  \n",
    "    \n",
    "    \n",
    "    for i in range(yo.shape[1]):\n",
    "        ax[i//2,i%2].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax[i//2,i%2].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax[i//2,i%2].plot(pred_value[:,i], label=\"LLAAT\")\n",
    "        ax[i//2,i%2].plot(actual_value[:,i], label=\"Actual\")\n",
    "        ax[i//2,i%2].set_title(\"Forecasted performance for l=%d\" %(i+1))\n",
    "        ax[i//2,i%2].legend()\n",
    "        \n",
    "    #fig.text(0.5, 0, \"Stage of training\", ha='center', fontsize=20)\n",
    "    #fig.text(0, 0.5, \"Copper price value\", va='center', rotation='vertical')\n",
    "\n",
    "    \n",
    "    fig.suptitle(\"In the %s process in the M=%d window\"%(name, block_index))\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_adopted_node(network,block_index):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20,5))\n",
    "    ax.set_title(\"Total amount of adopted hidden nodes in the training process in the M=%d window\"%(block_index))\n",
    "    ax.plot(network.nb_node_acceptable,\"-o\")\n",
    "\n",
    "    ax.set_xlabel(\"Stage of training\")\n",
    "    ax.set_ylabel(\"Hidden nodes\")\n",
    "    \n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(network, nb_step4, nb_step6_1, nb_step6_2, x_test, y_test, start, end, block_index):\n",
    "\n",
    "    ## Training_Step\n",
    "    print(\"<<Training step>>\")\n",
    "    print(\"The training time(s):\",end - start)\n",
    "    yo, loss= network.forward()\n",
    "    \n",
    "    pre_train = yo.data.cpu()\n",
    "    true_train = network.y.data.cpu()\n",
    "    \n",
    "    pred_value_train = torch.FloatTensor(sc.inverse_transform(pre_train))\n",
    "    actual_value_train = torch.FloatTensor(sc.inverse_transform(true_train))\n",
    "    accuracy_train = accuracy_cacl(pred_value_train,actual_value_train)\n",
    "\n",
    "    ## Test_step\n",
    "#     print(\"<<Testing step>>\")\n",
    "    pred_value_test = torch.FloatTensor(sc.inverse_transform(network.forecast(x_test).data.cpu()))\n",
    "    accuracy_test = accuracy_cacl(pred_value_test, y_test)\n",
    "    \n",
    "    total_time = nb_step4 + nb_step6_1 + nb_step6_2\n",
    "    print(\"<<The percentage of each step>>\")\n",
    "    print(\"Step 4: %.2f%%\"%((nb_step4/total_time)*100))\n",
    "    print(\"Step 6.1: %.2f%%\"%((nb_step6_1/total_time)*100))\n",
    "    print(\"Step 6.2: %.2f%%\"%((nb_step6_2/total_time)*100))\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"Total frequency of cramming occurrences:\",nb_step6_2)\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"The amount of hidden node that be pruned:\",network.nb_node_pruned)\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"The amount of adopted hidden nodes:\",network.nb_node_acceptable[-1].item())\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"<<Accuracy in training step>>\")\n",
    "    print(\"The accuracy for l = 1: %.1f%%\" %(accuracy_train[0]*100))\n",
    "    print(\"The accuracy for l = 2: %.1f%%\" %(accuracy_train[1]*100))\n",
    "    print(\"The accuracy for l = 3: %.1f%%\" %(accuracy_train[2]*100))\n",
    "    print(\"The accuracy for l = 4: %.1f%%\" %(accuracy_train[3]*100))\n",
    "\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"<<Accuracy in inferencing step>>\")\n",
    "    print(\"The accuracy for l = 1: %.1f%%\" %(accuracy_test[0]*100))\n",
    "    print(\"The accuracy for l = 2: %.1f%%\" %(accuracy_test[1]*100))\n",
    "    print(\"The accuracy for l = 3: %.1f%%\" %(accuracy_test[2]*100))\n",
    "    print(\"The accuracy for l = 4: %.1f%%\" %(accuracy_test[3]*100))\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    plot_result(\"training\",pred_value_train, actual_value_train,block_index)\n",
    "    plot_result(\"inferencing\",pred_value_test, y_test,block_index)\n",
    "    plot_adopted_node(network,block_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTrain(train, pastWeek=4, futureWeek=4, defaultWeek=1):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(train.shape[0]-futureWeek-pastWeek):\n",
    "        X = np.array(train.iloc[i:i+defaultWeek])\n",
    "        X = np.append(X,train[\"CCSP\"].iloc[i+defaultWeek:i+pastWeek])\n",
    "        X_train.append(X.reshape(X.size))\n",
    "        Y_train.append(np.array(train.iloc[i+pastWeek:i+pastWeek+futureWeek][\"CCSP\"]))\n",
    "    return np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use min-max normalization to scale the data to the range from 1 to 0\n",
    "sc = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design get_data() to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_data(futureWeek):\n",
    "    \n",
    "#     ## Read weekly copper price data\n",
    "#     path = \"WeeklyFinalData.csv\"\n",
    "#     data = read(path)\n",
    "    \n",
    "#     date = data[\"Date\"]\n",
    "#     data.drop(\"Date\", axis=1, inplace=True)\n",
    "    \n",
    "#     ## Add time lag (pastWeek=4, futureWeek=1)\n",
    "#     x_data, y_data = buildTrain(data, futureWeek=futureWeek)\n",
    "\n",
    "    \n",
    "#     ## Split the data to training data and test data\n",
    "#     x_train_data = x_data[:int(x_data.shape[0]*0.8)]\n",
    "#     x_test_data = x_data[int(x_data.shape[0]*0.8):]\n",
    "#     y_train_data = y_data[:int(x_data.shape[0]*0.8)]\n",
    "#     y_test_data = y_data[int(x_data.shape[0]*0.8):]\n",
    "\n",
    "\n",
    "#     return (x_train_data, x_test_data, y_train_data, y_test_data)\n",
    "\n",
    "# #     return (x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(futureWeek):\n",
    "    \n",
    "    ## Read weekly copper price data\n",
    "    path = \"WeeklyFinalData.csv\"\n",
    "    data = read(path)\n",
    "    \n",
    "    date = data[\"Date\"]\n",
    "    data.drop(\"Date\", axis=1, inplace=True)\n",
    "    \n",
    "    ## Add time lag (pastWeek=4, futureWeek=1)\n",
    "    x_data, y_data = buildTrain(data, futureWeek=futureWeek)\n",
    "\n",
    "\n",
    "    return (x_data, y_data)\n",
    "\n",
    "#     return (x_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializing(network, initial_x, initial_y):\n",
    "    print(\"Initializing module\")\n",
    "    ## Find each minimum output value y\n",
    "    min_y = torch.min(initial_y, axis=0)\n",
    "\n",
    "    ## Subtract min_y from each y\n",
    "    res_y = initial_y-min_y.values\n",
    "    \n",
    "    ## Use linear regression to find the initial W1,b1,Wo,bo\n",
    "    reg = LinearRegression().fit(initial_x, res_y)\n",
    "#     ## Set up the initial parameter of the network\n",
    "    network.linear1.weight = torch.nn.Parameter(torch.FloatTensor(reg.coef_).cuda())\n",
    "#     network.linear1.weight = network.linear1.weight.cuda()\n",
    "    network.linear1.bias = torch.nn.Parameter(torch.FloatTensor(reg.intercept_).cuda())\n",
    "    network.linear2.weight=torch.nn.Parameter(torch.FloatTensor([[1,0,0,0], [0,1,0,0],[0,0,1,0],[0,0,0,1]]).cuda())\n",
    "    network.linear2.bias = torch.nn.Parameter(torch.FloatTensor(min_y.values).cuda())\n",
    "    ## Set up the acceptable of the initial network as True\n",
    "    network.acceptable =True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecting(network, x_train_scaled, y_train_scaled):\n",
    "    \n",
    "    print(\"<<Selecting module>>\")\n",
    "    loss = []\n",
    "    temp_network = copy.deepcopy(network)\n",
    "    \n",
    "    ## Put each data into network to calculate the loss value\n",
    "    for i in range(x_train_scaled.shape[0]):\n",
    "        temp_network.setData(x_train_scaled[i].reshape(1,-1), y_train_scaled[i].reshape(1,-1))\n",
    "        loss.append((temp_network.forward()[1].item(),i))\n",
    "\n",
    "#     ## Sort the data according to the loss value from smallest to largest, and save the data index in sorted_index\n",
    "    sorted_index = [sorted_data[1] for sorted_data in sorted(loss, key = lambda x:x[0])]\n",
    "    \n",
    "    \n",
    "    ## Print out some info for debug\n",
    "    print(\"The loss value of k:\",loss[sorted_index[0]])\n",
    "#     print(\"The second_loss value of k:\",loss[sorted_index[1]])\n",
    "    print(\"Selecting module finish!\")\n",
    "    \n",
    "    return sorted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching(network):\n",
    "\n",
    "    times_enlarge=0\n",
    "    times_shrink=0\n",
    "    print(\"<<Matching module>>\")\n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "#     yo, loss = network.forward()\n",
    "    network.acceptable = False\n",
    "    initial_network = copy.deepcopy(network)\n",
    "#     while True:\n",
    "        \n",
    "#         print(\"最後審判\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "#         print(\"你的Loss值\")\n",
    "#         print(loss)\n",
    "#         if torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "\n",
    "#             ## If true, set the acceptable of the network as true and return it\n",
    "#             network.acceptable = True\n",
    "#             print(\"Matching finished - the network is acceptable\")\n",
    "#             print(\"<<Final Network>>\")\n",
    "#             print(network.state_dict())\n",
    "# #             print(\"<<Pre-network>>\")\n",
    "# #             print(network_pre.state_dict())\n",
    "#             return(network)\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "\n",
    "        yo, loss = network.forward()\n",
    "        network_pre = copy.deepcopy(network)\n",
    "        loss_pre = loss\n",
    "\n",
    "#         print(\"<<再次確認一下要調整的network\")\n",
    "#             print(network.state_dict())\n",
    "#         print(torch.abs(yo-network.y))\n",
    "#         print(\"你的Loss值\",loss)\n",
    "#         print(\"loss2\", loss_pre)\n",
    "#         print(\"<<Before>>\")\n",
    "#             print(\"lr\",network.learning_rate)\n",
    "#         print(\"W1\",network.linear1.weight)\n",
    "\n",
    "            # Backward and check the loss performance of the network with new learning rate\n",
    "        network.backward_Adam(loss)\n",
    "        yo, loss = network.forward()\n",
    "\n",
    "#         print(\"調整後看一下\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "#         print(\"我看一下Loss值\",loss)\n",
    "#             print(\"<<更新後的network\")\n",
    "#             print(network.state_dict())\n",
    "#         print(\"los3\", loss)\n",
    "\n",
    "#         print(\"<<After>>\")\n",
    "#             print(\"lr\",network.learning_rate)\n",
    "#         print(\"W1\",network.linear1.weight)\n",
    "              ## Identify that all forecast value has met the error term\n",
    "\n",
    "            # Confirm whether the loss value of the adjusted network is smaller than the current one\n",
    "        if loss < loss_pre and torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "            \n",
    "#             print(\"我成功了\")\n",
    "            # If true, multiply the learning rate by 1.2\n",
    "            network.acceptable = True\n",
    "            print(\"Matching finished - the network is acceptable\")\n",
    "#             print(\"<<Final Network>>\")\n",
    "#             print(network.state_dict())\n",
    "#             print(\"<<Pre-network>>\")\n",
    "#             print(network_pre.state_dict())\n",
    "            print(\"Number of enlarge:\",times_enlarge)\n",
    "            print(\"Number of shrink:\",times_shrink)\n",
    "            return(network)\n",
    "\n",
    "\n",
    "#                 print(\"<<Enlarge>>\")\n",
    "        # On the contrary, reduce the learning rate\n",
    "        elif loss < loss_pre:\n",
    "#             print(\"快成功了，加油\")\n",
    "            times_enlarge+=1\n",
    "            network.learning_rate *= 1.2\n",
    "            \n",
    "    \n",
    "        else:         \n",
    "\n",
    "            # Identify whether the current learning rate is less than the threshold\n",
    "            if network.learning_rate <= network.threshold_for_lr:\n",
    "\n",
    "                # If true, set the acceptable of the network as false and return it\n",
    "                network.acceptable = False\n",
    "                print(\"Matching finished - the network is Unacceptable\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "                return(initial_network)\n",
    "\n",
    "            # On the contrary, restore w and adjust the learning rate\n",
    "            else:\n",
    "#                 print(\"我在縮小\")\n",
    "                # Restore the papameter of the network\n",
    "                network = copy.deepcopy(network_pre)\n",
    "                times_shrink+=1\n",
    "                network.learning_rate *= 0.7\n",
    "\n",
    "#                     print(\"<<After>>\")\n",
    "#                     print(network.learning_rate)\n",
    "#                     print(\"<<Shrink>>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching for reorganizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_for_reorganizing(network):\n",
    "\n",
    "    times_enlarge=0\n",
    "    times_shrink=0\n",
    "    print(\"<<Matching module>>\")\n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "#     yo, loss = network.forward()\n",
    "    network.acceptable = False\n",
    "    initial_network = copy.deepcopy(network)\n",
    "#     while True:\n",
    "        \n",
    "#         print(\"最後審判\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "#         print(\"你的Loss值\")\n",
    "#         print(loss)\n",
    "#         if torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "\n",
    "#             ## If true, set the acceptable of the network as true and return it\n",
    "#             network.acceptable = True\n",
    "#             print(\"Matching finished - the network is acceptable\")\n",
    "#             print(\"<<Final Network>>\")\n",
    "#             print(network.state_dict())\n",
    "# #             print(\"<<Pre-network>>\")\n",
    "# #             print(network_pre.state_dict())\n",
    "#             return(network)\n",
    "    \n",
    "    \n",
    "    for i in range(1000):\n",
    "\n",
    "        yo, loss = network.forward()\n",
    "        network_pre = copy.deepcopy(network)\n",
    "        loss_pre = loss\n",
    "\n",
    "#         print(\"<<再次確認一下要調整的network\")\n",
    "#             print(network.state_dict())\n",
    "#         print(\"誤差值\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "#         print(\"你的Loss值\",loss)\n",
    "#         print(\"loss2\", loss_pre)\n",
    "#         print(\"<<Before>>\")\n",
    "#             print(\"lr\",network.learning_rate)\n",
    "#         print(\"W1\",network.linear1.weight)\n",
    "\n",
    "            # Backward and check the loss performance of the network with new learning rate\n",
    "        network.backward_Adam(loss)\n",
    "        yo, loss = network.forward()\n",
    "\n",
    "#         print(\"調整後看一下\")\n",
    "#         print(\"誤差值\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "#         print(\"我看一下Loss值\",loss)\n",
    "#             print(\"<<更新後的network\")\n",
    "#             print(network.state_dict())\n",
    "#         print(\"loss\", loss)\n",
    "\n",
    "#         print(\"<<After>>\")\n",
    "#             print(\"lr\",network.learning_rate)\n",
    "#         print(\"W1\",network.linear1.weight)\n",
    "              ## Identify that all forecast value has met the error term\n",
    "\n",
    "            # Confirm whether the loss value of the adjusted network is smaller than the current one\n",
    "        if loss < loss_pre and torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "            \n",
    "            print(\"我成功了\")\n",
    "            # If true, multiply the learning rate by 1.2\n",
    "            network.acceptable = True\n",
    "            print(\"Matching finished - the network is acceptable\")\n",
    "#             print(\"<<Final Network>>\")\n",
    "#             print(network.state_dict())\n",
    "#             print(\"<<Pre-network>>\")\n",
    "#             print(network_pre.state_dict())\n",
    "            print(\"Number of enlarge:\",times_enlarge)\n",
    "            print(\"Number of shrink:\",times_shrink)\n",
    "            return(network)\n",
    "\n",
    "\n",
    "#                 print(\"<<Enlarge>>\")\n",
    "        # On the contrary, reduce the learning rate\n",
    "        elif loss < loss_pre:\n",
    "            #print(\"快成功了，加油\")\n",
    "            times_enlarge+=1\n",
    "            network.learning_rate *= 1.2\n",
    "            \n",
    "    \n",
    "        else:         \n",
    "\n",
    "            # Identify whether the current learning rate is less than the threshold\n",
    "            if network.learning_rate <= network.threshold_for_lr:\n",
    "\n",
    "                # If true, set the acceptable of the network as false and return it\n",
    "                network.acceptable = False\n",
    "                print(\"Matching finished - the network is Unacceptable\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "                return(initial_network)\n",
    "\n",
    "            # On the contrary, restore w and adjust the learning rate\n",
    "            else:\n",
    "                #print(\"我在縮小\")\n",
    "                # Restore the papameter of the network\n",
    "                network = copy.deepcopy(network_pre)\n",
    "                times_shrink+=1\n",
    "                network.learning_rate *= 0.7\n",
    "\n",
    "                \n",
    "    network.acceptable = False\n",
    "    print(\"Matching的第%d回合\"%(i+1))\n",
    "    print(\"Matching finished - the network is Unacceptable\")\n",
    "    print(\"Number of enlarge:\",times_enlarge)\n",
    "    print(\"Number of shrink:\",times_shrink)\n",
    "    return(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Record program start time\n",
    "# start = time.time()\n",
    "\n",
    "# ## Record the number of each step\n",
    "# nb_step4 = 0\n",
    "# nb_step6_1 = 0\n",
    "# nb_step6_2 = 0\n",
    "\n",
    "# x_train, x_test, y_train, y_test = get_data(4)\n",
    "\n",
    "# # x_train = torch.FloatTensor(sc.fit_transform(x_train))\n",
    "# # x_test = torch.FloatTensor(sc.transform(x_test))\n",
    "# # y_train = torch.FloatTensor(sc.fit_transform(y_train))\n",
    "\n",
    "# initial_x = torch.FloatTensor(np.round(x_train[:x_train.shape[1]+1],0))\n",
    "# initial_y = torch.FloatTensor(np.round(y_train[:x_train.shape[1]+1],0))\n",
    "\n",
    "# x_train = torch.FloatTensor(x_train[x_train.shape[1]+1:])\n",
    "# y_train = torch.FloatTensor(y_train[x_train.shape[1]+1:])\n",
    "\n",
    "# network = Network(4,initial_x,initial_y)\n",
    "# initializing(network, initial_x, initial_y)\n",
    "# print(\"<<Initializing後看一下差異>>\")\n",
    "# yo,loss = network.forward()\n",
    "# print(torch.abs(network.y-yo))\n",
    "\n",
    "# for i in range(0, 1):\n",
    "    \n",
    "#     print(\"現在訓練到第幾筆資料: %d\"%(i+x_train.shape[1]+2))\n",
    "    \n",
    "#     sorted_index = selecting(network, x_train, y_train)\n",
    "#     ## Add new data for training\n",
    "#     network.addData(x_train[sorted_index[0]], y_train[sorted_index[0]])\n",
    "#     print(\"現在要進去模型的數據，索引%d，y=\"%(sorted_index[0]),y_train[sorted_index[0]].data)\n",
    "#     x_train = np.delete(x_train, sorted_index[0], 0)\n",
    "#     y_train = np.delete(y_train, sorted_index[0], 0)\n",
    "    \n",
    "#     print(\"<<(前)差異>>\")\n",
    "#     yo,loss = network.forward()\n",
    "#     print(torch.abs(network.y-yo))\n",
    "    \n",
    "#     network = matching_for_reorganizing(network)\n",
    "    \n",
    "#     print(\"<<(後)差異>>\")\n",
    "#     yo,loss = network.forward()\n",
    "#     print(torch.abs(network.y-yo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cramming module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramming(network):\n",
    "    \n",
    "    torch.random.manual_seed(0)\n",
    "    print(\"<<Cramming module>>\")\n",
    "\n",
    "    \n",
    "    ## Find unsatisfied data:K\n",
    "    yo, loss = network.forward()\n",
    "    undesired_index = torch.nonzero(torch.abs(yo-network.y) > network.threshold_for_error)\n",
    "\n",
    "    ## Print out the undesired_index for debug\n",
    "    print(\"The index of the undesired data:\",undesired_index)\n",
    "\n",
    "\n",
    "    # Unsatisfied situation\n",
    "    ## Find the index of the unsatisfied data\n",
    "    k_data_num = undesired_index[0][0]\n",
    "\n",
    "    undesired_data = torch.reshape(network.x[k_data_num,:], [1,-1])\n",
    "\n",
    "    ## Remove the data that does not meet the error term\n",
    "    left_data = network.x[:k_data_num,:]\n",
    "    right_data = network.x[k_data_num+1:,:]\n",
    "    remain_tensor = torch.cat([left_data, right_data], 0)\n",
    "\n",
    "        \n",
    "    ## Use the random method to find out the gamma and zeta\n",
    "    while True:\n",
    "\n",
    "        ## Find m-vector gamma: r\n",
    "        ## Use the random method to generate the gamma that can make the conditions met\n",
    "        gamma = torch.rand(size=[1,network.x.shape[1]]).cuda()\n",
    "        subtract_undesired_data = torch.sub(remain_tensor, undesired_data)\n",
    "        matmul_value = torch.mm(gamma,torch.t(subtract_undesired_data))\n",
    "\n",
    "        if torch.all(matmul_value != 0):\n",
    "            break\n",
    "\n",
    "    while True:\n",
    "\n",
    "        ## Find the tiny value: zeta\n",
    "        ## Use the random method to generate the zeta that can make the conditions met\n",
    "        zeta = torch.rand(size=[1]).cuda()\n",
    "        \n",
    "        if torch.all(torch.mul(torch.add(zeta,matmul_value),torch.sub(zeta,matmul_value))<0):\n",
    "            break\n",
    "\n",
    "    for i in range(undesired_index.shape[0]):\n",
    "        \n",
    "        k_l = undesired_index[i][1]\n",
    "#         print(\"The output node:\",k_l)\n",
    "        ## The weight of input layer to hidden layer I\n",
    "        w10 = gamma\n",
    "        w11 = gamma\n",
    "        w12 = gamma\n",
    "        \n",
    "        W1_new = torch.cat([w10,w11,w12],0)\n",
    "#         print(\"W1_new.shape:\",W1_new.shape)\n",
    "        \n",
    "        ## The bias of input layer to hidden layer I\n",
    "        matual_value = torch.mm(gamma,torch.t(undesired_data))\n",
    "\n",
    "        b10 = torch.sub(zeta,matual_value)\n",
    "        b11 = -1*matual_value\n",
    "        b12 = torch.sub(-1*zeta,matual_value)\n",
    "        \n",
    "        \n",
    "        b1_new = torch.reshape(torch.cat([b10,b11,b12],0),[3])\n",
    "       \n",
    "#         print(\"b1_new\",b1_new)\n",
    "    \n",
    "    \n",
    "        ## The weight of hidden layer I to output layer\n",
    "        gap = network.y[k_data_num, k_l]-yo[k_data_num, k_l]\n",
    "#         print(\"gap:\",gap)\n",
    "        \n",
    "        wo0_value = gap/zeta\n",
    "        wo1_value = (-2*gap)/zeta\n",
    "        wo2_value = gap/zeta\n",
    "\n",
    "        index = torch.tensor([[k_l]])\n",
    "    \n",
    "        wo0 = torch.FloatTensor(torch.zeros(1, 4).scatter_(1, index, 1)).cuda() * wo0_value\n",
    "        wo1 = torch.FloatTensor(torch.zeros(1, 4).scatter_(1, index, 1)).cuda() * wo1_value\n",
    "        wo2 = torch.FloatTensor(torch.zeros(1, 4).scatter_(1, index, 1)).cuda() * wo2_value\n",
    "        \n",
    "        \n",
    "#         print(\"Wo0\",wo0_value)\n",
    "#         print(\"Wo1\",wo1_value)\n",
    "#         print(\"Wo2\",wo2_value)\n",
    "            \n",
    "        Wo_new = torch.t(torch.cat([wo0,wo1,wo2],0))\n",
    "        \n",
    "#         print(\"Wo_new.shape\",Wo_new.shape)\n",
    "        \n",
    "        ## Add new neuroes to the network\n",
    "        network.linear1.weight = torch.nn.Parameter(torch.cat([network.linear1.weight.data, W1_new]))\n",
    "        network.linear1.bias = torch.nn.Parameter(torch.cat([network.linear1.bias.data, b1_new]))\n",
    "        network.linear2.weight = torch.nn.Parameter(torch.cat([network.linear2.weight.data, Wo_new],1))\n",
    "#         print(network.state_dict())\n",
    "#         yo, loss = network.forward()\n",
    "\n",
    "#         print(torch.abs(network.y-yo))\n",
    "    \n",
    "    yo, loss = network.forward()\n",
    "    ## Determine if cramming is successful and print out the corresponding information\n",
    "    if torch.all(torch.abs(yo[k_data_num,k_l]-network.y[k_data_num,k_l]) <= network.threshold_for_error):\n",
    "        network.acceptable = True \n",
    "        print(\"Cramming success!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Cramming failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_data, x_test_data, y_train_data, y_test_data = get_data(4)\n",
    "\n",
    "# x_train = torch.FloatTensor(x_train_data)\n",
    "# x_test = torch.FloatTensor(x_test_data)\n",
    "# y_train = torch.FloatTensor(y_train_data)\n",
    "\n",
    "\n",
    "# initial_x = x_train_scaled[:x_train_scaled.shape[1]+1]\n",
    "# initial_y = y_train_scaled[:x_train_scaled.shape[1]+1]\n",
    "\n",
    "# x_train = x_train_scaled[x_train_scaled.shape[1]+1:]\n",
    "# y_train = y_train_scaled[x_train_scaled.shape[1]+1:]\n",
    "\n",
    "# # print(initial_x)\n",
    "# # print(initial_y)\n",
    "\n",
    "# network = Network(4,initial_x,initial_y)\n",
    "# initializing(network, initial_x, initial_y)\n",
    "# sorted_index = selecting(network, x_train, y_train)\n",
    "# network.addData(x_train[sorted_index[0]], y_train[sorted_index[0]])\n",
    "\n",
    "# yo,loss = network.forward()\n",
    "# print(\"<<誤差>>\")\n",
    "# print(torch.abs(yo-network.y))\n",
    "\n",
    "# reorganizing(network)\n",
    "\n",
    "# print(type(network.parameters()))\n",
    "# print(list(network.parameters())[0].device)\n",
    "\n",
    "# print(network.x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularizing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularizing(network):\n",
    "\n",
    "    print(\"<<Regularizing module>>\")\n",
    "    ## Record the number of executions\n",
    "    times_enlarge = 0\n",
    "    times_shrink = 0\n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "\n",
    "    ## Set epoch to 100\n",
    "    for i in range(100):\n",
    "\n",
    "        ## Store the parameter of the network\n",
    "        network_pre = copy.deepcopy(network)\n",
    "        yo, loss = network.forward(1e-3)\n",
    "        loss_pre = loss\n",
    "\n",
    "#         print(\"調整前的network\")\n",
    "#         print(\"<<變數>>\")\n",
    "#         print(network.state_dict())\n",
    "#         print(\"<<Loss值>>\")\n",
    "#         print(loss)\n",
    "#         print(\"差異\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "        \n",
    "        ## Backward operation to obtain w'\n",
    "        network.backward_Adam(loss)\n",
    "        yo, loss = network.forward(1e-3)\n",
    "#         print(\"調整後的network\")\n",
    "#         print(\"<<變數>>\")\n",
    "#         print(network.state_dict())\n",
    "#         print(\"<<Loss值>>\")\n",
    "#         print(loss)\n",
    "#         print(\"差異\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "         # Confirm whether the adjusted loss value is smaller than the current one\n",
    "        if loss <= loss_pre:\n",
    "            \n",
    "            ## Identify that all forecast value has met the error term\n",
    "            if torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "                \n",
    "                ## If true, multiply the learning rate by 1.2\n",
    "                network.learning_rate *= 1.2\n",
    "                times_enlarge += 1\n",
    "#                 print(\"Regularizing %d process - Enlarge\"%i)\n",
    "                print(\"第\\\"%d\\\"回合是成功執行regularizing\"%(i+1))\n",
    "#                 print(\"差異\")\n",
    "#                 print(torch.abs(yo-network.y))\n",
    "\n",
    "            else:\n",
    "\n",
    "                ## Else, restore w and end the process\n",
    "                network = network_pre\n",
    "                print(\"Regularizing結束\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "#                 print(\"Regularizing result: Unable to meet the error term\")\n",
    "                print(\"因為沒有顧好預測誤差\")\n",
    "                return(network)\n",
    "\n",
    "        # If the adjusted loss value is not smaller than the current one\n",
    "        else:\n",
    "\n",
    "            ## If the learning rate is greater than the threshold for learning rate\n",
    "            if network.learning_rate > network.threshold_for_lr:\n",
    "                \n",
    "                ## Restore the w and multiply the learning rate by 0.7\n",
    "                network = network_pre\n",
    "                network.learning_rate *= 0.7\n",
    "                times_shrink += 1\n",
    "#                 print(\"把Learning rate變小\")\n",
    "#                 print(\"Regularizing %d process - Shrink\"%i)\n",
    "             ## If the learning rate is smaller than the threshold for learning rate\n",
    "            else:\n",
    "                \n",
    "                ## Restore the w\n",
    "                network = network_pre\n",
    "                print(\"Regularizing結束\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "#                 print(\"Regularizing result: Less than the epsilon for the learning rate\")\n",
    "                print(\"因為Learning不能這麼小啦\")\n",
    "                return(network)\n",
    "\n",
    "    print(\"第\\\"%d\\\"回合Regularizing module完畢\"%(i+1))\n",
    "    print(\"Number of enlarge:\",times_enlarge)\n",
    "    print(\"Number of shrink:\",times_shrink)\n",
    "#             print(\"Regularizing result: The number of rounds has reached\")\n",
    "    return(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorganizing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganizing(network):\n",
    "    print(\"<<Reorganizing module>>\")\n",
    "    ## Set up the k = 1, and p = the number of hidden node\n",
    "    k = 1\n",
    "#     p = network.W1.shape[1]\n",
    "    p = network.linear1.weight.data.shape[0]\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        ## If k > p, end of Process\n",
    "        if k > p:\n",
    "\n",
    "            print(\"Reorganizing result: The final number of neuro is \",p)\n",
    "            return(network)\n",
    "\n",
    "        ## Else, Process is ongoing\n",
    "        else:\n",
    "\n",
    "            ## Using the regularizing module to adjust the network\n",
    "            network = regularizing(network)\n",
    "            \n",
    "            ## Store the network and w\n",
    "            network_pre = copy.deepcopy(network)\n",
    "\n",
    "            ## Set up the acceptable of the network as false\n",
    "            network.acceptable = False\n",
    "\n",
    "            ## Ignore the K hidden node\n",
    "            network.linear1.weight = torch.nn.Parameter(torch.cat([network.linear1.weight[:k-1],network.linear1.weight[k:]],0))\n",
    "            network.linear1.bias = torch.nn.Parameter(torch.cat([network.linear1.bias[:k-1],network.linear1.bias[k:]]))\n",
    "            network.linear2.weight = torch.nn.Parameter(torch.cat([network.linear2.weight[:,:k-1],network.linear2.weight[:,k:]],1))\n",
    "\n",
    "            ## Using the matching module to adjust the network\n",
    "            network = matching_for_reorganizing(network)\n",
    "            \n",
    "            print(\"是不是可以不要你:\",network.acceptable)\n",
    "            \n",
    "            ## If the resulting network is acceptable, this means that the k hidden node can be removed\n",
    "            if network.acceptable and p!=1:\n",
    "\n",
    "                print(\"Drop out the nero number: %d / %d\" %(k, p))\n",
    "                network.nb_node_pruned += 1\n",
    "                ## p--\n",
    "                p-=1\n",
    "\n",
    "            ## Else, it means that the k hidden node cannot be removed\n",
    "            else:\n",
    "                \n",
    "                ## Restore the network and w\n",
    "                network = network_pre\n",
    "                print(\"Cannot drop out the nero number: %d / %d\" %(k, p))\n",
    "                \n",
    "                ## k++\n",
    "                k+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, nb_neuro, x_train_scaled, y_train_scaled):\n",
    "        \n",
    "        super(Network, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(x_train_scaled.shape[1], nb_neuro).cuda()\n",
    "        self.linear2 = torch.nn.Linear(nb_neuro, y_train_scaled.shape[1]).cuda()\n",
    "        \n",
    "        \n",
    "        # Stop criteria - threshold\n",
    "        self.threshold_for_error = 0.07\n",
    "        self.threshold_for_lr = 1e-4\n",
    "        \n",
    "        # Input data \n",
    "        self.x = torch.FloatTensor(x_train_scaled).cuda()\n",
    "        self.y = torch.FloatTensor(y_train_scaled).cuda()\n",
    "        \n",
    "        # Learning rate\n",
    "        self.learning_rate = 1e-2\n",
    "        \n",
    "        # Whether the network is acceptable, default as False\n",
    "        self.acceptable = False\n",
    "        \n",
    "        # Some record for experiment\n",
    "        self.nb_node_pruned = 0\n",
    "        self.nb_node_acceptable=torch.IntTensor([nb_neuro])\n",
    "        \n",
    "    ## Forecast the test data\n",
    "    def forecast(self, x_test):\n",
    "    \n",
    "        x_test = torch.FloatTensor(x_test).cuda()\n",
    "        activation_value = self.linear1(x_test).clamp(min=0)\n",
    "        forecast_value = self.linear2(activation_value)\n",
    "       \n",
    "        return forecast_value\n",
    "\n",
    "    ## Reset the x and y data\n",
    "    def setData(self, x_train_scaled, y_train_scaled):\n",
    "        self.x = torch.FloatTensor(x_train_scaled).cuda()\n",
    "        self.y = torch.FloatTensor(y_train_scaled).cuda()\n",
    "    \n",
    "    ## Add the new data to the x and y data\n",
    "    def addData(self, new_x_train, new_y_train):\n",
    "\n",
    "        self.x = torch.cat([self.x, new_x_train.reshape(1,-1).cuda()],0)\n",
    "        self.y = torch.cat([self.y, new_y_train.reshape(1,-1).cuda()],0)\n",
    "    \n",
    "    ## forward operation\n",
    "    def forward(self, reg_strength=0):\n",
    "       \n",
    "        y1 = self.linear1(self.x).clamp(min=0)\n",
    "        yo = self.linear2(y1)\n",
    "\n",
    "        # performance measure\n",
    "        param_val= torch.sum(torch.pow(self.linear2.bias.data,2))+torch.sum(torch.pow(self.linear2.weight.data,2))+torch.sum(torch.pow(self.linear1.bias.data,2))+torch.sum(torch.pow(self.linear1.weight.data,2))\n",
    "        reg_term= reg_strength/((self.linear2.bias.data.shape[0]*(self.linear2.weight.data.shape[1]+1)) +(self.linear1.bias.data.shape[0]*(self.linear1.weight.data.shape[1]+1)))*param_val\n",
    "        loss = torch.nn.functional.mse_loss(yo,self.y)+reg_term\n",
    "        loss = loss.cuda()\n",
    "        return(yo, loss)\n",
    "\n",
    "    # backward operation\n",
    "    def backward_Adam(self,loss):    \n",
    "\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The <<91>> Block\n",
      "Initializing module\n",
      "<<Initializing後看一下差異>>\n",
      "tensor([[    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 20\n",
      "X 資料 torch.Size([87, 18])\n",
      "Y 資料 torch.Size([87, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.03448425978422165, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.8397, 0.8232, 0.8489, 0.7474])\n",
      "目前模型的Data torch.Size([20, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.8479, 0.7929, 0.8148, 0.7288],\n",
      "        [0.7929, 0.8148, 0.7787, 0.7667],\n",
      "        [0.8148, 0.7787, 0.8192, 0.7525],\n",
      "        [0.7787, 0.8192, 0.8041, 0.7692],\n",
      "        [0.8192, 0.8041, 0.8220, 0.7407],\n",
      "        [0.8041, 0.8220, 0.7915, 0.6961],\n",
      "        [0.8220, 0.7915, 0.7438, 0.6677],\n",
      "        [0.7915, 0.7438, 0.7135, 0.6333],\n",
      "        [0.7438, 0.7135, 0.6767, 0.6163],\n",
      "        [0.7135, 0.6767, 0.6585, 0.6104],\n",
      "        [0.6767, 0.6585, 0.6522, 0.6143],\n",
      "        [0.6585, 0.6522, 0.6564, 0.6294],\n",
      "        [0.6522, 0.6564, 0.6725, 0.6487],\n",
      "        [0.6564, 0.6725, 0.6931, 0.6572],\n",
      "        [0.6725, 0.6931, 0.7023, 0.7300],\n",
      "        [0.6931, 0.7023, 0.7800, 0.7813],\n",
      "        [0.7023, 0.7800, 0.8348, 0.7858],\n",
      "        [0.7800, 0.8348, 0.8397, 0.7704],\n",
      "        [0.8348, 0.8397, 0.8232, 0.7944],\n",
      "        [0.9715, 1.1599, 0.9185, 0.7963]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.1318,     0.3366,     0.0696,     0.0489]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 125\n",
      "Number of shrink: 67\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0082,     0.0287,     0.0021,     0.0001],\n",
      "        [    0.0048,     0.0238,     0.0021,     0.0005],\n",
      "        [    0.0046,     0.0163,     0.0015,     0.0003],\n",
      "        [    0.0064,     0.0183,     0.0039,     0.0020],\n",
      "        [    0.0078,     0.0141,     0.0047,     0.0026],\n",
      "        [    0.0067,     0.0052,     0.0060,     0.0039],\n",
      "        [    0.0062,     0.0077,     0.0038,     0.0019],\n",
      "        [    0.0014,     0.0070,     0.0001,     0.0011],\n",
      "        [    0.0063,     0.0089,     0.0032,     0.0036],\n",
      "        [    0.0114,     0.0200,     0.0058,     0.0056],\n",
      "        [    0.0117,     0.0018,     0.0082,     0.0079],\n",
      "        [    0.0135,     0.0112,     0.0080,     0.0076],\n",
      "        [    0.0129,     0.0131,     0.0070,     0.0068],\n",
      "        [    0.0096,     0.0096,     0.0050,     0.0051],\n",
      "        [    0.0044,     0.0021,     0.0030,     0.0036],\n",
      "        [    0.0021,     0.0266,     0.0023,     0.0034],\n",
      "        [    0.0107,     0.0450,     0.0029,     0.0009],\n",
      "        [    0.0189,     0.0550,     0.0077,     0.0046],\n",
      "        [    0.0257,     0.0783,     0.0083,     0.0048],\n",
      "        [    0.0716,     0.2133,     0.0377,     0.0247]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 3\n",
      "因為沒有顧好預測誤差\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Drop out the nero number: 1 / 4\n",
      "<<Regularizing module>>\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "因為沒有顧好預測誤差\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Drop out the nero number: 1 / 3\n",
      "<<Regularizing module>>\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Drop out the nero number: 1 / 2\n",
      "<<Regularizing module>>\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 66\n",
      "Number of shrink: 34\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0853, 0.0313, 0.0543, 0.0143],\n",
      "        [0.0224, 0.0456, 0.0138, 0.0118],\n",
      "        [0.0474, 0.0125, 0.0560, 0.0121],\n",
      "        [0.0083, 0.0500, 0.0391, 0.0093],\n",
      "        [0.0555, 0.0414, 0.0608, 0.0077],\n",
      "        [0.0508, 0.0694, 0.0362, 0.0055],\n",
      "        [0.0748, 0.0449, 0.0079, 0.0062],\n",
      "        [0.0523, 0.0050, 0.0338, 0.0049],\n",
      "        [0.0091, 0.0211, 0.0681, 0.0023],\n",
      "        [0.0199, 0.0565, 0.0854, 0.0018],\n",
      "        [0.0573, 0.0754, 0.0921, 0.0009],\n",
      "        [0.0784, 0.0845, 0.0896, 0.0010],\n",
      "        [0.0890, 0.0845, 0.0759, 0.0014],\n",
      "        [0.0864, 0.0698, 0.0561, 0.0029],\n",
      "        [0.0860, 0.0646, 0.0559, 0.0047],\n",
      "        [0.0772, 0.0668, 0.0151, 0.0034],\n",
      "        [0.0696, 0.0094, 0.0691, 0.0011],\n",
      "        [0.0113, 0.0673, 0.0757, 0.0002],\n",
      "        [0.0604, 0.0667, 0.0561, 0.0017],\n",
      "        [0.0641, 0.0490, 0.0810, 0.0542]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.7313473224639893\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 21\n",
      "X 資料 torch.Size([86, 18])\n",
      "Y 資料 torch.Size([86, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0010256152600049973, 40)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引40，y= tensor([0.7660, 0.7803, 0.7764, 0.7036])\n",
      "目前模型的Data torch.Size([21, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7626, 0.7616, 0.7605, 0.7431],\n",
      "        [0.7705, 0.7692, 0.7649, 0.7784],\n",
      "        [0.7674, 0.7662, 0.7632, 0.7646],\n",
      "        [0.7705, 0.7692, 0.7650, 0.7785],\n",
      "        [0.7637, 0.7627, 0.7612, 0.7484],\n",
      "        [0.7533, 0.7526, 0.7552, 0.7015],\n",
      "        [0.7471, 0.7466, 0.7518, 0.6739],\n",
      "        [0.7391, 0.7388, 0.7472, 0.6382],\n",
      "        [0.7348, 0.7346, 0.7448, 0.6186],\n",
      "        [0.7333, 0.7332, 0.7440, 0.6122],\n",
      "        [0.7340, 0.7339, 0.7443, 0.6152],\n",
      "        [0.7369, 0.7367, 0.7460, 0.6284],\n",
      "        [0.7412, 0.7408, 0.7484, 0.6473],\n",
      "        [0.7427, 0.7423, 0.7493, 0.6543],\n",
      "        [0.7586, 0.7577, 0.7582, 0.7253],\n",
      "        [0.7703, 0.7691, 0.7649, 0.7779],\n",
      "        [0.7719, 0.7706, 0.7657, 0.7847],\n",
      "        [0.7687, 0.7675, 0.7640, 0.7707],\n",
      "        [0.7744, 0.7730, 0.7672, 0.7961],\n",
      "        [0.7756, 0.7742, 0.7679, 0.8016],\n",
      "        [0.7674, 0.7662, 0.7632, 0.7647]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0853, 0.0313, 0.0543, 0.0143],\n",
      "        [0.0224, 0.0456, 0.0138, 0.0118],\n",
      "        [0.0474, 0.0125, 0.0560, 0.0121],\n",
      "        [0.0083, 0.0500, 0.0391, 0.0093],\n",
      "        [0.0555, 0.0414, 0.0608, 0.0077],\n",
      "        [0.0508, 0.0694, 0.0362, 0.0055],\n",
      "        [0.0748, 0.0449, 0.0079, 0.0062],\n",
      "        [0.0523, 0.0050, 0.0338, 0.0049],\n",
      "        [0.0091, 0.0211, 0.0681, 0.0023],\n",
      "        [0.0199, 0.0565, 0.0854, 0.0018],\n",
      "        [0.0573, 0.0754, 0.0921, 0.0009],\n",
      "        [0.0784, 0.0845, 0.0896, 0.0010],\n",
      "        [0.0890, 0.0845, 0.0759, 0.0014],\n",
      "        [0.0864, 0.0698, 0.0561, 0.0029],\n",
      "        [0.0860, 0.0646, 0.0559, 0.0047],\n",
      "        [0.0772, 0.0668, 0.0151, 0.0034],\n",
      "        [0.0696, 0.0094, 0.0691, 0.0011],\n",
      "        [0.0113, 0.0673, 0.0757, 0.0002],\n",
      "        [0.0604, 0.0667, 0.0561, 0.0017],\n",
      "        [0.0641, 0.0490, 0.0810, 0.0542],\n",
      "        [0.0014, 0.0141, 0.0132, 0.0611]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0824,     0.0285,     0.0514,     0.0156],\n",
      "        [    0.0186,     0.0418,     0.0098,     0.0098],\n",
      "        [    0.0449,     0.0101,     0.0531,     0.0080],\n",
      "        [    0.0054,     0.0472,     0.0357,     0.0037],\n",
      "        [    0.0548,     0.0407,     0.0593,     0.0001],\n",
      "        [    0.0530,     0.0716,     0.0372,     0.0040],\n",
      "        [    0.0776,     0.0477,     0.0062,     0.0001],\n",
      "        [    0.0570,     0.0096,     0.0303,     0.0013],\n",
      "        [    0.0144,     0.0157,     0.0638,     0.0029],\n",
      "        [    0.0146,     0.0512,     0.0812,     0.0017],\n",
      "        [    0.0515,     0.0695,     0.0876,     0.0051],\n",
      "        [    0.0726,     0.0786,     0.0852,     0.0098],\n",
      "        [    0.0833,     0.0788,     0.0719,     0.0130],\n",
      "        [    0.0804,     0.0639,     0.0521,     0.0170],\n",
      "        [    0.0829,     0.0615,     0.0547,     0.0219],\n",
      "        [    0.0775,     0.0671,     0.0134,     0.0180],\n",
      "        [    0.0710,     0.0080,     0.0665,     0.0130],\n",
      "        [    0.0103,     0.0664,     0.0737,     0.0106],\n",
      "        [    0.0578,     0.0640,     0.0525,     0.0078],\n",
      "        [    0.0599,     0.0449,     0.0764,     0.0492],\n",
      "        [    0.0033,     0.0187,     0.0148,     0.0306]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.2592225074768066\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 22\n",
      "X 資料 torch.Size([85, 18])\n",
      "Y 資料 torch.Size([85, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.001385867828503251, 6)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引6，y= tensor([0.7822, 0.7445, 0.6986, 0.6342])\n",
      "目前模型的Data torch.Size([22, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7655, 0.7644, 0.7634, 0.7444],\n",
      "        [0.7743, 0.7730, 0.7689, 0.7765],\n",
      "        [0.7699, 0.7687, 0.7661, 0.7604],\n",
      "        [0.7733, 0.7720, 0.7683, 0.7729],\n",
      "        [0.7644, 0.7633, 0.7627, 0.7406],\n",
      "        [0.7510, 0.7503, 0.7542, 0.6921],\n",
      "        [0.7443, 0.7438, 0.7500, 0.6677],\n",
      "        [0.7345, 0.7342, 0.7438, 0.6320],\n",
      "        [0.7294, 0.7292, 0.7405, 0.6134],\n",
      "        [0.7281, 0.7279, 0.7397, 0.6087],\n",
      "        [0.7282, 0.7280, 0.7398, 0.6091],\n",
      "        [0.7311, 0.7308, 0.7416, 0.6195],\n",
      "        [0.7355, 0.7352, 0.7444, 0.6357],\n",
      "        [0.7368, 0.7364, 0.7452, 0.6403],\n",
      "        [0.7555, 0.7546, 0.7570, 0.7081],\n",
      "        [0.7707, 0.7694, 0.7666, 0.7633],\n",
      "        [0.7733, 0.7720, 0.7683, 0.7729],\n",
      "        [0.7697, 0.7685, 0.7660, 0.7598],\n",
      "        [0.7771, 0.7757, 0.7707, 0.7866],\n",
      "        [0.7798, 0.7784, 0.7724, 0.7966],\n",
      "        [0.7627, 0.7616, 0.7616, 0.7342],\n",
      "        [0.7281, 0.7279, 0.7397, 0.6087]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0824,     0.0285,     0.0514,     0.0156],\n",
      "        [    0.0186,     0.0418,     0.0098,     0.0098],\n",
      "        [    0.0449,     0.0101,     0.0531,     0.0080],\n",
      "        [    0.0054,     0.0472,     0.0357,     0.0037],\n",
      "        [    0.0548,     0.0407,     0.0593,     0.0001],\n",
      "        [    0.0530,     0.0716,     0.0372,     0.0040],\n",
      "        [    0.0776,     0.0477,     0.0062,     0.0001],\n",
      "        [    0.0570,     0.0096,     0.0303,     0.0013],\n",
      "        [    0.0144,     0.0157,     0.0638,     0.0029],\n",
      "        [    0.0146,     0.0512,     0.0812,     0.0017],\n",
      "        [    0.0515,     0.0695,     0.0876,     0.0051],\n",
      "        [    0.0726,     0.0786,     0.0852,     0.0098],\n",
      "        [    0.0833,     0.0788,     0.0719,     0.0130],\n",
      "        [    0.0804,     0.0639,     0.0521,     0.0170],\n",
      "        [    0.0829,     0.0615,     0.0547,     0.0219],\n",
      "        [    0.0775,     0.0671,     0.0134,     0.0180],\n",
      "        [    0.0710,     0.0080,     0.0665,     0.0130],\n",
      "        [    0.0103,     0.0664,     0.0737,     0.0106],\n",
      "        [    0.0578,     0.0640,     0.0525,     0.0078],\n",
      "        [    0.0599,     0.0449,     0.0764,     0.0492],\n",
      "        [    0.0033,     0.0187,     0.0148,     0.0306],\n",
      "        [    0.0541,     0.0166,     0.0411,     0.0255]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0716,     0.0197,     0.0468,     0.0293],\n",
      "        [    0.0069,     0.0320,     0.0040,     0.0202],\n",
      "        [    0.0345,     0.0015,     0.0485,     0.0175],\n",
      "        [    0.0052,     0.0385,     0.0308,     0.0114],\n",
      "        [    0.0469,     0.0346,     0.0566,     0.0060],\n",
      "        [    0.0489,     0.0693,     0.0379,     0.0000],\n",
      "        [    0.0743,     0.0461,     0.0046,     0.0065],\n",
      "        [    0.0562,     0.0106,     0.0264,     0.0044],\n",
      "        [    0.0147,     0.0137,     0.0589,     0.0033],\n",
      "        [    0.0129,     0.0478,     0.0752,     0.0011],\n",
      "        [    0.0507,     0.0670,     0.0823,     0.0004],\n",
      "        [    0.0716,     0.0759,     0.0799,     0.0070],\n",
      "        [    0.0826,     0.0764,     0.0670,     0.0123],\n",
      "        [    0.0793,     0.0611,     0.0470,     0.0183],\n",
      "        [    0.0851,     0.0619,     0.0529,     0.0265],\n",
      "        [    0.0839,     0.0718,     0.0114,     0.0207],\n",
      "        [    0.0789,     0.0019,     0.0634,     0.0130],\n",
      "        [    0.0028,     0.0606,     0.0710,     0.0093],\n",
      "        [    0.0477,     0.0558,     0.0477,     0.0043],\n",
      "        [    0.0475,     0.0344,     0.0699,     0.0577],\n",
      "        [    0.0020,     0.0151,     0.0140,     0.0304],\n",
      "        [    0.0564,     0.0206,     0.0347,     0.0245]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.7860679626464844\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 23\n",
      "X 資料 torch.Size([84, 18])\n",
      "Y 資料 torch.Size([84, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0014152918010950089, 3)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引3，y= tensor([0.7931, 0.7916, 0.8055, 0.7320])\n",
      "目前模型的Data torch.Size([23, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7762, 0.7732, 0.7680, 0.7581],\n",
      "        [0.7860, 0.7828, 0.7747, 0.7869],\n",
      "        [0.7803, 0.7772, 0.7708, 0.7699],\n",
      "        [0.7839, 0.7807, 0.7733, 0.7807],\n",
      "        [0.7723, 0.7694, 0.7653, 0.7467],\n",
      "        [0.7551, 0.7526, 0.7535, 0.6961],\n",
      "        [0.7477, 0.7453, 0.7484, 0.6742],\n",
      "        [0.7353, 0.7332, 0.7399, 0.6377],\n",
      "        [0.7291, 0.7272, 0.7356, 0.6196],\n",
      "        [0.7264, 0.7245, 0.7337, 0.6115],\n",
      "        [0.7274, 0.7255, 0.7345, 0.6147],\n",
      "        [0.7301, 0.7281, 0.7363, 0.6224],\n",
      "        [0.7348, 0.7327, 0.7395, 0.6364],\n",
      "        [0.7357, 0.7336, 0.7402, 0.6390],\n",
      "        [0.7576, 0.7551, 0.7552, 0.7035],\n",
      "        [0.7770, 0.7741, 0.7686, 0.7605],\n",
      "        [0.7812, 0.7782, 0.7715, 0.7729],\n",
      "        [0.7773, 0.7743, 0.7687, 0.7612],\n",
      "        [0.7871, 0.7839, 0.7755, 0.7901],\n",
      "        [0.7922, 0.7889, 0.7790, 0.8051],\n",
      "        [0.7680, 0.7652, 0.7624, 0.7340],\n",
      "        [0.7258, 0.7239, 0.7333, 0.6097],\n",
      "        [0.7584, 0.7558, 0.7557, 0.7056]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0716,     0.0197,     0.0468,     0.0293],\n",
      "        [    0.0069,     0.0320,     0.0040,     0.0202],\n",
      "        [    0.0345,     0.0015,     0.0485,     0.0175],\n",
      "        [    0.0052,     0.0385,     0.0308,     0.0114],\n",
      "        [    0.0469,     0.0346,     0.0566,     0.0060],\n",
      "        [    0.0489,     0.0693,     0.0379,     0.0000],\n",
      "        [    0.0743,     0.0461,     0.0046,     0.0065],\n",
      "        [    0.0562,     0.0106,     0.0264,     0.0044],\n",
      "        [    0.0147,     0.0137,     0.0589,     0.0033],\n",
      "        [    0.0129,     0.0478,     0.0752,     0.0011],\n",
      "        [    0.0507,     0.0670,     0.0823,     0.0004],\n",
      "        [    0.0716,     0.0759,     0.0799,     0.0070],\n",
      "        [    0.0826,     0.0764,     0.0670,     0.0123],\n",
      "        [    0.0793,     0.0611,     0.0470,     0.0183],\n",
      "        [    0.0851,     0.0619,     0.0529,     0.0265],\n",
      "        [    0.0839,     0.0718,     0.0114,     0.0207],\n",
      "        [    0.0789,     0.0019,     0.0634,     0.0130],\n",
      "        [    0.0028,     0.0606,     0.0710,     0.0093],\n",
      "        [    0.0477,     0.0558,     0.0477,     0.0043],\n",
      "        [    0.0475,     0.0344,     0.0699,     0.0577],\n",
      "        [    0.0020,     0.0151,     0.0140,     0.0304],\n",
      "        [    0.0564,     0.0206,     0.0347,     0.0245],\n",
      "        [    0.0347,     0.0358,     0.0498,     0.0264]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0663, 0.0140, 0.0405, 0.0318],\n",
      "        [0.0009, 0.0256, 0.0032, 0.0195],\n",
      "        [0.0305, 0.0030, 0.0429, 0.0150],\n",
      "        [0.0093, 0.0339, 0.0250, 0.0073],\n",
      "        [0.0457, 0.0330, 0.0535, 0.0003],\n",
      "        [0.0522, 0.0721, 0.0388, 0.0077],\n",
      "        [0.0781, 0.0495, 0.0030, 0.0011],\n",
      "        [0.0632, 0.0171, 0.0220, 0.0024],\n",
      "        [0.0228, 0.0061, 0.0536, 0.0030],\n",
      "        [0.0063, 0.0416, 0.0708, 0.0003],\n",
      "        [0.0430, 0.0598, 0.0771, 0.0042],\n",
      "        [0.0634, 0.0683, 0.0745, 0.0139],\n",
      "        [0.0748, 0.0691, 0.0620, 0.0209],\n",
      "        [0.0711, 0.0534, 0.0418, 0.0282],\n",
      "        [0.0804, 0.0577, 0.0511, 0.0391],\n",
      "        [0.0844, 0.0728, 0.0086, 0.0303],\n",
      "        [0.0819, 0.0015, 0.0586, 0.0188],\n",
      "        [0.0004, 0.0577, 0.0668, 0.0144],\n",
      "        [0.0421, 0.0498, 0.0408, 0.0065],\n",
      "        [0.0391, 0.0256, 0.0607, 0.0596],\n",
      "        [0.0011, 0.0155, 0.0126, 0.0219],\n",
      "        [0.0624, 0.0262, 0.0307, 0.0241],\n",
      "        [0.0299, 0.0307, 0.0446, 0.0161]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.324050188064575\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 24\n",
      "X 資料 torch.Size([83, 18])\n",
      "Y 資料 torch.Size([83, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.001983913127332926, 40)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引40，y= tensor([0.7518, 0.7644, 0.7162, 0.5422])\n",
      "目前模型的Data torch.Size([24, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7815, 0.7789, 0.7743, 0.7606],\n",
      "        [0.7920, 0.7892, 0.7819, 0.7861],\n",
      "        [0.7843, 0.7817, 0.7763, 0.7674],\n",
      "        [0.7881, 0.7854, 0.7790, 0.7765],\n",
      "        [0.7735, 0.7711, 0.7684, 0.7410],\n",
      "        [0.7519, 0.7498, 0.7527, 0.6883],\n",
      "        [0.7438, 0.7420, 0.7468, 0.6688],\n",
      "        [0.7283, 0.7267, 0.7355, 0.6309],\n",
      "        [0.7210, 0.7196, 0.7303, 0.6133],\n",
      "        [0.7197, 0.7183, 0.7293, 0.6101],\n",
      "        [0.7197, 0.7183, 0.7293, 0.6101],\n",
      "        [0.7219, 0.7205, 0.7309, 0.6155],\n",
      "        [0.7270, 0.7254, 0.7346, 0.6278],\n",
      "        [0.7275, 0.7259, 0.7350, 0.6290],\n",
      "        [0.7529, 0.7509, 0.7534, 0.6909],\n",
      "        [0.7776, 0.7751, 0.7714, 0.7509],\n",
      "        [0.7842, 0.7815, 0.7762, 0.7670],\n",
      "        [0.7796, 0.7771, 0.7729, 0.7560],\n",
      "        [0.7927, 0.7899, 0.7824, 0.7879],\n",
      "        [0.8006, 0.7976, 0.7881, 0.8070],\n",
      "        [0.7671, 0.7648, 0.7638, 0.7255],\n",
      "        [0.7197, 0.7183, 0.7293, 0.6101],\n",
      "        [0.7632, 0.7609, 0.7609, 0.7159],\n",
      "        [0.7197, 0.7183, 0.7293, 0.6101]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0663, 0.0140, 0.0405, 0.0318],\n",
      "        [0.0009, 0.0256, 0.0032, 0.0195],\n",
      "        [0.0305, 0.0030, 0.0429, 0.0150],\n",
      "        [0.0093, 0.0339, 0.0250, 0.0073],\n",
      "        [0.0457, 0.0330, 0.0535, 0.0003],\n",
      "        [0.0522, 0.0721, 0.0388, 0.0077],\n",
      "        [0.0781, 0.0495, 0.0030, 0.0011],\n",
      "        [0.0632, 0.0171, 0.0220, 0.0024],\n",
      "        [0.0228, 0.0061, 0.0536, 0.0030],\n",
      "        [0.0063, 0.0416, 0.0708, 0.0003],\n",
      "        [0.0430, 0.0598, 0.0771, 0.0042],\n",
      "        [0.0634, 0.0683, 0.0745, 0.0139],\n",
      "        [0.0748, 0.0691, 0.0620, 0.0209],\n",
      "        [0.0711, 0.0534, 0.0418, 0.0282],\n",
      "        [0.0804, 0.0577, 0.0511, 0.0391],\n",
      "        [0.0844, 0.0728, 0.0086, 0.0303],\n",
      "        [0.0819, 0.0015, 0.0586, 0.0188],\n",
      "        [0.0004, 0.0577, 0.0668, 0.0144],\n",
      "        [0.0421, 0.0498, 0.0408, 0.0065],\n",
      "        [0.0391, 0.0256, 0.0607, 0.0596],\n",
      "        [0.0011, 0.0155, 0.0126, 0.0219],\n",
      "        [0.0624, 0.0262, 0.0307, 0.0241],\n",
      "        [0.0299, 0.0307, 0.0446, 0.0161],\n",
      "        [0.0321, 0.0461, 0.0131, 0.0679]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 66\n",
      "Number of shrink: 34\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0580, 0.0042, 0.0348, 0.0374],\n",
      "        [0.0075, 0.0155, 0.0094, 0.0220],\n",
      "        [0.0237, 0.0112, 0.0382, 0.0163],\n",
      "        [0.0158, 0.0259, 0.0204, 0.0069],\n",
      "        [0.0418, 0.0279, 0.0515, 0.0012],\n",
      "        [0.0521, 0.0713, 0.0406, 0.0110],\n",
      "        [0.0780, 0.0489, 0.0008, 0.0002],\n",
      "        [0.0656, 0.0194, 0.0173, 0.0040],\n",
      "        [0.0262, 0.0027, 0.0477, 0.0045],\n",
      "        [0.0024, 0.0378, 0.0645, 0.0024],\n",
      "        [0.0392, 0.0559, 0.0708, 0.0063],\n",
      "        [0.0591, 0.0640, 0.0680, 0.0177],\n",
      "        [0.0704, 0.0649, 0.0557, 0.0262],\n",
      "        [0.0662, 0.0486, 0.0351, 0.0350],\n",
      "        [0.0778, 0.0558, 0.0473, 0.0484],\n",
      "        [0.0860, 0.0756, 0.0083, 0.0382],\n",
      "        [0.0855, 0.0065, 0.0564, 0.0243],\n",
      "        [0.0030, 0.0531, 0.0650, 0.0190],\n",
      "        [0.0363, 0.0424, 0.0366, 0.0099],\n",
      "        [0.0305, 0.0152, 0.0540, 0.0600],\n",
      "        [0.0028, 0.0128, 0.0126, 0.0175],\n",
      "        [0.0663, 0.0301, 0.0245, 0.0262],\n",
      "        [0.0236, 0.0234, 0.0412, 0.0094],\n",
      "        [0.0360, 0.0500, 0.0069, 0.0658]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.8521714210510254\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 25\n",
      "X 資料 torch.Size([82, 18])\n",
      "Y 資料 torch.Size([82, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0026611611247062683, 39)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引39，y= tensor([0.7764, 0.7518, 0.7644, 0.6702])\n",
      "目前模型的Data torch.Size([25, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7899, 0.7887, 0.7800, 0.7661],\n",
      "        [0.8004, 0.7993, 0.7882, 0.7887],\n",
      "        [0.7911, 0.7899, 0.7810, 0.7687],\n",
      "        [0.7946, 0.7934, 0.7836, 0.7761],\n",
      "        [0.7774, 0.7762, 0.7704, 0.7395],\n",
      "        [0.7520, 0.7507, 0.7508, 0.6851],\n",
      "        [0.7439, 0.7426, 0.7446, 0.6679],\n",
      "        [0.7258, 0.7244, 0.7307, 0.6293],\n",
      "        [0.7176, 0.7162, 0.7244, 0.6117],\n",
      "        [0.7159, 0.7144, 0.7230, 0.6080],\n",
      "        [0.7159, 0.7144, 0.7230, 0.6080],\n",
      "        [0.7176, 0.7162, 0.7244, 0.6117],\n",
      "        [0.7226, 0.7212, 0.7283, 0.6225],\n",
      "        [0.7226, 0.7211, 0.7282, 0.6223],\n",
      "        [0.7503, 0.7490, 0.7496, 0.6816],\n",
      "        [0.7791, 0.7779, 0.7717, 0.7431],\n",
      "        [0.7878, 0.7865, 0.7784, 0.7616],\n",
      "        [0.7830, 0.7818, 0.7747, 0.7514],\n",
      "        [0.7985, 0.7973, 0.7867, 0.7845],\n",
      "        [0.8092, 0.8080, 0.7949, 0.8074],\n",
      "        [0.7688, 0.7675, 0.7638, 0.7211],\n",
      "        [0.7159, 0.7144, 0.7230, 0.6080],\n",
      "        [0.7695, 0.7682, 0.7643, 0.7225],\n",
      "        [0.7159, 0.7144, 0.7230, 0.6080],\n",
      "        [0.7159, 0.7144, 0.7230, 0.6080]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0580, 0.0042, 0.0348, 0.0374],\n",
      "        [0.0075, 0.0155, 0.0094, 0.0220],\n",
      "        [0.0237, 0.0112, 0.0382, 0.0163],\n",
      "        [0.0158, 0.0259, 0.0204, 0.0069],\n",
      "        [0.0418, 0.0279, 0.0515, 0.0012],\n",
      "        [0.0521, 0.0713, 0.0406, 0.0110],\n",
      "        [0.0780, 0.0489, 0.0008, 0.0002],\n",
      "        [0.0656, 0.0194, 0.0173, 0.0040],\n",
      "        [0.0262, 0.0027, 0.0477, 0.0045],\n",
      "        [0.0024, 0.0378, 0.0645, 0.0024],\n",
      "        [0.0392, 0.0559, 0.0708, 0.0063],\n",
      "        [0.0591, 0.0640, 0.0680, 0.0177],\n",
      "        [0.0704, 0.0649, 0.0557, 0.0262],\n",
      "        [0.0662, 0.0486, 0.0351, 0.0350],\n",
      "        [0.0778, 0.0558, 0.0473, 0.0484],\n",
      "        [0.0860, 0.0756, 0.0083, 0.0382],\n",
      "        [0.0855, 0.0065, 0.0564, 0.0243],\n",
      "        [0.0030, 0.0531, 0.0650, 0.0190],\n",
      "        [0.0363, 0.0424, 0.0366, 0.0099],\n",
      "        [0.0305, 0.0152, 0.0540, 0.0600],\n",
      "        [0.0028, 0.0128, 0.0126, 0.0175],\n",
      "        [0.0663, 0.0301, 0.0245, 0.0262],\n",
      "        [0.0236, 0.0234, 0.0412, 0.0094],\n",
      "        [0.0360, 0.0500, 0.0069, 0.0658],\n",
      "        [0.0605, 0.0374, 0.0414, 0.0622]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0512, 0.0051, 0.0263, 0.0454],\n",
      "        [0.0141, 0.0057, 0.0185, 0.0286],\n",
      "        [0.0177, 0.0197, 0.0304, 0.0225],\n",
      "        [0.0214, 0.0176, 0.0127, 0.0119],\n",
      "        [0.0370, 0.0217, 0.0457, 0.0037],\n",
      "        [0.0485, 0.0684, 0.0378, 0.0065],\n",
      "        [0.0741, 0.0462, 0.0033, 0.0060],\n",
      "        [0.0624, 0.0188, 0.0177, 0.0018],\n",
      "        [0.0234, 0.0021, 0.0472, 0.0010],\n",
      "        [0.0044, 0.0362, 0.0632, 0.0017],\n",
      "        [0.0419, 0.0552, 0.0701, 0.0007],\n",
      "        [0.0612, 0.0627, 0.0670, 0.0134],\n",
      "        [0.0724, 0.0638, 0.0549, 0.0227],\n",
      "        [0.0678, 0.0472, 0.0339, 0.0322],\n",
      "        [0.0795, 0.0566, 0.0483, 0.0477],\n",
      "        [0.0889, 0.0798, 0.0040, 0.0373],\n",
      "        [0.0895, 0.0127, 0.0505, 0.0218],\n",
      "        [0.0072, 0.0470, 0.0592, 0.0157],\n",
      "        [0.0309, 0.0339, 0.0286, 0.0053],\n",
      "        [0.0238, 0.0044, 0.0440, 0.0664],\n",
      "        [0.0082, 0.0066, 0.0069, 0.0244],\n",
      "        [0.0611, 0.0282, 0.0259, 0.0155],\n",
      "        [0.0160, 0.0147, 0.0336, 0.0020],\n",
      "        [0.0340, 0.0516, 0.0055, 0.0699],\n",
      "        [0.0585, 0.0390, 0.0427, 0.0582]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.379886865615845\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 26\n",
      "X 資料 torch.Size([81, 18])\n",
      "Y 資料 torch.Size([81, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0022915476001799107, 3)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引3，y= tensor([0.7916, 0.8055, 0.7822, 0.6968])\n",
      "目前模型的Data torch.Size([26, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7967, 0.7980, 0.7885, 0.7741],\n",
      "        [0.8070, 0.8091, 0.7972, 0.7953],\n",
      "        [0.7971, 0.7984, 0.7888, 0.7750],\n",
      "        [0.8001, 0.8017, 0.7914, 0.7812],\n",
      "        [0.7822, 0.7823, 0.7762, 0.7444],\n",
      "        [0.7555, 0.7536, 0.7537, 0.6896],\n",
      "        [0.7478, 0.7453, 0.7471, 0.6737],\n",
      "        [0.7290, 0.7250, 0.7312, 0.6351],\n",
      "        [0.7204, 0.7156, 0.7239, 0.6173],\n",
      "        [0.7178, 0.7129, 0.7217, 0.6121],\n",
      "        [0.7186, 0.7137, 0.7223, 0.6136],\n",
      "        [0.7198, 0.7149, 0.7233, 0.6160],\n",
      "        [0.7246, 0.7202, 0.7274, 0.6259],\n",
      "        [0.7242, 0.7197, 0.7271, 0.6251],\n",
      "        [0.7520, 0.7497, 0.7506, 0.6823],\n",
      "        [0.7820, 0.7821, 0.7761, 0.7440],\n",
      "        [0.7918, 0.7927, 0.7843, 0.7641],\n",
      "        [0.7872, 0.7878, 0.7805, 0.7547],\n",
      "        [0.8039, 0.8058, 0.7946, 0.7891],\n",
      "        [0.8159, 0.8188, 0.8048, 0.8138],\n",
      "        [0.7742, 0.7737, 0.7695, 0.7280],\n",
      "        [0.7211, 0.7164, 0.7245, 0.6187],\n",
      "        [0.7771, 0.7769, 0.7719, 0.7340],\n",
      "        [0.7178, 0.7129, 0.7217, 0.6121],\n",
      "        [0.7178, 0.7129, 0.7217, 0.6121],\n",
      "        [0.7432, 0.7403, 0.7432, 0.6643]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0512, 0.0051, 0.0263, 0.0454],\n",
      "        [0.0141, 0.0057, 0.0185, 0.0286],\n",
      "        [0.0177, 0.0197, 0.0304, 0.0225],\n",
      "        [0.0214, 0.0176, 0.0127, 0.0119],\n",
      "        [0.0370, 0.0217, 0.0457, 0.0037],\n",
      "        [0.0485, 0.0684, 0.0378, 0.0065],\n",
      "        [0.0741, 0.0462, 0.0033, 0.0060],\n",
      "        [0.0624, 0.0188, 0.0177, 0.0018],\n",
      "        [0.0234, 0.0021, 0.0472, 0.0010],\n",
      "        [0.0044, 0.0362, 0.0632, 0.0017],\n",
      "        [0.0419, 0.0552, 0.0701, 0.0007],\n",
      "        [0.0612, 0.0627, 0.0670, 0.0134],\n",
      "        [0.0724, 0.0638, 0.0549, 0.0227],\n",
      "        [0.0678, 0.0472, 0.0339, 0.0322],\n",
      "        [0.0795, 0.0566, 0.0483, 0.0477],\n",
      "        [0.0889, 0.0798, 0.0040, 0.0373],\n",
      "        [0.0895, 0.0127, 0.0505, 0.0218],\n",
      "        [0.0072, 0.0470, 0.0592, 0.0157],\n",
      "        [0.0309, 0.0339, 0.0286, 0.0053],\n",
      "        [0.0238, 0.0044, 0.0440, 0.0664],\n",
      "        [0.0082, 0.0066, 0.0069, 0.0244],\n",
      "        [0.0611, 0.0282, 0.0259, 0.0155],\n",
      "        [0.0160, 0.0147, 0.0336, 0.0020],\n",
      "        [0.0340, 0.0516, 0.0055, 0.0699],\n",
      "        [0.0585, 0.0390, 0.0427, 0.0582],\n",
      "        [0.0484, 0.0652, 0.0389, 0.0325]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0497, 0.0106, 0.0223, 0.0459],\n",
      "        [0.0152, 0.0003, 0.0230, 0.0281],\n",
      "        [0.0175, 0.0238, 0.0275, 0.0205],\n",
      "        [0.0214, 0.0134, 0.0097, 0.0095],\n",
      "        [0.0375, 0.0198, 0.0448, 0.0006],\n",
      "        [0.0495, 0.0695, 0.0397, 0.0100],\n",
      "        [0.0746, 0.0474, 0.0013, 0.0039],\n",
      "        [0.0632, 0.0223, 0.0137, 0.0007],\n",
      "        [0.0241, 0.0019, 0.0425, 0.0010],\n",
      "        [0.0054, 0.0339, 0.0599, 0.0032],\n",
      "        [0.0422, 0.0521, 0.0662, 0.0006],\n",
      "        [0.0605, 0.0585, 0.0622, 0.0156],\n",
      "        [0.0711, 0.0595, 0.0501, 0.0260],\n",
      "        [0.0664, 0.0427, 0.0290, 0.0357],\n",
      "        [0.0777, 0.0542, 0.0454, 0.0527],\n",
      "        [0.0882, 0.0816, 0.0032, 0.0407],\n",
      "        [0.0901, 0.0167, 0.0477, 0.0229],\n",
      "        [0.0080, 0.0432, 0.0567, 0.0164],\n",
      "        [0.0286, 0.0267, 0.0232, 0.0034],\n",
      "        [0.0208, 0.0046, 0.0370, 0.0695],\n",
      "        [0.0072, 0.0061, 0.0072, 0.0204],\n",
      "        [0.0558, 0.0251, 0.0269, 0.0053],\n",
      "        [0.0108, 0.0066, 0.0277, 0.0106],\n",
      "        [0.0329, 0.0538, 0.0022, 0.0714],\n",
      "        [0.0575, 0.0412, 0.0460, 0.0566],\n",
      "        [0.0430, 0.0601, 0.0360, 0.0228]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.8818888664245605\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 27\n",
      "X 資料 torch.Size([80, 18])\n",
      "Y 資料 torch.Size([80, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0020291313994675875, 3)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引3，y= tensor([0.8055, 0.7822, 0.7445, 0.6538])\n",
      "目前模型的Data torch.Size([27, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7981, 0.8035, 0.7925, 0.7747],\n",
      "        [0.8081, 0.8151, 0.8018, 0.7948],\n",
      "        [0.7973, 0.8026, 0.7917, 0.7730],\n",
      "        [0.8001, 0.8058, 0.7943, 0.7787],\n",
      "        [0.7817, 0.7842, 0.7771, 0.7412],\n",
      "        [0.7546, 0.7524, 0.7518, 0.6861],\n",
      "        [0.7474, 0.7440, 0.7451, 0.6716],\n",
      "        [0.7282, 0.7216, 0.7272, 0.6326],\n",
      "        [0.7197, 0.7116, 0.7192, 0.6153],\n",
      "        [0.7189, 0.7106, 0.7184, 0.6136],\n",
      "        [0.7189, 0.7106, 0.7184, 0.6136],\n",
      "        [0.7190, 0.7107, 0.7185, 0.6138],\n",
      "        [0.7234, 0.7159, 0.7226, 0.6227],\n",
      "        [0.7228, 0.7152, 0.7221, 0.6216],\n",
      "        [0.7502, 0.7473, 0.7477, 0.6773],\n",
      "        [0.7814, 0.7839, 0.7768, 0.7406],\n",
      "        [0.7924, 0.7968, 0.7871, 0.7630],\n",
      "        [0.7880, 0.7916, 0.7830, 0.7540],\n",
      "        [0.8062, 0.8130, 0.8000, 0.7910],\n",
      "        [0.8189, 0.8279, 0.8119, 0.8169],\n",
      "        [0.7732, 0.7743, 0.7692, 0.7239],\n",
      "        [0.7264, 0.7194, 0.7255, 0.6289],\n",
      "        [0.7824, 0.7850, 0.7777, 0.7426],\n",
      "        [0.7189, 0.7106, 0.7184, 0.6136],\n",
      "        [0.7189, 0.7106, 0.7184, 0.6136],\n",
      "        [0.7486, 0.7454, 0.7462, 0.6739],\n",
      "        [0.7344, 0.7288, 0.7329, 0.6451]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0497, 0.0106, 0.0223, 0.0459],\n",
      "        [0.0152, 0.0003, 0.0230, 0.0281],\n",
      "        [0.0175, 0.0238, 0.0275, 0.0205],\n",
      "        [0.0214, 0.0134, 0.0097, 0.0095],\n",
      "        [0.0375, 0.0198, 0.0448, 0.0006],\n",
      "        [0.0495, 0.0695, 0.0397, 0.0100],\n",
      "        [0.0746, 0.0474, 0.0013, 0.0039],\n",
      "        [0.0632, 0.0223, 0.0137, 0.0007],\n",
      "        [0.0241, 0.0019, 0.0425, 0.0010],\n",
      "        [0.0054, 0.0339, 0.0599, 0.0032],\n",
      "        [0.0422, 0.0521, 0.0662, 0.0006],\n",
      "        [0.0605, 0.0585, 0.0622, 0.0156],\n",
      "        [0.0711, 0.0595, 0.0501, 0.0260],\n",
      "        [0.0664, 0.0427, 0.0290, 0.0357],\n",
      "        [0.0777, 0.0542, 0.0454, 0.0527],\n",
      "        [0.0882, 0.0816, 0.0032, 0.0407],\n",
      "        [0.0901, 0.0167, 0.0477, 0.0229],\n",
      "        [0.0080, 0.0432, 0.0567, 0.0164],\n",
      "        [0.0286, 0.0267, 0.0232, 0.0034],\n",
      "        [0.0208, 0.0046, 0.0370, 0.0695],\n",
      "        [0.0072, 0.0061, 0.0072, 0.0204],\n",
      "        [0.0558, 0.0251, 0.0269, 0.0053],\n",
      "        [0.0108, 0.0066, 0.0277, 0.0106],\n",
      "        [0.0329, 0.0538, 0.0022, 0.0714],\n",
      "        [0.0575, 0.0412, 0.0460, 0.0566],\n",
      "        [0.0430, 0.0601, 0.0360, 0.0228],\n",
      "        [0.0711, 0.0534, 0.0116, 0.0087]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 63\n",
      "Number of shrink: 37\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0463,     0.0159,     0.0186,     0.0492],\n",
      "        [    0.0184,     0.0059,     0.0270,     0.0312],\n",
      "        [    0.0143,     0.0286,     0.0242,     0.0231],\n",
      "        [    0.0242,     0.0088,     0.0066,     0.0115],\n",
      "        [    0.0345,     0.0162,     0.0426,     0.0024],\n",
      "        [    0.0463,     0.0673,     0.0389,     0.0085],\n",
      "        [    0.0713,     0.0456,     0.0017,     0.0053],\n",
      "        [    0.0598,     0.0214,     0.0131,     0.0006],\n",
      "        [    0.0207,     0.0016,     0.0414,     0.0000],\n",
      "        [    0.0084,     0.0336,     0.0584,     0.0033],\n",
      "        [    0.0456,     0.0523,     0.0651,     0.0003],\n",
      "        [    0.0637,     0.0586,     0.0609,     0.0150],\n",
      "        [    0.0741,     0.0594,     0.0488,     0.0259],\n",
      "        [    0.0692,     0.0424,     0.0275,     0.0359],\n",
      "        [    0.0797,     0.0547,     0.0448,     0.0536],\n",
      "        [    0.0900,     0.0837,     0.0022,     0.0413],\n",
      "        [    0.0922,     0.0199,     0.0458,     0.0226],\n",
      "        [    0.0102,     0.0402,     0.0549,     0.0160],\n",
      "        [    0.0265,     0.0226,     0.0203,     0.0025],\n",
      "        [    0.0185,     0.0097,     0.0332,     0.0710],\n",
      "        [    0.0115,     0.0013,     0.0041,     0.0247],\n",
      "        [    0.0496,     0.0210,     0.0290,     0.0016],\n",
      "        [    0.0061,     0.0009,     0.0238,     0.0159],\n",
      "        [    0.0300,     0.0541,     0.0007,     0.0715],\n",
      "        [    0.0545,     0.0415,     0.0475,     0.0566],\n",
      "        [    0.0375,     0.0554,     0.0333,     0.0167],\n",
      "        [    0.0650,     0.0488,     0.0091,     0.0016]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.307362079620361\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 28\n",
      "X 資料 torch.Size([79, 18])\n",
      "Y 資料 torch.Size([79, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.00350576126947999, 2)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引2，y= tensor([0.7986, 0.7931, 0.7916, 0.7538])\n",
      "目前模型的Data torch.Size([28, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.8016, 0.8088, 0.7962, 0.7779],\n",
      "        [0.8113, 0.8207, 0.8058, 0.7978],\n",
      "        [0.8005, 0.8073, 0.7950, 0.7756],\n",
      "        [0.8029, 0.8104, 0.7975, 0.7807],\n",
      "        [0.7847, 0.7879, 0.7794, 0.7431],\n",
      "        [0.7578, 0.7546, 0.7526, 0.6876],\n",
      "        [0.7506, 0.7459, 0.7455, 0.6730],\n",
      "        [0.7317, 0.7224, 0.7266, 0.6338],\n",
      "        [0.7231, 0.7119, 0.7181, 0.6162],\n",
      "        [0.7219, 0.7103, 0.7169, 0.6137],\n",
      "        [0.7223, 0.7109, 0.7173, 0.6146],\n",
      "        [0.7222, 0.7108, 0.7172, 0.6144],\n",
      "        [0.7263, 0.7158, 0.7213, 0.6228],\n",
      "        [0.7256, 0.7149, 0.7206, 0.6214],\n",
      "        [0.7523, 0.7479, 0.7471, 0.6763],\n",
      "        [0.7832, 0.7860, 0.7778, 0.7400],\n",
      "        [0.7945, 0.7999, 0.7891, 0.7632],\n",
      "        [0.7902, 0.7946, 0.7848, 0.7544],\n",
      "        [0.8084, 0.8171, 0.8029, 0.7919],\n",
      "        [0.8212, 0.8330, 0.8157, 0.8184],\n",
      "        [0.7775, 0.7790, 0.7722, 0.7283],\n",
      "        [0.7326, 0.7236, 0.7275, 0.6358],\n",
      "        [0.7870, 0.7907, 0.7817, 0.7479],\n",
      "        [0.7219, 0.7103, 0.7169, 0.6137],\n",
      "        [0.7219, 0.7103, 0.7169, 0.6137],\n",
      "        [0.7541, 0.7501, 0.7489, 0.6800],\n",
      "        [0.7405, 0.7334, 0.7354, 0.6521],\n",
      "        [0.7494, 0.7443, 0.7442, 0.6703]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0463,     0.0159,     0.0186,     0.0492],\n",
      "        [    0.0184,     0.0059,     0.0270,     0.0312],\n",
      "        [    0.0143,     0.0286,     0.0242,     0.0231],\n",
      "        [    0.0242,     0.0088,     0.0066,     0.0115],\n",
      "        [    0.0345,     0.0162,     0.0426,     0.0024],\n",
      "        [    0.0463,     0.0673,     0.0389,     0.0085],\n",
      "        [    0.0713,     0.0456,     0.0017,     0.0053],\n",
      "        [    0.0598,     0.0214,     0.0131,     0.0006],\n",
      "        [    0.0207,     0.0016,     0.0414,     0.0000],\n",
      "        [    0.0084,     0.0336,     0.0584,     0.0033],\n",
      "        [    0.0456,     0.0523,     0.0651,     0.0003],\n",
      "        [    0.0637,     0.0586,     0.0609,     0.0150],\n",
      "        [    0.0741,     0.0594,     0.0488,     0.0259],\n",
      "        [    0.0692,     0.0424,     0.0275,     0.0359],\n",
      "        [    0.0797,     0.0547,     0.0448,     0.0536],\n",
      "        [    0.0900,     0.0837,     0.0022,     0.0413],\n",
      "        [    0.0922,     0.0199,     0.0458,     0.0226],\n",
      "        [    0.0102,     0.0402,     0.0549,     0.0160],\n",
      "        [    0.0265,     0.0226,     0.0203,     0.0025],\n",
      "        [    0.0185,     0.0097,     0.0332,     0.0710],\n",
      "        [    0.0115,     0.0013,     0.0041,     0.0247],\n",
      "        [    0.0496,     0.0210,     0.0290,     0.0016],\n",
      "        [    0.0061,     0.0009,     0.0238,     0.0159],\n",
      "        [    0.0300,     0.0541,     0.0007,     0.0715],\n",
      "        [    0.0545,     0.0415,     0.0475,     0.0566],\n",
      "        [    0.0375,     0.0554,     0.0333,     0.0167],\n",
      "        [    0.0650,     0.0488,     0.0091,     0.0016],\n",
      "        [    0.0493,     0.0488,     0.0474,     0.0835]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0453, 0.0177, 0.0130, 0.0522],\n",
      "        [0.0188, 0.0074, 0.0331, 0.0334],\n",
      "        [0.0150, 0.0283, 0.0206, 0.0227],\n",
      "        [0.0232, 0.0094, 0.0030, 0.0105],\n",
      "        [0.0357, 0.0177, 0.0412, 0.0006],\n",
      "        [0.0479, 0.0705, 0.0410, 0.0121],\n",
      "        [0.0721, 0.0480, 0.0004, 0.0031],\n",
      "        [0.0608, 0.0248, 0.0088, 0.0025],\n",
      "        [0.0208, 0.0042, 0.0371, 0.0015],\n",
      "        [0.0095, 0.0326, 0.0553, 0.0044],\n",
      "        [0.0463, 0.0507, 0.0616, 0.0005],\n",
      "        [0.0645, 0.0570, 0.0574, 0.0146],\n",
      "        [0.0733, 0.0562, 0.0441, 0.0285],\n",
      "        [0.0682, 0.0388, 0.0224, 0.0391],\n",
      "        [0.0777, 0.0508, 0.0416, 0.0582],\n",
      "        [0.0889, 0.0822, 0.0009, 0.0431],\n",
      "        [0.0924, 0.0206, 0.0417, 0.0212],\n",
      "        [0.0105, 0.0395, 0.0512, 0.0146],\n",
      "        [0.0249, 0.0197, 0.0133, 0.0019],\n",
      "        [0.0162, 0.0140, 0.0240, 0.0773],\n",
      "        [0.0079, 0.0063, 0.0063, 0.0174],\n",
      "        [0.0431, 0.0147, 0.0330, 0.0143],\n",
      "        [0.0008, 0.0059, 0.0151, 0.0276],\n",
      "        [0.0289, 0.0552, 0.0024, 0.0726],\n",
      "        [0.0534, 0.0426, 0.0506, 0.0554],\n",
      "        [0.0312, 0.0486, 0.0270, 0.0039],\n",
      "        [0.0576, 0.0412, 0.0032, 0.0131],\n",
      "        [0.0420, 0.0410, 0.0406, 0.0688]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.756629228591919\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 29\n",
      "X 資料 torch.Size([78, 18])\n",
      "Y 資料 torch.Size([78, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0048393490724265575, 35)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引35，y= tensor([0.7803, 0.7764, 0.7518, 0.7154])\n",
      "目前模型的Data torch.Size([29, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.8025, 0.8106, 0.8018, 0.7809],\n",
      "        [0.8117, 0.8222, 0.8119, 0.8000],\n",
      "        [0.7998, 0.8070, 0.7987, 0.7751],\n",
      "        [0.8019, 0.8098, 0.8011, 0.7797],\n",
      "        [0.7835, 0.7864, 0.7807, 0.7413],\n",
      "        [0.7561, 0.7515, 0.7504, 0.6840],\n",
      "        [0.7498, 0.7434, 0.7435, 0.6708],\n",
      "        [0.7306, 0.7190, 0.7222, 0.6308],\n",
      "        [0.7230, 0.7092, 0.7138, 0.6148],\n",
      "        [0.7230, 0.7092, 0.7138, 0.6148],\n",
      "        [0.7230, 0.7092, 0.7138, 0.6148],\n",
      "        [0.7230, 0.7092, 0.7138, 0.6148],\n",
      "        [0.7255, 0.7125, 0.7166, 0.6202],\n",
      "        [0.7246, 0.7113, 0.7156, 0.6182],\n",
      "        [0.7503, 0.7440, 0.7439, 0.6718],\n",
      "        [0.7821, 0.7845, 0.7791, 0.7382],\n",
      "        [0.7947, 0.8006, 0.7931, 0.7646],\n",
      "        [0.7905, 0.7953, 0.7885, 0.7559],\n",
      "        [0.8099, 0.8200, 0.8099, 0.7963],\n",
      "        [0.8235, 0.8372, 0.8249, 0.8247],\n",
      "        [0.7739, 0.7740, 0.7700, 0.7210],\n",
      "        [0.7391, 0.7298, 0.7316, 0.6485],\n",
      "        [0.7923, 0.7975, 0.7904, 0.7596],\n",
      "        [0.7230, 0.7092, 0.7138, 0.6148],\n",
      "        [0.7230, 0.7092, 0.7138, 0.6148],\n",
      "        [0.7604, 0.7569, 0.7551, 0.6929],\n",
      "        [0.7479, 0.7410, 0.7413, 0.6669],\n",
      "        [0.7566, 0.7521, 0.7510, 0.6850],\n",
      "        [0.7230, 0.7092, 0.7138, 0.6148]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0453, 0.0177, 0.0130, 0.0522],\n",
      "        [0.0188, 0.0074, 0.0331, 0.0334],\n",
      "        [0.0150, 0.0283, 0.0206, 0.0227],\n",
      "        [0.0232, 0.0094, 0.0030, 0.0105],\n",
      "        [0.0357, 0.0177, 0.0412, 0.0006],\n",
      "        [0.0479, 0.0705, 0.0410, 0.0121],\n",
      "        [0.0721, 0.0480, 0.0004, 0.0031],\n",
      "        [0.0608, 0.0248, 0.0088, 0.0025],\n",
      "        [0.0208, 0.0042, 0.0371, 0.0015],\n",
      "        [0.0095, 0.0326, 0.0553, 0.0044],\n",
      "        [0.0463, 0.0507, 0.0616, 0.0005],\n",
      "        [0.0645, 0.0570, 0.0574, 0.0146],\n",
      "        [0.0733, 0.0562, 0.0441, 0.0285],\n",
      "        [0.0682, 0.0388, 0.0224, 0.0391],\n",
      "        [0.0777, 0.0508, 0.0416, 0.0582],\n",
      "        [0.0889, 0.0822, 0.0009, 0.0431],\n",
      "        [0.0924, 0.0206, 0.0417, 0.0212],\n",
      "        [0.0105, 0.0395, 0.0512, 0.0146],\n",
      "        [0.0249, 0.0197, 0.0133, 0.0019],\n",
      "        [0.0162, 0.0140, 0.0240, 0.0773],\n",
      "        [0.0079, 0.0063, 0.0063, 0.0174],\n",
      "        [0.0431, 0.0147, 0.0330, 0.0143],\n",
      "        [0.0008, 0.0059, 0.0151, 0.0276],\n",
      "        [0.0289, 0.0552, 0.0024, 0.0726],\n",
      "        [0.0534, 0.0426, 0.0506, 0.0554],\n",
      "        [0.0312, 0.0486, 0.0270, 0.0039],\n",
      "        [0.0576, 0.0412, 0.0032, 0.0131],\n",
      "        [0.0420, 0.0410, 0.0406, 0.0688],\n",
      "        [0.0573, 0.0671, 0.0381, 0.1006]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 48\n",
      "Number of shrink: 31\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0445,     0.0193,     0.0101,     0.0541],\n",
      "        [    0.0195,     0.0091,     0.0368,     0.0355],\n",
      "        [    0.0144,     0.0296,     0.0180,     0.0241],\n",
      "        [    0.0238,     0.0081,     0.0003,     0.0120],\n",
      "        [    0.0348,     0.0161,     0.0396,     0.0022],\n",
      "        [    0.0465,     0.0685,     0.0410,     0.0101],\n",
      "        [    0.0703,     0.0456,     0.0004,     0.0057],\n",
      "        [    0.0585,     0.0219,     0.0078,     0.0006],\n",
      "        [    0.0175,     0.0002,     0.0366,     0.0033],\n",
      "        [    0.0128,     0.0366,     0.0548,     0.0092],\n",
      "        [    0.0496,     0.0548,     0.0611,     0.0053],\n",
      "        [    0.0678,     0.0611,     0.0569,     0.0098],\n",
      "        [    0.0756,     0.0589,     0.0426,     0.0258],\n",
      "        [    0.0705,     0.0415,     0.0208,     0.0365],\n",
      "        [    0.0791,     0.0527,     0.0411,     0.0566],\n",
      "        [    0.0900,     0.0840,     0.0008,     0.0411],\n",
      "        [    0.0938,     0.0229,     0.0387,     0.0182],\n",
      "        [    0.0121,     0.0371,     0.0483,     0.0114],\n",
      "        [    0.0230,     0.0166,     0.0085,     0.0065],\n",
      "        [    0.0144,     0.0172,     0.0180,     0.0821],\n",
      "        [    0.0071,     0.0069,     0.0075,     0.0153],\n",
      "        [    0.0383,     0.0087,     0.0355,     0.0226],\n",
      "        [    0.0028,     0.0111,     0.0095,     0.0353],\n",
      "        [    0.0256,     0.0511,     0.0029,     0.0774],\n",
      "        [    0.0501,     0.0386,     0.0511,     0.0507],\n",
      "        [    0.0268,     0.0428,     0.0232,     0.0045],\n",
      "        [    0.0529,     0.0350,     0.0000,     0.0217],\n",
      "        [    0.0371,     0.0345,     0.0364,     0.0594],\n",
      "        [    0.0540,     0.0631,     0.0385,     0.0958]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.120731353759766\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 30\n",
      "X 資料 torch.Size([77, 18])\n",
      "Y 資料 torch.Size([77, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.005870661232620478, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.8232, 0.8489, 0.7986, 0.7422])\n",
      "目前模型的Data torch.Size([30, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.8033, 0.8122, 0.8047, 0.7829],\n",
      "        [0.8124, 0.8239, 0.8155, 0.8022],\n",
      "        [0.8004, 0.8084, 0.8012, 0.7766],\n",
      "        [0.8026, 0.8112, 0.8038, 0.7812],\n",
      "        [0.7845, 0.7880, 0.7823, 0.7429],\n",
      "        [0.7576, 0.7535, 0.7505, 0.6860],\n",
      "        [0.7517, 0.7459, 0.7434, 0.6734],\n",
      "        [0.7330, 0.7219, 0.7213, 0.6339],\n",
      "        [0.7263, 0.7133, 0.7133, 0.6196],\n",
      "        [0.7263, 0.7133, 0.7133, 0.6196],\n",
      "        [0.7263, 0.7133, 0.7133, 0.6196],\n",
      "        [0.7263, 0.7133, 0.7133, 0.6196],\n",
      "        [0.7278, 0.7153, 0.7152, 0.6229],\n",
      "        [0.7268, 0.7140, 0.7140, 0.6207],\n",
      "        [0.7517, 0.7459, 0.7434, 0.6734],\n",
      "        [0.7832, 0.7863, 0.7808, 0.7401],\n",
      "        [0.7961, 0.8029, 0.7961, 0.7676],\n",
      "        [0.7921, 0.7978, 0.7914, 0.7591],\n",
      "        [0.8118, 0.8231, 0.8148, 0.8009],\n",
      "        [0.8253, 0.8404, 0.8308, 0.8295],\n",
      "        [0.7731, 0.7734, 0.7689, 0.7189],\n",
      "        [0.7438, 0.7358, 0.7341, 0.6568],\n",
      "        [0.7960, 0.8027, 0.7960, 0.7673],\n",
      "        [0.7263, 0.7133, 0.7133, 0.6196],\n",
      "        [0.7263, 0.7133, 0.7133, 0.6196],\n",
      "        [0.7648, 0.7627, 0.7590, 0.7012],\n",
      "        [0.7526, 0.7471, 0.7446, 0.6754],\n",
      "        [0.7616, 0.7586, 0.7552, 0.6944],\n",
      "        [0.7263, 0.7133, 0.7133, 0.6196],\n",
      "        [0.7517, 0.7459, 0.7435, 0.6735]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0445,     0.0193,     0.0101,     0.0541],\n",
      "        [    0.0195,     0.0091,     0.0368,     0.0355],\n",
      "        [    0.0144,     0.0296,     0.0180,     0.0241],\n",
      "        [    0.0238,     0.0081,     0.0003,     0.0120],\n",
      "        [    0.0348,     0.0161,     0.0396,     0.0022],\n",
      "        [    0.0465,     0.0685,     0.0410,     0.0101],\n",
      "        [    0.0703,     0.0456,     0.0004,     0.0057],\n",
      "        [    0.0585,     0.0219,     0.0078,     0.0006],\n",
      "        [    0.0175,     0.0002,     0.0366,     0.0033],\n",
      "        [    0.0128,     0.0366,     0.0548,     0.0092],\n",
      "        [    0.0496,     0.0548,     0.0611,     0.0053],\n",
      "        [    0.0678,     0.0611,     0.0569,     0.0098],\n",
      "        [    0.0756,     0.0589,     0.0426,     0.0258],\n",
      "        [    0.0705,     0.0415,     0.0208,     0.0365],\n",
      "        [    0.0791,     0.0527,     0.0411,     0.0566],\n",
      "        [    0.0900,     0.0840,     0.0008,     0.0411],\n",
      "        [    0.0938,     0.0229,     0.0387,     0.0182],\n",
      "        [    0.0121,     0.0371,     0.0483,     0.0114],\n",
      "        [    0.0230,     0.0166,     0.0085,     0.0065],\n",
      "        [    0.0144,     0.0172,     0.0180,     0.0821],\n",
      "        [    0.0071,     0.0069,     0.0075,     0.0153],\n",
      "        [    0.0383,     0.0087,     0.0355,     0.0226],\n",
      "        [    0.0028,     0.0111,     0.0095,     0.0353],\n",
      "        [    0.0256,     0.0511,     0.0029,     0.0774],\n",
      "        [    0.0501,     0.0386,     0.0511,     0.0507],\n",
      "        [    0.0268,     0.0428,     0.0232,     0.0045],\n",
      "        [    0.0529,     0.0350,     0.0000,     0.0217],\n",
      "        [    0.0371,     0.0345,     0.0364,     0.0594],\n",
      "        [    0.0540,     0.0631,     0.0385,     0.0958],\n",
      "        [    0.0715,     0.1029,     0.0552,     0.0688]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0441, 0.0195, 0.0060, 0.0520],\n",
      "        [0.0195, 0.0086, 0.0412, 0.0325],\n",
      "        [0.0143, 0.0296, 0.0147, 0.0213],\n",
      "        [0.0241, 0.0081, 0.0034, 0.0094],\n",
      "        [0.0344, 0.0156, 0.0377, 0.0001],\n",
      "        [0.0457, 0.0671, 0.0414, 0.0118],\n",
      "        [0.0690, 0.0435, 0.0007, 0.0051],\n",
      "        [0.0571, 0.0193, 0.0056, 0.0002],\n",
      "        [0.0151, 0.0038, 0.0351, 0.0052],\n",
      "        [0.0153, 0.0406, 0.0533, 0.0111],\n",
      "        [0.0521, 0.0588, 0.0596, 0.0072],\n",
      "        [0.0702, 0.0651, 0.0554, 0.0080],\n",
      "        [0.0772, 0.0618, 0.0401, 0.0259],\n",
      "        [0.0724, 0.0448, 0.0186, 0.0358],\n",
      "        [0.0803, 0.0547, 0.0406, 0.0574],\n",
      "        [0.0909, 0.0852, 0.0033, 0.0423],\n",
      "        [0.0949, 0.0240, 0.0346, 0.0191],\n",
      "        [0.0133, 0.0356, 0.0444, 0.0118],\n",
      "        [0.0213, 0.0150, 0.0019, 0.0070],\n",
      "        [0.0123, 0.0191, 0.0096, 0.0834],\n",
      "        [0.0084, 0.0051, 0.0056, 0.0147],\n",
      "        [0.0347, 0.0034, 0.0375, 0.0271],\n",
      "        [0.0054, 0.0142, 0.0035, 0.0376],\n",
      "        [0.0231, 0.0471, 0.0044, 0.0792],\n",
      "        [0.0476, 0.0345, 0.0526, 0.0488],\n",
      "        [0.0236, 0.0384, 0.0196, 0.0081],\n",
      "        [0.0491, 0.0298, 0.0030, 0.0264],\n",
      "        [0.0328, 0.0288, 0.0319, 0.0536],\n",
      "        [0.0516, 0.0591, 0.0400, 0.0939],\n",
      "        [0.0678, 0.0977, 0.0524, 0.0642]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.560221433639526\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 31\n",
      "X 資料 torch.Size([76, 18])\n",
      "Y 資料 torch.Size([76, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.00552107160910964, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.8489, 0.7986, 0.7931, 0.7408])\n",
      "目前模型的Data torch.Size([31, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.8038, 0.8124, 0.8088, 0.7808],\n",
      "        [0.8124, 0.8234, 0.8200, 0.7992],\n",
      "        [0.8005, 0.8083, 0.8045, 0.7738],\n",
      "        [0.8028, 0.8112, 0.8075, 0.7787],\n",
      "        [0.7848, 0.7884, 0.7843, 0.7405],\n",
      "        [0.7584, 0.7549, 0.7501, 0.6843],\n",
      "        [0.7530, 0.7480, 0.7431, 0.6728],\n",
      "        [0.7344, 0.7245, 0.7191, 0.6334],\n",
      "        [0.7287, 0.7173, 0.7118, 0.6214],\n",
      "        [0.7287, 0.7173, 0.7118, 0.6214],\n",
      "        [0.7287, 0.7173, 0.7118, 0.6214],\n",
      "        [0.7287, 0.7173, 0.7118, 0.6214],\n",
      "        [0.7294, 0.7181, 0.7126, 0.6228],\n",
      "        [0.7287, 0.7173, 0.7118, 0.6214],\n",
      "        [0.7528, 0.7478, 0.7429, 0.6725],\n",
      "        [0.7841, 0.7875, 0.7833, 0.7389],\n",
      "        [0.7972, 0.8041, 0.8002, 0.7667],\n",
      "        [0.7933, 0.7992, 0.7953, 0.7586],\n",
      "        [0.8135, 0.8247, 0.8213, 0.8014],\n",
      "        [0.8274, 0.8423, 0.8392, 0.8308],\n",
      "        [0.7744, 0.7752, 0.7708, 0.7183],\n",
      "        [0.7475, 0.7411, 0.7360, 0.6613],\n",
      "        [0.7985, 0.8058, 0.8020, 0.7696],\n",
      "        [0.7287, 0.7173, 0.7118, 0.6214],\n",
      "        [0.7287, 0.7173, 0.7118, 0.6214],\n",
      "        [0.7680, 0.7671, 0.7626, 0.7049],\n",
      "        [0.7564, 0.7524, 0.7475, 0.6802],\n",
      "        [0.7658, 0.7643, 0.7597, 0.7002],\n",
      "        [0.7287, 0.7173, 0.7118, 0.6214],\n",
      "        [0.7554, 0.7511, 0.7463, 0.6781],\n",
      "        [0.7488, 0.7428, 0.7377, 0.6641]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0441, 0.0195, 0.0060, 0.0520],\n",
      "        [0.0195, 0.0086, 0.0412, 0.0325],\n",
      "        [0.0143, 0.0296, 0.0147, 0.0213],\n",
      "        [0.0241, 0.0081, 0.0034, 0.0094],\n",
      "        [0.0344, 0.0156, 0.0377, 0.0001],\n",
      "        [0.0457, 0.0671, 0.0414, 0.0118],\n",
      "        [0.0690, 0.0435, 0.0007, 0.0051],\n",
      "        [0.0571, 0.0193, 0.0056, 0.0002],\n",
      "        [0.0151, 0.0038, 0.0351, 0.0052],\n",
      "        [0.0153, 0.0406, 0.0533, 0.0111],\n",
      "        [0.0521, 0.0588, 0.0596, 0.0072],\n",
      "        [0.0702, 0.0651, 0.0554, 0.0080],\n",
      "        [0.0772, 0.0618, 0.0401, 0.0259],\n",
      "        [0.0724, 0.0448, 0.0186, 0.0358],\n",
      "        [0.0803, 0.0547, 0.0406, 0.0574],\n",
      "        [0.0909, 0.0852, 0.0033, 0.0423],\n",
      "        [0.0949, 0.0240, 0.0346, 0.0191],\n",
      "        [0.0133, 0.0356, 0.0444, 0.0118],\n",
      "        [0.0213, 0.0150, 0.0019, 0.0070],\n",
      "        [0.0123, 0.0191, 0.0096, 0.0834],\n",
      "        [0.0084, 0.0051, 0.0056, 0.0147],\n",
      "        [0.0347, 0.0034, 0.0375, 0.0271],\n",
      "        [0.0054, 0.0142, 0.0035, 0.0376],\n",
      "        [0.0231, 0.0471, 0.0044, 0.0792],\n",
      "        [0.0476, 0.0345, 0.0526, 0.0488],\n",
      "        [0.0236, 0.0384, 0.0196, 0.0081],\n",
      "        [0.0491, 0.0298, 0.0030, 0.0264],\n",
      "        [0.0328, 0.0288, 0.0319, 0.0536],\n",
      "        [0.0516, 0.0591, 0.0400, 0.0939],\n",
      "        [0.0678, 0.0977, 0.0524, 0.0642],\n",
      "        [0.1000, 0.0559, 0.0554, 0.0767]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0426, 0.0192, 0.0021, 0.0522],\n",
      "        [0.0209, 0.0082, 0.0461, 0.0327],\n",
      "        [0.0131, 0.0289, 0.0116, 0.0210],\n",
      "        [0.0254, 0.0085, 0.0070, 0.0094],\n",
      "        [0.0326, 0.0158, 0.0359, 0.0001],\n",
      "        [0.0431, 0.0665, 0.0421, 0.0105],\n",
      "        [0.0656, 0.0419, 0.0011, 0.0080],\n",
      "        [0.0531, 0.0173, 0.0035, 0.0036],\n",
      "        [0.0110, 0.0059, 0.0322, 0.0085],\n",
      "        [0.0193, 0.0426, 0.0504, 0.0144],\n",
      "        [0.0569, 0.0618, 0.0578, 0.0122],\n",
      "        [0.0743, 0.0671, 0.0526, 0.0046],\n",
      "        [0.0811, 0.0636, 0.0371, 0.0229],\n",
      "        [0.0764, 0.0468, 0.0158, 0.0325],\n",
      "        [0.0838, 0.0563, 0.0403, 0.0545],\n",
      "        [0.0940, 0.0866, 0.0067, 0.0393],\n",
      "        [0.0984, 0.0264, 0.0286, 0.0145],\n",
      "        [0.0171, 0.0331, 0.0387, 0.0070],\n",
      "        [0.0166, 0.0109, 0.0081, 0.0146],\n",
      "        [0.0071, 0.0239, 0.0029, 0.0925],\n",
      "        [0.0094, 0.0064, 0.0064, 0.0131],\n",
      "        [0.0270, 0.0035, 0.0425, 0.0389],\n",
      "        [0.0116, 0.0199, 0.0065, 0.0479],\n",
      "        [0.0190, 0.0451, 0.0073, 0.0826],\n",
      "        [0.0436, 0.0325, 0.0555, 0.0455],\n",
      "        [0.0163, 0.0317, 0.0124, 0.0196],\n",
      "        [0.0413, 0.0226, 0.0094, 0.0387],\n",
      "        [0.0238, 0.0200, 0.0225, 0.0385],\n",
      "        [0.0475, 0.0570, 0.0429, 0.0906],\n",
      "        [0.0597, 0.0901, 0.0456, 0.0511],\n",
      "        [0.0903, 0.0463, 0.0473, 0.0605]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.955801010131836\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 32\n",
      "X 資料 torch.Size([75, 18])\n",
      "Y 資料 torch.Size([75, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0075189946219325066, 32)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引32，y= tensor([0.7437, 0.7660, 0.7803, 0.7266])\n",
      "目前模型的Data torch.Size([32, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.8052, 0.8121, 0.8126, 0.7809],\n",
      "        [0.8138, 0.8230, 0.8249, 0.7993],\n",
      "        [0.8017, 0.8077, 0.8077, 0.7734],\n",
      "        [0.8041, 0.8107, 0.8111, 0.7786],\n",
      "        [0.7866, 0.7883, 0.7860, 0.7408],\n",
      "        [0.7610, 0.7555, 0.7493, 0.6856],\n",
      "        [0.7564, 0.7496, 0.7427, 0.6757],\n",
      "        [0.7384, 0.7265, 0.7170, 0.6369],\n",
      "        [0.7328, 0.7193, 0.7089, 0.6248],\n",
      "        [0.7328, 0.7193, 0.7089, 0.6248],\n",
      "        [0.7336, 0.7203, 0.7100, 0.6264],\n",
      "        [0.7328, 0.7193, 0.7089, 0.6248],\n",
      "        [0.7333, 0.7200, 0.7096, 0.6258],\n",
      "        [0.7328, 0.7193, 0.7089, 0.6248],\n",
      "        [0.7563, 0.7495, 0.7426, 0.6755],\n",
      "        [0.7871, 0.7889, 0.7868, 0.7419],\n",
      "        [0.8007, 0.8064, 0.8062, 0.7713],\n",
      "        [0.7971, 0.8017, 0.8010, 0.7635],\n",
      "        [0.8182, 0.8288, 0.8313, 0.8090],\n",
      "        [0.8326, 0.8471, 0.8518, 0.8399],\n",
      "        [0.7754, 0.7740, 0.7700, 0.7167],\n",
      "        [0.7552, 0.7481, 0.7411, 0.6731],\n",
      "        [0.8047, 0.8115, 0.8120, 0.7799],\n",
      "        [0.7328, 0.7193, 0.7089, 0.6248],\n",
      "        [0.7328, 0.7193, 0.7089, 0.6248],\n",
      "        [0.7753, 0.7738, 0.7698, 0.7164],\n",
      "        [0.7642, 0.7595, 0.7539, 0.6925],\n",
      "        [0.7748, 0.7731, 0.7691, 0.7153],\n",
      "        [0.7328, 0.7193, 0.7089, 0.6248],\n",
      "        [0.7636, 0.7588, 0.7530, 0.6911],\n",
      "        [0.7585, 0.7523, 0.7458, 0.6803],\n",
      "        [0.8303, 0.8443, 0.8486, 0.8351]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0426, 0.0192, 0.0021, 0.0522],\n",
      "        [0.0209, 0.0082, 0.0461, 0.0327],\n",
      "        [0.0131, 0.0289, 0.0116, 0.0210],\n",
      "        [0.0254, 0.0085, 0.0070, 0.0094],\n",
      "        [0.0326, 0.0158, 0.0359, 0.0001],\n",
      "        [0.0431, 0.0665, 0.0421, 0.0105],\n",
      "        [0.0656, 0.0419, 0.0011, 0.0080],\n",
      "        [0.0531, 0.0173, 0.0035, 0.0036],\n",
      "        [0.0110, 0.0059, 0.0322, 0.0085],\n",
      "        [0.0193, 0.0426, 0.0504, 0.0144],\n",
      "        [0.0569, 0.0618, 0.0578, 0.0122],\n",
      "        [0.0743, 0.0671, 0.0526, 0.0046],\n",
      "        [0.0811, 0.0636, 0.0371, 0.0229],\n",
      "        [0.0764, 0.0468, 0.0158, 0.0325],\n",
      "        [0.0838, 0.0563, 0.0403, 0.0545],\n",
      "        [0.0940, 0.0866, 0.0067, 0.0393],\n",
      "        [0.0984, 0.0264, 0.0286, 0.0145],\n",
      "        [0.0171, 0.0331, 0.0387, 0.0070],\n",
      "        [0.0166, 0.0109, 0.0081, 0.0146],\n",
      "        [0.0071, 0.0239, 0.0029, 0.0925],\n",
      "        [0.0094, 0.0064, 0.0064, 0.0131],\n",
      "        [0.0270, 0.0035, 0.0425, 0.0389],\n",
      "        [0.0116, 0.0199, 0.0065, 0.0479],\n",
      "        [0.0190, 0.0451, 0.0073, 0.0826],\n",
      "        [0.0436, 0.0325, 0.0555, 0.0455],\n",
      "        [0.0163, 0.0317, 0.0124, 0.0196],\n",
      "        [0.0413, 0.0226, 0.0094, 0.0387],\n",
      "        [0.0238, 0.0200, 0.0225, 0.0385],\n",
      "        [0.0475, 0.0570, 0.0429, 0.0906],\n",
      "        [0.0597, 0.0901, 0.0456, 0.0511],\n",
      "        [0.0903, 0.0463, 0.0473, 0.0605],\n",
      "        [0.0867, 0.0783, 0.0683, 0.1085]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 63\n",
      "Number of shrink: 37\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0494, 0.0126, 0.0038, 0.0433],\n",
      "        [0.0135, 0.0013, 0.0453, 0.0237],\n",
      "        [0.0204, 0.0214, 0.0149, 0.0105],\n",
      "        [0.0183, 0.0155, 0.0047, 0.0002],\n",
      "        [0.0384, 0.0218, 0.0398, 0.0087],\n",
      "        [0.0461, 0.0699, 0.0467, 0.0159],\n",
      "        [0.0678, 0.0444, 0.0053, 0.0038],\n",
      "        [0.0533, 0.0179, 0.0011, 0.0019],\n",
      "        [0.0098, 0.0070, 0.0289, 0.0094],\n",
      "        [0.0205, 0.0438, 0.0470, 0.0153],\n",
      "        [0.0597, 0.0651, 0.0572, 0.0168],\n",
      "        [0.0755, 0.0682, 0.0492, 0.0037],\n",
      "        [0.0824, 0.0649, 0.0341, 0.0215],\n",
      "        [0.0776, 0.0479, 0.0124, 0.0316],\n",
      "        [0.0826, 0.0553, 0.0379, 0.0561],\n",
      "        [0.0910, 0.0844, 0.0076, 0.0415],\n",
      "        [0.0945, 0.0234, 0.0265, 0.0173],\n",
      "        [0.0132, 0.0363, 0.0373, 0.0102],\n",
      "        [0.0219, 0.0150, 0.0115, 0.0107],\n",
      "        [0.0135, 0.0189, 0.0075, 0.0878],\n",
      "        [0.0122, 0.0337, 0.0384, 0.0329],\n",
      "        [0.0284, 0.0021, 0.0394, 0.0365],\n",
      "        [0.0074, 0.0166, 0.0089, 0.0449],\n",
      "        [0.0178, 0.0440, 0.0106, 0.0835],\n",
      "        [0.0424, 0.0314, 0.0589, 0.0446],\n",
      "        [0.0180, 0.0328, 0.0119, 0.0189],\n",
      "        [0.0431, 0.0242, 0.0075, 0.0365],\n",
      "        [0.0231, 0.0179, 0.0182, 0.0338],\n",
      "        [0.0463, 0.0559, 0.0463, 0.0897],\n",
      "        [0.0594, 0.0890, 0.0442, 0.0487],\n",
      "        [0.0888, 0.0437, 0.0449, 0.0558],\n",
      "        [0.0591, 0.0452, 0.0377, 0.0554]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.29886794090271\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 33\n",
      "X 資料 torch.Size([74, 18])\n",
      "Y 資料 torch.Size([74, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0081675099208951, 11)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引11，y= tensor([0.6289, 0.6416, 0.6166, 0.5391])\n",
      "目前模型的Data torch.Size([33, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7984, 0.8055, 0.8110, 0.7721],\n",
      "        [0.8064, 0.8161, 0.8241, 0.7903],\n",
      "        [0.7944, 0.8002, 0.8044, 0.7630],\n",
      "        [0.7971, 0.8037, 0.8087, 0.7690],\n",
      "        [0.7808, 0.7822, 0.7821, 0.7320],\n",
      "        [0.7580, 0.7521, 0.7448, 0.6802],\n",
      "        [0.7541, 0.7470, 0.7385, 0.6715],\n",
      "        [0.7381, 0.7259, 0.7124, 0.6352],\n",
      "        [0.7340, 0.7204, 0.7055, 0.6257],\n",
      "        [0.7340, 0.7204, 0.7055, 0.6257],\n",
      "        [0.7364, 0.7236, 0.7094, 0.6311],\n",
      "        [0.7340, 0.7204, 0.7055, 0.6257],\n",
      "        [0.7346, 0.7213, 0.7066, 0.6271],\n",
      "        [0.7340, 0.7204, 0.7055, 0.6257],\n",
      "        [0.7552, 0.7484, 0.7402, 0.6739],\n",
      "        [0.7842, 0.7867, 0.7877, 0.7397],\n",
      "        [0.7968, 0.8034, 0.8084, 0.7685],\n",
      "        [0.7932, 0.7986, 0.8024, 0.7602],\n",
      "        [0.8130, 0.8247, 0.8347, 0.8051],\n",
      "        [0.8262, 0.8421, 0.8564, 0.8352],\n",
      "        [0.7538, 0.7466, 0.7380, 0.6707],\n",
      "        [0.7538, 0.7466, 0.7379, 0.6707],\n",
      "        [0.8005, 0.8083, 0.8144, 0.7769],\n",
      "        [0.7340, 0.7204, 0.7055, 0.6257],\n",
      "        [0.7340, 0.7204, 0.7055, 0.6257],\n",
      "        [0.7736, 0.7727, 0.7703, 0.7156],\n",
      "        [0.7624, 0.7579, 0.7520, 0.6902],\n",
      "        [0.7755, 0.7752, 0.7734, 0.7200],\n",
      "        [0.7340, 0.7204, 0.7055, 0.6257],\n",
      "        [0.7639, 0.7599, 0.7544, 0.6936],\n",
      "        [0.7601, 0.7549, 0.7482, 0.6850],\n",
      "        [0.8028, 0.8112, 0.8180, 0.7819],\n",
      "        [0.7340, 0.7204, 0.7055, 0.6257]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0494, 0.0126, 0.0038, 0.0433],\n",
      "        [0.0135, 0.0013, 0.0453, 0.0237],\n",
      "        [0.0204, 0.0214, 0.0149, 0.0105],\n",
      "        [0.0183, 0.0155, 0.0047, 0.0002],\n",
      "        [0.0384, 0.0218, 0.0398, 0.0087],\n",
      "        [0.0461, 0.0699, 0.0467, 0.0159],\n",
      "        [0.0678, 0.0444, 0.0053, 0.0038],\n",
      "        [0.0533, 0.0179, 0.0011, 0.0019],\n",
      "        [0.0098, 0.0070, 0.0289, 0.0094],\n",
      "        [0.0205, 0.0438, 0.0470, 0.0153],\n",
      "        [0.0597, 0.0651, 0.0572, 0.0168],\n",
      "        [0.0755, 0.0682, 0.0492, 0.0037],\n",
      "        [0.0824, 0.0649, 0.0341, 0.0215],\n",
      "        [0.0776, 0.0479, 0.0124, 0.0316],\n",
      "        [0.0826, 0.0553, 0.0379, 0.0561],\n",
      "        [0.0910, 0.0844, 0.0076, 0.0415],\n",
      "        [0.0945, 0.0234, 0.0265, 0.0173],\n",
      "        [0.0132, 0.0363, 0.0373, 0.0102],\n",
      "        [0.0219, 0.0150, 0.0115, 0.0107],\n",
      "        [0.0135, 0.0189, 0.0075, 0.0878],\n",
      "        [0.0122, 0.0337, 0.0384, 0.0329],\n",
      "        [0.0284, 0.0021, 0.0394, 0.0365],\n",
      "        [0.0074, 0.0166, 0.0089, 0.0449],\n",
      "        [0.0178, 0.0440, 0.0106, 0.0835],\n",
      "        [0.0424, 0.0314, 0.0589, 0.0446],\n",
      "        [0.0180, 0.0328, 0.0119, 0.0189],\n",
      "        [0.0431, 0.0242, 0.0075, 0.0365],\n",
      "        [0.0231, 0.0179, 0.0182, 0.0338],\n",
      "        [0.0463, 0.0559, 0.0463, 0.0897],\n",
      "        [0.0594, 0.0890, 0.0442, 0.0487],\n",
      "        [0.0888, 0.0437, 0.0449, 0.0558],\n",
      "        [0.0591, 0.0452, 0.0377, 0.0554],\n",
      "        [0.1051, 0.0788, 0.0890, 0.0866]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0495, 0.0120, 0.0030, 0.0387],\n",
      "        [0.0138, 0.0005, 0.0464, 0.0179],\n",
      "        [0.0214, 0.0199, 0.0153, 0.0049],\n",
      "        [0.0177, 0.0168, 0.0047, 0.0057],\n",
      "        [0.0407, 0.0240, 0.0417, 0.0137],\n",
      "        [0.0502, 0.0727, 0.0505, 0.0196],\n",
      "        [0.0720, 0.0471, 0.0091, 0.0008],\n",
      "        [0.0589, 0.0212, 0.0065, 0.0003],\n",
      "        [0.0164, 0.0026, 0.0220, 0.0061],\n",
      "        [0.0136, 0.0390, 0.0396, 0.0113],\n",
      "        [0.0539, 0.0615, 0.0515, 0.0145],\n",
      "        [0.0687, 0.0636, 0.0420, 0.0075],\n",
      "        [0.0760, 0.0607, 0.0274, 0.0248],\n",
      "        [0.0707, 0.0431, 0.0050, 0.0356],\n",
      "        [0.0779, 0.0518, 0.0332, 0.0605],\n",
      "        [0.0891, 0.0824, 0.0061, 0.0468],\n",
      "        [0.0942, 0.0225, 0.0260, 0.0223],\n",
      "        [0.0126, 0.0372, 0.0371, 0.0148],\n",
      "        [0.0200, 0.0142, 0.0149, 0.0067],\n",
      "        [0.0097, 0.0212, 0.0134, 0.0848],\n",
      "        [0.0166, 0.0367, 0.0426, 0.0362],\n",
      "        [0.0309, 0.0014, 0.0382, 0.0370],\n",
      "        [0.0088, 0.0177, 0.0121, 0.0428],\n",
      "        [0.0248, 0.0488, 0.0181, 0.0794],\n",
      "        [0.0493, 0.0362, 0.0663, 0.0486],\n",
      "        [0.0189, 0.0328, 0.0113, 0.0182],\n",
      "        [0.0448, 0.0244, 0.0073, 0.0367],\n",
      "        [0.0228, 0.0165, 0.0157, 0.0325],\n",
      "        [0.0533, 0.0607, 0.0537, 0.0938],\n",
      "        [0.0605, 0.0886, 0.0437, 0.0477],\n",
      "        [0.0898, 0.0429, 0.0439, 0.0537],\n",
      "        [0.0585, 0.0436, 0.0375, 0.0486],\n",
      "        [0.0982, 0.0740, 0.0816, 0.0825]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.671313524246216\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 34\n",
      "X 資料 torch.Size([73, 18])\n",
      "Y 資料 torch.Size([73, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.008875027298927307, 52)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引52，y= tensor([0.6024, 0.6329, 0.7118, 0.7353])\n",
      "目前模型的Data torch.Size([34, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7984, 0.8049, 0.8118, 0.7675],\n",
      "        [0.8067, 0.8153, 0.8252, 0.7845],\n",
      "        [0.7934, 0.7987, 0.8040, 0.7574],\n",
      "        [0.7965, 0.8025, 0.8088, 0.7636],\n",
      "        [0.7786, 0.7801, 0.7803, 0.7269],\n",
      "        [0.7539, 0.7492, 0.7410, 0.6765],\n",
      "        [0.7500, 0.7443, 0.7347, 0.6685],\n",
      "        [0.7326, 0.7226, 0.7070, 0.6330],\n",
      "        [0.7274, 0.7161, 0.6987, 0.6224],\n",
      "        [0.7270, 0.7156, 0.6981, 0.6216],\n",
      "        [0.7305, 0.7200, 0.7037, 0.6288],\n",
      "        [0.7272, 0.7158, 0.6984, 0.6219],\n",
      "        [0.7282, 0.7170, 0.6999, 0.6239],\n",
      "        [0.7270, 0.7156, 0.6981, 0.6216],\n",
      "        [0.7505, 0.7449, 0.7355, 0.6695],\n",
      "        [0.7822, 0.7847, 0.7861, 0.7345],\n",
      "        [0.7965, 0.8025, 0.8088, 0.7636],\n",
      "        [0.7926, 0.7976, 0.8026, 0.7556],\n",
      "        [0.8149, 0.8255, 0.8381, 0.8011],\n",
      "        [0.8300, 0.8444, 0.8623, 0.8321],\n",
      "        [0.7494, 0.7436, 0.7338, 0.6674],\n",
      "        [0.7513, 0.7459, 0.7368, 0.6712],\n",
      "        [0.8020, 0.8093, 0.8175, 0.7748],\n",
      "        [0.7270, 0.7156, 0.6981, 0.6216],\n",
      "        [0.7270, 0.7156, 0.6981, 0.6216],\n",
      "        [0.7727, 0.7727, 0.7709, 0.7149],\n",
      "        [0.7607, 0.7578, 0.7518, 0.6905],\n",
      "        [0.7758, 0.7766, 0.7759, 0.7213],\n",
      "        [0.7270, 0.7156, 0.6981, 0.6216],\n",
      "        [0.7627, 0.7602, 0.7550, 0.6945],\n",
      "        [0.7591, 0.7557, 0.7492, 0.6871],\n",
      "        [0.8021, 0.8096, 0.8178, 0.7751],\n",
      "        [0.7270, 0.7156, 0.6981, 0.6216],\n",
      "        [0.7270, 0.7156, 0.6981, 0.6216]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0495, 0.0120, 0.0030, 0.0387],\n",
      "        [0.0138, 0.0005, 0.0464, 0.0179],\n",
      "        [0.0214, 0.0199, 0.0153, 0.0049],\n",
      "        [0.0177, 0.0168, 0.0047, 0.0057],\n",
      "        [0.0407, 0.0240, 0.0417, 0.0137],\n",
      "        [0.0502, 0.0727, 0.0505, 0.0196],\n",
      "        [0.0720, 0.0471, 0.0091, 0.0008],\n",
      "        [0.0589, 0.0212, 0.0065, 0.0003],\n",
      "        [0.0164, 0.0026, 0.0220, 0.0061],\n",
      "        [0.0136, 0.0390, 0.0396, 0.0113],\n",
      "        [0.0539, 0.0615, 0.0515, 0.0145],\n",
      "        [0.0687, 0.0636, 0.0420, 0.0075],\n",
      "        [0.0760, 0.0607, 0.0274, 0.0248],\n",
      "        [0.0707, 0.0431, 0.0050, 0.0356],\n",
      "        [0.0779, 0.0518, 0.0332, 0.0605],\n",
      "        [0.0891, 0.0824, 0.0061, 0.0468],\n",
      "        [0.0942, 0.0225, 0.0260, 0.0223],\n",
      "        [0.0126, 0.0372, 0.0371, 0.0148],\n",
      "        [0.0200, 0.0142, 0.0149, 0.0067],\n",
      "        [0.0097, 0.0212, 0.0134, 0.0848],\n",
      "        [0.0166, 0.0367, 0.0426, 0.0362],\n",
      "        [0.0309, 0.0014, 0.0382, 0.0370],\n",
      "        [0.0088, 0.0177, 0.0121, 0.0428],\n",
      "        [0.0248, 0.0488, 0.0181, 0.0794],\n",
      "        [0.0493, 0.0362, 0.0663, 0.0486],\n",
      "        [0.0189, 0.0328, 0.0113, 0.0182],\n",
      "        [0.0448, 0.0244, 0.0073, 0.0367],\n",
      "        [0.0228, 0.0165, 0.0157, 0.0325],\n",
      "        [0.0533, 0.0607, 0.0537, 0.0938],\n",
      "        [0.0605, 0.0886, 0.0437, 0.0477],\n",
      "        [0.0898, 0.0429, 0.0439, 0.0537],\n",
      "        [0.0585, 0.0436, 0.0375, 0.0486],\n",
      "        [0.0982, 0.0740, 0.0816, 0.0825],\n",
      "        [0.1246, 0.0828, 0.0136, 0.1137]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0488,     0.0151,     0.0000,     0.0436],\n",
      "        [    0.0150,     0.0040,     0.0491,     0.0218],\n",
      "        [    0.0216,     0.0219,     0.0133,     0.0090],\n",
      "        [    0.0177,     0.0146,     0.0068,     0.0017],\n",
      "        [    0.0425,     0.0237,     0.0404,     0.0093],\n",
      "        [    0.0541,     0.0746,     0.0496,     0.0137],\n",
      "        [    0.0757,     0.0487,     0.0074,     0.0080],\n",
      "        [    0.0640,     0.0242,     0.0049,     0.0080],\n",
      "        [    0.0223,     0.0012,     0.0230,     0.0141],\n",
      "        [    0.0059,     0.0329,     0.0381,     0.0161],\n",
      "        [    0.0477,     0.0573,     0.0518,     0.0215],\n",
      "        [    0.0619,     0.0587,     0.0418,     0.0009],\n",
      "        [    0.0688,     0.0554,     0.0266,     0.0190],\n",
      "        [    0.0634,     0.0376,     0.0040,     0.0300],\n",
      "        [    0.0728,     0.0485,     0.0328,     0.0560],\n",
      "        [    0.0869,     0.0822,     0.0066,     0.0437],\n",
      "        [    0.0939,     0.0243,     0.0244,     0.0188],\n",
      "        [    0.0120,     0.0356,     0.0355,     0.0111],\n",
      "        [    0.0180,     0.0098,     0.0179,     0.0104],\n",
      "        [    0.0051,     0.0285,     0.0185,     0.0899],\n",
      "        [    0.0226,     0.0410,     0.0441,     0.0331],\n",
      "        [    0.0336,     0.0011,     0.0413,     0.0457],\n",
      "        [    0.0107,     0.0222,     0.0163,     0.0490],\n",
      "        [    0.0325,     0.0548,     0.0196,     0.0843],\n",
      "        [    0.0570,     0.0422,     0.0679,     0.0437],\n",
      "        [    0.0197,     0.0311,     0.0077,     0.0258],\n",
      "        [    0.0463,     0.0234,     0.0111,     0.0457],\n",
      "        [    0.0221,     0.0130,     0.0103,     0.0227],\n",
      "        [    0.0610,     0.0668,     0.0553,     0.0889],\n",
      "        [    0.0610,     0.0864,     0.0385,     0.0374],\n",
      "        [    0.0900,     0.0403,     0.0380,     0.0421],\n",
      "        [    0.0568,     0.0437,     0.0365,     0.0483],\n",
      "        [    0.0905,     0.0680,     0.0800,     0.0874],\n",
      "        [    0.1169,     0.0767,     0.0152,     0.1088]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.042555332183838\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 35\n",
      "X 資料 torch.Size([72, 18])\n",
      "Y 資料 torch.Size([72, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.008509849198162556, 10)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引10，y= tensor([0.5708, 0.6289, 0.6416, 0.5770])\n",
      "目前模型的Data torch.Size([35, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7991, 0.8080, 0.8148, 0.7723],\n",
      "        [0.8079, 0.8188, 0.8278, 0.7884],\n",
      "        [0.7932, 0.8007, 0.8060, 0.7615],\n",
      "        [0.7964, 0.8047, 0.8108, 0.7675],\n",
      "        [0.7767, 0.7804, 0.7816, 0.7314],\n",
      "        [0.7499, 0.7473, 0.7419, 0.6824],\n",
      "        [0.7462, 0.7428, 0.7364, 0.6757],\n",
      "        [0.7274, 0.7196, 0.7085, 0.6413],\n",
      "        [0.7215, 0.7122, 0.6997, 0.6304],\n",
      "        [0.7193, 0.7096, 0.6966, 0.6265],\n",
      "        [0.7244, 0.7158, 0.7040, 0.6357],\n",
      "        [0.7204, 0.7109, 0.6981, 0.6285],\n",
      "        [0.7211, 0.7117, 0.6991, 0.6296],\n",
      "        [0.7198, 0.7101, 0.6972, 0.6272],\n",
      "        [0.7453, 0.7417, 0.7351, 0.6740],\n",
      "        [0.7801, 0.7845, 0.7866, 0.7376],\n",
      "        [0.7962, 0.8044, 0.8104, 0.7670],\n",
      "        [0.7920, 0.7992, 0.8042, 0.7593],\n",
      "        [0.8169, 0.8299, 0.8411, 0.8048],\n",
      "        [0.8346, 0.8518, 0.8674, 0.8373],\n",
      "        [0.7434, 0.7393, 0.7322, 0.6705],\n",
      "        [0.7485, 0.7456, 0.7398, 0.6799],\n",
      "        [0.8038, 0.8138, 0.8218, 0.7810],\n",
      "        [0.7193, 0.7096, 0.6966, 0.6265],\n",
      "        [0.7193, 0.7096, 0.6966, 0.6265],\n",
      "        [0.7719, 0.7744, 0.7744, 0.7226],\n",
      "        [0.7592, 0.7588, 0.7557, 0.6994],\n",
      "        [0.7765, 0.7802, 0.7813, 0.7311],\n",
      "        [0.7193, 0.7096, 0.6966, 0.6265],\n",
      "        [0.7622, 0.7625, 0.7601, 0.7049],\n",
      "        [0.7589, 0.7583, 0.7551, 0.6988],\n",
      "        [0.8005, 0.8097, 0.8168, 0.7749],\n",
      "        [0.7193, 0.7096, 0.6966, 0.6265],\n",
      "        [0.7193, 0.7096, 0.6966, 0.6265],\n",
      "        [0.7193, 0.7096, 0.6966, 0.6265]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0488,     0.0151,     0.0000,     0.0436],\n",
      "        [    0.0150,     0.0040,     0.0491,     0.0218],\n",
      "        [    0.0216,     0.0219,     0.0133,     0.0090],\n",
      "        [    0.0177,     0.0146,     0.0068,     0.0017],\n",
      "        [    0.0425,     0.0237,     0.0404,     0.0093],\n",
      "        [    0.0541,     0.0746,     0.0496,     0.0137],\n",
      "        [    0.0757,     0.0487,     0.0074,     0.0080],\n",
      "        [    0.0640,     0.0242,     0.0049,     0.0080],\n",
      "        [    0.0223,     0.0012,     0.0230,     0.0141],\n",
      "        [    0.0059,     0.0329,     0.0381,     0.0161],\n",
      "        [    0.0477,     0.0573,     0.0518,     0.0215],\n",
      "        [    0.0619,     0.0587,     0.0418,     0.0009],\n",
      "        [    0.0688,     0.0554,     0.0266,     0.0190],\n",
      "        [    0.0634,     0.0376,     0.0040,     0.0300],\n",
      "        [    0.0728,     0.0485,     0.0328,     0.0560],\n",
      "        [    0.0869,     0.0822,     0.0066,     0.0437],\n",
      "        [    0.0939,     0.0243,     0.0244,     0.0188],\n",
      "        [    0.0120,     0.0356,     0.0355,     0.0111],\n",
      "        [    0.0180,     0.0098,     0.0179,     0.0104],\n",
      "        [    0.0051,     0.0285,     0.0185,     0.0899],\n",
      "        [    0.0226,     0.0410,     0.0441,     0.0331],\n",
      "        [    0.0336,     0.0011,     0.0413,     0.0457],\n",
      "        [    0.0107,     0.0222,     0.0163,     0.0490],\n",
      "        [    0.0325,     0.0548,     0.0196,     0.0843],\n",
      "        [    0.0570,     0.0422,     0.0679,     0.0437],\n",
      "        [    0.0197,     0.0311,     0.0077,     0.0258],\n",
      "        [    0.0463,     0.0234,     0.0111,     0.0457],\n",
      "        [    0.0221,     0.0130,     0.0103,     0.0227],\n",
      "        [    0.0610,     0.0668,     0.0553,     0.0889],\n",
      "        [    0.0610,     0.0864,     0.0385,     0.0374],\n",
      "        [    0.0900,     0.0403,     0.0380,     0.0421],\n",
      "        [    0.0568,     0.0437,     0.0365,     0.0483],\n",
      "        [    0.0905,     0.0680,     0.0800,     0.0874],\n",
      "        [    0.1169,     0.0767,     0.0152,     0.1088],\n",
      "        [    0.1485,     0.0807,     0.0549,     0.0495]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0475, 0.0158, 0.0007, 0.0414],\n",
      "        [0.0167, 0.0046, 0.0493, 0.0183],\n",
      "        [0.0214, 0.0218, 0.0133, 0.0064],\n",
      "        [0.0182, 0.0145, 0.0068, 0.0045],\n",
      "        [0.0442, 0.0248, 0.0409, 0.0111],\n",
      "        [0.0582, 0.0767, 0.0501, 0.0134],\n",
      "        [0.0800, 0.0507, 0.0077, 0.0087],\n",
      "        [0.0701, 0.0269, 0.0053, 0.0102],\n",
      "        [0.0291, 0.0044, 0.0223, 0.0164],\n",
      "        [0.0059, 0.0241, 0.0308, 0.0108],\n",
      "        [0.0405, 0.0535, 0.0502, 0.0224],\n",
      "        [0.0539, 0.0543, 0.0396, 0.0003],\n",
      "        [0.0607, 0.0507, 0.0241, 0.0189],\n",
      "        [0.0550, 0.0327, 0.0013, 0.0299],\n",
      "        [0.0667, 0.0445, 0.0301, 0.0579],\n",
      "        [0.0843, 0.0797, 0.0043, 0.0479],\n",
      "        [0.0930, 0.0228, 0.0262, 0.0238],\n",
      "        [0.0109, 0.0372, 0.0371, 0.0155],\n",
      "        [0.0161, 0.0096, 0.0172, 0.0053],\n",
      "        [0.0006, 0.0304, 0.0192, 0.0849],\n",
      "        [0.0272, 0.0432, 0.0446, 0.0323],\n",
      "        [0.0374, 0.0005, 0.0413, 0.0467],\n",
      "        [0.0122, 0.0228, 0.0167, 0.0461],\n",
      "        [0.0445, 0.0639, 0.0272, 0.0786],\n",
      "        [0.0691, 0.0513, 0.0754, 0.0494],\n",
      "        [0.0214, 0.0319, 0.0077, 0.0250],\n",
      "        [0.0490, 0.0245, 0.0113, 0.0460],\n",
      "        [0.0226, 0.0127, 0.0092, 0.0227],\n",
      "        [0.0730, 0.0759, 0.0628, 0.0946],\n",
      "        [0.0631, 0.0869, 0.0378, 0.0366],\n",
      "        [0.0921, 0.0407, 0.0370, 0.0407],\n",
      "        [0.0571, 0.0432, 0.0357, 0.0443],\n",
      "        [0.0784, 0.0589, 0.0724, 0.0817],\n",
      "        [0.1049, 0.0676, 0.0228, 0.1145],\n",
      "        [0.1364, 0.0716, 0.0474, 0.0438]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.422417879104614\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 36\n",
      "X 資料 torch.Size([71, 18])\n",
      "Y 資料 torch.Size([71, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0071201203390955925, 10)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引10，y= tensor([0.6416, 0.6166, 0.5761, 0.5546])\n",
      "目前模型的Data torch.Size([36, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.8004, 0.8087, 0.8155, 0.7702],\n",
      "        [0.8096, 0.8194, 0.8281, 0.7850],\n",
      "        [0.7934, 0.8005, 0.8060, 0.7589],\n",
      "        [0.7970, 0.8048, 0.8109, 0.7647],\n",
      "        [0.7751, 0.7793, 0.7811, 0.7296],\n",
      "        [0.7458, 0.7453, 0.7414, 0.6826],\n",
      "        [0.7420, 0.7408, 0.7361, 0.6764],\n",
      "        [0.7214, 0.7169, 0.7082, 0.6434],\n",
      "        [0.7147, 0.7091, 0.6990, 0.6326],\n",
      "        [0.7075, 0.7008, 0.6893, 0.6212],\n",
      "        [0.7172, 0.7120, 0.7024, 0.6366],\n",
      "        [0.7125, 0.7065, 0.6960, 0.6291],\n",
      "        [0.7129, 0.7070, 0.6966, 0.6298],\n",
      "        [0.7113, 0.7052, 0.6945, 0.6273],\n",
      "        [0.7393, 0.7377, 0.7324, 0.6721],\n",
      "        [0.7774, 0.7820, 0.7843, 0.7333],\n",
      "        [0.7953, 0.8028, 0.8086, 0.7620],\n",
      "        [0.7909, 0.7977, 0.8026, 0.7549],\n",
      "        [0.8187, 0.8301, 0.8405, 0.7997],\n",
      "        [0.8391, 0.8537, 0.8681, 0.8323],\n",
      "        [0.7388, 0.7371, 0.7318, 0.6713],\n",
      "        [0.7447, 0.7440, 0.7399, 0.6809],\n",
      "        [0.8053, 0.8144, 0.8222, 0.7781],\n",
      "        [0.7073, 0.7005, 0.6890, 0.6208],\n",
      "        [0.7073, 0.7005, 0.6890, 0.6208],\n",
      "        [0.7702, 0.7736, 0.7745, 0.7218],\n",
      "        [0.7565, 0.7577, 0.7559, 0.6998],\n",
      "        [0.7760, 0.7804, 0.7824, 0.7311],\n",
      "        [0.7073, 0.7005, 0.6890, 0.6208],\n",
      "        [0.7601, 0.7619, 0.7608, 0.7056],\n",
      "        [0.7567, 0.7580, 0.7562, 0.7001],\n",
      "        [0.8008, 0.8092, 0.8160, 0.7708],\n",
      "        [0.7073, 0.7005, 0.6890, 0.6208],\n",
      "        [0.7073, 0.7005, 0.6890, 0.6208],\n",
      "        [0.7073, 0.7005, 0.6890, 0.6208],\n",
      "        [0.7073, 0.7005, 0.6890, 0.6208]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0475, 0.0158, 0.0007, 0.0414],\n",
      "        [0.0167, 0.0046, 0.0493, 0.0183],\n",
      "        [0.0214, 0.0218, 0.0133, 0.0064],\n",
      "        [0.0182, 0.0145, 0.0068, 0.0045],\n",
      "        [0.0442, 0.0248, 0.0409, 0.0111],\n",
      "        [0.0582, 0.0767, 0.0501, 0.0134],\n",
      "        [0.0800, 0.0507, 0.0077, 0.0087],\n",
      "        [0.0701, 0.0269, 0.0053, 0.0102],\n",
      "        [0.0291, 0.0044, 0.0223, 0.0164],\n",
      "        [0.0059, 0.0241, 0.0308, 0.0108],\n",
      "        [0.0405, 0.0535, 0.0502, 0.0224],\n",
      "        [0.0539, 0.0543, 0.0396, 0.0003],\n",
      "        [0.0607, 0.0507, 0.0241, 0.0189],\n",
      "        [0.0550, 0.0327, 0.0013, 0.0299],\n",
      "        [0.0667, 0.0445, 0.0301, 0.0579],\n",
      "        [0.0843, 0.0797, 0.0043, 0.0479],\n",
      "        [0.0930, 0.0228, 0.0262, 0.0238],\n",
      "        [0.0109, 0.0372, 0.0371, 0.0155],\n",
      "        [0.0161, 0.0096, 0.0172, 0.0053],\n",
      "        [0.0006, 0.0304, 0.0192, 0.0849],\n",
      "        [0.0272, 0.0432, 0.0446, 0.0323],\n",
      "        [0.0374, 0.0005, 0.0413, 0.0467],\n",
      "        [0.0122, 0.0228, 0.0167, 0.0461],\n",
      "        [0.0445, 0.0639, 0.0272, 0.0786],\n",
      "        [0.0691, 0.0513, 0.0754, 0.0494],\n",
      "        [0.0214, 0.0319, 0.0077, 0.0250],\n",
      "        [0.0490, 0.0245, 0.0113, 0.0460],\n",
      "        [0.0226, 0.0127, 0.0092, 0.0227],\n",
      "        [0.0730, 0.0759, 0.0628, 0.0946],\n",
      "        [0.0631, 0.0869, 0.0378, 0.0366],\n",
      "        [0.0921, 0.0407, 0.0370, 0.0407],\n",
      "        [0.0571, 0.0432, 0.0357, 0.0443],\n",
      "        [0.0784, 0.0589, 0.0724, 0.0817],\n",
      "        [0.1049, 0.0676, 0.0228, 0.1145],\n",
      "        [0.1364, 0.0716, 0.0474, 0.0438],\n",
      "        [0.0657, 0.0839, 0.1129, 0.0661]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0429,     0.0177,     0.0021,     0.0400],\n",
      "        [    0.0217,     0.0063,     0.0504,     0.0158],\n",
      "        [    0.0181,     0.0227,     0.0129,     0.0045],\n",
      "        [    0.0219,     0.0134,     0.0073,     0.0066],\n",
      "        [    0.0427,     0.0248,     0.0413,     0.0126],\n",
      "        [    0.0591,     0.0774,     0.0509,     0.0130],\n",
      "        [    0.0811,     0.0514,     0.0084,     0.0095],\n",
      "        [    0.0730,     0.0283,     0.0064,     0.0121],\n",
      "        [    0.0328,     0.0063,     0.0208,     0.0183],\n",
      "        [    0.0107,     0.0215,     0.0285,     0.0125],\n",
      "        [    0.0365,     0.0511,     0.0481,     0.0235],\n",
      "        [    0.0490,     0.0512,     0.0367,     0.0003],\n",
      "        [    0.0556,     0.0473,     0.0209,     0.0186],\n",
      "        [    0.0496,     0.0291,     0.0021,     0.0299],\n",
      "        [    0.0636,     0.0417,     0.0271,     0.0595],\n",
      "        [    0.0845,     0.0782,     0.0022,     0.0515],\n",
      "        [    0.0951,     0.0222,     0.0276,     0.0279],\n",
      "        [    0.0128,     0.0376,     0.0382,     0.0190],\n",
      "        [    0.0108,     0.0083,     0.0178,     0.0015],\n",
      "        [    0.0074,     0.0335,     0.0215,     0.0814],\n",
      "        [    0.0287,     0.0441,     0.0455,     0.0314],\n",
      "        [    0.0372,     0.0001,     0.0421,     0.0489],\n",
      "        [    0.0172,     0.0248,     0.0182,     0.0444],\n",
      "        [    0.0560,     0.0738,     0.0380,     0.0708],\n",
      "        [    0.0806,     0.0612,     0.0862,     0.0573],\n",
      "        [    0.0193,     0.0309,     0.0068,     0.0254],\n",
      "        [    0.0478,     0.0236,     0.0123,     0.0475],\n",
      "        [    0.0190,     0.0104,     0.0069,     0.0212],\n",
      "        [    0.0845,     0.0858,     0.0736,     0.1024],\n",
      "        [    0.0614,     0.0857,     0.0365,     0.0350],\n",
      "        [    0.0902,     0.0390,     0.0351,     0.0382],\n",
      "        [    0.0602,     0.0434,     0.0352,     0.0407],\n",
      "        [    0.0669,     0.0490,     0.0616,     0.0739],\n",
      "        [    0.0934,     0.0577,     0.0335,     0.1224],\n",
      "        [    0.1250,     0.0617,     0.0366,     0.0360],\n",
      "        [    0.0542,     0.0740,     0.1021,     0.0583]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.806617021560669\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 37\n",
      "X 資料 torch.Size([70, 18])\n",
      "Y 資料 torch.Size([70, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.006600845605134964, 9)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引9，y= tensor([0.6038, 0.5708, 0.6289, 0.6005])\n",
      "目前模型的Data torch.Size([37, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.8050, 0.8106, 0.8169, 0.7688],\n",
      "        [0.8146, 0.8211, 0.8291, 0.7825],\n",
      "        [0.7967, 0.8015, 0.8064, 0.7570],\n",
      "        [0.8007, 0.8058, 0.8114, 0.7626],\n",
      "        [0.7765, 0.7792, 0.7807, 0.7281],\n",
      "        [0.7449, 0.7445, 0.7406, 0.6831],\n",
      "        [0.7409, 0.7401, 0.7354, 0.6772],\n",
      "        [0.7185, 0.7155, 0.7070, 0.6453],\n",
      "        [0.7110, 0.7072, 0.6974, 0.6346],\n",
      "        [0.7028, 0.6982, 0.6870, 0.6229],\n",
      "        [0.7132, 0.7097, 0.7003, 0.6378],\n",
      "        [0.7075, 0.7034, 0.6931, 0.6297],\n",
      "        [0.7078, 0.7037, 0.6934, 0.6300],\n",
      "        [0.7059, 0.7017, 0.6910, 0.6274],\n",
      "        [0.7361, 0.7348, 0.7294, 0.6705],\n",
      "        [0.7777, 0.7805, 0.7822, 0.7298],\n",
      "        [0.7974, 0.8022, 0.8072, 0.7579],\n",
      "        [0.7929, 0.7972, 0.8015, 0.7515],\n",
      "        [0.8240, 0.8314, 0.8410, 0.7959],\n",
      "        [0.8471, 0.8568, 0.8703, 0.8288],\n",
      "        [0.7373, 0.7362, 0.7309, 0.6722],\n",
      "        [0.7450, 0.7446, 0.7406, 0.6831],\n",
      "        [0.8104, 0.8164, 0.8237, 0.7764],\n",
      "        [0.6958, 0.6906, 0.6782, 0.6130],\n",
      "        [0.6958, 0.6906, 0.6782, 0.6130],\n",
      "        [0.7723, 0.7746, 0.7754, 0.7221],\n",
      "        [0.7577, 0.7586, 0.7568, 0.7013],\n",
      "        [0.7796, 0.7827, 0.7847, 0.7326],\n",
      "        [0.6958, 0.6906, 0.6782, 0.6130],\n",
      "        [0.7619, 0.7631, 0.7621, 0.7072],\n",
      "        [0.7586, 0.7596, 0.7580, 0.7026],\n",
      "        [0.8039, 0.8093, 0.8155, 0.7672],\n",
      "        [0.6958, 0.6906, 0.6782, 0.6130],\n",
      "        [0.6958, 0.6906, 0.6782, 0.6130],\n",
      "        [0.6958, 0.6906, 0.6782, 0.6130],\n",
      "        [0.6958, 0.6906, 0.6782, 0.6130],\n",
      "        [0.6975, 0.6924, 0.6803, 0.6153]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0429,     0.0177,     0.0021,     0.0400],\n",
      "        [    0.0217,     0.0063,     0.0504,     0.0158],\n",
      "        [    0.0181,     0.0227,     0.0129,     0.0045],\n",
      "        [    0.0219,     0.0134,     0.0073,     0.0066],\n",
      "        [    0.0427,     0.0248,     0.0413,     0.0126],\n",
      "        [    0.0591,     0.0774,     0.0509,     0.0130],\n",
      "        [    0.0811,     0.0514,     0.0084,     0.0095],\n",
      "        [    0.0730,     0.0283,     0.0064,     0.0121],\n",
      "        [    0.0328,     0.0063,     0.0208,     0.0183],\n",
      "        [    0.0107,     0.0215,     0.0285,     0.0125],\n",
      "        [    0.0365,     0.0511,     0.0481,     0.0235],\n",
      "        [    0.0490,     0.0512,     0.0367,     0.0003],\n",
      "        [    0.0556,     0.0473,     0.0209,     0.0186],\n",
      "        [    0.0496,     0.0291,     0.0021,     0.0299],\n",
      "        [    0.0636,     0.0417,     0.0271,     0.0595],\n",
      "        [    0.0845,     0.0782,     0.0022,     0.0515],\n",
      "        [    0.0951,     0.0222,     0.0276,     0.0279],\n",
      "        [    0.0128,     0.0376,     0.0382,     0.0190],\n",
      "        [    0.0108,     0.0083,     0.0178,     0.0015],\n",
      "        [    0.0074,     0.0335,     0.0215,     0.0814],\n",
      "        [    0.0287,     0.0441,     0.0455,     0.0314],\n",
      "        [    0.0372,     0.0001,     0.0421,     0.0489],\n",
      "        [    0.0172,     0.0248,     0.0182,     0.0444],\n",
      "        [    0.0560,     0.0738,     0.0380,     0.0708],\n",
      "        [    0.0806,     0.0612,     0.0862,     0.0573],\n",
      "        [    0.0193,     0.0309,     0.0068,     0.0254],\n",
      "        [    0.0478,     0.0236,     0.0123,     0.0475],\n",
      "        [    0.0190,     0.0104,     0.0069,     0.0212],\n",
      "        [    0.0845,     0.0858,     0.0736,     0.1024],\n",
      "        [    0.0614,     0.0857,     0.0365,     0.0350],\n",
      "        [    0.0902,     0.0390,     0.0351,     0.0382],\n",
      "        [    0.0602,     0.0434,     0.0352,     0.0407],\n",
      "        [    0.0669,     0.0490,     0.0616,     0.0739],\n",
      "        [    0.0934,     0.0577,     0.0335,     0.1224],\n",
      "        [    0.1250,     0.0617,     0.0366,     0.0360],\n",
      "        [    0.0542,     0.0740,     0.1021,     0.0583],\n",
      "        [    0.0936,     0.1215,     0.0514,     0.0149]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 63\n",
      "Number of shrink: 37\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0423, 0.0169, 0.0004, 0.0366],\n",
      "        [0.0228, 0.0060, 0.0486, 0.0118],\n",
      "        [0.0181, 0.0213, 0.0149, 0.0013],\n",
      "        [0.0221, 0.0146, 0.0054, 0.0100],\n",
      "        [0.0443, 0.0276, 0.0437, 0.0151],\n",
      "        [0.0625, 0.0819, 0.0536, 0.0139],\n",
      "        [0.0847, 0.0561, 0.0111, 0.0089],\n",
      "        [0.0778, 0.0343, 0.0093, 0.0127],\n",
      "        [0.0383, 0.0128, 0.0177, 0.0191],\n",
      "        [0.0167, 0.0145, 0.0254, 0.0137],\n",
      "        [0.0310, 0.0446, 0.0448, 0.0240],\n",
      "        [0.0429, 0.0440, 0.0330, 0.0006],\n",
      "        [0.0491, 0.0398, 0.0169, 0.0187],\n",
      "        [0.0428, 0.0213, 0.0064, 0.0301],\n",
      "        [0.0587, 0.0356, 0.0231, 0.0612],\n",
      "        [0.0825, 0.0749, 0.0010, 0.0548],\n",
      "        [0.0948, 0.0206, 0.0299, 0.0314],\n",
      "        [0.0122, 0.0396, 0.0406, 0.0223],\n",
      "        [0.0089, 0.0077, 0.0165, 0.0026],\n",
      "        [0.0117, 0.0365, 0.0216, 0.0775],\n",
      "        [0.0342, 0.0509, 0.0503, 0.0341],\n",
      "        [0.0398, 0.0037, 0.0402, 0.0490],\n",
      "        [0.0197, 0.0261, 0.0184, 0.0428],\n",
      "        [0.0627, 0.0815, 0.0415, 0.0720],\n",
      "        [0.0872, 0.0689, 0.0897, 0.0561],\n",
      "        [0.0197, 0.0324, 0.0077, 0.0249],\n",
      "        [0.0496, 0.0265, 0.0107, 0.0471],\n",
      "        [0.0180, 0.0105, 0.0066, 0.0209],\n",
      "        [0.0911, 0.0935, 0.0771, 0.1012],\n",
      "        [0.0620, 0.0874, 0.0370, 0.0345],\n",
      "        [0.0906, 0.0404, 0.0351, 0.0370],\n",
      "        [0.0587, 0.0403, 0.0309, 0.0346],\n",
      "        [0.0603, 0.0413, 0.0581, 0.0750],\n",
      "        [0.0868, 0.0500, 0.0371, 0.1212],\n",
      "        [0.1183, 0.0540, 0.0331, 0.0371],\n",
      "        [0.0475, 0.0663, 0.0986, 0.0595],\n",
      "        [0.0854, 0.1121, 0.0459, 0.0138]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.15885591506958\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 38\n",
      "X 資料 torch.Size([69, 18])\n",
      "Y 資料 torch.Size([69, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.006859936285763979, 9)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引9，y= tensor([0.6166, 0.5761, 0.5927, 0.5506])\n",
      "目前模型的Data torch.Size([38, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.8056, 0.8098, 0.8152, 0.7654],\n",
      "        [0.8157, 0.8208, 0.8273, 0.7785],\n",
      "        [0.7967, 0.8001, 0.8044, 0.7538],\n",
      "        [0.8009, 0.8047, 0.8095, 0.7593],\n",
      "        [0.7750, 0.7764, 0.7782, 0.7256],\n",
      "        [0.7416, 0.7400, 0.7379, 0.6822],\n",
      "        [0.7373, 0.7353, 0.7327, 0.6766],\n",
      "        [0.7136, 0.7096, 0.7042, 0.6459],\n",
      "        [0.7055, 0.7007, 0.6944, 0.6353],\n",
      "        [0.6968, 0.6912, 0.6839, 0.6240],\n",
      "        [0.7077, 0.7031, 0.6970, 0.6382],\n",
      "        [0.7014, 0.6962, 0.6894, 0.6300],\n",
      "        [0.7014, 0.6962, 0.6894, 0.6300],\n",
      "        [0.6992, 0.6938, 0.6868, 0.6272],\n",
      "        [0.7312, 0.7287, 0.7254, 0.6688],\n",
      "        [0.7757, 0.7772, 0.7791, 0.7265],\n",
      "        [0.7971, 0.8006, 0.8050, 0.7544],\n",
      "        [0.7923, 0.7953, 0.7991, 0.7481],\n",
      "        [0.8260, 0.8320, 0.8397, 0.7918],\n",
      "        [0.8514, 0.8598, 0.8705, 0.8249],\n",
      "        [0.7318, 0.7294, 0.7261, 0.6695],\n",
      "        [0.7423, 0.7408, 0.7388, 0.6832],\n",
      "        [0.8128, 0.8177, 0.8239, 0.7748],\n",
      "        [0.6892, 0.6829, 0.6747, 0.6141],\n",
      "        [0.6892, 0.6829, 0.6747, 0.6141],\n",
      "        [0.7719, 0.7731, 0.7745, 0.7216],\n",
      "        [0.7559, 0.7557, 0.7553, 0.7009],\n",
      "        [0.7806, 0.7826, 0.7850, 0.7330],\n",
      "        [0.6892, 0.6829, 0.6747, 0.6141],\n",
      "        [0.7612, 0.7615, 0.7617, 0.7078],\n",
      "        [0.7582, 0.7582, 0.7580, 0.7039],\n",
      "        [0.8023, 0.8063, 0.8112, 0.7612],\n",
      "        [0.6892, 0.6829, 0.6747, 0.6141],\n",
      "        [0.6892, 0.6829, 0.6747, 0.6141],\n",
      "        [0.6892, 0.6829, 0.6747, 0.6141],\n",
      "        [0.6892, 0.6829, 0.6747, 0.6141],\n",
      "        [0.6893, 0.6830, 0.6748, 0.6143],\n",
      "        [0.6892, 0.6829, 0.6747, 0.6141]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0423, 0.0169, 0.0004, 0.0366],\n",
      "        [0.0228, 0.0060, 0.0486, 0.0118],\n",
      "        [0.0181, 0.0213, 0.0149, 0.0013],\n",
      "        [0.0221, 0.0146, 0.0054, 0.0100],\n",
      "        [0.0443, 0.0276, 0.0437, 0.0151],\n",
      "        [0.0625, 0.0819, 0.0536, 0.0139],\n",
      "        [0.0847, 0.0561, 0.0111, 0.0089],\n",
      "        [0.0778, 0.0343, 0.0093, 0.0127],\n",
      "        [0.0383, 0.0128, 0.0177, 0.0191],\n",
      "        [0.0167, 0.0145, 0.0254, 0.0137],\n",
      "        [0.0310, 0.0446, 0.0448, 0.0240],\n",
      "        [0.0429, 0.0440, 0.0330, 0.0006],\n",
      "        [0.0491, 0.0398, 0.0169, 0.0187],\n",
      "        [0.0428, 0.0213, 0.0064, 0.0301],\n",
      "        [0.0587, 0.0356, 0.0231, 0.0612],\n",
      "        [0.0825, 0.0749, 0.0010, 0.0548],\n",
      "        [0.0948, 0.0206, 0.0299, 0.0314],\n",
      "        [0.0122, 0.0396, 0.0406, 0.0223],\n",
      "        [0.0089, 0.0077, 0.0165, 0.0026],\n",
      "        [0.0117, 0.0365, 0.0216, 0.0775],\n",
      "        [0.0342, 0.0509, 0.0503, 0.0341],\n",
      "        [0.0398, 0.0037, 0.0402, 0.0490],\n",
      "        [0.0197, 0.0261, 0.0184, 0.0428],\n",
      "        [0.0627, 0.0815, 0.0415, 0.0720],\n",
      "        [0.0872, 0.0689, 0.0897, 0.0561],\n",
      "        [0.0197, 0.0324, 0.0077, 0.0249],\n",
      "        [0.0496, 0.0265, 0.0107, 0.0471],\n",
      "        [0.0180, 0.0105, 0.0066, 0.0209],\n",
      "        [0.0911, 0.0935, 0.0771, 0.1012],\n",
      "        [0.0620, 0.0874, 0.0370, 0.0345],\n",
      "        [0.0906, 0.0404, 0.0351, 0.0370],\n",
      "        [0.0587, 0.0403, 0.0309, 0.0346],\n",
      "        [0.0603, 0.0413, 0.0581, 0.0750],\n",
      "        [0.0868, 0.0500, 0.0371, 0.1212],\n",
      "        [0.1183, 0.0540, 0.0331, 0.0371],\n",
      "        [0.0475, 0.0663, 0.0986, 0.0595],\n",
      "        [0.0854, 0.1121, 0.0459, 0.0138],\n",
      "        [0.0726, 0.1068, 0.0820, 0.0635]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0385, 0.0202, 0.0025, 0.0343],\n",
      "        [0.0268, 0.0096, 0.0506, 0.0087],\n",
      "        [0.0145, 0.0244, 0.0126, 0.0002],\n",
      "        [0.0257, 0.0115, 0.0075, 0.0120],\n",
      "        [0.0419, 0.0260, 0.0422, 0.0157],\n",
      "        [0.0613, 0.0816, 0.0521, 0.0121],\n",
      "        [0.0837, 0.0560, 0.0098, 0.0109],\n",
      "        [0.0777, 0.0351, 0.0081, 0.0161],\n",
      "        [0.0389, 0.0145, 0.0183, 0.0226],\n",
      "        [0.0176, 0.0125, 0.0259, 0.0178],\n",
      "        [0.0298, 0.0422, 0.0447, 0.0265],\n",
      "        [0.0411, 0.0410, 0.0325, 0.0032],\n",
      "        [0.0470, 0.0365, 0.0158, 0.0165],\n",
      "        [0.0403, 0.0174, 0.0078, 0.0282],\n",
      "        [0.0574, 0.0332, 0.0220, 0.0613],\n",
      "        [0.0830, 0.0745, 0.0017, 0.0577],\n",
      "        [0.0966, 0.0216, 0.0298, 0.0352],\n",
      "        [0.0137, 0.0388, 0.0407, 0.0259],\n",
      "        [0.0055, 0.0048, 0.0174, 0.0075],\n",
      "        [0.0178, 0.0424, 0.0248, 0.0730],\n",
      "        [0.0359, 0.0538, 0.0519, 0.0348],\n",
      "        [0.0395, 0.0043, 0.0406, 0.0496],\n",
      "        [0.0245, 0.0305, 0.0214, 0.0409],\n",
      "        [0.0716, 0.0924, 0.0501, 0.0673],\n",
      "        [0.0962, 0.0798, 0.0983, 0.0607],\n",
      "        [0.0174, 0.0308, 0.0061, 0.0245],\n",
      "        [0.0486, 0.0264, 0.0113, 0.0470],\n",
      "        [0.0138, 0.0069, 0.0031, 0.0199],\n",
      "        [0.1001, 0.1043, 0.0857, 0.1058],\n",
      "        [0.0587, 0.0847, 0.0338, 0.0324],\n",
      "        [0.0871, 0.0375, 0.0315, 0.0343],\n",
      "        [0.0592, 0.0400, 0.0294, 0.0289],\n",
      "        [0.0513, 0.0304, 0.0495, 0.0704],\n",
      "        [0.0778, 0.0392, 0.0456, 0.1258],\n",
      "        [0.1094, 0.0432, 0.0245, 0.0325],\n",
      "        [0.0386, 0.0555, 0.0900, 0.0549],\n",
      "        [0.0800, 0.1052, 0.0415, 0.0134],\n",
      "        [0.0636, 0.0960, 0.0734, 0.0589]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.50992202758789\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 39\n",
      "X 資料 torch.Size([68, 18])\n",
      "Y 資料 torch.Size([68, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0066216010600328445, 9)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引9，y= tensor([0.5761, 0.5927, 0.5884, 0.5521])\n",
      "目前模型的Data torch.Size([39, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.8094, 0.8131, 0.8173, 0.7631],\n",
      "        [0.8197, 0.8244, 0.8294, 0.7754],\n",
      "        [0.8003, 0.8032, 0.8066, 0.7523],\n",
      "        [0.8044, 0.8077, 0.8115, 0.7573],\n",
      "        [0.7773, 0.7781, 0.7797, 0.7250],\n",
      "        [0.7428, 0.7404, 0.7393, 0.6839],\n",
      "        [0.7383, 0.7354, 0.7341, 0.6786],\n",
      "        [0.7138, 0.7087, 0.7054, 0.6494],\n",
      "        [0.7049, 0.6990, 0.6950, 0.6389],\n",
      "        [0.6959, 0.6892, 0.6844, 0.6282],\n",
      "        [0.7065, 0.7007, 0.6969, 0.6408],\n",
      "        [0.6996, 0.6932, 0.6888, 0.6326],\n",
      "        [0.6992, 0.6928, 0.6884, 0.6322],\n",
      "        [0.6966, 0.6900, 0.6853, 0.6291],\n",
      "        [0.7300, 0.7264, 0.7243, 0.6687],\n",
      "        [0.7761, 0.7768, 0.7783, 0.7236],\n",
      "        [0.7989, 0.8017, 0.8050, 0.7507],\n",
      "        [0.7938, 0.7961, 0.7990, 0.7446],\n",
      "        [0.8294, 0.8349, 0.8407, 0.7869],\n",
      "        [0.8575, 0.8657, 0.8736, 0.8203],\n",
      "        [0.7301, 0.7265, 0.7245, 0.6688],\n",
      "        [0.7427, 0.7403, 0.7392, 0.6838],\n",
      "        [0.8176, 0.8221, 0.8269, 0.7729],\n",
      "        [0.6802, 0.6720, 0.6661, 0.6095],\n",
      "        [0.6802, 0.6720, 0.6661, 0.6095],\n",
      "        [0.7742, 0.7747, 0.7761, 0.7213],\n",
      "        [0.7569, 0.7558, 0.7559, 0.7007],\n",
      "        [0.7848, 0.7862, 0.7885, 0.7339],\n",
      "        [0.6802, 0.6720, 0.6661, 0.6095],\n",
      "        [0.7645, 0.7641, 0.7648, 0.7098],\n",
      "        [0.7618, 0.7611, 0.7616, 0.7065],\n",
      "        [0.8029, 0.8060, 0.8097, 0.7554],\n",
      "        [0.6802, 0.6720, 0.6661, 0.6095],\n",
      "        [0.6802, 0.6720, 0.6661, 0.6095],\n",
      "        [0.6802, 0.6720, 0.6661, 0.6095],\n",
      "        [0.6802, 0.6720, 0.6661, 0.6095],\n",
      "        [0.6839, 0.6760, 0.6704, 0.6139],\n",
      "        [0.6802, 0.6720, 0.6661, 0.6095],\n",
      "        [0.6802, 0.6720, 0.6661, 0.6095]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0385, 0.0202, 0.0025, 0.0343],\n",
      "        [0.0268, 0.0096, 0.0506, 0.0087],\n",
      "        [0.0145, 0.0244, 0.0126, 0.0002],\n",
      "        [0.0257, 0.0115, 0.0075, 0.0120],\n",
      "        [0.0419, 0.0260, 0.0422, 0.0157],\n",
      "        [0.0613, 0.0816, 0.0521, 0.0121],\n",
      "        [0.0837, 0.0560, 0.0098, 0.0109],\n",
      "        [0.0777, 0.0351, 0.0081, 0.0161],\n",
      "        [0.0389, 0.0145, 0.0183, 0.0226],\n",
      "        [0.0176, 0.0125, 0.0259, 0.0178],\n",
      "        [0.0298, 0.0422, 0.0447, 0.0265],\n",
      "        [0.0411, 0.0410, 0.0325, 0.0032],\n",
      "        [0.0470, 0.0365, 0.0158, 0.0165],\n",
      "        [0.0403, 0.0174, 0.0078, 0.0282],\n",
      "        [0.0574, 0.0332, 0.0220, 0.0613],\n",
      "        [0.0830, 0.0745, 0.0017, 0.0577],\n",
      "        [0.0966, 0.0216, 0.0298, 0.0352],\n",
      "        [0.0137, 0.0388, 0.0407, 0.0259],\n",
      "        [0.0055, 0.0048, 0.0174, 0.0075],\n",
      "        [0.0178, 0.0424, 0.0248, 0.0730],\n",
      "        [0.0359, 0.0538, 0.0519, 0.0348],\n",
      "        [0.0395, 0.0043, 0.0406, 0.0496],\n",
      "        [0.0245, 0.0305, 0.0214, 0.0409],\n",
      "        [0.0716, 0.0924, 0.0501, 0.0673],\n",
      "        [0.0962, 0.0798, 0.0983, 0.0607],\n",
      "        [0.0174, 0.0308, 0.0061, 0.0245],\n",
      "        [0.0486, 0.0264, 0.0113, 0.0470],\n",
      "        [0.0138, 0.0069, 0.0031, 0.0199],\n",
      "        [0.1001, 0.1043, 0.0857, 0.1058],\n",
      "        [0.0587, 0.0847, 0.0338, 0.0324],\n",
      "        [0.0871, 0.0375, 0.0315, 0.0343],\n",
      "        [0.0592, 0.0400, 0.0294, 0.0289],\n",
      "        [0.0513, 0.0304, 0.0495, 0.0704],\n",
      "        [0.0778, 0.0392, 0.0456, 0.1258],\n",
      "        [0.1094, 0.0432, 0.0245, 0.0325],\n",
      "        [0.0386, 0.0555, 0.0900, 0.0549],\n",
      "        [0.0800, 0.1052, 0.0415, 0.0134],\n",
      "        [0.0636, 0.0960, 0.0734, 0.0589],\n",
      "        [0.1041, 0.0794, 0.0777, 0.0574]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0366, 0.0218, 0.0035, 0.0323],\n",
      "        [0.0291, 0.0114, 0.0518, 0.0062],\n",
      "        [0.0123, 0.0266, 0.0108, 0.0011],\n",
      "        [0.0279, 0.0095, 0.0090, 0.0133],\n",
      "        [0.0408, 0.0244, 0.0407, 0.0158],\n",
      "        [0.0607, 0.0799, 0.0500, 0.0098],\n",
      "        [0.0834, 0.0545, 0.0078, 0.0132],\n",
      "        [0.0780, 0.0337, 0.0058, 0.0200],\n",
      "        [0.0402, 0.0138, 0.0199, 0.0263],\n",
      "        [0.0189, 0.0132, 0.0278, 0.0221],\n",
      "        [0.0276, 0.0418, 0.0451, 0.0289],\n",
      "        [0.0384, 0.0402, 0.0326, 0.0057],\n",
      "        [0.0440, 0.0353, 0.0156, 0.0144],\n",
      "        [0.0368, 0.0159, 0.0084, 0.0263],\n",
      "        [0.0550, 0.0320, 0.0213, 0.0611],\n",
      "        [0.0815, 0.0732, 0.0032, 0.0606],\n",
      "        [0.0962, 0.0210, 0.0309, 0.0388],\n",
      "        [0.0132, 0.0395, 0.0418, 0.0293],\n",
      "        [0.0044, 0.0046, 0.0167, 0.0123],\n",
      "        [0.0213, 0.0446, 0.0257, 0.0685],\n",
      "        [0.0361, 0.0526, 0.0501, 0.0321],\n",
      "        [0.0405, 0.0042, 0.0410, 0.0502],\n",
      "        [0.0272, 0.0327, 0.0230, 0.0390],\n",
      "        [0.0831, 0.1020, 0.0590, 0.0619],\n",
      "        [0.1076, 0.0894, 0.1073, 0.0661],\n",
      "        [0.0169, 0.0299, 0.0052, 0.0240],\n",
      "        [0.0493, 0.0263, 0.0116, 0.0467],\n",
      "        [0.0117, 0.0045, 0.0009, 0.0196],\n",
      "        [0.1115, 0.1140, 0.0947, 0.1113],\n",
      "        [0.0569, 0.0821, 0.0311, 0.0306],\n",
      "        [0.0851, 0.0347, 0.0285, 0.0320],\n",
      "        [0.0606, 0.0412, 0.0301, 0.0267],\n",
      "        [0.0399, 0.0208, 0.0406, 0.0650],\n",
      "        [0.0664, 0.0295, 0.0546, 0.1312],\n",
      "        [0.0979, 0.0335, 0.0155, 0.0271],\n",
      "        [0.0271, 0.0458, 0.0811, 0.0495],\n",
      "        [0.0742, 0.1015, 0.0388, 0.0139],\n",
      "        [0.0522, 0.0863, 0.0645, 0.0535],\n",
      "        [0.0927, 0.0697, 0.0688, 0.0520]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.891716957092285\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 40\n",
      "X 資料 torch.Size([67, 18])\n",
      "Y 資料 torch.Size([67, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.008617883548140526, 26)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引26，y= tensor([0.7644, 0.7162, 0.5794, 0.4770])\n",
      "目前模型的Data torch.Size([40, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.8113, 0.8147, 0.8183, 0.7611],\n",
      "        [0.8220, 0.8262, 0.8305, 0.7729],\n",
      "        [0.8025, 0.8053, 0.8084, 0.7514],\n",
      "        [0.8066, 0.8097, 0.8130, 0.7559],\n",
      "        [0.7785, 0.7796, 0.7812, 0.7249],\n",
      "        [0.7434, 0.7421, 0.7415, 0.6863],\n",
      "        [0.7385, 0.7369, 0.7360, 0.6809],\n",
      "        [0.7134, 0.7101, 0.7077, 0.6533],\n",
      "        [0.7036, 0.6997, 0.6966, 0.6425],\n",
      "        [0.6945, 0.6899, 0.6863, 0.6325],\n",
      "        [0.7042, 0.7003, 0.6973, 0.6432],\n",
      "        [0.6969, 0.6924, 0.6889, 0.6351],\n",
      "        [0.6962, 0.6917, 0.6882, 0.6343],\n",
      "        [0.6932, 0.6885, 0.6848, 0.6310],\n",
      "        [0.7275, 0.7252, 0.7236, 0.6688],\n",
      "        [0.7746, 0.7755, 0.7769, 0.7207],\n",
      "        [0.7985, 0.8010, 0.8039, 0.7470],\n",
      "        [0.7932, 0.7954, 0.7979, 0.7411],\n",
      "        [0.8304, 0.8351, 0.8399, 0.7821],\n",
      "        [0.8610, 0.8679, 0.8746, 0.8158],\n",
      "        [0.7299, 0.7277, 0.7263, 0.6715],\n",
      "        [0.7417, 0.7403, 0.7396, 0.6844],\n",
      "        [0.8203, 0.8243, 0.8285, 0.7710],\n",
      "        [0.6688, 0.6624, 0.6572, 0.6041],\n",
      "        [0.6688, 0.6624, 0.6572, 0.6041],\n",
      "        [0.7747, 0.7756, 0.7770, 0.7208],\n",
      "        [0.7562, 0.7559, 0.7561, 0.7004],\n",
      "        [0.7869, 0.7886, 0.7908, 0.7342],\n",
      "        [0.6688, 0.6624, 0.6572, 0.6041],\n",
      "        [0.7664, 0.7667, 0.7676, 0.7116],\n",
      "        [0.7638, 0.7640, 0.7647, 0.7088],\n",
      "        [0.8042, 0.8072, 0.8104, 0.7533],\n",
      "        [0.6688, 0.6624, 0.6572, 0.6041],\n",
      "        [0.6688, 0.6624, 0.6572, 0.6041],\n",
      "        [0.6688, 0.6624, 0.6572, 0.6041],\n",
      "        [0.6688, 0.6624, 0.6572, 0.6041],\n",
      "        [0.6781, 0.6723, 0.6677, 0.6144],\n",
      "        [0.6688, 0.6624, 0.6572, 0.6041],\n",
      "        [0.6688, 0.6624, 0.6572, 0.6041],\n",
      "        [0.6701, 0.6638, 0.6587, 0.6056]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0366, 0.0218, 0.0035, 0.0323],\n",
      "        [0.0291, 0.0114, 0.0518, 0.0062],\n",
      "        [0.0123, 0.0266, 0.0108, 0.0011],\n",
      "        [0.0279, 0.0095, 0.0090, 0.0133],\n",
      "        [0.0408, 0.0244, 0.0407, 0.0158],\n",
      "        [0.0607, 0.0799, 0.0500, 0.0098],\n",
      "        [0.0834, 0.0545, 0.0078, 0.0132],\n",
      "        [0.0780, 0.0337, 0.0058, 0.0200],\n",
      "        [0.0402, 0.0138, 0.0199, 0.0263],\n",
      "        [0.0189, 0.0132, 0.0278, 0.0221],\n",
      "        [0.0276, 0.0418, 0.0451, 0.0289],\n",
      "        [0.0384, 0.0402, 0.0326, 0.0057],\n",
      "        [0.0440, 0.0353, 0.0156, 0.0144],\n",
      "        [0.0368, 0.0159, 0.0084, 0.0263],\n",
      "        [0.0550, 0.0320, 0.0213, 0.0611],\n",
      "        [0.0815, 0.0732, 0.0032, 0.0606],\n",
      "        [0.0962, 0.0210, 0.0309, 0.0388],\n",
      "        [0.0132, 0.0395, 0.0418, 0.0293],\n",
      "        [0.0044, 0.0046, 0.0167, 0.0123],\n",
      "        [0.0213, 0.0446, 0.0257, 0.0685],\n",
      "        [0.0361, 0.0526, 0.0501, 0.0321],\n",
      "        [0.0405, 0.0042, 0.0410, 0.0502],\n",
      "        [0.0272, 0.0327, 0.0230, 0.0390],\n",
      "        [0.0831, 0.1020, 0.0590, 0.0619],\n",
      "        [0.1076, 0.0894, 0.1073, 0.0661],\n",
      "        [0.0169, 0.0299, 0.0052, 0.0240],\n",
      "        [0.0493, 0.0263, 0.0116, 0.0467],\n",
      "        [0.0117, 0.0045, 0.0009, 0.0196],\n",
      "        [0.1115, 0.1140, 0.0947, 0.1113],\n",
      "        [0.0569, 0.0821, 0.0311, 0.0306],\n",
      "        [0.0851, 0.0347, 0.0285, 0.0320],\n",
      "        [0.0606, 0.0412, 0.0301, 0.0267],\n",
      "        [0.0399, 0.0208, 0.0406, 0.0650],\n",
      "        [0.0664, 0.0295, 0.0546, 0.1312],\n",
      "        [0.0979, 0.0335, 0.0155, 0.0271],\n",
      "        [0.0271, 0.0458, 0.0811, 0.0495],\n",
      "        [0.0742, 0.1015, 0.0388, 0.0139],\n",
      "        [0.0522, 0.0863, 0.0645, 0.0535],\n",
      "        [0.0927, 0.0697, 0.0688, 0.0520],\n",
      "        [0.0943, 0.0524, 0.0793, 0.1286]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 63\n",
      "Number of shrink: 37\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0377, 0.0201, 0.0013, 0.0295],\n",
      "        [0.0277, 0.0095, 0.0497, 0.0036],\n",
      "        [0.0133, 0.0248, 0.0135, 0.0043],\n",
      "        [0.0269, 0.0112, 0.0066, 0.0162],\n",
      "        [0.0410, 0.0256, 0.0438, 0.0194],\n",
      "        [0.0593, 0.0798, 0.0531, 0.0136],\n",
      "        [0.0819, 0.0543, 0.0109, 0.0095],\n",
      "        [0.0754, 0.0326, 0.0091, 0.0162],\n",
      "        [0.0374, 0.0127, 0.0163, 0.0220],\n",
      "        [0.0158, 0.0146, 0.0240, 0.0177],\n",
      "        [0.0300, 0.0426, 0.0411, 0.0243],\n",
      "        [0.0408, 0.0408, 0.0281, 0.0006],\n",
      "        [0.0463, 0.0358, 0.0110, 0.0196],\n",
      "        [0.0392, 0.0164, 0.0131, 0.0316],\n",
      "        [0.0565, 0.0320, 0.0174, 0.0656],\n",
      "        [0.0815, 0.0722, 0.0061, 0.0642],\n",
      "        [0.0958, 0.0199, 0.0331, 0.0416],\n",
      "        [0.0128, 0.0406, 0.0442, 0.0323],\n",
      "        [0.0055, 0.0061, 0.0155, 0.0141],\n",
      "        [0.0197, 0.0429, 0.0256, 0.0678],\n",
      "        [0.0364, 0.0545, 0.0559, 0.0385],\n",
      "        [0.0396, 0.0046, 0.0373, 0.0459],\n",
      "        [0.0265, 0.0316, 0.0218, 0.0372],\n",
      "        [0.0794, 0.1005, 0.0636, 0.0567],\n",
      "        [0.1040, 0.0879, 0.1118, 0.0713],\n",
      "        [0.0166, 0.0305, 0.0078, 0.0208],\n",
      "        [0.0488, 0.0271, 0.0081, 0.0426],\n",
      "        [0.0110, 0.0046, 0.0024, 0.0217],\n",
      "        [0.1079, 0.1124, 0.0993, 0.1165],\n",
      "        [0.0552, 0.0815, 0.0326, 0.0327],\n",
      "        [0.0835, 0.0341, 0.0302, 0.0344],\n",
      "        [0.0576, 0.0373, 0.0251, 0.0213],\n",
      "        [0.0435, 0.0223, 0.0360, 0.0598],\n",
      "        [0.0700, 0.0311, 0.0592, 0.1364],\n",
      "        [0.1016, 0.0351, 0.0110, 0.0219],\n",
      "        [0.0308, 0.0474, 0.0765, 0.0442],\n",
      "        [0.0759, 0.1010, 0.0324, 0.0069],\n",
      "        [0.0558, 0.0879, 0.0599, 0.0483],\n",
      "        [0.0963, 0.0713, 0.0642, 0.0468],\n",
      "        [0.0920, 0.0522, 0.0732, 0.1219]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 10.25454068183899\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 41\n",
      "X 資料 torch.Size([66, 18])\n",
      "Y 資料 torch.Size([66, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.009071806445717812, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引1，y= tensor([0.6986, 0.6777, 0.6534, 0.5816])\n",
      "目前模型的Data torch.Size([41, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.8102, 0.8130, 0.8161, 0.7582],\n",
      "        [0.8206, 0.8243, 0.8285, 0.7703],\n",
      "        [0.8015, 0.8036, 0.8057, 0.7482],\n",
      "        [0.8057, 0.8081, 0.8107, 0.7530],\n",
      "        [0.7783, 0.7784, 0.7782, 0.7213],\n",
      "        [0.7447, 0.7422, 0.7384, 0.6825],\n",
      "        [0.7401, 0.7372, 0.7329, 0.6772],\n",
      "        [0.7161, 0.7112, 0.7044, 0.6494],\n",
      "        [0.7064, 0.7007, 0.6929, 0.6382],\n",
      "        [0.6976, 0.6912, 0.6825, 0.6281],\n",
      "        [0.7067, 0.7011, 0.6933, 0.6386],\n",
      "        [0.6993, 0.6930, 0.6845, 0.6300],\n",
      "        [0.6985, 0.6922, 0.6835, 0.6290],\n",
      "        [0.6955, 0.6890, 0.6800, 0.6256],\n",
      "        [0.7290, 0.7251, 0.7197, 0.6643],\n",
      "        [0.7746, 0.7745, 0.7739, 0.7171],\n",
      "        [0.7981, 0.7999, 0.8017, 0.7442],\n",
      "        [0.7928, 0.7942, 0.7955, 0.7382],\n",
      "        [0.8293, 0.8336, 0.8388, 0.7804],\n",
      "        [0.8594, 0.8662, 0.8745, 0.8151],\n",
      "        [0.7296, 0.7258, 0.7204, 0.6650],\n",
      "        [0.7426, 0.7399, 0.7359, 0.6801],\n",
      "        [0.8196, 0.8232, 0.8273, 0.7692],\n",
      "        [0.6724, 0.6640, 0.6526, 0.5989],\n",
      "        [0.6724, 0.6640, 0.6526, 0.5989],\n",
      "        [0.7751, 0.7750, 0.7744, 0.7176],\n",
      "        [0.7567, 0.7551, 0.7526, 0.6964],\n",
      "        [0.7876, 0.7885, 0.7892, 0.7321],\n",
      "        [0.6724, 0.6640, 0.6526, 0.5989],\n",
      "        [0.7681, 0.7674, 0.7661, 0.7095],\n",
      "        [0.7654, 0.7645, 0.7629, 0.7064],\n",
      "        [0.8012, 0.8033, 0.8054, 0.7479],\n",
      "        [0.6724, 0.6640, 0.6526, 0.5989],\n",
      "        [0.6724, 0.6640, 0.6526, 0.5989],\n",
      "        [0.6724, 0.6640, 0.6526, 0.5989],\n",
      "        [0.6724, 0.6640, 0.6526, 0.5989],\n",
      "        [0.6797, 0.6719, 0.6613, 0.6074],\n",
      "        [0.6724, 0.6640, 0.6526, 0.5989],\n",
      "        [0.6724, 0.6640, 0.6526, 0.5989],\n",
      "        [0.6724, 0.6640, 0.6526, 0.5989],\n",
      "        [0.7615, 0.7603, 0.7583, 0.7019]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0377, 0.0201, 0.0013, 0.0295],\n",
      "        [0.0277, 0.0095, 0.0497, 0.0036],\n",
      "        [0.0133, 0.0248, 0.0135, 0.0043],\n",
      "        [0.0269, 0.0112, 0.0066, 0.0162],\n",
      "        [0.0410, 0.0256, 0.0438, 0.0194],\n",
      "        [0.0593, 0.0798, 0.0531, 0.0136],\n",
      "        [0.0819, 0.0543, 0.0109, 0.0095],\n",
      "        [0.0754, 0.0326, 0.0091, 0.0162],\n",
      "        [0.0374, 0.0127, 0.0163, 0.0220],\n",
      "        [0.0158, 0.0146, 0.0240, 0.0177],\n",
      "        [0.0300, 0.0426, 0.0411, 0.0243],\n",
      "        [0.0408, 0.0408, 0.0281, 0.0006],\n",
      "        [0.0463, 0.0358, 0.0110, 0.0196],\n",
      "        [0.0392, 0.0164, 0.0131, 0.0316],\n",
      "        [0.0565, 0.0320, 0.0174, 0.0656],\n",
      "        [0.0815, 0.0722, 0.0061, 0.0642],\n",
      "        [0.0958, 0.0199, 0.0331, 0.0416],\n",
      "        [0.0128, 0.0406, 0.0442, 0.0323],\n",
      "        [0.0055, 0.0061, 0.0155, 0.0141],\n",
      "        [0.0197, 0.0429, 0.0256, 0.0678],\n",
      "        [0.0364, 0.0545, 0.0559, 0.0385],\n",
      "        [0.0396, 0.0046, 0.0373, 0.0459],\n",
      "        [0.0265, 0.0316, 0.0218, 0.0372],\n",
      "        [0.0794, 0.1005, 0.0636, 0.0567],\n",
      "        [0.1040, 0.0879, 0.1118, 0.0713],\n",
      "        [0.0166, 0.0305, 0.0078, 0.0208],\n",
      "        [0.0488, 0.0271, 0.0081, 0.0426],\n",
      "        [0.0110, 0.0046, 0.0024, 0.0217],\n",
      "        [0.1079, 0.1124, 0.0993, 0.1165],\n",
      "        [0.0552, 0.0815, 0.0326, 0.0327],\n",
      "        [0.0835, 0.0341, 0.0302, 0.0344],\n",
      "        [0.0576, 0.0373, 0.0251, 0.0213],\n",
      "        [0.0435, 0.0223, 0.0360, 0.0598],\n",
      "        [0.0700, 0.0311, 0.0592, 0.1364],\n",
      "        [0.1016, 0.0351, 0.0110, 0.0219],\n",
      "        [0.0308, 0.0474, 0.0765, 0.0442],\n",
      "        [0.0759, 0.1010, 0.0324, 0.0069],\n",
      "        [0.0558, 0.0879, 0.0599, 0.0483],\n",
      "        [0.0963, 0.0713, 0.0642, 0.0468],\n",
      "        [0.0920, 0.0522, 0.0732, 0.1219],\n",
      "        [0.0629, 0.0826, 0.1049, 0.1204]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0427,     0.0144,     0.0051,     0.0229],\n",
      "        [    0.0226,     0.0038,     0.0434,     0.0029],\n",
      "        [    0.0161,     0.0216,     0.0172,     0.0083],\n",
      "        [    0.0249,     0.0135,     0.0039,     0.0192],\n",
      "        [    0.0428,     0.0277,     0.0462,     0.0222],\n",
      "        [    0.0588,     0.0794,     0.0528,     0.0138],\n",
      "        [    0.0822,     0.0548,     0.0116,     0.0082],\n",
      "        [    0.0753,     0.0327,     0.0093,     0.0152],\n",
      "        [    0.0372,     0.0127,     0.0162,     0.0212],\n",
      "        [    0.0144,     0.0160,     0.0255,     0.0184],\n",
      "        [    0.0294,     0.0418,     0.0401,     0.0226],\n",
      "        [    0.0411,     0.0410,     0.0282,     0.0001],\n",
      "        [    0.0468,     0.0363,     0.0114,     0.0200],\n",
      "        [    0.0401,     0.0174,     0.0122,     0.0315],\n",
      "        [    0.0579,     0.0334,     0.0188,     0.0649],\n",
      "        [    0.0810,     0.0716,     0.0070,     0.0655],\n",
      "        [    0.0939,     0.0177,     0.0357,     0.0445],\n",
      "        [    0.0098,     0.0440,     0.0481,     0.0364],\n",
      "        [    0.0099,     0.0109,     0.0100,     0.0197],\n",
      "        [    0.0152,     0.0379,     0.0199,     0.0620],\n",
      "        [    0.0371,     0.0554,     0.0570,     0.0403],\n",
      "        [    0.0489,     0.0149,     0.0259,     0.0342],\n",
      "        [    0.0208,     0.0252,     0.0147,     0.0299],\n",
      "        [    0.0782,     0.0992,     0.0624,     0.0570],\n",
      "        [    0.1027,     0.0866,     0.1106,     0.0710],\n",
      "        [    0.0239,     0.0386,     0.0168,     0.0115],\n",
      "        [    0.0587,     0.0379,     0.0039,     0.0303],\n",
      "        [    0.0169,     0.0110,     0.0096,     0.0292],\n",
      "        [    0.1067,     0.1112,     0.0980,     0.1162],\n",
      "        [    0.0577,     0.0844,     0.0359,     0.0365],\n",
      "        [    0.0873,     0.0384,     0.0350,     0.0396],\n",
      "        [    0.0549,     0.0342,     0.0216,     0.0175],\n",
      "        [    0.0448,     0.0236,     0.0372,     0.0601],\n",
      "        [    0.0712,     0.0323,     0.0579,     0.1361],\n",
      "        [    0.1028,     0.0363,     0.0122,     0.0222],\n",
      "        [    0.0320,     0.0486,     0.0777,     0.0446],\n",
      "        [    0.0705,     0.0951,     0.0257,     0.0004],\n",
      "        [    0.0571,     0.0891,     0.0611,     0.0486],\n",
      "        [    0.0976,     0.0725,     0.0654,     0.0471],\n",
      "        [    0.0908,     0.0510,     0.0744,     0.1222],\n",
      "        [    0.0507,     0.0693,     0.0902,     0.1054]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 10.608229637145996\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 42\n",
      "X 資料 torch.Size([65, 18])\n",
      "Y 資料 torch.Size([65, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.007045379839837551, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.7445, 0.6986, 0.6777, 0.6114])\n",
      "目前模型的Data torch.Size([42, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.8051, 0.8073, 0.8097, 0.7517],\n",
      "        [0.8155, 0.8186, 0.8221, 0.7638],\n",
      "        [0.7987, 0.8003, 0.8021, 0.7442],\n",
      "        [0.8037, 0.8058, 0.8080, 0.7500],\n",
      "        [0.7765, 0.7763, 0.7757, 0.7185],\n",
      "        [0.7452, 0.7426, 0.7387, 0.6822],\n",
      "        [0.7398, 0.7367, 0.7322, 0.6759],\n",
      "        [0.7161, 0.7111, 0.7042, 0.6485],\n",
      "        [0.7066, 0.7008, 0.6929, 0.6374],\n",
      "        [0.6991, 0.6927, 0.6840, 0.6288],\n",
      "        [0.7061, 0.7003, 0.6923, 0.6369],\n",
      "        [0.6996, 0.6932, 0.6846, 0.6293],\n",
      "        [0.6990, 0.6926, 0.6839, 0.6287],\n",
      "        [0.6965, 0.6899, 0.6809, 0.6257],\n",
      "        [0.7304, 0.7266, 0.7211, 0.6651],\n",
      "        [0.7742, 0.7739, 0.7730, 0.7158],\n",
      "        [0.7962, 0.7977, 0.7992, 0.7414],\n",
      "        [0.7899, 0.7908, 0.7916, 0.7340],\n",
      "        [0.8249, 0.8288, 0.8332, 0.7747],\n",
      "        [0.8549, 0.8611, 0.8687, 0.8094],\n",
      "        [0.7289, 0.7249, 0.7193, 0.6633],\n",
      "        [0.7333, 0.7297, 0.7245, 0.6684],\n",
      "        [0.8139, 0.8168, 0.8201, 0.7619],\n",
      "        [0.6736, 0.6652, 0.6538, 0.5992],\n",
      "        [0.6736, 0.6652, 0.6538, 0.5992],\n",
      "        [0.7677, 0.7669, 0.7653, 0.7083],\n",
      "        [0.7468, 0.7443, 0.7406, 0.6841],\n",
      "        [0.7817, 0.7821, 0.7820, 0.7246],\n",
      "        [0.6736, 0.6652, 0.6538, 0.5992],\n",
      "        [0.7655, 0.7645, 0.7628, 0.7058],\n",
      "        [0.7616, 0.7603, 0.7581, 0.7012],\n",
      "        [0.7985, 0.8002, 0.8019, 0.7441],\n",
      "        [0.6736, 0.6652, 0.6538, 0.5992],\n",
      "        [0.6736, 0.6652, 0.6538, 0.5992],\n",
      "        [0.6736, 0.6652, 0.6538, 0.5992],\n",
      "        [0.6736, 0.6652, 0.6538, 0.5992],\n",
      "        [0.6743, 0.6659, 0.6546, 0.6000],\n",
      "        [0.6736, 0.6652, 0.6538, 0.5992],\n",
      "        [0.6736, 0.6652, 0.6538, 0.5992],\n",
      "        [0.6736, 0.6652, 0.6538, 0.5992],\n",
      "        [0.7493, 0.7470, 0.7435, 0.6869],\n",
      "        [0.7765, 0.7764, 0.7758, 0.7185]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0427,     0.0144,     0.0051,     0.0229],\n",
      "        [    0.0226,     0.0038,     0.0434,     0.0029],\n",
      "        [    0.0161,     0.0216,     0.0172,     0.0083],\n",
      "        [    0.0249,     0.0135,     0.0039,     0.0192],\n",
      "        [    0.0428,     0.0277,     0.0462,     0.0222],\n",
      "        [    0.0588,     0.0794,     0.0528,     0.0138],\n",
      "        [    0.0822,     0.0548,     0.0116,     0.0082],\n",
      "        [    0.0753,     0.0327,     0.0093,     0.0152],\n",
      "        [    0.0372,     0.0127,     0.0162,     0.0212],\n",
      "        [    0.0144,     0.0160,     0.0255,     0.0184],\n",
      "        [    0.0294,     0.0418,     0.0401,     0.0226],\n",
      "        [    0.0411,     0.0410,     0.0282,     0.0001],\n",
      "        [    0.0468,     0.0363,     0.0114,     0.0200],\n",
      "        [    0.0401,     0.0174,     0.0122,     0.0315],\n",
      "        [    0.0579,     0.0334,     0.0188,     0.0649],\n",
      "        [    0.0810,     0.0716,     0.0070,     0.0655],\n",
      "        [    0.0939,     0.0177,     0.0357,     0.0445],\n",
      "        [    0.0098,     0.0440,     0.0481,     0.0364],\n",
      "        [    0.0099,     0.0109,     0.0100,     0.0197],\n",
      "        [    0.0152,     0.0379,     0.0199,     0.0620],\n",
      "        [    0.0371,     0.0554,     0.0570,     0.0403],\n",
      "        [    0.0489,     0.0149,     0.0259,     0.0342],\n",
      "        [    0.0208,     0.0252,     0.0147,     0.0299],\n",
      "        [    0.0782,     0.0992,     0.0624,     0.0570],\n",
      "        [    0.1027,     0.0866,     0.1106,     0.0710],\n",
      "        [    0.0239,     0.0386,     0.0168,     0.0115],\n",
      "        [    0.0587,     0.0379,     0.0039,     0.0303],\n",
      "        [    0.0169,     0.0110,     0.0096,     0.0292],\n",
      "        [    0.1067,     0.1112,     0.0980,     0.1162],\n",
      "        [    0.0577,     0.0844,     0.0359,     0.0365],\n",
      "        [    0.0873,     0.0384,     0.0350,     0.0396],\n",
      "        [    0.0549,     0.0342,     0.0216,     0.0175],\n",
      "        [    0.0448,     0.0236,     0.0372,     0.0601],\n",
      "        [    0.0712,     0.0323,     0.0579,     0.1361],\n",
      "        [    0.1028,     0.0363,     0.0122,     0.0222],\n",
      "        [    0.0320,     0.0486,     0.0777,     0.0446],\n",
      "        [    0.0705,     0.0951,     0.0257,     0.0004],\n",
      "        [    0.0571,     0.0891,     0.0611,     0.0486],\n",
      "        [    0.0976,     0.0725,     0.0654,     0.0471],\n",
      "        [    0.0908,     0.0510,     0.0744,     0.1222],\n",
      "        [    0.0507,     0.0693,     0.0902,     0.1054],\n",
      "        [    0.0320,     0.0778,     0.0981,     0.1071]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 63\n",
      "Number of shrink: 37\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0438, 0.0123, 0.0070, 0.0210],\n",
      "        [0.0215, 0.0015, 0.0414, 0.0048],\n",
      "        [0.0162, 0.0205, 0.0181, 0.0091],\n",
      "        [0.0254, 0.0140, 0.0037, 0.0194],\n",
      "        [0.0424, 0.0282, 0.0468, 0.0228],\n",
      "        [0.0572, 0.0784, 0.0521, 0.0133],\n",
      "        [0.0807, 0.0541, 0.0113, 0.0085],\n",
      "        [0.0735, 0.0315, 0.0088, 0.0157],\n",
      "        [0.0358, 0.0119, 0.0161, 0.0210],\n",
      "        [0.0125, 0.0173, 0.0258, 0.0187],\n",
      "        [0.0297, 0.0412, 0.0385, 0.0210],\n",
      "        [0.0416, 0.0408, 0.0269, 0.0014],\n",
      "        [0.0477, 0.0365, 0.0106, 0.0209],\n",
      "        [0.0413, 0.0179, 0.0127, 0.0321],\n",
      "        [0.0597, 0.0345, 0.0194, 0.0644],\n",
      "        [0.0817, 0.0713, 0.0073, 0.0658],\n",
      "        [0.0936, 0.0164, 0.0368, 0.0456],\n",
      "        [0.0094, 0.0455, 0.0495, 0.0378],\n",
      "        [0.0108, 0.0130, 0.0084, 0.0213],\n",
      "        [0.0144, 0.0360, 0.0188, 0.0610],\n",
      "        [0.0344, 0.0533, 0.0554, 0.0387],\n",
      "        [0.0542, 0.0214, 0.0181, 0.0265],\n",
      "        [0.0173, 0.0204, 0.0099, 0.0252],\n",
      "        [0.0792, 0.1011, 0.0658, 0.0536],\n",
      "        [0.1037, 0.0885, 0.1140, 0.0744],\n",
      "        [0.0285, 0.0445, 0.0235, 0.0050],\n",
      "        [0.0644, 0.0449, 0.0122, 0.0222],\n",
      "        [0.0203, 0.0157, 0.0147, 0.0342],\n",
      "        [0.1077, 0.1130, 0.1014, 0.1196],\n",
      "        [0.0583, 0.0858, 0.0377, 0.0382],\n",
      "        [0.0893, 0.0415, 0.0387, 0.0432],\n",
      "        [0.0569, 0.0355, 0.0233, 0.0192],\n",
      "        [0.0438, 0.0217, 0.0338, 0.0567],\n",
      "        [0.0702, 0.0305, 0.0613, 0.1395],\n",
      "        [0.1018, 0.0345, 0.0088, 0.0188],\n",
      "        [0.0310, 0.0468, 0.0743, 0.0412],\n",
      "        [0.0688, 0.0925, 0.0215, 0.0046],\n",
      "        [0.0561, 0.0873, 0.0577, 0.0452],\n",
      "        [0.0966, 0.0707, 0.0620, 0.0437],\n",
      "        [0.0917, 0.0528, 0.0711, 0.1189],\n",
      "        [0.0437, 0.0609, 0.0805, 0.0959],\n",
      "        [0.0262, 0.0707, 0.0902, 0.0993]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 10.979552984237671\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 43\n",
      "X 資料 torch.Size([64, 18])\n",
      "Y 資料 torch.Size([64, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.007213495206087828, 2)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引2，y= tensor([0.6214, 0.5756, 0.5930, 0.5623])\n",
      "目前模型的Data torch.Size([43, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.8041, 0.8052, 0.8078, 0.7498],\n",
      "        [0.8144, 0.8163, 0.8201, 0.7618],\n",
      "        [0.7986, 0.7993, 0.8012, 0.7433],\n",
      "        [0.8041, 0.8052, 0.8078, 0.7498],\n",
      "        [0.7769, 0.7758, 0.7752, 0.7179],\n",
      "        [0.7469, 0.7435, 0.7393, 0.6828],\n",
      "        [0.7412, 0.7374, 0.7325, 0.6762],\n",
      "        [0.7180, 0.7123, 0.7047, 0.6489],\n",
      "        [0.7080, 0.7015, 0.6928, 0.6373],\n",
      "        [0.7010, 0.6940, 0.6844, 0.6290],\n",
      "        [0.7063, 0.6997, 0.6908, 0.6353],\n",
      "        [0.7001, 0.6930, 0.6833, 0.6280],\n",
      "        [0.6999, 0.6928, 0.6831, 0.6278],\n",
      "        [0.6977, 0.6904, 0.6804, 0.6252],\n",
      "        [0.7322, 0.7277, 0.7217, 0.6656],\n",
      "        [0.7748, 0.7736, 0.7727, 0.7155],\n",
      "        [0.7959, 0.7964, 0.7980, 0.7403],\n",
      "        [0.7894, 0.7894, 0.7902, 0.7326],\n",
      "        [0.8240, 0.8267, 0.8316, 0.7731],\n",
      "        [0.8541, 0.8592, 0.8677, 0.8084],\n",
      "        [0.7316, 0.7270, 0.7210, 0.6649],\n",
      "        [0.7280, 0.7231, 0.7167, 0.6607],\n",
      "        [0.8104, 0.8121, 0.8154, 0.7572],\n",
      "        [0.6727, 0.6634, 0.6504, 0.5958],\n",
      "        [0.6727, 0.6634, 0.6504, 0.5958],\n",
      "        [0.7631, 0.7610, 0.7587, 0.7018],\n",
      "        [0.7411, 0.7372, 0.7324, 0.6760],\n",
      "        [0.7783, 0.7774, 0.7769, 0.7196],\n",
      "        [0.6727, 0.6634, 0.6504, 0.5958],\n",
      "        [0.7650, 0.7630, 0.7610, 0.7040],\n",
      "        [0.7595, 0.7571, 0.7544, 0.6976],\n",
      "        [0.8006, 0.8015, 0.8036, 0.7457],\n",
      "        [0.6727, 0.6634, 0.6504, 0.5958],\n",
      "        [0.6727, 0.6634, 0.6504, 0.5958],\n",
      "        [0.6727, 0.6634, 0.6504, 0.5958],\n",
      "        [0.6727, 0.6634, 0.6504, 0.5958],\n",
      "        [0.6727, 0.6634, 0.6504, 0.5958],\n",
      "        [0.6727, 0.6634, 0.6504, 0.5958],\n",
      "        [0.6727, 0.6634, 0.6504, 0.5958],\n",
      "        [0.6727, 0.6634, 0.6505, 0.5959],\n",
      "        [0.7423, 0.7386, 0.7338, 0.6774],\n",
      "        [0.7707, 0.7692, 0.7679, 0.7107],\n",
      "        [0.6954, 0.6879, 0.6776, 0.6224]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0438, 0.0123, 0.0070, 0.0210],\n",
      "        [0.0215, 0.0015, 0.0414, 0.0048],\n",
      "        [0.0162, 0.0205, 0.0181, 0.0091],\n",
      "        [0.0254, 0.0140, 0.0037, 0.0194],\n",
      "        [0.0424, 0.0282, 0.0468, 0.0228],\n",
      "        [0.0572, 0.0784, 0.0521, 0.0133],\n",
      "        [0.0807, 0.0541, 0.0113, 0.0085],\n",
      "        [0.0735, 0.0315, 0.0088, 0.0157],\n",
      "        [0.0358, 0.0119, 0.0161, 0.0210],\n",
      "        [0.0125, 0.0173, 0.0258, 0.0187],\n",
      "        [0.0297, 0.0412, 0.0385, 0.0210],\n",
      "        [0.0416, 0.0408, 0.0269, 0.0014],\n",
      "        [0.0477, 0.0365, 0.0106, 0.0209],\n",
      "        [0.0413, 0.0179, 0.0127, 0.0321],\n",
      "        [0.0597, 0.0345, 0.0194, 0.0644],\n",
      "        [0.0817, 0.0713, 0.0073, 0.0658],\n",
      "        [0.0936, 0.0164, 0.0368, 0.0456],\n",
      "        [0.0094, 0.0455, 0.0495, 0.0378],\n",
      "        [0.0108, 0.0130, 0.0084, 0.0213],\n",
      "        [0.0144, 0.0360, 0.0188, 0.0610],\n",
      "        [0.0344, 0.0533, 0.0554, 0.0387],\n",
      "        [0.0542, 0.0214, 0.0181, 0.0265],\n",
      "        [0.0173, 0.0204, 0.0099, 0.0252],\n",
      "        [0.0792, 0.1011, 0.0658, 0.0536],\n",
      "        [0.1037, 0.0885, 0.1140, 0.0744],\n",
      "        [0.0285, 0.0445, 0.0235, 0.0050],\n",
      "        [0.0644, 0.0449, 0.0122, 0.0222],\n",
      "        [0.0203, 0.0157, 0.0147, 0.0342],\n",
      "        [0.1077, 0.1130, 0.1014, 0.1196],\n",
      "        [0.0583, 0.0858, 0.0377, 0.0382],\n",
      "        [0.0893, 0.0415, 0.0387, 0.0432],\n",
      "        [0.0569, 0.0355, 0.0233, 0.0192],\n",
      "        [0.0438, 0.0217, 0.0338, 0.0567],\n",
      "        [0.0702, 0.0305, 0.0613, 0.1395],\n",
      "        [0.1018, 0.0345, 0.0088, 0.0188],\n",
      "        [0.0310, 0.0468, 0.0743, 0.0412],\n",
      "        [0.0688, 0.0925, 0.0215, 0.0046],\n",
      "        [0.0561, 0.0873, 0.0577, 0.0452],\n",
      "        [0.0966, 0.0707, 0.0620, 0.0437],\n",
      "        [0.0917, 0.0528, 0.0711, 0.1189],\n",
      "        [0.0437, 0.0609, 0.0805, 0.0959],\n",
      "        [0.0262, 0.0707, 0.0902, 0.0993],\n",
      "        [0.0739, 0.1123, 0.0847, 0.0602]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0466,     0.0104,     0.0087,     0.0200],\n",
      "        [    0.0187,     0.0000,     0.0399,     0.0056],\n",
      "        [    0.0162,     0.0217,     0.0164,     0.0069],\n",
      "        [    0.0267,     0.0113,     0.0071,     0.0154],\n",
      "        [    0.0414,     0.0267,     0.0445,     0.0201],\n",
      "        [    0.0541,     0.0755,     0.0480,     0.0089],\n",
      "        [    0.0787,     0.0524,     0.0085,     0.0114],\n",
      "        [    0.0716,     0.0307,     0.0068,     0.0177],\n",
      "        [    0.0339,     0.0114,     0.0178,     0.0228],\n",
      "        [    0.0091,     0.0193,     0.0293,     0.0221],\n",
      "        [    0.0301,     0.0401,     0.0385,     0.0211],\n",
      "        [    0.0434,     0.0410,     0.0284,     0.0001],\n",
      "        [    0.0499,     0.0370,     0.0124,     0.0190],\n",
      "        [    0.0438,     0.0188,     0.0105,     0.0298],\n",
      "        [    0.0639,     0.0383,     0.0246,     0.0591],\n",
      "        [    0.0843,     0.0746,     0.0030,     0.0611],\n",
      "        [    0.0948,     0.0186,     0.0339,     0.0422],\n",
      "        [    0.0089,     0.0452,     0.0487,     0.0365],\n",
      "        [    0.0126,     0.0131,     0.0084,     0.0205],\n",
      "        [    0.0139,     0.0381,     0.0211,     0.0642],\n",
      "        [    0.0353,     0.0552,     0.0565,     0.0396],\n",
      "        [    0.0659,     0.0354,     0.0037,     0.0125],\n",
      "        [    0.0127,     0.0167,     0.0061,     0.0222],\n",
      "        [    0.0783,     0.1027,     0.0662,     0.0531],\n",
      "        [    0.1029,     0.0901,     0.1144,     0.0749],\n",
      "        [    0.0366,     0.0535,     0.0326,     0.0036],\n",
      "        [    0.0763,     0.0588,     0.0265,     0.0084],\n",
      "        [    0.0250,     0.0204,     0.0193,     0.0383],\n",
      "        [    0.1068,     0.1147,     0.1018,     0.1201],\n",
      "        [    0.0585,     0.0860,     0.0371,     0.0373],\n",
      "        [    0.0914,     0.0438,     0.0405,     0.0447],\n",
      "        [    0.0550,     0.0345,     0.0226,     0.0191],\n",
      "        [    0.0446,     0.0201,     0.0335,     0.0562],\n",
      "        [    0.0711,     0.0288,     0.0617,     0.1400],\n",
      "        [    0.1026,     0.0328,     0.0084,     0.0183],\n",
      "        [    0.0319,     0.0451,     0.0740,     0.0407],\n",
      "        [    0.0696,     0.0908,     0.0212,     0.0052],\n",
      "        [    0.0569,     0.0856,     0.0574,     0.0447],\n",
      "        [    0.0974,     0.0690,     0.0617,     0.0432],\n",
      "        [    0.0909,     0.0545,     0.0707,     0.1183],\n",
      "        [    0.0284,     0.0433,     0.0620,     0.0780],\n",
      "        [    0.0133,     0.0565,     0.0753,     0.0851],\n",
      "        [    0.0560,     0.0904,     0.0619,     0.0377]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 11.33927035331726\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 44\n",
      "X 資料 torch.Size([63, 18])\n",
      "Y 資料 torch.Size([63, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.005243330728262663, 2)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引2，y= tensor([0.5756, 0.5930, 0.6008, 0.5904])\n",
      "目前模型的Data torch.Size([44, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.8013, 0.8033, 0.8061, 0.7487],\n",
      "        [0.8116, 0.8148, 0.8187, 0.7611],\n",
      "        [0.7986, 0.8004, 0.8029, 0.7456],\n",
      "        [0.8055, 0.8080, 0.8112, 0.7538],\n",
      "        [0.7778, 0.7773, 0.7774, 0.7206],\n",
      "        [0.7500, 0.7465, 0.7435, 0.6872],\n",
      "        [0.7433, 0.7390, 0.7353, 0.6791],\n",
      "        [0.7199, 0.7131, 0.7067, 0.6510],\n",
      "        [0.7099, 0.7020, 0.6945, 0.6390],\n",
      "        [0.7044, 0.6960, 0.6878, 0.6324],\n",
      "        [0.7068, 0.6986, 0.6908, 0.6353],\n",
      "        [0.7019, 0.6932, 0.6848, 0.6295],\n",
      "        [0.7021, 0.6934, 0.6849, 0.6296],\n",
      "        [0.7002, 0.6913, 0.6827, 0.6274],\n",
      "        [0.7364, 0.7314, 0.7269, 0.6709],\n",
      "        [0.7775, 0.7769, 0.7770, 0.7201],\n",
      "        [0.7971, 0.7987, 0.8009, 0.7437],\n",
      "        [0.7889, 0.7896, 0.7910, 0.7339],\n",
      "        [0.8222, 0.8266, 0.8317, 0.7739],\n",
      "        [0.8536, 0.8613, 0.8699, 0.8115],\n",
      "        [0.7307, 0.7251, 0.7199, 0.6640],\n",
      "        [0.7163, 0.7091, 0.7023, 0.6467],\n",
      "        [0.8058, 0.8083, 0.8116, 0.7541],\n",
      "        [0.6735, 0.6617, 0.6500, 0.5953],\n",
      "        [0.6735, 0.6617, 0.6500, 0.5953],\n",
      "        [0.7550, 0.7520, 0.7496, 0.6932],\n",
      "        [0.7292, 0.7234, 0.7180, 0.6622],\n",
      "        [0.7736, 0.7727, 0.7723, 0.7155],\n",
      "        [0.6735, 0.6617, 0.6500, 0.5953],\n",
      "        [0.7648, 0.7629, 0.7615, 0.7049],\n",
      "        [0.7575, 0.7548, 0.7526, 0.6962],\n",
      "        [0.7987, 0.8005, 0.8029, 0.7456],\n",
      "        [0.6735, 0.6617, 0.6500, 0.5953],\n",
      "        [0.6735, 0.6617, 0.6500, 0.5953],\n",
      "        [0.6735, 0.6617, 0.6500, 0.5953],\n",
      "        [0.6735, 0.6617, 0.6500, 0.5953],\n",
      "        [0.6735, 0.6617, 0.6500, 0.5953],\n",
      "        [0.6735, 0.6617, 0.6500, 0.5953],\n",
      "        [0.6735, 0.6617, 0.6500, 0.5953],\n",
      "        [0.6735, 0.6617, 0.6500, 0.5953],\n",
      "        [0.7270, 0.7210, 0.7154, 0.6596],\n",
      "        [0.7578, 0.7551, 0.7530, 0.6965],\n",
      "        [0.6774, 0.6660, 0.6548, 0.6000],\n",
      "        [0.6816, 0.6707, 0.6599, 0.6050]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0466,     0.0104,     0.0087,     0.0200],\n",
      "        [    0.0187,     0.0000,     0.0399,     0.0056],\n",
      "        [    0.0162,     0.0217,     0.0164,     0.0069],\n",
      "        [    0.0267,     0.0113,     0.0071,     0.0154],\n",
      "        [    0.0414,     0.0267,     0.0445,     0.0201],\n",
      "        [    0.0541,     0.0755,     0.0480,     0.0089],\n",
      "        [    0.0787,     0.0524,     0.0085,     0.0114],\n",
      "        [    0.0716,     0.0307,     0.0068,     0.0177],\n",
      "        [    0.0339,     0.0114,     0.0178,     0.0228],\n",
      "        [    0.0091,     0.0193,     0.0293,     0.0221],\n",
      "        [    0.0301,     0.0401,     0.0385,     0.0211],\n",
      "        [    0.0434,     0.0410,     0.0284,     0.0001],\n",
      "        [    0.0499,     0.0370,     0.0124,     0.0190],\n",
      "        [    0.0438,     0.0188,     0.0105,     0.0298],\n",
      "        [    0.0639,     0.0383,     0.0246,     0.0591],\n",
      "        [    0.0843,     0.0746,     0.0030,     0.0611],\n",
      "        [    0.0948,     0.0186,     0.0339,     0.0422],\n",
      "        [    0.0089,     0.0452,     0.0487,     0.0365],\n",
      "        [    0.0126,     0.0131,     0.0084,     0.0205],\n",
      "        [    0.0139,     0.0381,     0.0211,     0.0642],\n",
      "        [    0.0353,     0.0552,     0.0565,     0.0396],\n",
      "        [    0.0659,     0.0354,     0.0037,     0.0125],\n",
      "        [    0.0127,     0.0167,     0.0061,     0.0222],\n",
      "        [    0.0783,     0.1027,     0.0662,     0.0531],\n",
      "        [    0.1029,     0.0901,     0.1144,     0.0749],\n",
      "        [    0.0366,     0.0535,     0.0326,     0.0036],\n",
      "        [    0.0763,     0.0588,     0.0265,     0.0084],\n",
      "        [    0.0250,     0.0204,     0.0193,     0.0383],\n",
      "        [    0.1068,     0.1147,     0.1018,     0.1201],\n",
      "        [    0.0585,     0.0860,     0.0371,     0.0373],\n",
      "        [    0.0914,     0.0438,     0.0405,     0.0447],\n",
      "        [    0.0550,     0.0345,     0.0226,     0.0191],\n",
      "        [    0.0446,     0.0201,     0.0335,     0.0562],\n",
      "        [    0.0711,     0.0288,     0.0617,     0.1400],\n",
      "        [    0.1026,     0.0328,     0.0084,     0.0183],\n",
      "        [    0.0319,     0.0451,     0.0740,     0.0407],\n",
      "        [    0.0696,     0.0908,     0.0212,     0.0052],\n",
      "        [    0.0569,     0.0856,     0.0574,     0.0447],\n",
      "        [    0.0974,     0.0690,     0.0617,     0.0432],\n",
      "        [    0.0909,     0.0545,     0.0707,     0.1183],\n",
      "        [    0.0284,     0.0433,     0.0620,     0.0780],\n",
      "        [    0.0133,     0.0565,     0.0753,     0.0851],\n",
      "        [    0.0560,     0.0904,     0.0619,     0.0377],\n",
      "        [    0.1059,     0.0777,     0.0591,     0.0146]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0454, 0.0122, 0.0064, 0.0229],\n",
      "        [0.0203, 0.0021, 0.0426, 0.0023],\n",
      "        [0.0139, 0.0245, 0.0128, 0.0027],\n",
      "        [0.0298, 0.0075, 0.0116, 0.0104],\n",
      "        [0.0398, 0.0244, 0.0414, 0.0162],\n",
      "        [0.0528, 0.0735, 0.0451, 0.0050],\n",
      "        [0.0780, 0.0510, 0.0063, 0.0148],\n",
      "        [0.0720, 0.0304, 0.0056, 0.0203],\n",
      "        [0.0344, 0.0111, 0.0190, 0.0255],\n",
      "        [0.0095, 0.0197, 0.0306, 0.0249],\n",
      "        [0.0291, 0.0398, 0.0391, 0.0232],\n",
      "        [0.0422, 0.0405, 0.0288, 0.0020],\n",
      "        [0.0486, 0.0366, 0.0128, 0.0171],\n",
      "        [0.0426, 0.0183, 0.0101, 0.0279],\n",
      "        [0.0647, 0.0399, 0.0271, 0.0554],\n",
      "        [0.0864, 0.0774, 0.0006, 0.0567],\n",
      "        [0.0970, 0.0215, 0.0303, 0.0379],\n",
      "        [0.0106, 0.0429, 0.0457, 0.0328],\n",
      "        [0.0093, 0.0092, 0.0130, 0.0155],\n",
      "        [0.0194, 0.0442, 0.0280, 0.0712],\n",
      "        [0.0359, 0.0551, 0.0556, 0.0374],\n",
      "        [0.0709, 0.0401, 0.0006, 0.0097],\n",
      "        [0.0141, 0.0187, 0.0086, 0.0253],\n",
      "        [0.0853, 0.1093, 0.0724, 0.0489],\n",
      "        [0.1098, 0.0967, 0.1206, 0.0792],\n",
      "        [0.0386, 0.0551, 0.0337, 0.0036],\n",
      "        [0.0810, 0.0632, 0.0306, 0.0058],\n",
      "        [0.0241, 0.0190, 0.0171, 0.0352],\n",
      "        [0.1138, 0.1213, 0.1080, 0.1243],\n",
      "        [0.0568, 0.0836, 0.0339, 0.0331],\n",
      "        [0.0903, 0.0421, 0.0379, 0.0411],\n",
      "        [0.0570, 0.0370, 0.0258, 0.0229],\n",
      "        [0.0377, 0.0135, 0.0273, 0.0520],\n",
      "        [0.0641, 0.0222, 0.0679, 0.1443],\n",
      "        [0.0957, 0.0262, 0.0022, 0.0141],\n",
      "        [0.0249, 0.0385, 0.0678, 0.0364],\n",
      "        [0.0627, 0.0842, 0.0149, 0.0094],\n",
      "        [0.0500, 0.0790, 0.0512, 0.0405],\n",
      "        [0.0905, 0.0624, 0.0555, 0.0390],\n",
      "        [0.0960, 0.0590, 0.0667, 0.1163],\n",
      "        [0.0220, 0.0370, 0.0558, 0.0733],\n",
      "        [0.0092, 0.0527, 0.0716, 0.0826],\n",
      "        [0.0451, 0.0795, 0.0509, 0.0288],\n",
      "        [0.0965, 0.0683, 0.0497, 0.0073]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 11.701692819595337\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 45\n",
      "X 資料 torch.Size([62, 18])\n",
      "Y 資料 torch.Size([62, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.005849136970937252, 2)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引2，y= tensor([0.5930, 0.6008, 0.6309, 0.5651])\n",
      "目前模型的Data torch.Size([45, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.8025, 0.8051, 0.8084, 0.7517],\n",
      "        [0.8132, 0.8169, 0.8214, 0.7644],\n",
      "        [0.8009, 0.8033, 0.8064, 0.7498],\n",
      "        [0.8085, 0.8117, 0.8157, 0.7588],\n",
      "        [0.7795, 0.7796, 0.7805, 0.7245],\n",
      "        [0.7512, 0.7485, 0.7463, 0.6911],\n",
      "        [0.7439, 0.7405, 0.7375, 0.6825],\n",
      "        [0.7194, 0.7134, 0.7079, 0.6536],\n",
      "        [0.7094, 0.7024, 0.6957, 0.6417],\n",
      "        [0.7039, 0.6963, 0.6891, 0.6353],\n",
      "        [0.7058, 0.6984, 0.6913, 0.6374],\n",
      "        [0.7007, 0.6927, 0.6852, 0.6314],\n",
      "        [0.7008, 0.6929, 0.6853, 0.6316],\n",
      "        [0.6990, 0.6908, 0.6831, 0.6294],\n",
      "        [0.7372, 0.7331, 0.7294, 0.6746],\n",
      "        [0.7795, 0.7797, 0.7806, 0.7246],\n",
      "        [0.7993, 0.8015, 0.8045, 0.7479],\n",
      "        [0.7906, 0.7919, 0.7940, 0.7376],\n",
      "        [0.8255, 0.8305, 0.8363, 0.7789],\n",
      "        [0.8591, 0.8675, 0.8769, 0.8185],\n",
      "        [0.7301, 0.7252, 0.7207, 0.6661],\n",
      "        [0.7113, 0.7044, 0.6980, 0.6439],\n",
      "        [0.8072, 0.8103, 0.8141, 0.7573],\n",
      "        [0.6665, 0.6551, 0.6438, 0.5911],\n",
      "        [0.6665, 0.6551, 0.6438, 0.5911],\n",
      "        [0.7530, 0.7504, 0.7484, 0.6932],\n",
      "        [0.7245, 0.7190, 0.7140, 0.6595],\n",
      "        [0.7745, 0.7742, 0.7745, 0.7186],\n",
      "        [0.6665, 0.6551, 0.6438, 0.5911],\n",
      "        [0.7664, 0.7653, 0.7647, 0.7091],\n",
      "        [0.7585, 0.7566, 0.7552, 0.6998],\n",
      "        [0.8006, 0.8030, 0.8061, 0.7495],\n",
      "        [0.6665, 0.6551, 0.6438, 0.5911],\n",
      "        [0.6665, 0.6551, 0.6438, 0.5911],\n",
      "        [0.6665, 0.6551, 0.6438, 0.5911],\n",
      "        [0.6665, 0.6551, 0.6438, 0.5911],\n",
      "        [0.6665, 0.6551, 0.6438, 0.5911],\n",
      "        [0.6665, 0.6551, 0.6438, 0.5911],\n",
      "        [0.6665, 0.6551, 0.6438, 0.5911],\n",
      "        [0.6684, 0.6571, 0.6461, 0.5933],\n",
      "        [0.7205, 0.7147, 0.7092, 0.6549],\n",
      "        [0.7537, 0.7512, 0.7493, 0.6941],\n",
      "        [0.6666, 0.6551, 0.6439, 0.5911],\n",
      "        [0.6721, 0.6612, 0.6506, 0.5977],\n",
      "        [0.6948, 0.6862, 0.6780, 0.6244]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0454, 0.0122, 0.0064, 0.0229],\n",
      "        [0.0203, 0.0021, 0.0426, 0.0023],\n",
      "        [0.0139, 0.0245, 0.0128, 0.0027],\n",
      "        [0.0298, 0.0075, 0.0116, 0.0104],\n",
      "        [0.0398, 0.0244, 0.0414, 0.0162],\n",
      "        [0.0528, 0.0735, 0.0451, 0.0050],\n",
      "        [0.0780, 0.0510, 0.0063, 0.0148],\n",
      "        [0.0720, 0.0304, 0.0056, 0.0203],\n",
      "        [0.0344, 0.0111, 0.0190, 0.0255],\n",
      "        [0.0095, 0.0197, 0.0306, 0.0249],\n",
      "        [0.0291, 0.0398, 0.0391, 0.0232],\n",
      "        [0.0422, 0.0405, 0.0288, 0.0020],\n",
      "        [0.0486, 0.0366, 0.0128, 0.0171],\n",
      "        [0.0426, 0.0183, 0.0101, 0.0279],\n",
      "        [0.0647, 0.0399, 0.0271, 0.0554],\n",
      "        [0.0864, 0.0774, 0.0006, 0.0567],\n",
      "        [0.0970, 0.0215, 0.0303, 0.0379],\n",
      "        [0.0106, 0.0429, 0.0457, 0.0328],\n",
      "        [0.0093, 0.0092, 0.0130, 0.0155],\n",
      "        [0.0194, 0.0442, 0.0280, 0.0712],\n",
      "        [0.0359, 0.0551, 0.0556, 0.0374],\n",
      "        [0.0709, 0.0401, 0.0006, 0.0097],\n",
      "        [0.0141, 0.0187, 0.0086, 0.0253],\n",
      "        [0.0853, 0.1093, 0.0724, 0.0489],\n",
      "        [0.1098, 0.0967, 0.1206, 0.0792],\n",
      "        [0.0386, 0.0551, 0.0337, 0.0036],\n",
      "        [0.0810, 0.0632, 0.0306, 0.0058],\n",
      "        [0.0241, 0.0190, 0.0171, 0.0352],\n",
      "        [0.1138, 0.1213, 0.1080, 0.1243],\n",
      "        [0.0568, 0.0836, 0.0339, 0.0331],\n",
      "        [0.0903, 0.0421, 0.0379, 0.0411],\n",
      "        [0.0570, 0.0370, 0.0258, 0.0229],\n",
      "        [0.0377, 0.0135, 0.0273, 0.0520],\n",
      "        [0.0641, 0.0222, 0.0679, 0.1443],\n",
      "        [0.0957, 0.0262, 0.0022, 0.0141],\n",
      "        [0.0249, 0.0385, 0.0678, 0.0364],\n",
      "        [0.0627, 0.0842, 0.0149, 0.0094],\n",
      "        [0.0500, 0.0790, 0.0512, 0.0405],\n",
      "        [0.0905, 0.0624, 0.0555, 0.0390],\n",
      "        [0.0960, 0.0590, 0.0667, 0.1163],\n",
      "        [0.0220, 0.0370, 0.0558, 0.0733],\n",
      "        [0.0092, 0.0527, 0.0716, 0.0826],\n",
      "        [0.0451, 0.0795, 0.0509, 0.0288],\n",
      "        [0.0965, 0.0683, 0.0497, 0.0073],\n",
      "        [0.1018, 0.0854, 0.0471, 0.0593]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 42\n",
      "Number of shrink: 28\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0471,     0.0101,     0.0083,     0.0206],\n",
      "        [    0.0188,     0.0001,     0.0409,     0.0046],\n",
      "        [    0.0154,     0.0228,     0.0143,     0.0047],\n",
      "        [    0.0291,     0.0085,     0.0110,     0.0116],\n",
      "        [    0.0416,     0.0264,     0.0431,     0.0182],\n",
      "        [    0.0549,     0.0753,     0.0466,     0.0067],\n",
      "        [    0.0806,     0.0533,     0.0082,     0.0127],\n",
      "        [    0.0755,     0.0334,     0.0083,     0.0176],\n",
      "        [    0.0381,     0.0142,     0.0163,     0.0228],\n",
      "        [    0.0131,     0.0167,     0.0280,     0.0223],\n",
      "        [    0.0258,     0.0372,     0.0368,     0.0210],\n",
      "        [    0.0387,     0.0378,     0.0264,     0.0003],\n",
      "        [    0.0452,     0.0339,     0.0105,     0.0193],\n",
      "        [    0.0393,     0.0158,     0.0122,     0.0299],\n",
      "        [    0.0633,     0.0390,     0.0266,     0.0560],\n",
      "        [    0.0865,     0.0776,     0.0013,     0.0564],\n",
      "        [    0.0980,     0.0224,     0.0289,     0.0371],\n",
      "        [    0.0108,     0.0427,     0.0451,     0.0326],\n",
      "        [    0.0072,     0.0074,     0.0154,     0.0138],\n",
      "        [    0.0233,     0.0475,     0.0320,     0.0742],\n",
      "        [    0.0399,     0.0588,     0.0591,     0.0410],\n",
      "        [    0.0751,     0.0438,     0.0040,     0.0063],\n",
      "        [    0.0152,     0.0196,     0.0101,     0.0261],\n",
      "        [    0.0884,     0.1113,     0.0738,     0.0476],\n",
      "        [    0.1130,     0.0987,     0.1221,     0.0804],\n",
      "        [    0.0403,     0.0565,     0.0347,     0.0048],\n",
      "        [    0.0848,     0.0666,     0.0337,     0.0026],\n",
      "        [    0.0231,     0.0177,     0.0153,     0.0338],\n",
      "        [    0.1169,     0.1233,     0.1095,     0.1255],\n",
      "        [    0.0558,     0.0823,     0.0319,     0.0316],\n",
      "        [    0.0895,     0.0409,     0.0361,     0.0396],\n",
      "        [    0.0547,     0.0344,     0.0234,     0.0201],\n",
      "        [    0.0345,     0.0115,     0.0258,     0.0507],\n",
      "        [    0.0610,     0.0202,     0.0694,     0.1455],\n",
      "        [    0.0926,     0.0242,     0.0007,     0.0128],\n",
      "        [    0.0218,     0.0365,     0.0663,     0.0352],\n",
      "        [    0.0596,     0.0823,     0.0135,     0.0106],\n",
      "        [    0.0468,     0.0770,     0.0497,     0.0392],\n",
      "        [    0.0873,     0.0604,     0.0540,     0.0377],\n",
      "        [    0.1010,     0.0630,     0.0630,     0.1129],\n",
      "        [    0.0166,     0.0319,     0.0508,     0.0684],\n",
      "        [    0.0056,     0.0491,     0.0683,     0.0791],\n",
      "        [    0.0420,     0.0775,     0.0494,     0.0275],\n",
      "        [    0.0878,     0.0602,     0.0415,     0.0006],\n",
      "        [    0.0945,     0.0785,     0.0402,     0.0526]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.004988431930542\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 46\n",
      "X 資料 torch.Size([61, 18])\n",
      "Y 資料 torch.Size([61, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.008763475343585014, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.6777, 0.6534, 0.6214, 0.5387])\n",
      "目前模型的Data torch.Size([46, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.8008, 0.8030, 0.8065, 0.7494],\n",
      "        [0.8117, 0.8149, 0.8196, 0.7621],\n",
      "        [0.7994, 0.8015, 0.8049, 0.7478],\n",
      "        [0.8079, 0.8107, 0.8150, 0.7576],\n",
      "        [0.7776, 0.7777, 0.7789, 0.7225],\n",
      "        [0.7492, 0.7467, 0.7448, 0.6894],\n",
      "        [0.7414, 0.7382, 0.7356, 0.6804],\n",
      "        [0.7160, 0.7104, 0.7052, 0.6509],\n",
      "        [0.7058, 0.6993, 0.6930, 0.6390],\n",
      "        [0.7003, 0.6934, 0.6865, 0.6327],\n",
      "        [0.7025, 0.6957, 0.6890, 0.6352],\n",
      "        [0.6972, 0.6900, 0.6828, 0.6291],\n",
      "        [0.6974, 0.6902, 0.6830, 0.6293],\n",
      "        [0.6957, 0.6883, 0.6809, 0.6273],\n",
      "        [0.7358, 0.7321, 0.7289, 0.6739],\n",
      "        [0.7797, 0.7799, 0.7813, 0.7249],\n",
      "        [0.8003, 0.8024, 0.8059, 0.7488],\n",
      "        [0.7908, 0.7921, 0.7946, 0.7378],\n",
      "        [0.8276, 0.8323, 0.8387, 0.7806],\n",
      "        [0.8630, 0.8708, 0.8809, 0.8216],\n",
      "        [0.7261, 0.7215, 0.7172, 0.6626],\n",
      "        [0.7071, 0.7008, 0.6945, 0.6405],\n",
      "        [0.8083, 0.8112, 0.8156, 0.7581],\n",
      "        [0.6634, 0.6531, 0.6423, 0.5898],\n",
      "        [0.6634, 0.6531, 0.6423, 0.5898],\n",
      "        [0.7513, 0.7490, 0.7475, 0.6919],\n",
      "        [0.7207, 0.7156, 0.7108, 0.6563],\n",
      "        [0.7755, 0.7754, 0.7763, 0.7200],\n",
      "        [0.6634, 0.6531, 0.6423, 0.5898],\n",
      "        [0.7674, 0.7666, 0.7667, 0.7106],\n",
      "        [0.7593, 0.7577, 0.7570, 0.7012],\n",
      "        [0.7984, 0.8004, 0.8037, 0.7466],\n",
      "        [0.6634, 0.6531, 0.6423, 0.5898],\n",
      "        [0.6634, 0.6531, 0.6423, 0.5898],\n",
      "        [0.6634, 0.6531, 0.6423, 0.5898],\n",
      "        [0.6634, 0.6531, 0.6423, 0.5898],\n",
      "        [0.6634, 0.6531, 0.6423, 0.5898],\n",
      "        [0.6634, 0.6531, 0.6423, 0.5898],\n",
      "        [0.6634, 0.6531, 0.6423, 0.5898],\n",
      "        [0.6634, 0.6531, 0.6424, 0.5899],\n",
      "        [0.7152, 0.7096, 0.7042, 0.6499],\n",
      "        [0.7501, 0.7477, 0.7460, 0.6905],\n",
      "        [0.6634, 0.6531, 0.6423, 0.5898],\n",
      "        [0.6634, 0.6531, 0.6423, 0.5898],\n",
      "        [0.6874, 0.6793, 0.6711, 0.6177],\n",
      "        [0.7306, 0.7264, 0.7226, 0.6678]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0471,     0.0101,     0.0083,     0.0206],\n",
      "        [    0.0188,     0.0001,     0.0409,     0.0046],\n",
      "        [    0.0154,     0.0228,     0.0143,     0.0047],\n",
      "        [    0.0291,     0.0085,     0.0110,     0.0116],\n",
      "        [    0.0416,     0.0264,     0.0431,     0.0182],\n",
      "        [    0.0549,     0.0753,     0.0466,     0.0067],\n",
      "        [    0.0806,     0.0533,     0.0082,     0.0127],\n",
      "        [    0.0755,     0.0334,     0.0083,     0.0176],\n",
      "        [    0.0381,     0.0142,     0.0163,     0.0228],\n",
      "        [    0.0131,     0.0167,     0.0280,     0.0223],\n",
      "        [    0.0258,     0.0372,     0.0368,     0.0210],\n",
      "        [    0.0387,     0.0378,     0.0264,     0.0003],\n",
      "        [    0.0452,     0.0339,     0.0105,     0.0193],\n",
      "        [    0.0393,     0.0158,     0.0122,     0.0299],\n",
      "        [    0.0633,     0.0390,     0.0266,     0.0560],\n",
      "        [    0.0865,     0.0776,     0.0013,     0.0564],\n",
      "        [    0.0980,     0.0224,     0.0289,     0.0371],\n",
      "        [    0.0108,     0.0427,     0.0451,     0.0326],\n",
      "        [    0.0072,     0.0074,     0.0154,     0.0138],\n",
      "        [    0.0233,     0.0475,     0.0320,     0.0742],\n",
      "        [    0.0399,     0.0588,     0.0591,     0.0410],\n",
      "        [    0.0751,     0.0438,     0.0040,     0.0063],\n",
      "        [    0.0152,     0.0196,     0.0101,     0.0261],\n",
      "        [    0.0884,     0.1113,     0.0738,     0.0476],\n",
      "        [    0.1130,     0.0987,     0.1221,     0.0804],\n",
      "        [    0.0403,     0.0565,     0.0347,     0.0048],\n",
      "        [    0.0848,     0.0666,     0.0337,     0.0026],\n",
      "        [    0.0231,     0.0177,     0.0153,     0.0338],\n",
      "        [    0.1169,     0.1233,     0.1095,     0.1255],\n",
      "        [    0.0558,     0.0823,     0.0319,     0.0316],\n",
      "        [    0.0895,     0.0409,     0.0361,     0.0396],\n",
      "        [    0.0547,     0.0344,     0.0234,     0.0201],\n",
      "        [    0.0345,     0.0115,     0.0258,     0.0507],\n",
      "        [    0.0610,     0.0202,     0.0694,     0.1455],\n",
      "        [    0.0926,     0.0242,     0.0007,     0.0128],\n",
      "        [    0.0218,     0.0365,     0.0663,     0.0352],\n",
      "        [    0.0596,     0.0823,     0.0135,     0.0106],\n",
      "        [    0.0468,     0.0770,     0.0497,     0.0392],\n",
      "        [    0.0873,     0.0604,     0.0540,     0.0377],\n",
      "        [    0.1010,     0.0630,     0.0630,     0.1129],\n",
      "        [    0.0166,     0.0319,     0.0508,     0.0684],\n",
      "        [    0.0056,     0.0491,     0.0683,     0.0791],\n",
      "        [    0.0420,     0.0775,     0.0494,     0.0275],\n",
      "        [    0.0878,     0.0602,     0.0415,     0.0006],\n",
      "        [    0.0945,     0.0785,     0.0402,     0.0526],\n",
      "        [    0.0529,     0.0730,     0.1012,     0.1291]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0512,     0.0055,     0.0141,     0.0142],\n",
      "        [    0.0147,     0.0045,     0.0350,     0.0109],\n",
      "        [    0.0176,     0.0202,     0.0179,     0.0089],\n",
      "        [    0.0279,     0.0100,     0.0085,     0.0146],\n",
      "        [    0.0429,     0.0280,     0.0456,     0.0214],\n",
      "        [    0.0538,     0.0744,     0.0462,     0.0072],\n",
      "        [    0.0802,     0.0533,     0.0088,     0.0113],\n",
      "        [    0.0745,     0.0328,     0.0081,     0.0168],\n",
      "        [    0.0374,     0.0140,     0.0161,     0.0215],\n",
      "        [    0.0119,     0.0175,     0.0285,     0.0217],\n",
      "        [    0.0260,     0.0369,     0.0361,     0.0192],\n",
      "        [    0.0388,     0.0373,     0.0255,     0.0022],\n",
      "        [    0.0455,     0.0335,     0.0098,     0.0211],\n",
      "        [    0.0399,     0.0158,     0.0125,     0.0313],\n",
      "        [    0.0644,     0.0398,     0.0270,     0.0566],\n",
      "        [    0.0863,     0.0772,     0.0001,     0.0584],\n",
      "        [    0.0969,     0.0211,     0.0311,     0.0399],\n",
      "        [    0.0093,     0.0445,     0.0478,     0.0360],\n",
      "        [    0.0084,     0.0088,     0.0130,     0.0167],\n",
      "        [    0.0227,     0.0471,     0.0304,     0.0723],\n",
      "        [    0.0396,     0.0589,     0.0597,     0.0425],\n",
      "        [    0.0803,     0.0501,     0.0113,     0.0018],\n",
      "        [    0.0126,     0.0166,     0.0060,     0.0215],\n",
      "        [    0.0894,     0.1131,     0.0760,     0.0443],\n",
      "        [    0.1139,     0.1005,     0.1242,     0.0837],\n",
      "        [    0.0444,     0.0613,     0.0406,     0.0114],\n",
      "        [    0.0912,     0.0740,     0.0423,     0.0068],\n",
      "        [    0.0249,     0.0199,     0.0184,     0.0376],\n",
      "        [    0.1179,     0.1251,     0.1116,     0.1289],\n",
      "        [    0.0551,     0.0817,     0.0320,     0.0324],\n",
      "        [    0.0897,     0.0414,     0.0373,     0.0415],\n",
      "        [    0.0535,     0.0329,     0.0210,     0.0171],\n",
      "        [    0.0336,     0.0097,     0.0236,     0.0474],\n",
      "        [    0.0600,     0.0184,     0.0715,     0.1488],\n",
      "        [    0.0916,     0.0224,     0.0014,     0.0095],\n",
      "        [    0.0208,     0.0347,     0.0641,     0.0318],\n",
      "        [    0.0586,     0.0805,     0.0113,     0.0140],\n",
      "        [    0.0459,     0.0752,     0.0475,     0.0359],\n",
      "        [    0.0864,     0.0586,     0.0518,     0.0344],\n",
      "        [    0.1014,     0.0643,     0.0615,     0.1102],\n",
      "        [    0.0079,     0.0219,     0.0396,     0.0563],\n",
      "        [    0.0015,     0.0410,     0.0589,     0.0691],\n",
      "        [    0.0410,     0.0757,     0.0472,     0.0242],\n",
      "        [    0.0868,     0.0583,     0.0394,     0.0039],\n",
      "        [    0.0881,     0.0709,     0.0316,     0.0431],\n",
      "        [    0.0439,     0.0627,     0.0895,     0.1168]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.41275143623352\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 47\n",
      "X 資料 torch.Size([60, 18])\n",
      "Y 資料 torch.Size([60, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0077853817492723465, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.6534, 0.6214, 0.5756, 0.5549])\n",
      "目前模型的Data torch.Size([47, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7967, 0.7984, 0.8007, 0.7430],\n",
      "        [0.8076, 0.8103, 0.8138, 0.7558],\n",
      "        [0.7972, 0.7989, 0.8013, 0.7436],\n",
      "        [0.8066, 0.8092, 0.8126, 0.7546],\n",
      "        [0.7763, 0.7761, 0.7764, 0.7193],\n",
      "        [0.7503, 0.7475, 0.7452, 0.6889],\n",
      "        [0.7418, 0.7382, 0.7351, 0.6790],\n",
      "        [0.7170, 0.7110, 0.7054, 0.6501],\n",
      "        [0.7064, 0.6995, 0.6928, 0.6378],\n",
      "        [0.7015, 0.6941, 0.6870, 0.6321],\n",
      "        [0.7027, 0.6954, 0.6883, 0.6334],\n",
      "        [0.6973, 0.6895, 0.6819, 0.6271],\n",
      "        [0.6977, 0.6899, 0.6823, 0.6276],\n",
      "        [0.6963, 0.6884, 0.6807, 0.6259],\n",
      "        [0.7370, 0.7329, 0.7293, 0.6734],\n",
      "        [0.7794, 0.7795, 0.7801, 0.7229],\n",
      "        [0.7992, 0.8011, 0.8037, 0.7459],\n",
      "        [0.7893, 0.7903, 0.7919, 0.7345],\n",
      "        [0.8264, 0.8309, 0.8363, 0.7777],\n",
      "        [0.8624, 0.8703, 0.8793, 0.8196],\n",
      "        [0.7264, 0.7214, 0.7167, 0.6611],\n",
      "        [0.7018, 0.6945, 0.6873, 0.6324],\n",
      "        [0.8057, 0.8082, 0.8115, 0.7535],\n",
      "        [0.6624, 0.6513, 0.6402, 0.5865],\n",
      "        [0.6624, 0.6513, 0.6402, 0.5865],\n",
      "        [0.7472, 0.7442, 0.7416, 0.6854],\n",
      "        [0.7143, 0.7081, 0.7022, 0.6470],\n",
      "        [0.7737, 0.7732, 0.7733, 0.7163],\n",
      "        [0.6624, 0.6513, 0.6402, 0.5865],\n",
      "        [0.7682, 0.7671, 0.7666, 0.7098],\n",
      "        [0.7592, 0.7573, 0.7559, 0.6993],\n",
      "        [0.7972, 0.7989, 0.8013, 0.7436],\n",
      "        [0.6624, 0.6513, 0.6402, 0.5865],\n",
      "        [0.6624, 0.6513, 0.6402, 0.5865],\n",
      "        [0.6624, 0.6513, 0.6402, 0.5865],\n",
      "        [0.6624, 0.6513, 0.6402, 0.5865],\n",
      "        [0.6624, 0.6513, 0.6402, 0.5865],\n",
      "        [0.6624, 0.6513, 0.6402, 0.5865],\n",
      "        [0.6624, 0.6513, 0.6402, 0.5865],\n",
      "        [0.6630, 0.6519, 0.6409, 0.5872],\n",
      "        [0.7065, 0.6996, 0.6929, 0.6379],\n",
      "        [0.7431, 0.7396, 0.7366, 0.6805],\n",
      "        [0.6624, 0.6513, 0.6402, 0.5865],\n",
      "        [0.6624, 0.6513, 0.6402, 0.5865],\n",
      "        [0.6811, 0.6717, 0.6625, 0.6082],\n",
      "        [0.7216, 0.7161, 0.7109, 0.6555],\n",
      "        [0.7086, 0.7019, 0.6954, 0.6403]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0512,     0.0055,     0.0141,     0.0142],\n",
      "        [    0.0147,     0.0045,     0.0350,     0.0109],\n",
      "        [    0.0176,     0.0202,     0.0179,     0.0089],\n",
      "        [    0.0279,     0.0100,     0.0085,     0.0146],\n",
      "        [    0.0429,     0.0280,     0.0456,     0.0214],\n",
      "        [    0.0538,     0.0744,     0.0462,     0.0072],\n",
      "        [    0.0802,     0.0533,     0.0088,     0.0113],\n",
      "        [    0.0745,     0.0328,     0.0081,     0.0168],\n",
      "        [    0.0374,     0.0140,     0.0161,     0.0215],\n",
      "        [    0.0119,     0.0175,     0.0285,     0.0217],\n",
      "        [    0.0260,     0.0369,     0.0361,     0.0192],\n",
      "        [    0.0388,     0.0373,     0.0255,     0.0022],\n",
      "        [    0.0455,     0.0335,     0.0098,     0.0211],\n",
      "        [    0.0399,     0.0158,     0.0125,     0.0313],\n",
      "        [    0.0644,     0.0398,     0.0270,     0.0566],\n",
      "        [    0.0863,     0.0772,     0.0001,     0.0584],\n",
      "        [    0.0969,     0.0211,     0.0311,     0.0399],\n",
      "        [    0.0093,     0.0445,     0.0478,     0.0360],\n",
      "        [    0.0084,     0.0088,     0.0130,     0.0167],\n",
      "        [    0.0227,     0.0471,     0.0304,     0.0723],\n",
      "        [    0.0396,     0.0589,     0.0597,     0.0425],\n",
      "        [    0.0803,     0.0501,     0.0113,     0.0018],\n",
      "        [    0.0126,     0.0166,     0.0060,     0.0215],\n",
      "        [    0.0894,     0.1131,     0.0760,     0.0443],\n",
      "        [    0.1139,     0.1005,     0.1242,     0.0837],\n",
      "        [    0.0444,     0.0613,     0.0406,     0.0114],\n",
      "        [    0.0912,     0.0740,     0.0423,     0.0068],\n",
      "        [    0.0249,     0.0199,     0.0184,     0.0376],\n",
      "        [    0.1179,     0.1251,     0.1116,     0.1289],\n",
      "        [    0.0551,     0.0817,     0.0320,     0.0324],\n",
      "        [    0.0897,     0.0414,     0.0373,     0.0415],\n",
      "        [    0.0535,     0.0329,     0.0210,     0.0171],\n",
      "        [    0.0336,     0.0097,     0.0236,     0.0474],\n",
      "        [    0.0600,     0.0184,     0.0715,     0.1488],\n",
      "        [    0.0916,     0.0224,     0.0014,     0.0095],\n",
      "        [    0.0208,     0.0347,     0.0641,     0.0318],\n",
      "        [    0.0586,     0.0805,     0.0113,     0.0140],\n",
      "        [    0.0459,     0.0752,     0.0475,     0.0359],\n",
      "        [    0.0864,     0.0586,     0.0518,     0.0344],\n",
      "        [    0.1014,     0.0643,     0.0615,     0.1102],\n",
      "        [    0.0079,     0.0219,     0.0396,     0.0563],\n",
      "        [    0.0015,     0.0410,     0.0589,     0.0691],\n",
      "        [    0.0410,     0.0757,     0.0472,     0.0242],\n",
      "        [    0.0868,     0.0583,     0.0394,     0.0039],\n",
      "        [    0.0881,     0.0709,     0.0316,     0.0431],\n",
      "        [    0.0439,     0.0627,     0.0895,     0.1168],\n",
      "        [    0.0552,     0.0804,     0.1197,     0.0854]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0532, 0.0032, 0.0165, 0.0130],\n",
      "        [0.0127, 0.0068, 0.0326, 0.0121],\n",
      "        [0.0173, 0.0205, 0.0175, 0.0074],\n",
      "        [0.0294, 0.0084, 0.0104, 0.0116],\n",
      "        [0.0420, 0.0271, 0.0445, 0.0194],\n",
      "        [0.0524, 0.0729, 0.0445, 0.0048],\n",
      "        [0.0802, 0.0533, 0.0087, 0.0120],\n",
      "        [0.0749, 0.0332, 0.0084, 0.0169],\n",
      "        [0.0383, 0.0150, 0.0151, 0.0209],\n",
      "        [0.0120, 0.0174, 0.0285, 0.0221],\n",
      "        [0.0237, 0.0344, 0.0335, 0.0169],\n",
      "        [0.0375, 0.0359, 0.0241, 0.0034],\n",
      "        [0.0445, 0.0325, 0.0088, 0.0218],\n",
      "        [0.0388, 0.0147, 0.0137, 0.0322],\n",
      "        [0.0653, 0.0408, 0.0282, 0.0549],\n",
      "        [0.0873, 0.0782, 0.0014, 0.0562],\n",
      "        [0.0981, 0.0223, 0.0297, 0.0374],\n",
      "        [0.0092, 0.0447, 0.0478, 0.0350],\n",
      "        [0.0080, 0.0084, 0.0136, 0.0149],\n",
      "        [0.0262, 0.0508, 0.0346, 0.0779],\n",
      "        [0.0392, 0.0585, 0.0591, 0.0414],\n",
      "        [0.0891, 0.0597, 0.0217, 0.0117],\n",
      "        [0.0120, 0.0159, 0.0054, 0.0221],\n",
      "        [0.0901, 0.1138, 0.0767, 0.0436],\n",
      "        [0.1146, 0.1012, 0.1249, 0.0844],\n",
      "        [0.0492, 0.0666, 0.0462, 0.0163],\n",
      "        [0.1000, 0.0837, 0.0527, 0.0166],\n",
      "        [0.0260, 0.0212, 0.0196, 0.0379],\n",
      "        [0.1185, 0.1257, 0.1123, 0.1296],\n",
      "        [0.0539, 0.0805, 0.0305, 0.0301],\n",
      "        [0.0899, 0.0416, 0.0374, 0.0409],\n",
      "        [0.0548, 0.0343, 0.0226, 0.0197],\n",
      "        [0.0329, 0.0090, 0.0229, 0.0467],\n",
      "        [0.0594, 0.0177, 0.0722, 0.1495],\n",
      "        [0.0909, 0.0217, 0.0021, 0.0088],\n",
      "        [0.0201, 0.0341, 0.0635, 0.0312],\n",
      "        [0.0579, 0.0798, 0.0106, 0.0146],\n",
      "        [0.0452, 0.0746, 0.0469, 0.0352],\n",
      "        [0.0857, 0.0580, 0.0511, 0.0337],\n",
      "        [0.1020, 0.0648, 0.0610, 0.1097],\n",
      "        [0.0041, 0.0087, 0.0252, 0.0426],\n",
      "        [0.0104, 0.0313, 0.0484, 0.0593],\n",
      "        [0.0403, 0.0750, 0.0466, 0.0235],\n",
      "        [0.0861, 0.0577, 0.0387, 0.0046],\n",
      "        [0.0787, 0.0606, 0.0204, 0.0323],\n",
      "        [0.0320, 0.0497, 0.0753, 0.1033],\n",
      "        [0.0431, 0.0671, 0.1053, 0.0716]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.853376865386963\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 48\n",
      "X 資料 torch.Size([59, 18])\n",
      "Y 資料 torch.Size([59, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.008752355352044106, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引1，y= tensor([0.6309, 0.6038, 0.5708, 0.5885])\n",
      "目前模型的Data torch.Size([48, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7947, 0.7961, 0.7983, 0.7417],\n",
      "        [0.8056, 0.8080, 0.8114, 0.7545],\n",
      "        [0.7975, 0.7992, 0.8018, 0.7451],\n",
      "        [0.8082, 0.8108, 0.8145, 0.7576],\n",
      "        [0.7772, 0.7770, 0.7775, 0.7213],\n",
      "        [0.7517, 0.7490, 0.7470, 0.6913],\n",
      "        [0.7417, 0.7382, 0.7351, 0.6797],\n",
      "        [0.7166, 0.7106, 0.7050, 0.6501],\n",
      "        [0.7055, 0.6985, 0.6918, 0.6371],\n",
      "        [0.7015, 0.6941, 0.6870, 0.6324],\n",
      "        [0.7004, 0.6929, 0.6857, 0.6312],\n",
      "        [0.6960, 0.6881, 0.6805, 0.6260],\n",
      "        [0.6967, 0.6889, 0.6813, 0.6268],\n",
      "        [0.6952, 0.6872, 0.6795, 0.6251],\n",
      "        [0.7379, 0.7339, 0.7305, 0.6751],\n",
      "        [0.7805, 0.7805, 0.7814, 0.7251],\n",
      "        [0.8004, 0.8023, 0.8052, 0.7485],\n",
      "        [0.7892, 0.7901, 0.7919, 0.7354],\n",
      "        [0.8268, 0.8313, 0.8368, 0.7795],\n",
      "        [0.8659, 0.8740, 0.8835, 0.8253],\n",
      "        [0.7268, 0.7218, 0.7173, 0.6622],\n",
      "        [0.6930, 0.6848, 0.6769, 0.6225],\n",
      "        [0.8052, 0.8076, 0.8109, 0.7541],\n",
      "        [0.6618, 0.6506, 0.6395, 0.5858],\n",
      "        [0.6618, 0.6506, 0.6395, 0.5858],\n",
      "        [0.7425, 0.7389, 0.7360, 0.6805],\n",
      "        [0.7055, 0.6985, 0.6918, 0.6371],\n",
      "        [0.7726, 0.7719, 0.7720, 0.7159],\n",
      "        [0.6618, 0.6506, 0.6395, 0.5858],\n",
      "        [0.7694, 0.7684, 0.7681, 0.7121],\n",
      "        [0.7590, 0.7570, 0.7557, 0.6999],\n",
      "        [0.7985, 0.8002, 0.8029, 0.7462],\n",
      "        [0.6618, 0.6506, 0.6395, 0.5858],\n",
      "        [0.6618, 0.6506, 0.6395, 0.5858],\n",
      "        [0.6618, 0.6506, 0.6395, 0.5858],\n",
      "        [0.6618, 0.6506, 0.6395, 0.5858],\n",
      "        [0.6618, 0.6506, 0.6395, 0.5858],\n",
      "        [0.6618, 0.6506, 0.6395, 0.5858],\n",
      "        [0.6618, 0.6506, 0.6395, 0.5858],\n",
      "        [0.6625, 0.6514, 0.6404, 0.5866],\n",
      "        [0.6945, 0.6864, 0.6786, 0.6242],\n",
      "        [0.7342, 0.7299, 0.7261, 0.6708],\n",
      "        [0.6618, 0.6506, 0.6395, 0.5858],\n",
      "        [0.6618, 0.6506, 0.6395, 0.5858],\n",
      "        [0.6716, 0.6614, 0.6513, 0.5974],\n",
      "        [0.7097, 0.7030, 0.6968, 0.6420],\n",
      "        [0.6964, 0.6886, 0.6810, 0.6265],\n",
      "        [0.7100, 0.7034, 0.6971, 0.6424]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0532, 0.0032, 0.0165, 0.0130],\n",
      "        [0.0127, 0.0068, 0.0326, 0.0121],\n",
      "        [0.0173, 0.0205, 0.0175, 0.0074],\n",
      "        [0.0294, 0.0084, 0.0104, 0.0116],\n",
      "        [0.0420, 0.0271, 0.0445, 0.0194],\n",
      "        [0.0524, 0.0729, 0.0445, 0.0048],\n",
      "        [0.0802, 0.0533, 0.0087, 0.0120],\n",
      "        [0.0749, 0.0332, 0.0084, 0.0169],\n",
      "        [0.0383, 0.0150, 0.0151, 0.0209],\n",
      "        [0.0120, 0.0174, 0.0285, 0.0221],\n",
      "        [0.0237, 0.0344, 0.0335, 0.0169],\n",
      "        [0.0375, 0.0359, 0.0241, 0.0034],\n",
      "        [0.0445, 0.0325, 0.0088, 0.0218],\n",
      "        [0.0388, 0.0147, 0.0137, 0.0322],\n",
      "        [0.0653, 0.0408, 0.0282, 0.0549],\n",
      "        [0.0873, 0.0782, 0.0014, 0.0562],\n",
      "        [0.0981, 0.0223, 0.0297, 0.0374],\n",
      "        [0.0092, 0.0447, 0.0478, 0.0350],\n",
      "        [0.0080, 0.0084, 0.0136, 0.0149],\n",
      "        [0.0262, 0.0508, 0.0346, 0.0779],\n",
      "        [0.0392, 0.0585, 0.0591, 0.0414],\n",
      "        [0.0891, 0.0597, 0.0217, 0.0117],\n",
      "        [0.0120, 0.0159, 0.0054, 0.0221],\n",
      "        [0.0901, 0.1138, 0.0767, 0.0436],\n",
      "        [0.1146, 0.1012, 0.1249, 0.0844],\n",
      "        [0.0492, 0.0666, 0.0462, 0.0163],\n",
      "        [0.1000, 0.0837, 0.0527, 0.0166],\n",
      "        [0.0260, 0.0212, 0.0196, 0.0379],\n",
      "        [0.1185, 0.1257, 0.1123, 0.1296],\n",
      "        [0.0539, 0.0805, 0.0305, 0.0301],\n",
      "        [0.0899, 0.0416, 0.0374, 0.0409],\n",
      "        [0.0548, 0.0343, 0.0226, 0.0197],\n",
      "        [0.0329, 0.0090, 0.0229, 0.0467],\n",
      "        [0.0594, 0.0177, 0.0722, 0.1495],\n",
      "        [0.0909, 0.0217, 0.0021, 0.0088],\n",
      "        [0.0201, 0.0341, 0.0635, 0.0312],\n",
      "        [0.0579, 0.0798, 0.0106, 0.0146],\n",
      "        [0.0452, 0.0746, 0.0469, 0.0352],\n",
      "        [0.0857, 0.0580, 0.0511, 0.0337],\n",
      "        [0.1020, 0.0648, 0.0610, 0.1097],\n",
      "        [0.0041, 0.0087, 0.0252, 0.0426],\n",
      "        [0.0104, 0.0313, 0.0484, 0.0593],\n",
      "        [0.0403, 0.0750, 0.0466, 0.0235],\n",
      "        [0.0861, 0.0577, 0.0387, 0.0046],\n",
      "        [0.0787, 0.0606, 0.0204, 0.0323],\n",
      "        [0.0320, 0.0497, 0.0753, 0.1033],\n",
      "        [0.0431, 0.0671, 0.1053, 0.0716],\n",
      "        [0.0791, 0.0995, 0.1263, 0.0538]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0561, 0.0004, 0.0191, 0.0113],\n",
      "        [0.0089, 0.0105, 0.0292, 0.0148],\n",
      "        [0.0202, 0.0177, 0.0200, 0.0090],\n",
      "        [0.0273, 0.0103, 0.0091, 0.0123],\n",
      "        [0.0450, 0.0300, 0.0476, 0.0214],\n",
      "        [0.0547, 0.0752, 0.0475, 0.0064],\n",
      "        [0.0828, 0.0558, 0.0122, 0.0100],\n",
      "        [0.0779, 0.0363, 0.0131, 0.0141],\n",
      "        [0.0413, 0.0180, 0.0103, 0.0180],\n",
      "        [0.0146, 0.0147, 0.0240, 0.0196],\n",
      "        [0.0209, 0.0315, 0.0287, 0.0142],\n",
      "        [0.0346, 0.0329, 0.0191, 0.0063],\n",
      "        [0.0418, 0.0297, 0.0040, 0.0245],\n",
      "        [0.0363, 0.0120, 0.0183, 0.0347],\n",
      "        [0.0639, 0.0395, 0.0260, 0.0555],\n",
      "        [0.0871, 0.0783, 0.0016, 0.0549],\n",
      "        [0.0989, 0.0237, 0.0276, 0.0345],\n",
      "        [0.0091, 0.0444, 0.0472, 0.0335],\n",
      "        [0.0061, 0.0059, 0.0175, 0.0106],\n",
      "        [0.0304, 0.0560, 0.0424, 0.0856],\n",
      "        [0.0428, 0.0622, 0.0642, 0.0448],\n",
      "        [0.0933, 0.0641, 0.0283, 0.0161],\n",
      "        [0.0141, 0.0186, 0.0090, 0.0263],\n",
      "        [0.0907, 0.1144, 0.0798, 0.0430],\n",
      "        [0.1153, 0.1018, 0.1280, 0.0851],\n",
      "        [0.0501, 0.0674, 0.0478, 0.0163],\n",
      "        [0.1037, 0.0876, 0.0585, 0.0204],\n",
      "        [0.0227, 0.0171, 0.0152, 0.0325],\n",
      "        [0.1192, 0.1264, 0.1154, 0.1302],\n",
      "        [0.0506, 0.0765, 0.0262, 0.0249],\n",
      "        [0.0867, 0.0378, 0.0335, 0.0359],\n",
      "        [0.0512, 0.0307, 0.0192, 0.0171],\n",
      "        [0.0322, 0.0084, 0.0199, 0.0461],\n",
      "        [0.0587, 0.0171, 0.0753, 0.1502],\n",
      "        [0.0903, 0.0211, 0.0052, 0.0081],\n",
      "        [0.0195, 0.0334, 0.0604, 0.0305],\n",
      "        [0.0573, 0.0791, 0.0076, 0.0153],\n",
      "        [0.0445, 0.0739, 0.0438, 0.0345],\n",
      "        [0.0850, 0.0573, 0.0481, 0.0331],\n",
      "        [0.1033, 0.0662, 0.0571, 0.1082],\n",
      "        [0.0109, 0.0014, 0.0155, 0.0351],\n",
      "        [0.0152, 0.0262, 0.0419, 0.0545],\n",
      "        [0.0397, 0.0743, 0.0435, 0.0229],\n",
      "        [0.0855, 0.0570, 0.0356, 0.0052],\n",
      "        [0.0682, 0.0491, 0.0055, 0.0201],\n",
      "        [0.0246, 0.0417, 0.0651, 0.0952],\n",
      "        [0.0341, 0.0575, 0.0930, 0.0615],\n",
      "        [0.0695, 0.0892, 0.1135, 0.0432]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.289734840393066\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 49\n",
      "X 資料 torch.Size([58, 18])\n",
      "Y 資料 torch.Size([58, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.007899763062596321, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引1，y= tensor([0.5927, 0.5884, 0.5900, 0.5749])\n",
      "目前模型的Data torch.Size([49, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7918, 0.7933, 0.7957, 0.7401],\n",
      "        [0.8018, 0.8043, 0.8079, 0.7519],\n",
      "        [0.7946, 0.7964, 0.7992, 0.7434],\n",
      "        [0.8060, 0.8090, 0.8131, 0.7570],\n",
      "        [0.7742, 0.7741, 0.7743, 0.7192],\n",
      "        [0.7493, 0.7467, 0.7440, 0.6897],\n",
      "        [0.7392, 0.7356, 0.7316, 0.6777],\n",
      "        [0.7136, 0.7075, 0.7004, 0.6474],\n",
      "        [0.7025, 0.6954, 0.6869, 0.6343],\n",
      "        [0.6989, 0.6914, 0.6825, 0.6300],\n",
      "        [0.6976, 0.6900, 0.6809, 0.6284],\n",
      "        [0.6931, 0.6851, 0.6754, 0.6231],\n",
      "        [0.6940, 0.6861, 0.6766, 0.6242],\n",
      "        [0.6926, 0.6845, 0.6749, 0.6225],\n",
      "        [0.7365, 0.7326, 0.7283, 0.6745],\n",
      "        [0.7802, 0.7806, 0.7817, 0.7264],\n",
      "        [0.8013, 0.8037, 0.8073, 0.7513],\n",
      "        [0.7891, 0.7904, 0.7925, 0.7369],\n",
      "        [0.8287, 0.8338, 0.8408, 0.7838],\n",
      "        [0.8701, 0.8793, 0.8913, 0.8329],\n",
      "        [0.7232, 0.7181, 0.7122, 0.6588],\n",
      "        [0.6889, 0.6804, 0.6703, 0.6181],\n",
      "        [0.8072, 0.8102, 0.8145, 0.7583],\n",
      "        [0.6611, 0.6500, 0.6364, 0.5852],\n",
      "        [0.6611, 0.6500, 0.6364, 0.5852],\n",
      "        [0.7415, 0.7381, 0.7344, 0.6804],\n",
      "        [0.7018, 0.6946, 0.6860, 0.6334],\n",
      "        [0.7760, 0.7760, 0.7765, 0.7213],\n",
      "        [0.6611, 0.6500, 0.6364, 0.5852],\n",
      "        [0.7726, 0.7723, 0.7724, 0.7174],\n",
      "        [0.7622, 0.7608, 0.7596, 0.7049],\n",
      "        [0.7949, 0.7967, 0.7995, 0.7437],\n",
      "        [0.6611, 0.6500, 0.6364, 0.5852],\n",
      "        [0.6611, 0.6500, 0.6364, 0.5852],\n",
      "        [0.6611, 0.6500, 0.6364, 0.5852],\n",
      "        [0.6611, 0.6500, 0.6364, 0.5852],\n",
      "        [0.6611, 0.6500, 0.6364, 0.5852],\n",
      "        [0.6611, 0.6500, 0.6364, 0.5852],\n",
      "        [0.6611, 0.6500, 0.6364, 0.5852],\n",
      "        [0.6611, 0.6500, 0.6364, 0.5852],\n",
      "        [0.6877, 0.6791, 0.6688, 0.6166],\n",
      "        [0.7293, 0.7248, 0.7195, 0.6660],\n",
      "        [0.6611, 0.6500, 0.6364, 0.5852],\n",
      "        [0.6611, 0.6500, 0.6364, 0.5852],\n",
      "        [0.6611, 0.6500, 0.6364, 0.5852],\n",
      "        [0.7022, 0.6951, 0.6866, 0.6339],\n",
      "        [0.6875, 0.6789, 0.6686, 0.6164],\n",
      "        [0.7004, 0.6930, 0.6843, 0.6317],\n",
      "        [0.6965, 0.6888, 0.6795, 0.6271]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0561, 0.0004, 0.0191, 0.0113],\n",
      "        [0.0089, 0.0105, 0.0292, 0.0148],\n",
      "        [0.0202, 0.0177, 0.0200, 0.0090],\n",
      "        [0.0273, 0.0103, 0.0091, 0.0123],\n",
      "        [0.0450, 0.0300, 0.0476, 0.0214],\n",
      "        [0.0547, 0.0752, 0.0475, 0.0064],\n",
      "        [0.0828, 0.0558, 0.0122, 0.0100],\n",
      "        [0.0779, 0.0363, 0.0131, 0.0141],\n",
      "        [0.0413, 0.0180, 0.0103, 0.0180],\n",
      "        [0.0146, 0.0147, 0.0240, 0.0196],\n",
      "        [0.0209, 0.0315, 0.0287, 0.0142],\n",
      "        [0.0346, 0.0329, 0.0191, 0.0063],\n",
      "        [0.0418, 0.0297, 0.0040, 0.0245],\n",
      "        [0.0363, 0.0120, 0.0183, 0.0347],\n",
      "        [0.0639, 0.0395, 0.0260, 0.0555],\n",
      "        [0.0871, 0.0783, 0.0016, 0.0549],\n",
      "        [0.0989, 0.0237, 0.0276, 0.0345],\n",
      "        [0.0091, 0.0444, 0.0472, 0.0335],\n",
      "        [0.0061, 0.0059, 0.0175, 0.0106],\n",
      "        [0.0304, 0.0560, 0.0424, 0.0856],\n",
      "        [0.0428, 0.0622, 0.0642, 0.0448],\n",
      "        [0.0933, 0.0641, 0.0283, 0.0161],\n",
      "        [0.0141, 0.0186, 0.0090, 0.0263],\n",
      "        [0.0907, 0.1144, 0.0798, 0.0430],\n",
      "        [0.1153, 0.1018, 0.1280, 0.0851],\n",
      "        [0.0501, 0.0674, 0.0478, 0.0163],\n",
      "        [0.1037, 0.0876, 0.0585, 0.0204],\n",
      "        [0.0227, 0.0171, 0.0152, 0.0325],\n",
      "        [0.1192, 0.1264, 0.1154, 0.1302],\n",
      "        [0.0506, 0.0765, 0.0262, 0.0249],\n",
      "        [0.0867, 0.0378, 0.0335, 0.0359],\n",
      "        [0.0512, 0.0307, 0.0192, 0.0171],\n",
      "        [0.0322, 0.0084, 0.0199, 0.0461],\n",
      "        [0.0587, 0.0171, 0.0753, 0.1502],\n",
      "        [0.0903, 0.0211, 0.0052, 0.0081],\n",
      "        [0.0195, 0.0334, 0.0604, 0.0305],\n",
      "        [0.0573, 0.0791, 0.0076, 0.0153],\n",
      "        [0.0445, 0.0739, 0.0438, 0.0345],\n",
      "        [0.0850, 0.0573, 0.0481, 0.0331],\n",
      "        [0.1033, 0.0662, 0.0571, 0.1082],\n",
      "        [0.0109, 0.0014, 0.0155, 0.0351],\n",
      "        [0.0152, 0.0262, 0.0419, 0.0545],\n",
      "        [0.0397, 0.0743, 0.0435, 0.0229],\n",
      "        [0.0855, 0.0570, 0.0356, 0.0052],\n",
      "        [0.0682, 0.0491, 0.0055, 0.0201],\n",
      "        [0.0246, 0.0417, 0.0651, 0.0952],\n",
      "        [0.0341, 0.0575, 0.0930, 0.0615],\n",
      "        [0.0695, 0.0892, 0.1135, 0.0432],\n",
      "        [0.1038, 0.1004, 0.0896, 0.0522]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0556,     0.0011,     0.0184,     0.0125],\n",
      "        [    0.0100,     0.0091,     0.0307,     0.0128],\n",
      "        [    0.0177,     0.0205,     0.0169,     0.0056],\n",
      "        [    0.0302,     0.0069,     0.0128,     0.0082],\n",
      "        [    0.0416,     0.0262,     0.0434,     0.0168],\n",
      "        [    0.0498,     0.0699,     0.0416,     0.0000],\n",
      "        [    0.0795,     0.0525,     0.0084,     0.0144],\n",
      "        [    0.0735,     0.0318,     0.0080,     0.0198],\n",
      "        [    0.0365,     0.0133,     0.0157,     0.0241],\n",
      "        [    0.0096,     0.0197,     0.0296,     0.0259],\n",
      "        [    0.0254,     0.0359,     0.0337,     0.0199],\n",
      "        [    0.0391,     0.0372,     0.0241,     0.0006],\n",
      "        [    0.0461,     0.0339,     0.0088,     0.0190],\n",
      "        [    0.0401,     0.0156,     0.0141,     0.0298],\n",
      "        [    0.0676,     0.0432,     0.0302,     0.0507],\n",
      "        [    0.0900,     0.0816,     0.0053,     0.0509],\n",
      "        [    0.1017,     0.0269,     0.0241,     0.0307],\n",
      "        [    0.0114,     0.0418,     0.0443,     0.0302],\n",
      "        [    0.0038,     0.0029,     0.0207,     0.0071],\n",
      "        [    0.0334,     0.0600,     0.0466,     0.0898],\n",
      "        [    0.0455,     0.0655,     0.0678,     0.0475],\n",
      "        [    0.0933,     0.0648,     0.0289,     0.0158],\n",
      "        [    0.0177,     0.0228,     0.0136,     0.0312],\n",
      "        [    0.0926,     0.1173,     0.0827,     0.0411],\n",
      "        [    0.1171,     0.1047,     0.1309,     0.0869],\n",
      "        [    0.0481,     0.0654,     0.0455,     0.0134],\n",
      "        [    0.1051,     0.0896,     0.0606,     0.0216],\n",
      "        [    0.0193,     0.0135,     0.0111,     0.0280],\n",
      "        [    0.1211,     0.1293,     0.1183,     0.1321],\n",
      "        [    0.0469,     0.0724,     0.0217,     0.0199],\n",
      "        [    0.0838,     0.0347,     0.0300,     0.0319],\n",
      "        [    0.0467,     0.0259,     0.0138,     0.0124],\n",
      "        [    0.0304,     0.0055,     0.0169,     0.0442],\n",
      "        [    0.0569,     0.0142,     0.0783,     0.1520],\n",
      "        [    0.0884,     0.0182,     0.0081,     0.0063],\n",
      "        [    0.0176,     0.0305,     0.0574,     0.0287],\n",
      "        [    0.0554,     0.0763,     0.0046,     0.0171],\n",
      "        [    0.0427,     0.0710,     0.0408,     0.0327],\n",
      "        [    0.0832,     0.0544,     0.0451,     0.0312],\n",
      "        [    0.1042,     0.0680,     0.0553,     0.1075],\n",
      "        [    0.0146,     0.0033,     0.0104,     0.0311],\n",
      "        [    0.0166,     0.0243,     0.0399,     0.0534],\n",
      "        [    0.0378,     0.0715,     0.0405,     0.0210],\n",
      "        [    0.0836,     0.0542,     0.0327,     0.0071],\n",
      "        [    0.0663,     0.0463,     0.0026,     0.0182],\n",
      "        [    0.0209,     0.0371,     0.0602,     0.0912],\n",
      "        [    0.0305,     0.0528,     0.0879,     0.0576],\n",
      "        [    0.0661,     0.0849,     0.1089,     0.0396],\n",
      "        [    0.0903,     0.0849,     0.0726,     0.0366]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.698697328567505\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 50\n",
      "X 資料 torch.Size([57, 18])\n",
      "Y 資料 torch.Size([57, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.010384698398411274, 36)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引36，y= tensor([0.4785, 0.6024, 0.6329, 0.6661])\n",
      "目前模型的Data torch.Size([50, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7923, 0.7940, 0.7964, 0.7412],\n",
      "        [0.8029, 0.8057, 0.8095, 0.7538],\n",
      "        [0.7971, 0.7993, 0.8023, 0.7469],\n",
      "        [0.8089, 0.8124, 0.8168, 0.7610],\n",
      "        [0.7777, 0.7779, 0.7786, 0.7239],\n",
      "        [0.7543, 0.7520, 0.7499, 0.6961],\n",
      "        [0.7425, 0.7390, 0.7354, 0.6821],\n",
      "        [0.7180, 0.7120, 0.7055, 0.6531],\n",
      "        [0.7073, 0.7002, 0.6924, 0.6404],\n",
      "        [0.7039, 0.6964, 0.6881, 0.6363],\n",
      "        [0.7021, 0.6944, 0.6859, 0.6341],\n",
      "        [0.6976, 0.6895, 0.6805, 0.6288],\n",
      "        [0.6983, 0.6903, 0.6814, 0.6297],\n",
      "        [0.6964, 0.6882, 0.6790, 0.6275],\n",
      "        [0.7401, 0.7364, 0.7325, 0.6793],\n",
      "        [0.7832, 0.7839, 0.7853, 0.7304],\n",
      "        [0.8040, 0.8069, 0.8108, 0.7551],\n",
      "        [0.7914, 0.7930, 0.7954, 0.7402],\n",
      "        [0.8311, 0.8368, 0.8440, 0.7873],\n",
      "        [0.8731, 0.8832, 0.8955, 0.8372],\n",
      "        [0.7205, 0.7148, 0.7085, 0.6560],\n",
      "        [0.6888, 0.6798, 0.6697, 0.6184],\n",
      "        [0.8108, 0.8144, 0.8191, 0.7632],\n",
      "        [0.6593, 0.6471, 0.6335, 0.5833],\n",
      "        [0.6593, 0.6471, 0.6335, 0.5833],\n",
      "        [0.7435, 0.7401, 0.7367, 0.6833],\n",
      "        [0.7004, 0.6926, 0.6839, 0.6322],\n",
      "        [0.7793, 0.7796, 0.7805, 0.7258],\n",
      "        [0.6593, 0.6471, 0.6335, 0.5833],\n",
      "        [0.7764, 0.7764, 0.7770, 0.7224],\n",
      "        [0.7651, 0.7639, 0.7631, 0.7089],\n",
      "        [0.7904, 0.7919, 0.7941, 0.7390],\n",
      "        [0.6593, 0.6471, 0.6335, 0.5833],\n",
      "        [0.6593, 0.6471, 0.6335, 0.5833],\n",
      "        [0.6593, 0.6471, 0.6335, 0.5833],\n",
      "        [0.6593, 0.6471, 0.6335, 0.5833],\n",
      "        [0.6593, 0.6471, 0.6335, 0.5833],\n",
      "        [0.6593, 0.6471, 0.6335, 0.5833],\n",
      "        [0.6593, 0.6471, 0.6335, 0.5833],\n",
      "        [0.6602, 0.6482, 0.6347, 0.5845],\n",
      "        [0.6840, 0.6744, 0.6638, 0.6127],\n",
      "        [0.7279, 0.7229, 0.7176, 0.6648],\n",
      "        [0.6593, 0.6471, 0.6335, 0.5833],\n",
      "        [0.6593, 0.6471, 0.6335, 0.5833],\n",
      "        [0.6593, 0.6471, 0.6335, 0.5833],\n",
      "        [0.6985, 0.6905, 0.6816, 0.6299],\n",
      "        [0.6838, 0.6742, 0.6636, 0.6125],\n",
      "        [0.6970, 0.6888, 0.6797, 0.6281],\n",
      "        [0.6830, 0.6733, 0.6626, 0.6115],\n",
      "        [0.6593, 0.6471, 0.6335, 0.5833]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0556,     0.0011,     0.0184,     0.0125],\n",
      "        [    0.0100,     0.0091,     0.0307,     0.0128],\n",
      "        [    0.0177,     0.0205,     0.0169,     0.0056],\n",
      "        [    0.0302,     0.0069,     0.0128,     0.0082],\n",
      "        [    0.0416,     0.0262,     0.0434,     0.0168],\n",
      "        [    0.0498,     0.0699,     0.0416,     0.0000],\n",
      "        [    0.0795,     0.0525,     0.0084,     0.0144],\n",
      "        [    0.0735,     0.0318,     0.0080,     0.0198],\n",
      "        [    0.0365,     0.0133,     0.0157,     0.0241],\n",
      "        [    0.0096,     0.0197,     0.0296,     0.0259],\n",
      "        [    0.0254,     0.0359,     0.0337,     0.0199],\n",
      "        [    0.0391,     0.0372,     0.0241,     0.0006],\n",
      "        [    0.0461,     0.0339,     0.0088,     0.0190],\n",
      "        [    0.0401,     0.0156,     0.0141,     0.0298],\n",
      "        [    0.0676,     0.0432,     0.0302,     0.0507],\n",
      "        [    0.0900,     0.0816,     0.0053,     0.0509],\n",
      "        [    0.1017,     0.0269,     0.0241,     0.0307],\n",
      "        [    0.0114,     0.0418,     0.0443,     0.0302],\n",
      "        [    0.0038,     0.0029,     0.0207,     0.0071],\n",
      "        [    0.0334,     0.0600,     0.0466,     0.0898],\n",
      "        [    0.0455,     0.0655,     0.0678,     0.0475],\n",
      "        [    0.0933,     0.0648,     0.0289,     0.0158],\n",
      "        [    0.0177,     0.0228,     0.0136,     0.0312],\n",
      "        [    0.0926,     0.1173,     0.0827,     0.0411],\n",
      "        [    0.1171,     0.1047,     0.1309,     0.0869],\n",
      "        [    0.0481,     0.0654,     0.0455,     0.0134],\n",
      "        [    0.1051,     0.0896,     0.0606,     0.0216],\n",
      "        [    0.0193,     0.0135,     0.0111,     0.0280],\n",
      "        [    0.1211,     0.1293,     0.1183,     0.1321],\n",
      "        [    0.0469,     0.0724,     0.0217,     0.0199],\n",
      "        [    0.0838,     0.0347,     0.0300,     0.0319],\n",
      "        [    0.0467,     0.0259,     0.0138,     0.0124],\n",
      "        [    0.0304,     0.0055,     0.0169,     0.0442],\n",
      "        [    0.0569,     0.0142,     0.0783,     0.1520],\n",
      "        [    0.0884,     0.0182,     0.0081,     0.0063],\n",
      "        [    0.0176,     0.0305,     0.0574,     0.0287],\n",
      "        [    0.0554,     0.0763,     0.0046,     0.0171],\n",
      "        [    0.0427,     0.0710,     0.0408,     0.0327],\n",
      "        [    0.0832,     0.0544,     0.0451,     0.0312],\n",
      "        [    0.1042,     0.0680,     0.0553,     0.1075],\n",
      "        [    0.0146,     0.0033,     0.0104,     0.0311],\n",
      "        [    0.0166,     0.0243,     0.0399,     0.0534],\n",
      "        [    0.0378,     0.0715,     0.0405,     0.0210],\n",
      "        [    0.0836,     0.0542,     0.0327,     0.0071],\n",
      "        [    0.0663,     0.0463,     0.0026,     0.0182],\n",
      "        [    0.0209,     0.0371,     0.0602,     0.0912],\n",
      "        [    0.0305,     0.0528,     0.0879,     0.0576],\n",
      "        [    0.0661,     0.0849,     0.1089,     0.0396],\n",
      "        [    0.0903,     0.0849,     0.0726,     0.0366],\n",
      "        [    0.1808,     0.0447,     0.0006,     0.0828]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 2\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0561, 0.0002, 0.0195, 0.0122],\n",
      "        [0.0104, 0.0094, 0.0300, 0.0129],\n",
      "        [0.0165, 0.0214, 0.0162, 0.0042],\n",
      "        [0.0322, 0.0056, 0.0136, 0.0069],\n",
      "        [0.0407, 0.0250, 0.0420, 0.0145],\n",
      "        [0.0492, 0.0683, 0.0392, 0.0036],\n",
      "        [0.0811, 0.0528, 0.0079, 0.0164],\n",
      "        [0.0757, 0.0319, 0.0068, 0.0228],\n",
      "        [0.0394, 0.0137, 0.0168, 0.0271],\n",
      "        [0.0124, 0.0195, 0.0311, 0.0293],\n",
      "        [0.0221, 0.0352, 0.0346, 0.0228],\n",
      "        [0.0358, 0.0367, 0.0253, 0.0027],\n",
      "        [0.0429, 0.0334, 0.0101, 0.0157],\n",
      "        [0.0364, 0.0147, 0.0133, 0.0269],\n",
      "        [0.0659, 0.0430, 0.0308, 0.0486],\n",
      "        [0.0900, 0.0817, 0.0053, 0.0499],\n",
      "        [0.1029, 0.0275, 0.0238, 0.0299],\n",
      "        [0.0115, 0.0420, 0.0446, 0.0297],\n",
      "        [0.0015, 0.0021, 0.0206, 0.0070],\n",
      "        [0.0385, 0.0623, 0.0473, 0.0901],\n",
      "        [0.0472, 0.0652, 0.0661, 0.0441],\n",
      "        [0.0986, 0.0670, 0.0294, 0.0141],\n",
      "        [0.0214, 0.0258, 0.0163, 0.0344],\n",
      "        [0.1003, 0.1212, 0.0845, 0.0421],\n",
      "        [0.1249, 0.1086, 0.1327, 0.0860],\n",
      "        [0.0490, 0.0649, 0.0441, 0.0107],\n",
      "        [0.1107, 0.0927, 0.0623, 0.0211],\n",
      "        [0.0180, 0.0119, 0.0093, 0.0253],\n",
      "        [0.1288, 0.1332, 0.1201, 0.1311],\n",
      "        [0.0459, 0.0711, 0.0201, 0.0173],\n",
      "        [0.0837, 0.0339, 0.0288, 0.0296],\n",
      "        [0.0471, 0.0260, 0.0138, 0.0133],\n",
      "        [0.0226, 0.0016, 0.0152, 0.0451],\n",
      "        [0.0491, 0.0103, 0.0800, 0.1511],\n",
      "        [0.0806, 0.0143, 0.0099, 0.0072],\n",
      "        [0.0099, 0.0266, 0.0557, 0.0296],\n",
      "        [0.0476, 0.0723, 0.0028, 0.0162],\n",
      "        [0.0349, 0.0671, 0.0391, 0.0336],\n",
      "        [0.0754, 0.0505, 0.0433, 0.0322],\n",
      "        [0.1072, 0.0669, 0.0591, 0.1137],\n",
      "        [0.0230, 0.0087, 0.0065, 0.0296],\n",
      "        [0.0211, 0.0215, 0.0380, 0.0532],\n",
      "        [0.0300, 0.0675, 0.0388, 0.0220],\n",
      "        [0.0758, 0.0502, 0.0309, 0.0062],\n",
      "        [0.0585, 0.0424, 0.0008, 0.0192],\n",
      "        [0.0129, 0.0317, 0.0559, 0.0893],\n",
      "        [0.0215, 0.0468, 0.0834, 0.0555],\n",
      "        [0.0582, 0.0795, 0.1047, 0.0377],\n",
      "        [0.0760, 0.0732, 0.0618, 0.0286],\n",
      "        [0.1730, 0.0408, 0.0012, 0.0818]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 14.19424557685852\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 51\n",
      "X 資料 torch.Size([56, 18])\n",
      "Y 資料 torch.Size([56, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.009237682446837425, 2)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引2，y= tensor([0.5900, 0.6143, 0.6585, 0.6230])\n",
      "目前模型的Data torch.Size([51, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7917, 0.7931, 0.7953, 0.7409],\n",
      "        [0.8033, 0.8054, 0.8087, 0.7538],\n",
      "        [0.7983, 0.8002, 0.8030, 0.7483],\n",
      "        [0.8109, 0.8136, 0.8177, 0.7623],\n",
      "        [0.7786, 0.7790, 0.7799, 0.7262],\n",
      "        [0.7548, 0.7537, 0.7523, 0.6997],\n",
      "        [0.7408, 0.7387, 0.7359, 0.6840],\n",
      "        [0.7157, 0.7119, 0.7067, 0.6560],\n",
      "        [0.7044, 0.6998, 0.6935, 0.6434],\n",
      "        [0.7011, 0.6962, 0.6896, 0.6397],\n",
      "        [0.6987, 0.6937, 0.6868, 0.6371],\n",
      "        [0.6943, 0.6889, 0.6816, 0.6321],\n",
      "        [0.6951, 0.6898, 0.6826, 0.6330],\n",
      "        [0.6927, 0.6873, 0.6798, 0.6303],\n",
      "        [0.7384, 0.7361, 0.7331, 0.6814],\n",
      "        [0.7832, 0.7840, 0.7853, 0.7314],\n",
      "        [0.8052, 0.8075, 0.8110, 0.7560],\n",
      "        [0.7915, 0.7929, 0.7951, 0.7407],\n",
      "        [0.8333, 0.8376, 0.8438, 0.7874],\n",
      "        [0.8782, 0.8855, 0.8961, 0.8375],\n",
      "        [0.7188, 0.7152, 0.7102, 0.6595],\n",
      "        [0.6836, 0.6775, 0.6692, 0.6201],\n",
      "        [0.8145, 0.8174, 0.8218, 0.7663],\n",
      "        [0.6515, 0.6432, 0.6317, 0.5843],\n",
      "        [0.6515, 0.6432, 0.6317, 0.5843],\n",
      "        [0.7426, 0.7406, 0.7380, 0.6861],\n",
      "        [0.6948, 0.6895, 0.6822, 0.6326],\n",
      "        [0.7806, 0.7812, 0.7824, 0.7285],\n",
      "        [0.6515, 0.6432, 0.6317, 0.5843],\n",
      "        [0.7774, 0.7778, 0.7786, 0.7249],\n",
      "        [0.7651, 0.7647, 0.7643, 0.7112],\n",
      "        [0.7907, 0.7920, 0.7941, 0.7398],\n",
      "        [0.6515, 0.6432, 0.6317, 0.5843],\n",
      "        [0.6515, 0.6432, 0.6317, 0.5843],\n",
      "        [0.6515, 0.6432, 0.6317, 0.5843],\n",
      "        [0.6515, 0.6432, 0.6317, 0.5843],\n",
      "        [0.6515, 0.6432, 0.6317, 0.5843],\n",
      "        [0.6515, 0.6432, 0.6317, 0.5843],\n",
      "        [0.6515, 0.6432, 0.6317, 0.5843],\n",
      "        [0.6572, 0.6493, 0.6384, 0.5907],\n",
      "        [0.6756, 0.6690, 0.6599, 0.6112],\n",
      "        [0.7235, 0.7201, 0.7157, 0.6647],\n",
      "        [0.6515, 0.6432, 0.6317, 0.5843],\n",
      "        [0.6515, 0.6432, 0.6317, 0.5843],\n",
      "        [0.6515, 0.6432, 0.6317, 0.5843],\n",
      "        [0.6906, 0.6850, 0.6774, 0.6280],\n",
      "        [0.6749, 0.6682, 0.6590, 0.6104],\n",
      "        [0.6891, 0.6834, 0.6756, 0.6262],\n",
      "        [0.6687, 0.6615, 0.6518, 0.6034],\n",
      "        [0.6515, 0.6432, 0.6317, 0.5843],\n",
      "        [0.7274, 0.7243, 0.7203, 0.6691]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0561, 0.0002, 0.0195, 0.0122],\n",
      "        [0.0104, 0.0094, 0.0300, 0.0129],\n",
      "        [0.0165, 0.0214, 0.0162, 0.0042],\n",
      "        [0.0322, 0.0056, 0.0136, 0.0069],\n",
      "        [0.0407, 0.0250, 0.0420, 0.0145],\n",
      "        [0.0492, 0.0683, 0.0392, 0.0036],\n",
      "        [0.0811, 0.0528, 0.0079, 0.0164],\n",
      "        [0.0757, 0.0319, 0.0068, 0.0228],\n",
      "        [0.0394, 0.0137, 0.0168, 0.0271],\n",
      "        [0.0124, 0.0195, 0.0311, 0.0293],\n",
      "        [0.0221, 0.0352, 0.0346, 0.0228],\n",
      "        [0.0358, 0.0367, 0.0253, 0.0027],\n",
      "        [0.0429, 0.0334, 0.0101, 0.0157],\n",
      "        [0.0364, 0.0147, 0.0133, 0.0269],\n",
      "        [0.0659, 0.0430, 0.0308, 0.0486],\n",
      "        [0.0900, 0.0817, 0.0053, 0.0499],\n",
      "        [0.1029, 0.0275, 0.0238, 0.0299],\n",
      "        [0.0115, 0.0420, 0.0446, 0.0297],\n",
      "        [0.0015, 0.0021, 0.0206, 0.0070],\n",
      "        [0.0385, 0.0623, 0.0473, 0.0901],\n",
      "        [0.0472, 0.0652, 0.0661, 0.0441],\n",
      "        [0.0986, 0.0670, 0.0294, 0.0141],\n",
      "        [0.0214, 0.0258, 0.0163, 0.0344],\n",
      "        [0.1003, 0.1212, 0.0845, 0.0421],\n",
      "        [0.1249, 0.1086, 0.1327, 0.0860],\n",
      "        [0.0490, 0.0649, 0.0441, 0.0107],\n",
      "        [0.1107, 0.0927, 0.0623, 0.0211],\n",
      "        [0.0180, 0.0119, 0.0093, 0.0253],\n",
      "        [0.1288, 0.1332, 0.1201, 0.1311],\n",
      "        [0.0459, 0.0711, 0.0201, 0.0173],\n",
      "        [0.0837, 0.0339, 0.0288, 0.0296],\n",
      "        [0.0471, 0.0260, 0.0138, 0.0133],\n",
      "        [0.0226, 0.0016, 0.0152, 0.0451],\n",
      "        [0.0491, 0.0103, 0.0800, 0.1511],\n",
      "        [0.0806, 0.0143, 0.0099, 0.0072],\n",
      "        [0.0099, 0.0266, 0.0557, 0.0296],\n",
      "        [0.0476, 0.0723, 0.0028, 0.0162],\n",
      "        [0.0349, 0.0671, 0.0391, 0.0336],\n",
      "        [0.0754, 0.0505, 0.0433, 0.0322],\n",
      "        [0.1072, 0.0669, 0.0591, 0.1137],\n",
      "        [0.0230, 0.0087, 0.0065, 0.0296],\n",
      "        [0.0211, 0.0215, 0.0380, 0.0532],\n",
      "        [0.0300, 0.0675, 0.0388, 0.0220],\n",
      "        [0.0758, 0.0502, 0.0309, 0.0062],\n",
      "        [0.0585, 0.0424, 0.0008, 0.0192],\n",
      "        [0.0129, 0.0317, 0.0559, 0.0893],\n",
      "        [0.0215, 0.0468, 0.0834, 0.0555],\n",
      "        [0.0582, 0.0795, 0.1047, 0.0377],\n",
      "        [0.0760, 0.0732, 0.0618, 0.0286],\n",
      "        [0.1730, 0.0408, 0.0012, 0.0818],\n",
      "        [0.1375, 0.1101, 0.0618, 0.0461]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 2\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0594, 0.0027, 0.0215, 0.0098],\n",
      "        [0.0080, 0.0113, 0.0290, 0.0143],\n",
      "        [0.0184, 0.0199, 0.0168, 0.0051],\n",
      "        [0.0307, 0.0067, 0.0136, 0.0074],\n",
      "        [0.0419, 0.0256, 0.0416, 0.0144],\n",
      "        [0.0494, 0.0677, 0.0374, 0.0050],\n",
      "        [0.0830, 0.0539, 0.0081, 0.0159],\n",
      "        [0.0767, 0.0319, 0.0057, 0.0236],\n",
      "        [0.0397, 0.0130, 0.0186, 0.0288],\n",
      "        [0.0125, 0.0204, 0.0331, 0.0311],\n",
      "        [0.0223, 0.0365, 0.0371, 0.0250],\n",
      "        [0.0359, 0.0379, 0.0277, 0.0048],\n",
      "        [0.0426, 0.0343, 0.0120, 0.0140],\n",
      "        [0.0356, 0.0150, 0.0120, 0.0258],\n",
      "        [0.0650, 0.0429, 0.0318, 0.0479],\n",
      "        [0.0893, 0.0815, 0.0062, 0.0494],\n",
      "        [0.1024, 0.0275, 0.0227, 0.0293],\n",
      "        [0.0104, 0.0426, 0.0442, 0.0297],\n",
      "        [0.0022, 0.0025, 0.0213, 0.0069],\n",
      "        [0.0379, 0.0618, 0.0479, 0.0901],\n",
      "        [0.0570, 0.0746, 0.0754, 0.0532],\n",
      "        [0.1014, 0.0689, 0.0304, 0.0151],\n",
      "        [0.0223, 0.0273, 0.0191, 0.0365],\n",
      "        [0.1026, 0.1223, 0.0846, 0.0419],\n",
      "        [0.1271, 0.1097, 0.1328, 0.0861],\n",
      "        [0.0494, 0.0644, 0.0426, 0.0095],\n",
      "        [0.1144, 0.0955, 0.0643, 0.0232],\n",
      "        [0.0176, 0.0108, 0.0070, 0.0235],\n",
      "        [0.1311, 0.1343, 0.1202, 0.1313],\n",
      "        [0.0463, 0.0709, 0.0188, 0.0165],\n",
      "        [0.0846, 0.0341, 0.0279, 0.0291],\n",
      "        [0.0359, 0.0148, 0.0027, 0.0022],\n",
      "        [0.0204, 0.0005, 0.0150, 0.0450],\n",
      "        [0.0468, 0.0092, 0.0802, 0.1512],\n",
      "        [0.0784, 0.0132, 0.0100, 0.0071],\n",
      "        [0.0076, 0.0255, 0.0555, 0.0295],\n",
      "        [0.0454, 0.0713, 0.0027, 0.0163],\n",
      "        [0.0327, 0.0660, 0.0389, 0.0335],\n",
      "        [0.0732, 0.0494, 0.0432, 0.0320],\n",
      "        [0.1140, 0.0728, 0.0536, 0.1085],\n",
      "        [0.0285, 0.0134, 0.0025, 0.0257],\n",
      "        [0.0246, 0.0187, 0.0360, 0.0511],\n",
      "        [0.0278, 0.0665, 0.0386, 0.0218],\n",
      "        [0.0736, 0.0492, 0.0307, 0.0063],\n",
      "        [0.0563, 0.0413, 0.0007, 0.0190],\n",
      "        [0.0078, 0.0273, 0.0522, 0.0856],\n",
      "        [0.0161, 0.0422, 0.0795, 0.0517],\n",
      "        [0.0508, 0.0728, 0.0984, 0.0316],\n",
      "        [0.0586, 0.0559, 0.0440, 0.0115],\n",
      "        [0.1708, 0.0397, 0.0013, 0.0820],\n",
      "        [0.1209, 0.0934, 0.0446, 0.0295]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 14.660952091217041\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 52\n",
      "X 資料 torch.Size([55, 18])\n",
      "Y 資料 torch.Size([55, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.008041651919484138, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引1，y= tensor([0.5884, 0.5900, 0.6143, 0.6163])\n",
      "目前模型的Data torch.Size([52, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7884, 0.7902, 0.7933, 0.7386],\n",
      "        [0.8009, 0.8035, 0.8078, 0.7524],\n",
      "        [0.7964, 0.7987, 0.8025, 0.7474],\n",
      "        [0.8094, 0.8126, 0.8176, 0.7619],\n",
      "        [0.7774, 0.7784, 0.7804, 0.7263],\n",
      "        [0.7547, 0.7543, 0.7540, 0.7011],\n",
      "        [0.7389, 0.7375, 0.7357, 0.6836],\n",
      "        [0.7148, 0.7119, 0.7077, 0.6568],\n",
      "        [0.7041, 0.7005, 0.6953, 0.6450],\n",
      "        [0.7009, 0.6971, 0.6916, 0.6415],\n",
      "        [0.6990, 0.6950, 0.6893, 0.6393],\n",
      "        [0.6944, 0.6902, 0.6840, 0.6342],\n",
      "        [0.6948, 0.6906, 0.6845, 0.6347],\n",
      "        [0.6919, 0.6875, 0.6812, 0.6315],\n",
      "        [0.7375, 0.7360, 0.7341, 0.6821],\n",
      "        [0.7824, 0.7838, 0.7862, 0.7319],\n",
      "        [0.8047, 0.8075, 0.8121, 0.7566],\n",
      "        [0.7904, 0.7923, 0.7955, 0.7407],\n",
      "        [0.8326, 0.8372, 0.8445, 0.7875],\n",
      "        [0.8776, 0.8850, 0.8968, 0.8374],\n",
      "        [0.7090, 0.7057, 0.7010, 0.6504],\n",
      "        [0.6808, 0.6757, 0.6682, 0.6191],\n",
      "        [0.8154, 0.8189, 0.8246, 0.7685],\n",
      "        [0.6492, 0.6421, 0.6316, 0.5841],\n",
      "        [0.6492, 0.6421, 0.6316, 0.5841],\n",
      "        [0.7422, 0.7411, 0.7396, 0.6873],\n",
      "        [0.6911, 0.6866, 0.6802, 0.6306],\n",
      "        [0.7810, 0.7823, 0.7846, 0.7303],\n",
      "        [0.6492, 0.6421, 0.6316, 0.5841],\n",
      "        [0.7769, 0.7779, 0.7799, 0.7258],\n",
      "        [0.7643, 0.7645, 0.7652, 0.7118],\n",
      "        [0.7796, 0.7808, 0.7830, 0.7287],\n",
      "        [0.6492, 0.6421, 0.6316, 0.5841],\n",
      "        [0.6492, 0.6421, 0.6316, 0.5841],\n",
      "        [0.6492, 0.6421, 0.6316, 0.5841],\n",
      "        [0.6492, 0.6421, 0.6316, 0.5841],\n",
      "        [0.6492, 0.6421, 0.6316, 0.5841],\n",
      "        [0.6492, 0.6421, 0.6316, 0.5841],\n",
      "        [0.6492, 0.6421, 0.6316, 0.5841],\n",
      "        [0.6504, 0.6434, 0.6329, 0.5854],\n",
      "        [0.6701, 0.6643, 0.6558, 0.6073],\n",
      "        [0.7199, 0.7173, 0.7137, 0.6625],\n",
      "        [0.6492, 0.6421, 0.6316, 0.5841],\n",
      "        [0.6492, 0.6421, 0.6316, 0.5841],\n",
      "        [0.6492, 0.6421, 0.6316, 0.5841],\n",
      "        [0.6855, 0.6807, 0.6737, 0.6243],\n",
      "        [0.6695, 0.6637, 0.6551, 0.6066],\n",
      "        [0.6817, 0.6767, 0.6693, 0.6201],\n",
      "        [0.6513, 0.6443, 0.6339, 0.5863],\n",
      "        [0.6492, 0.6421, 0.6316, 0.5841],\n",
      "        [0.7108, 0.7076, 0.7031, 0.6524],\n",
      "        [0.7029, 0.6992, 0.6939, 0.6437]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0594, 0.0027, 0.0215, 0.0098],\n",
      "        [0.0080, 0.0113, 0.0290, 0.0143],\n",
      "        [0.0184, 0.0199, 0.0168, 0.0051],\n",
      "        [0.0307, 0.0067, 0.0136, 0.0074],\n",
      "        [0.0419, 0.0256, 0.0416, 0.0144],\n",
      "        [0.0494, 0.0677, 0.0374, 0.0050],\n",
      "        [0.0830, 0.0539, 0.0081, 0.0159],\n",
      "        [0.0767, 0.0319, 0.0057, 0.0236],\n",
      "        [0.0397, 0.0130, 0.0186, 0.0288],\n",
      "        [0.0125, 0.0204, 0.0331, 0.0311],\n",
      "        [0.0223, 0.0365, 0.0371, 0.0250],\n",
      "        [0.0359, 0.0379, 0.0277, 0.0048],\n",
      "        [0.0426, 0.0343, 0.0120, 0.0140],\n",
      "        [0.0356, 0.0150, 0.0120, 0.0258],\n",
      "        [0.0650, 0.0429, 0.0318, 0.0479],\n",
      "        [0.0893, 0.0815, 0.0062, 0.0494],\n",
      "        [0.1024, 0.0275, 0.0227, 0.0293],\n",
      "        [0.0104, 0.0426, 0.0442, 0.0297],\n",
      "        [0.0022, 0.0025, 0.0213, 0.0069],\n",
      "        [0.0379, 0.0618, 0.0479, 0.0901],\n",
      "        [0.0570, 0.0746, 0.0754, 0.0532],\n",
      "        [0.1014, 0.0689, 0.0304, 0.0151],\n",
      "        [0.0223, 0.0273, 0.0191, 0.0365],\n",
      "        [0.1026, 0.1223, 0.0846, 0.0419],\n",
      "        [0.1271, 0.1097, 0.1328, 0.0861],\n",
      "        [0.0494, 0.0644, 0.0426, 0.0095],\n",
      "        [0.1144, 0.0955, 0.0643, 0.0232],\n",
      "        [0.0176, 0.0108, 0.0070, 0.0235],\n",
      "        [0.1311, 0.1343, 0.1202, 0.1313],\n",
      "        [0.0463, 0.0709, 0.0188, 0.0165],\n",
      "        [0.0846, 0.0341, 0.0279, 0.0291],\n",
      "        [0.0359, 0.0148, 0.0027, 0.0022],\n",
      "        [0.0204, 0.0005, 0.0150, 0.0450],\n",
      "        [0.0468, 0.0092, 0.0802, 0.1512],\n",
      "        [0.0784, 0.0132, 0.0100, 0.0071],\n",
      "        [0.0076, 0.0255, 0.0555, 0.0295],\n",
      "        [0.0454, 0.0713, 0.0027, 0.0163],\n",
      "        [0.0327, 0.0660, 0.0389, 0.0335],\n",
      "        [0.0732, 0.0494, 0.0432, 0.0320],\n",
      "        [0.1140, 0.0728, 0.0536, 0.1085],\n",
      "        [0.0285, 0.0134, 0.0025, 0.0257],\n",
      "        [0.0246, 0.0187, 0.0360, 0.0511],\n",
      "        [0.0278, 0.0665, 0.0386, 0.0218],\n",
      "        [0.0736, 0.0492, 0.0307, 0.0063],\n",
      "        [0.0563, 0.0413, 0.0007, 0.0190],\n",
      "        [0.0078, 0.0273, 0.0522, 0.0856],\n",
      "        [0.0161, 0.0422, 0.0795, 0.0517],\n",
      "        [0.0508, 0.0728, 0.0984, 0.0316],\n",
      "        [0.0586, 0.0559, 0.0440, 0.0115],\n",
      "        [0.1708, 0.0397, 0.0013, 0.0820],\n",
      "        [0.1209, 0.0934, 0.0446, 0.0295],\n",
      "        [0.1146, 0.1093, 0.0797, 0.0274]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0633, 0.0067, 0.0255, 0.0062],\n",
      "        [0.0050, 0.0145, 0.0260, 0.0171],\n",
      "        [0.0203, 0.0180, 0.0184, 0.0066],\n",
      "        [0.0290, 0.0086, 0.0119, 0.0090],\n",
      "        [0.0431, 0.0268, 0.0424, 0.0149],\n",
      "        [0.0497, 0.0677, 0.0370, 0.0060],\n",
      "        [0.0856, 0.0563, 0.0102, 0.0147],\n",
      "        [0.0783, 0.0331, 0.0065, 0.0239],\n",
      "        [0.0412, 0.0139, 0.0181, 0.0294],\n",
      "        [0.0137, 0.0199, 0.0330, 0.0322],\n",
      "        [0.0210, 0.0359, 0.0369, 0.0261],\n",
      "        [0.0348, 0.0376, 0.0277, 0.0061],\n",
      "        [0.0414, 0.0337, 0.0118, 0.0129],\n",
      "        [0.0336, 0.0137, 0.0129, 0.0254],\n",
      "        [0.0629, 0.0411, 0.0303, 0.0486],\n",
      "        [0.0869, 0.0791, 0.0041, 0.0512],\n",
      "        [0.1002, 0.0251, 0.0248, 0.0313],\n",
      "        [0.0076, 0.0455, 0.0469, 0.0321],\n",
      "        [0.0051, 0.0058, 0.0182, 0.0102],\n",
      "        [0.0354, 0.0586, 0.0449, 0.0863],\n",
      "        [0.0626, 0.0799, 0.0807, 0.0571],\n",
      "        [0.1047, 0.0715, 0.0328, 0.0159],\n",
      "        [0.0227, 0.0276, 0.0199, 0.0371],\n",
      "        [0.1058, 0.1246, 0.0867, 0.0418],\n",
      "        [0.1303, 0.1120, 0.1349, 0.0862],\n",
      "        [0.0504, 0.0651, 0.0428, 0.0090],\n",
      "        [0.1189, 0.0995, 0.0683, 0.0256],\n",
      "        [0.0188, 0.0120, 0.0078, 0.0240],\n",
      "        [0.1343, 0.1366, 0.1223, 0.1314],\n",
      "        [0.0482, 0.0728, 0.0203, 0.0177],\n",
      "        [0.0869, 0.0363, 0.0298, 0.0304],\n",
      "        [0.0291, 0.0077, 0.0046, 0.0044],\n",
      "        [0.0172, 0.0018, 0.0130, 0.0449],\n",
      "        [0.0436, 0.0069, 0.0822, 0.1513],\n",
      "        [0.0752, 0.0109, 0.0121, 0.0070],\n",
      "        [0.0044, 0.0232, 0.0535, 0.0294],\n",
      "        [0.0422, 0.0690, 0.0006, 0.0165],\n",
      "        [0.0295, 0.0637, 0.0369, 0.0334],\n",
      "        [0.0700, 0.0471, 0.0411, 0.0319],\n",
      "        [0.1172, 0.0751, 0.0515, 0.1083],\n",
      "        [0.0347, 0.0190, 0.0032, 0.0219],\n",
      "        [0.0288, 0.0149, 0.0323, 0.0485],\n",
      "        [0.0246, 0.0642, 0.0366, 0.0217],\n",
      "        [0.0704, 0.0469, 0.0287, 0.0064],\n",
      "        [0.0531, 0.0390, 0.0014, 0.0189],\n",
      "        [0.0018, 0.0218, 0.0467, 0.0818],\n",
      "        [0.0100, 0.0367, 0.0739, 0.0480],\n",
      "        [0.0441, 0.0666, 0.0921, 0.0270],\n",
      "        [0.0534, 0.0514, 0.0396, 0.0091],\n",
      "        [0.1676, 0.0374, 0.0034, 0.0821],\n",
      "        [0.1054, 0.0777, 0.0279, 0.0148],\n",
      "        [0.0985, 0.0930, 0.0624, 0.0123]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 15.25868821144104\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 53\n",
      "X 資料 torch.Size([54, 18])\n",
      "Y 資料 torch.Size([54, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0076829902827739716, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.6008, 0.6309, 0.6038, 0.5342])\n",
      "目前模型的Data torch.Size([53, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7846, 0.7862, 0.7893, 0.7350],\n",
      "        [0.7979, 0.8003, 0.8047, 0.7495],\n",
      "        [0.7945, 0.7967, 0.8008, 0.7458],\n",
      "        [0.8077, 0.8106, 0.8160, 0.7602],\n",
      "        [0.7761, 0.7772, 0.7796, 0.7258],\n",
      "        [0.7544, 0.7542, 0.7545, 0.7021],\n",
      "        [0.7363, 0.7352, 0.7336, 0.6824],\n",
      "        [0.7132, 0.7108, 0.7070, 0.6572],\n",
      "        [0.7026, 0.6996, 0.6948, 0.6457],\n",
      "        [0.6998, 0.6966, 0.6915, 0.6426],\n",
      "        [0.6977, 0.6944, 0.6891, 0.6403],\n",
      "        [0.6933, 0.6898, 0.6841, 0.6355],\n",
      "        [0.6936, 0.6900, 0.6844, 0.6358],\n",
      "        [0.6900, 0.6862, 0.6802, 0.6319],\n",
      "        [0.7354, 0.7342, 0.7326, 0.6814],\n",
      "        [0.7800, 0.7814, 0.7841, 0.7300],\n",
      "        [0.8025, 0.8052, 0.8100, 0.7546],\n",
      "        [0.7876, 0.7894, 0.7928, 0.7383],\n",
      "        [0.8298, 0.8339, 0.8415, 0.7842],\n",
      "        [0.8751, 0.8818, 0.8938, 0.8337],\n",
      "        [0.7034, 0.7004, 0.6956, 0.6465],\n",
      "        [0.6775, 0.6731, 0.6658, 0.6183],\n",
      "        [0.8158, 0.8192, 0.8254, 0.7691],\n",
      "        [0.6461, 0.6398, 0.6295, 0.5840],\n",
      "        [0.6461, 0.6398, 0.6295, 0.5840],\n",
      "        [0.7413, 0.7404, 0.7394, 0.6878],\n",
      "        [0.6866, 0.6826, 0.6763, 0.6282],\n",
      "        [0.7798, 0.7811, 0.7838, 0.7298],\n",
      "        [0.6461, 0.6398, 0.6295, 0.5840],\n",
      "        [0.7750, 0.7761, 0.7783, 0.7246],\n",
      "        [0.7620, 0.7623, 0.7633, 0.7104],\n",
      "        [0.7728, 0.7737, 0.7757, 0.7221],\n",
      "        [0.6461, 0.6398, 0.6295, 0.5840],\n",
      "        [0.6461, 0.6398, 0.6295, 0.5840],\n",
      "        [0.6461, 0.6398, 0.6295, 0.5840],\n",
      "        [0.6461, 0.6398, 0.6295, 0.5840],\n",
      "        [0.6461, 0.6398, 0.6295, 0.5840],\n",
      "        [0.6461, 0.6398, 0.6295, 0.5840],\n",
      "        [0.6461, 0.6398, 0.6295, 0.5840],\n",
      "        [0.6472, 0.6410, 0.6309, 0.5853],\n",
      "        [0.6639, 0.6587, 0.6501, 0.6035],\n",
      "        [0.7158, 0.7135, 0.7099, 0.6600],\n",
      "        [0.6461, 0.6398, 0.6295, 0.5840],\n",
      "        [0.6461, 0.6398, 0.6295, 0.5840],\n",
      "        [0.6461, 0.6398, 0.6295, 0.5840],\n",
      "        [0.6795, 0.6752, 0.6681, 0.6205],\n",
      "        [0.6634, 0.6581, 0.6495, 0.6029],\n",
      "        [0.6750, 0.6704, 0.6629, 0.6155],\n",
      "        [0.6461, 0.6398, 0.6295, 0.5840],\n",
      "        [0.6461, 0.6398, 0.6295, 0.5840],\n",
      "        [0.6954, 0.6919, 0.6864, 0.6378],\n",
      "        [0.6869, 0.6830, 0.6767, 0.6285],\n",
      "        [0.6961, 0.6927, 0.6872, 0.6385]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0633, 0.0067, 0.0255, 0.0062],\n",
      "        [0.0050, 0.0145, 0.0260, 0.0171],\n",
      "        [0.0203, 0.0180, 0.0184, 0.0066],\n",
      "        [0.0290, 0.0086, 0.0119, 0.0090],\n",
      "        [0.0431, 0.0268, 0.0424, 0.0149],\n",
      "        [0.0497, 0.0677, 0.0370, 0.0060],\n",
      "        [0.0856, 0.0563, 0.0102, 0.0147],\n",
      "        [0.0783, 0.0331, 0.0065, 0.0239],\n",
      "        [0.0412, 0.0139, 0.0181, 0.0294],\n",
      "        [0.0137, 0.0199, 0.0330, 0.0322],\n",
      "        [0.0210, 0.0359, 0.0369, 0.0261],\n",
      "        [0.0348, 0.0376, 0.0277, 0.0061],\n",
      "        [0.0414, 0.0337, 0.0118, 0.0129],\n",
      "        [0.0336, 0.0137, 0.0129, 0.0254],\n",
      "        [0.0629, 0.0411, 0.0303, 0.0486],\n",
      "        [0.0869, 0.0791, 0.0041, 0.0512],\n",
      "        [0.1002, 0.0251, 0.0248, 0.0313],\n",
      "        [0.0076, 0.0455, 0.0469, 0.0321],\n",
      "        [0.0051, 0.0058, 0.0182, 0.0102],\n",
      "        [0.0354, 0.0586, 0.0449, 0.0863],\n",
      "        [0.0626, 0.0799, 0.0807, 0.0571],\n",
      "        [0.1047, 0.0715, 0.0328, 0.0159],\n",
      "        [0.0227, 0.0276, 0.0199, 0.0371],\n",
      "        [0.1058, 0.1246, 0.0867, 0.0418],\n",
      "        [0.1303, 0.1120, 0.1349, 0.0862],\n",
      "        [0.0504, 0.0651, 0.0428, 0.0090],\n",
      "        [0.1189, 0.0995, 0.0683, 0.0256],\n",
      "        [0.0188, 0.0120, 0.0078, 0.0240],\n",
      "        [0.1343, 0.1366, 0.1223, 0.1314],\n",
      "        [0.0482, 0.0728, 0.0203, 0.0177],\n",
      "        [0.0869, 0.0363, 0.0298, 0.0304],\n",
      "        [0.0291, 0.0077, 0.0046, 0.0044],\n",
      "        [0.0172, 0.0018, 0.0130, 0.0449],\n",
      "        [0.0436, 0.0069, 0.0822, 0.1513],\n",
      "        [0.0752, 0.0109, 0.0121, 0.0070],\n",
      "        [0.0044, 0.0232, 0.0535, 0.0294],\n",
      "        [0.0422, 0.0690, 0.0006, 0.0165],\n",
      "        [0.0295, 0.0637, 0.0369, 0.0334],\n",
      "        [0.0700, 0.0471, 0.0411, 0.0319],\n",
      "        [0.1172, 0.0751, 0.0515, 0.1083],\n",
      "        [0.0347, 0.0190, 0.0032, 0.0219],\n",
      "        [0.0288, 0.0149, 0.0323, 0.0485],\n",
      "        [0.0246, 0.0642, 0.0366, 0.0217],\n",
      "        [0.0704, 0.0469, 0.0287, 0.0064],\n",
      "        [0.0531, 0.0390, 0.0014, 0.0189],\n",
      "        [0.0018, 0.0218, 0.0467, 0.0818],\n",
      "        [0.0100, 0.0367, 0.0739, 0.0480],\n",
      "        [0.0441, 0.0666, 0.0921, 0.0270],\n",
      "        [0.0534, 0.0514, 0.0396, 0.0091],\n",
      "        [0.1676, 0.0374, 0.0034, 0.0821],\n",
      "        [0.1054, 0.0777, 0.0279, 0.0148],\n",
      "        [0.0985, 0.0930, 0.0624, 0.0123],\n",
      "        [0.0953, 0.0618, 0.0834, 0.1043]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 4\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0659, 0.0096, 0.0293, 0.0019],\n",
      "        [0.0031, 0.0169, 0.0227, 0.0210],\n",
      "        [0.0213, 0.0166, 0.0207, 0.0095],\n",
      "        [0.0280, 0.0101, 0.0095, 0.0121],\n",
      "        [0.0441, 0.0280, 0.0443, 0.0173],\n",
      "        [0.0504, 0.0684, 0.0383, 0.0042],\n",
      "        [0.0885, 0.0591, 0.0136, 0.0110],\n",
      "        [0.0811, 0.0356, 0.0095, 0.0207],\n",
      "        [0.0442, 0.0164, 0.0151, 0.0263],\n",
      "        [0.0167, 0.0174, 0.0301, 0.0291],\n",
      "        [0.0189, 0.0343, 0.0350, 0.0240],\n",
      "        [0.0323, 0.0356, 0.0254, 0.0037],\n",
      "        [0.0389, 0.0318, 0.0096, 0.0153],\n",
      "        [0.0306, 0.0112, 0.0157, 0.0283],\n",
      "        [0.0604, 0.0388, 0.0274, 0.0518],\n",
      "        [0.0858, 0.0778, 0.0020, 0.0539],\n",
      "        [0.1007, 0.0252, 0.0255, 0.0327],\n",
      "        [0.0073, 0.0460, 0.0482, 0.0341],\n",
      "        [0.0034, 0.0047, 0.0185, 0.0108],\n",
      "        [0.0390, 0.0612, 0.0465, 0.0868],\n",
      "        [0.0652, 0.0820, 0.0832, 0.0598],\n",
      "        [0.1052, 0.0712, 0.0326, 0.0160],\n",
      "        [0.0285, 0.0332, 0.0251, 0.0411],\n",
      "        [0.1085, 0.1263, 0.0884, 0.0401],\n",
      "        [0.1330, 0.1137, 0.1366, 0.0879],\n",
      "        [0.0477, 0.0621, 0.0400, 0.0069],\n",
      "        [0.1206, 0.1005, 0.0694, 0.0270],\n",
      "        [0.0148, 0.0079, 0.0041, 0.0212],\n",
      "        [0.1369, 0.1382, 0.1240, 0.1331],\n",
      "        [0.0461, 0.0707, 0.0187, 0.0168],\n",
      "        [0.0848, 0.0342, 0.0281, 0.0294],\n",
      "        [0.0270, 0.0054, 0.0077, 0.0080],\n",
      "        [0.0145, 0.0035, 0.0113, 0.0432],\n",
      "        [0.0410, 0.0052, 0.0839, 0.1530],\n",
      "        [0.0725, 0.0092, 0.0138, 0.0053],\n",
      "        [0.0017, 0.0215, 0.0518, 0.0277],\n",
      "        [0.0395, 0.0673, 0.0011, 0.0181],\n",
      "        [0.0268, 0.0621, 0.0352, 0.0317],\n",
      "        [0.0673, 0.0454, 0.0395, 0.0302],\n",
      "        [0.1181, 0.0750, 0.0518, 0.1085],\n",
      "        [0.0389, 0.0225, 0.0070, 0.0182],\n",
      "        [0.0299, 0.0141, 0.0312, 0.0471],\n",
      "        [0.0219, 0.0625, 0.0349, 0.0200],\n",
      "        [0.0677, 0.0452, 0.0270, 0.0081],\n",
      "        [0.0504, 0.0373, 0.0031, 0.0172],\n",
      "        [0.0027, 0.0179, 0.0424, 0.0775],\n",
      "        [0.0042, 0.0315, 0.0683, 0.0426],\n",
      "        [0.0359, 0.0588, 0.0837, 0.0189],\n",
      "        [0.0507, 0.0497, 0.0379, 0.0074],\n",
      "        [0.1649, 0.0357, 0.0051, 0.0838],\n",
      "        [0.0923, 0.0646, 0.0136, 0.0010],\n",
      "        [0.0844, 0.0789, 0.0469, 0.0025],\n",
      "        [0.0868, 0.0536, 0.0744, 0.0955]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 15.746028661727905\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 54\n",
      "X 資料 torch.Size([53, 18])\n",
      "Y 資料 torch.Size([53, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.009356598369777203, 15)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引15，y= tensor([0.5794, 0.5097, 0.5158, 0.5169])\n",
      "目前模型的Data torch.Size([54, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7820, 0.7833, 0.7855, 0.7307],\n",
      "        [0.7960, 0.7979, 0.8014, 0.7457],\n",
      "        [0.7935, 0.7953, 0.7986, 0.7430],\n",
      "        [0.8067, 0.8091, 0.8135, 0.7571],\n",
      "        [0.7751, 0.7761, 0.7777, 0.7233],\n",
      "        [0.7536, 0.7536, 0.7532, 0.7003],\n",
      "        [0.7334, 0.7324, 0.7302, 0.6787],\n",
      "        [0.7103, 0.7082, 0.7040, 0.6540],\n",
      "        [0.6996, 0.6970, 0.6918, 0.6425],\n",
      "        [0.6968, 0.6941, 0.6886, 0.6395],\n",
      "        [0.6956, 0.6928, 0.6873, 0.6382],\n",
      "        [0.6908, 0.6878, 0.6818, 0.6331],\n",
      "        [0.6911, 0.6881, 0.6821, 0.6334],\n",
      "        [0.6870, 0.6838, 0.6774, 0.6290],\n",
      "        [0.7330, 0.7319, 0.7297, 0.6782],\n",
      "        [0.7789, 0.7801, 0.7820, 0.7274],\n",
      "        [0.8030, 0.8052, 0.8093, 0.7531],\n",
      "        [0.7873, 0.7888, 0.7915, 0.7363],\n",
      "        [0.8315, 0.8350, 0.8417, 0.7836],\n",
      "        [0.8787, 0.8845, 0.8954, 0.8341],\n",
      "        [0.7008, 0.6983, 0.6931, 0.6438],\n",
      "        [0.6769, 0.6733, 0.6660, 0.6182],\n",
      "        [0.8216, 0.8248, 0.8306, 0.7731],\n",
      "        [0.6434, 0.6381, 0.6278, 0.5823],\n",
      "        [0.6434, 0.6381, 0.6278, 0.5823],\n",
      "        [0.7439, 0.7434, 0.7421, 0.6899],\n",
      "        [0.6849, 0.6816, 0.6751, 0.6268],\n",
      "        [0.7838, 0.7852, 0.7876, 0.7326],\n",
      "        [0.6434, 0.6381, 0.6278, 0.5823],\n",
      "        [0.7771, 0.7781, 0.7799, 0.7254],\n",
      "        [0.7640, 0.7644, 0.7650, 0.7114],\n",
      "        [0.7706, 0.7714, 0.7726, 0.7185],\n",
      "        [0.6434, 0.6381, 0.6278, 0.5823],\n",
      "        [0.6434, 0.6381, 0.6278, 0.5823],\n",
      "        [0.6434, 0.6381, 0.6278, 0.5823],\n",
      "        [0.6434, 0.6381, 0.6278, 0.5823],\n",
      "        [0.6434, 0.6381, 0.6278, 0.5823],\n",
      "        [0.6434, 0.6381, 0.6278, 0.5823],\n",
      "        [0.6434, 0.6381, 0.6278, 0.5823],\n",
      "        [0.6463, 0.6412, 0.6312, 0.5855],\n",
      "        [0.6597, 0.6552, 0.6464, 0.5997],\n",
      "        [0.7146, 0.7127, 0.7088, 0.6586],\n",
      "        [0.6434, 0.6381, 0.6278, 0.5823],\n",
      "        [0.6434, 0.6381, 0.6278, 0.5823],\n",
      "        [0.6434, 0.6381, 0.6278, 0.5823],\n",
      "        [0.6750, 0.6713, 0.6638, 0.6162],\n",
      "        [0.6576, 0.6530, 0.6440, 0.5975],\n",
      "        [0.6668, 0.6627, 0.6545, 0.6074],\n",
      "        [0.6434, 0.6381, 0.6278, 0.5823],\n",
      "        [0.6434, 0.6381, 0.6278, 0.5823],\n",
      "        [0.6823, 0.6789, 0.6721, 0.6240],\n",
      "        [0.6727, 0.6689, 0.6612, 0.6137],\n",
      "        [0.6877, 0.6845, 0.6782, 0.6297],\n",
      "        [0.6434, 0.6381, 0.6278, 0.5823]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0659, 0.0096, 0.0293, 0.0019],\n",
      "        [0.0031, 0.0169, 0.0227, 0.0210],\n",
      "        [0.0213, 0.0166, 0.0207, 0.0095],\n",
      "        [0.0280, 0.0101, 0.0095, 0.0121],\n",
      "        [0.0441, 0.0280, 0.0443, 0.0173],\n",
      "        [0.0504, 0.0684, 0.0383, 0.0042],\n",
      "        [0.0885, 0.0591, 0.0136, 0.0110],\n",
      "        [0.0811, 0.0356, 0.0095, 0.0207],\n",
      "        [0.0442, 0.0164, 0.0151, 0.0263],\n",
      "        [0.0167, 0.0174, 0.0301, 0.0291],\n",
      "        [0.0189, 0.0343, 0.0350, 0.0240],\n",
      "        [0.0323, 0.0356, 0.0254, 0.0037],\n",
      "        [0.0389, 0.0318, 0.0096, 0.0153],\n",
      "        [0.0306, 0.0112, 0.0157, 0.0283],\n",
      "        [0.0604, 0.0388, 0.0274, 0.0518],\n",
      "        [0.0858, 0.0778, 0.0020, 0.0539],\n",
      "        [0.1007, 0.0252, 0.0255, 0.0327],\n",
      "        [0.0073, 0.0460, 0.0482, 0.0341],\n",
      "        [0.0034, 0.0047, 0.0185, 0.0108],\n",
      "        [0.0390, 0.0612, 0.0465, 0.0868],\n",
      "        [0.0652, 0.0820, 0.0832, 0.0598],\n",
      "        [0.1052, 0.0712, 0.0326, 0.0160],\n",
      "        [0.0285, 0.0332, 0.0251, 0.0411],\n",
      "        [0.1085, 0.1263, 0.0884, 0.0401],\n",
      "        [0.1330, 0.1137, 0.1366, 0.0879],\n",
      "        [0.0477, 0.0621, 0.0400, 0.0069],\n",
      "        [0.1206, 0.1005, 0.0694, 0.0270],\n",
      "        [0.0148, 0.0079, 0.0041, 0.0212],\n",
      "        [0.1369, 0.1382, 0.1240, 0.1331],\n",
      "        [0.0461, 0.0707, 0.0187, 0.0168],\n",
      "        [0.0848, 0.0342, 0.0281, 0.0294],\n",
      "        [0.0270, 0.0054, 0.0077, 0.0080],\n",
      "        [0.0145, 0.0035, 0.0113, 0.0432],\n",
      "        [0.0410, 0.0052, 0.0839, 0.1530],\n",
      "        [0.0725, 0.0092, 0.0138, 0.0053],\n",
      "        [0.0017, 0.0215, 0.0518, 0.0277],\n",
      "        [0.0395, 0.0673, 0.0011, 0.0181],\n",
      "        [0.0268, 0.0621, 0.0352, 0.0317],\n",
      "        [0.0673, 0.0454, 0.0395, 0.0302],\n",
      "        [0.1181, 0.0750, 0.0518, 0.1085],\n",
      "        [0.0389, 0.0225, 0.0070, 0.0182],\n",
      "        [0.0299, 0.0141, 0.0312, 0.0471],\n",
      "        [0.0219, 0.0625, 0.0349, 0.0200],\n",
      "        [0.0677, 0.0452, 0.0270, 0.0081],\n",
      "        [0.0504, 0.0373, 0.0031, 0.0172],\n",
      "        [0.0027, 0.0179, 0.0424, 0.0775],\n",
      "        [0.0042, 0.0315, 0.0683, 0.0426],\n",
      "        [0.0359, 0.0588, 0.0837, 0.0189],\n",
      "        [0.0507, 0.0497, 0.0379, 0.0074],\n",
      "        [0.1649, 0.0357, 0.0051, 0.0838],\n",
      "        [0.0923, 0.0646, 0.0136, 0.0010],\n",
      "        [0.0844, 0.0789, 0.0469, 0.0025],\n",
      "        [0.0868, 0.0536, 0.0744, 0.0955],\n",
      "        [0.0640, 0.1285, 0.1120, 0.0654]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 12\n",
      "Number of shrink: 13\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 5\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0643, 0.0089, 0.0280, 0.0036],\n",
      "        [0.0048, 0.0160, 0.0241, 0.0192],\n",
      "        [0.0194, 0.0176, 0.0191, 0.0076],\n",
      "        [0.0298, 0.0091, 0.0110, 0.0103],\n",
      "        [0.0424, 0.0271, 0.0428, 0.0155],\n",
      "        [0.0489, 0.0677, 0.0369, 0.0060],\n",
      "        [0.0875, 0.0588, 0.0127, 0.0125],\n",
      "        [0.0802, 0.0355, 0.0086, 0.0222],\n",
      "        [0.0432, 0.0163, 0.0161, 0.0279],\n",
      "        [0.0157, 0.0175, 0.0310, 0.0308],\n",
      "        [0.0198, 0.0344, 0.0359, 0.0256],\n",
      "        [0.0331, 0.0355, 0.0262, 0.0052],\n",
      "        [0.0396, 0.0316, 0.0102, 0.0139],\n",
      "        [0.0311, 0.0109, 0.0153, 0.0271],\n",
      "        [0.0610, 0.0385, 0.0278, 0.0508],\n",
      "        [0.0866, 0.0777, 0.0025, 0.0529],\n",
      "        [0.1017, 0.0254, 0.0249, 0.0318],\n",
      "        [0.0082, 0.0460, 0.0477, 0.0331],\n",
      "        [0.0021, 0.0042, 0.0193, 0.0097],\n",
      "        [0.0407, 0.0621, 0.0476, 0.0879],\n",
      "        [0.0641, 0.0818, 0.0822, 0.0581],\n",
      "        [0.1043, 0.0712, 0.0316, 0.0143],\n",
      "        [0.0307, 0.0345, 0.0269, 0.0432],\n",
      "        [0.1109, 0.1298, 0.0911, 0.0385],\n",
      "        [0.1355, 0.1172, 0.1394, 0.0896],\n",
      "        [0.0461, 0.0614, 0.0386, 0.0049],\n",
      "        [0.1197, 0.1005, 0.0686, 0.0254],\n",
      "        [0.0131, 0.0070, 0.0026, 0.0194],\n",
      "        [0.1394, 0.1417, 0.1268, 0.1347],\n",
      "        [0.0449, 0.0704, 0.0178, 0.0155],\n",
      "        [0.0835, 0.0337, 0.0270, 0.0278],\n",
      "        [0.0283, 0.0059, 0.0067, 0.0065],\n",
      "        [0.0120, 0.0070, 0.0085, 0.0415],\n",
      "        [0.0385, 0.0018, 0.0867, 0.1547],\n",
      "        [0.0700, 0.0058, 0.0166, 0.0036],\n",
      "        [0.0007, 0.0181, 0.0490, 0.0260],\n",
      "        [0.0370, 0.0638, 0.0038, 0.0198],\n",
      "        [0.0243, 0.0586, 0.0324, 0.0300],\n",
      "        [0.0648, 0.0420, 0.0367, 0.0285],\n",
      "        [0.1167, 0.0743, 0.0535, 0.1110],\n",
      "        [0.0384, 0.0228, 0.0064, 0.0196],\n",
      "        [0.0289, 0.0143, 0.0321, 0.0487],\n",
      "        [0.0194, 0.0590, 0.0321, 0.0184],\n",
      "        [0.0652, 0.0417, 0.0242, 0.0098],\n",
      "        [0.0479, 0.0338, 0.0058, 0.0156],\n",
      "        [0.0021, 0.0176, 0.0429, 0.0788],\n",
      "        [0.0044, 0.0309, 0.0686, 0.0437],\n",
      "        [0.0357, 0.0578, 0.0834, 0.0195],\n",
      "        [0.0482, 0.0463, 0.0351, 0.0058],\n",
      "        [0.1624, 0.0323, 0.0078, 0.0854],\n",
      "        [0.0916, 0.0630, 0.0127, 0.0010],\n",
      "        [0.0836, 0.0772, 0.0460, 0.0026],\n",
      "        [0.0868, 0.0527, 0.0742, 0.0961],\n",
      "        [0.0616, 0.1251, 0.1094, 0.0639]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 15.992393970489502\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 55\n",
      "X 資料 torch.Size([52, 18])\n",
      "Y 資料 torch.Size([52, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.012087862007319927, 15)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引15，y= tensor([0.5097, 0.5158, 0.5523, 0.4724])\n",
      "目前模型的Data torch.Size([55, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7836, 0.7840, 0.7868, 0.7323],\n",
      "        [0.7977, 0.7988, 0.8028, 0.7474],\n",
      "        [0.7954, 0.7964, 0.8001, 0.7449],\n",
      "        [0.8086, 0.8102, 0.8151, 0.7589],\n",
      "        [0.7768, 0.7769, 0.7791, 0.7252],\n",
      "        [0.7551, 0.7542, 0.7545, 0.7021],\n",
      "        [0.7345, 0.7326, 0.7311, 0.6802],\n",
      "        [0.7113, 0.7083, 0.7048, 0.6555],\n",
      "        [0.7007, 0.6972, 0.6928, 0.6442],\n",
      "        [0.6978, 0.6942, 0.6895, 0.6411],\n",
      "        [0.6965, 0.6929, 0.6881, 0.6398],\n",
      "        [0.6916, 0.6877, 0.6825, 0.6346],\n",
      "        [0.6918, 0.6879, 0.6827, 0.6348],\n",
      "        [0.6874, 0.6834, 0.6778, 0.6302],\n",
      "        [0.7336, 0.7317, 0.7301, 0.6792],\n",
      "        [0.7798, 0.7800, 0.7825, 0.7283],\n",
      "        [0.8040, 0.8054, 0.8099, 0.7541],\n",
      "        [0.7882, 0.7889, 0.7920, 0.7373],\n",
      "        [0.8328, 0.8355, 0.8425, 0.7847],\n",
      "        [0.8804, 0.8853, 0.8965, 0.8353],\n",
      "        [0.7019, 0.6985, 0.6942, 0.6455],\n",
      "        [0.6778, 0.6733, 0.6669, 0.6199],\n",
      "        [0.8238, 0.8261, 0.8324, 0.7752],\n",
      "        [0.6409, 0.6347, 0.6251, 0.5806],\n",
      "        [0.6409, 0.6347, 0.6251, 0.5806],\n",
      "        [0.7455, 0.7441, 0.7436, 0.6919],\n",
      "        [0.6858, 0.6817, 0.6760, 0.6284],\n",
      "        [0.7855, 0.7861, 0.7890, 0.7345],\n",
      "        [0.6409, 0.6347, 0.6251, 0.5806],\n",
      "        [0.7783, 0.7785, 0.7808, 0.7268],\n",
      "        [0.7653, 0.7649, 0.7661, 0.7130],\n",
      "        [0.7720, 0.7719, 0.7736, 0.7200],\n",
      "        [0.6409, 0.6347, 0.6251, 0.5806],\n",
      "        [0.6409, 0.6347, 0.6251, 0.5806],\n",
      "        [0.6409, 0.6347, 0.6251, 0.5806],\n",
      "        [0.6409, 0.6347, 0.6251, 0.5806],\n",
      "        [0.6409, 0.6347, 0.6251, 0.5806],\n",
      "        [0.6409, 0.6347, 0.6251, 0.5806],\n",
      "        [0.6409, 0.6347, 0.6251, 0.5806],\n",
      "        [0.6478, 0.6419, 0.6329, 0.5880],\n",
      "        [0.6602, 0.6549, 0.6469, 0.6012],\n",
      "        [0.7156, 0.7129, 0.7098, 0.6601],\n",
      "        [0.6409, 0.6347, 0.6251, 0.5806],\n",
      "        [0.6409, 0.6347, 0.6251, 0.5806],\n",
      "        [0.6409, 0.6347, 0.6251, 0.5806],\n",
      "        [0.6755, 0.6709, 0.6643, 0.6175],\n",
      "        [0.6578, 0.6524, 0.6442, 0.5986],\n",
      "        [0.6666, 0.6616, 0.6542, 0.6080],\n",
      "        [0.6409, 0.6347, 0.6251, 0.5806],\n",
      "        [0.6409, 0.6347, 0.6251, 0.5806],\n",
      "        [0.6816, 0.6773, 0.6712, 0.6239],\n",
      "        [0.6720, 0.6672, 0.6603, 0.6137],\n",
      "        [0.6876, 0.6836, 0.6780, 0.6303],\n",
      "        [0.6410, 0.6348, 0.6252, 0.5808],\n",
      "        [0.6409, 0.6347, 0.6251, 0.5806]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0643, 0.0089, 0.0280, 0.0036],\n",
      "        [0.0048, 0.0160, 0.0241, 0.0192],\n",
      "        [0.0194, 0.0176, 0.0191, 0.0076],\n",
      "        [0.0298, 0.0091, 0.0110, 0.0103],\n",
      "        [0.0424, 0.0271, 0.0428, 0.0155],\n",
      "        [0.0489, 0.0677, 0.0369, 0.0060],\n",
      "        [0.0875, 0.0588, 0.0127, 0.0125],\n",
      "        [0.0802, 0.0355, 0.0086, 0.0222],\n",
      "        [0.0432, 0.0163, 0.0161, 0.0279],\n",
      "        [0.0157, 0.0175, 0.0310, 0.0308],\n",
      "        [0.0198, 0.0344, 0.0359, 0.0256],\n",
      "        [0.0331, 0.0355, 0.0262, 0.0052],\n",
      "        [0.0396, 0.0316, 0.0102, 0.0139],\n",
      "        [0.0311, 0.0109, 0.0153, 0.0271],\n",
      "        [0.0610, 0.0385, 0.0278, 0.0508],\n",
      "        [0.0866, 0.0777, 0.0025, 0.0529],\n",
      "        [0.1017, 0.0254, 0.0249, 0.0318],\n",
      "        [0.0082, 0.0460, 0.0477, 0.0331],\n",
      "        [0.0021, 0.0042, 0.0193, 0.0097],\n",
      "        [0.0407, 0.0621, 0.0476, 0.0879],\n",
      "        [0.0641, 0.0818, 0.0822, 0.0581],\n",
      "        [0.1043, 0.0712, 0.0316, 0.0143],\n",
      "        [0.0307, 0.0345, 0.0269, 0.0432],\n",
      "        [0.1109, 0.1298, 0.0911, 0.0385],\n",
      "        [0.1355, 0.1172, 0.1394, 0.0896],\n",
      "        [0.0461, 0.0614, 0.0386, 0.0049],\n",
      "        [0.1197, 0.1005, 0.0686, 0.0254],\n",
      "        [0.0131, 0.0070, 0.0026, 0.0194],\n",
      "        [0.1394, 0.1417, 0.1268, 0.1347],\n",
      "        [0.0449, 0.0704, 0.0178, 0.0155],\n",
      "        [0.0835, 0.0337, 0.0270, 0.0278],\n",
      "        [0.0283, 0.0059, 0.0067, 0.0065],\n",
      "        [0.0120, 0.0070, 0.0085, 0.0415],\n",
      "        [0.0385, 0.0018, 0.0867, 0.1547],\n",
      "        [0.0700, 0.0058, 0.0166, 0.0036],\n",
      "        [0.0007, 0.0181, 0.0490, 0.0260],\n",
      "        [0.0370, 0.0638, 0.0038, 0.0198],\n",
      "        [0.0243, 0.0586, 0.0324, 0.0300],\n",
      "        [0.0648, 0.0420, 0.0367, 0.0285],\n",
      "        [0.1167, 0.0743, 0.0535, 0.1110],\n",
      "        [0.0384, 0.0228, 0.0064, 0.0196],\n",
      "        [0.0289, 0.0143, 0.0321, 0.0487],\n",
      "        [0.0194, 0.0590, 0.0321, 0.0184],\n",
      "        [0.0652, 0.0417, 0.0242, 0.0098],\n",
      "        [0.0479, 0.0338, 0.0058, 0.0156],\n",
      "        [0.0021, 0.0176, 0.0429, 0.0788],\n",
      "        [0.0044, 0.0309, 0.0686, 0.0437],\n",
      "        [0.0357, 0.0578, 0.0834, 0.0195],\n",
      "        [0.0482, 0.0463, 0.0351, 0.0058],\n",
      "        [0.1624, 0.0323, 0.0078, 0.0854],\n",
      "        [0.0916, 0.0630, 0.0127, 0.0010],\n",
      "        [0.0836, 0.0772, 0.0460, 0.0026],\n",
      "        [0.0868, 0.0527, 0.0742, 0.0961],\n",
      "        [0.0616, 0.1251, 0.1094, 0.0639],\n",
      "        [0.1312, 0.1188, 0.0728, 0.1082]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 23\n",
      "Number of shrink: 19\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 6\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0655, 0.0101, 0.0282, 0.0028],\n",
      "        [0.0038, 0.0170, 0.0241, 0.0199],\n",
      "        [0.0206, 0.0164, 0.0192, 0.0084],\n",
      "        [0.0289, 0.0100, 0.0112, 0.0109],\n",
      "        [0.0437, 0.0284, 0.0431, 0.0164],\n",
      "        [0.0503, 0.0691, 0.0372, 0.0051],\n",
      "        [0.0891, 0.0605, 0.0132, 0.0113],\n",
      "        [0.0820, 0.0372, 0.0093, 0.0210],\n",
      "        [0.0447, 0.0178, 0.0157, 0.0270],\n",
      "        [0.0174, 0.0158, 0.0305, 0.0297],\n",
      "        [0.0184, 0.0330, 0.0356, 0.0247],\n",
      "        [0.0314, 0.0338, 0.0256, 0.0041],\n",
      "        [0.0377, 0.0297, 0.0094, 0.0152],\n",
      "        [0.0291, 0.0088, 0.0162, 0.0285],\n",
      "        [0.0593, 0.0368, 0.0272, 0.0520],\n",
      "        [0.0855, 0.0766, 0.0024, 0.0537],\n",
      "        [0.1007, 0.0244, 0.0248, 0.0324],\n",
      "        [0.0071, 0.0471, 0.0477, 0.0338],\n",
      "        [0.0026, 0.0047, 0.0199, 0.0099],\n",
      "        [0.0407, 0.0622, 0.0488, 0.0882],\n",
      "        [0.0683, 0.0861, 0.0856, 0.0618],\n",
      "        [0.1065, 0.0733, 0.0327, 0.0158],\n",
      "        [0.0303, 0.0341, 0.0276, 0.0431],\n",
      "        [0.1147, 0.1335, 0.0939, 0.0353],\n",
      "        [0.1392, 0.1209, 0.1422, 0.0927],\n",
      "        [0.0474, 0.0626, 0.0387, 0.0056],\n",
      "        [0.1218, 0.1026, 0.0696, 0.0269],\n",
      "        [0.0135, 0.0074, 0.0018, 0.0193],\n",
      "        [0.1431, 0.1455, 0.1296, 0.1378],\n",
      "        [0.0458, 0.0712, 0.0175, 0.0159],\n",
      "        [0.0843, 0.0345, 0.0267, 0.0282],\n",
      "        [0.0245, 0.0019, 0.0098, 0.0101],\n",
      "        [0.0083, 0.0107, 0.0057, 0.0384],\n",
      "        [0.0348, 0.0020, 0.0895, 0.1578],\n",
      "        [0.0663, 0.0020, 0.0194, 0.0005],\n",
      "        [0.0045, 0.0143, 0.0462, 0.0229],\n",
      "        [0.0333, 0.0600, 0.0066, 0.0229],\n",
      "        [0.0206, 0.0548, 0.0296, 0.0269],\n",
      "        [0.0611, 0.0382, 0.0339, 0.0254],\n",
      "        [0.1205, 0.0782, 0.0506, 0.1078],\n",
      "        [0.0411, 0.0255, 0.0081, 0.0176],\n",
      "        [0.0309, 0.0123, 0.0311, 0.0472],\n",
      "        [0.0157, 0.0552, 0.0293, 0.0153],\n",
      "        [0.0615, 0.0379, 0.0214, 0.0129],\n",
      "        [0.0442, 0.0301, 0.0086, 0.0124],\n",
      "        [0.0047, 0.0150, 0.0414, 0.0768],\n",
      "        [0.0015, 0.0280, 0.0667, 0.0414],\n",
      "        [0.0322, 0.0541, 0.0807, 0.0165],\n",
      "        [0.0445, 0.0425, 0.0323, 0.0027],\n",
      "        [0.1587, 0.0285, 0.0106, 0.0885],\n",
      "        [0.0870, 0.0582, 0.0088, 0.0032],\n",
      "        [0.0789, 0.0725, 0.0421, 0.0067],\n",
      "        [0.0835, 0.0493, 0.0718, 0.0933],\n",
      "        [0.0578, 0.1212, 0.1064, 0.0607],\n",
      "        [0.1275, 0.1151, 0.0699, 0.1051]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 16.28139066696167\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 56\n",
      "X 資料 torch.Size([51, 18])\n",
      "Y 資料 torch.Size([51, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.012712514959275723, 15)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引15，y= tensor([0.5158, 0.5523, 0.5048, 0.4504])\n",
      "目前模型的Data torch.Size([56, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7824, 0.7828, 0.7866, 0.7315],\n",
      "        [0.7967, 0.7978, 0.8029, 0.7468],\n",
      "        [0.7942, 0.7952, 0.8000, 0.7441],\n",
      "        [0.8076, 0.8092, 0.8152, 0.7583],\n",
      "        [0.7755, 0.7756, 0.7789, 0.7243],\n",
      "        [0.7537, 0.7528, 0.7542, 0.7012],\n",
      "        [0.7329, 0.7310, 0.7306, 0.6790],\n",
      "        [0.7095, 0.7066, 0.7042, 0.6543],\n",
      "        [0.6991, 0.6957, 0.6924, 0.6432],\n",
      "        [0.6961, 0.6925, 0.6890, 0.6400],\n",
      "        [0.6951, 0.6915, 0.6878, 0.6390],\n",
      "        [0.6899, 0.6861, 0.6820, 0.6335],\n",
      "        [0.6899, 0.6861, 0.6820, 0.6335],\n",
      "        [0.6854, 0.6814, 0.6769, 0.6287],\n",
      "        [0.7319, 0.7300, 0.7295, 0.6780],\n",
      "        [0.7786, 0.7789, 0.7824, 0.7276],\n",
      "        [0.8030, 0.8044, 0.8100, 0.7535],\n",
      "        [0.7871, 0.7878, 0.7920, 0.7366],\n",
      "        [0.8323, 0.8350, 0.8431, 0.7845],\n",
      "        [0.8804, 0.8854, 0.8977, 0.8356],\n",
      "        [0.6977, 0.6942, 0.6908, 0.6417],\n",
      "        [0.6757, 0.6712, 0.6659, 0.6184],\n",
      "        [0.8234, 0.8257, 0.8331, 0.7751],\n",
      "        [0.6372, 0.6309, 0.6223, 0.5775],\n",
      "        [0.6372, 0.6309, 0.6223, 0.5775],\n",
      "        [0.7443, 0.7429, 0.7435, 0.6911],\n",
      "        [0.6837, 0.6795, 0.6749, 0.6269],\n",
      "        [0.7851, 0.7857, 0.7898, 0.7345],\n",
      "        [0.6372, 0.6309, 0.6223, 0.5775],\n",
      "        [0.7775, 0.7777, 0.7811, 0.7263],\n",
      "        [0.7645, 0.7641, 0.7665, 0.7126],\n",
      "        [0.7682, 0.7679, 0.7705, 0.7165],\n",
      "        [0.6372, 0.6309, 0.6223, 0.5775],\n",
      "        [0.6372, 0.6309, 0.6223, 0.5775],\n",
      "        [0.6372, 0.6309, 0.6223, 0.5775],\n",
      "        [0.6372, 0.6309, 0.6223, 0.5775],\n",
      "        [0.6372, 0.6309, 0.6223, 0.5775],\n",
      "        [0.6372, 0.6309, 0.6223, 0.5775],\n",
      "        [0.6372, 0.6309, 0.6223, 0.5775],\n",
      "        [0.6439, 0.6380, 0.6299, 0.5847],\n",
      "        [0.6575, 0.6522, 0.6453, 0.5991],\n",
      "        [0.7136, 0.7109, 0.7088, 0.6586],\n",
      "        [0.6372, 0.6309, 0.6223, 0.5775],\n",
      "        [0.6372, 0.6309, 0.6223, 0.5775],\n",
      "        [0.6372, 0.6309, 0.6223, 0.5775],\n",
      "        [0.6730, 0.6683, 0.6628, 0.6155],\n",
      "        [0.6549, 0.6494, 0.6423, 0.5964],\n",
      "        [0.6631, 0.6580, 0.6516, 0.6050],\n",
      "        [0.6372, 0.6309, 0.6223, 0.5775],\n",
      "        [0.6372, 0.6309, 0.6223, 0.5775],\n",
      "        [0.6770, 0.6725, 0.6673, 0.6198],\n",
      "        [0.6673, 0.6624, 0.6564, 0.6095],\n",
      "        [0.6843, 0.6802, 0.6756, 0.6275],\n",
      "        [0.6372, 0.6309, 0.6223, 0.5775],\n",
      "        [0.6372, 0.6309, 0.6223, 0.5775],\n",
      "        [0.6372, 0.6309, 0.6223, 0.5775]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0655, 0.0101, 0.0282, 0.0028],\n",
      "        [0.0038, 0.0170, 0.0241, 0.0199],\n",
      "        [0.0206, 0.0164, 0.0192, 0.0084],\n",
      "        [0.0289, 0.0100, 0.0112, 0.0109],\n",
      "        [0.0437, 0.0284, 0.0431, 0.0164],\n",
      "        [0.0503, 0.0691, 0.0372, 0.0051],\n",
      "        [0.0891, 0.0605, 0.0132, 0.0113],\n",
      "        [0.0820, 0.0372, 0.0093, 0.0210],\n",
      "        [0.0447, 0.0178, 0.0157, 0.0270],\n",
      "        [0.0174, 0.0158, 0.0305, 0.0297],\n",
      "        [0.0184, 0.0330, 0.0356, 0.0247],\n",
      "        [0.0314, 0.0338, 0.0256, 0.0041],\n",
      "        [0.0377, 0.0297, 0.0094, 0.0152],\n",
      "        [0.0291, 0.0088, 0.0162, 0.0285],\n",
      "        [0.0593, 0.0368, 0.0272, 0.0520],\n",
      "        [0.0855, 0.0766, 0.0024, 0.0537],\n",
      "        [0.1007, 0.0244, 0.0248, 0.0324],\n",
      "        [0.0071, 0.0471, 0.0477, 0.0338],\n",
      "        [0.0026, 0.0047, 0.0199, 0.0099],\n",
      "        [0.0407, 0.0622, 0.0488, 0.0882],\n",
      "        [0.0683, 0.0861, 0.0856, 0.0618],\n",
      "        [0.1065, 0.0733, 0.0327, 0.0158],\n",
      "        [0.0303, 0.0341, 0.0276, 0.0431],\n",
      "        [0.1147, 0.1335, 0.0939, 0.0353],\n",
      "        [0.1392, 0.1209, 0.1422, 0.0927],\n",
      "        [0.0474, 0.0626, 0.0387, 0.0056],\n",
      "        [0.1218, 0.1026, 0.0696, 0.0269],\n",
      "        [0.0135, 0.0074, 0.0018, 0.0193],\n",
      "        [0.1431, 0.1455, 0.1296, 0.1378],\n",
      "        [0.0458, 0.0712, 0.0175, 0.0159],\n",
      "        [0.0843, 0.0345, 0.0267, 0.0282],\n",
      "        [0.0245, 0.0019, 0.0098, 0.0101],\n",
      "        [0.0083, 0.0107, 0.0057, 0.0384],\n",
      "        [0.0348, 0.0020, 0.0895, 0.1578],\n",
      "        [0.0663, 0.0020, 0.0194, 0.0005],\n",
      "        [0.0045, 0.0143, 0.0462, 0.0229],\n",
      "        [0.0333, 0.0600, 0.0066, 0.0229],\n",
      "        [0.0206, 0.0548, 0.0296, 0.0269],\n",
      "        [0.0611, 0.0382, 0.0339, 0.0254],\n",
      "        [0.1205, 0.0782, 0.0506, 0.1078],\n",
      "        [0.0411, 0.0255, 0.0081, 0.0176],\n",
      "        [0.0309, 0.0123, 0.0311, 0.0472],\n",
      "        [0.0157, 0.0552, 0.0293, 0.0153],\n",
      "        [0.0615, 0.0379, 0.0214, 0.0129],\n",
      "        [0.0442, 0.0301, 0.0086, 0.0124],\n",
      "        [0.0047, 0.0150, 0.0414, 0.0768],\n",
      "        [0.0015, 0.0280, 0.0667, 0.0414],\n",
      "        [0.0322, 0.0541, 0.0807, 0.0165],\n",
      "        [0.0445, 0.0425, 0.0323, 0.0027],\n",
      "        [0.1587, 0.0285, 0.0106, 0.0885],\n",
      "        [0.0870, 0.0582, 0.0088, 0.0032],\n",
      "        [0.0789, 0.0725, 0.0421, 0.0067],\n",
      "        [0.0835, 0.0493, 0.0718, 0.0933],\n",
      "        [0.0578, 0.1212, 0.1064, 0.0607],\n",
      "        [0.1275, 0.1151, 0.0699, 0.1051],\n",
      "        [0.1214, 0.0786, 0.1175, 0.1271]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 35\n",
      "Number of shrink: 25\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 8\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0631,     0.0067,     0.0262,     0.0037],\n",
      "        [    0.0067,     0.0130,     0.0265,     0.0187],\n",
      "        [    0.0184,     0.0197,     0.0175,     0.0078],\n",
      "        [    0.0314,     0.0065,     0.0130,     0.0102],\n",
      "        [    0.0425,     0.0262,     0.0423,     0.0166],\n",
      "        [    0.0491,     0.0668,     0.0362,     0.0053],\n",
      "        [    0.0881,     0.0584,     0.0122,     0.0116],\n",
      "        [    0.0814,     0.0356,     0.0085,     0.0212],\n",
      "        [    0.0439,     0.0159,     0.0169,     0.0277],\n",
      "        [    0.0168,     0.0174,     0.0314,     0.0301],\n",
      "        [    0.0195,     0.0351,     0.0372,     0.0257],\n",
      "        [    0.0313,     0.0348,     0.0259,     0.0039],\n",
      "        [    0.0372,     0.0302,     0.0092,     0.0158],\n",
      "        [    0.0280,     0.0087,     0.0170,     0.0296],\n",
      "        [    0.0589,     0.0374,     0.0266,     0.0532],\n",
      "        [    0.0864,     0.0785,     0.0028,     0.0542],\n",
      "        [    0.1023,     0.0270,     0.0239,     0.0326],\n",
      "        [    0.0087,     0.0444,     0.0466,     0.0338],\n",
      "        [    0.0010,     0.0001,     0.0226,     0.0086],\n",
      "        [    0.0458,     0.0683,     0.0527,     0.0903],\n",
      "        [    0.0751,     0.0921,     0.0929,     0.0691],\n",
      "        [    0.1069,     0.0728,     0.0327,     0.0161],\n",
      "        [    0.0342,     0.0391,     0.0308,     0.0449],\n",
      "        [    0.1216,     0.1397,     0.1008,     0.0289],\n",
      "        [    0.1462,     0.1271,     0.1490,     0.0992],\n",
      "        [    0.0456,     0.0598,     0.0370,     0.0048],\n",
      "        [    0.1221,     0.1019,     0.0695,     0.0272],\n",
      "        [    0.0093,     0.0021,     0.0022,     0.0165],\n",
      "        [    0.1501,     0.1517,     0.1364,     0.1443],\n",
      "        [    0.0429,     0.0672,     0.0149,     0.0143],\n",
      "        [    0.0812,     0.0302,     0.0236,     0.0262],\n",
      "        [    0.0189,     0.0029,     0.0166,     0.0173],\n",
      "        [    0.0013,     0.0169,     0.0012,     0.0320],\n",
      "        [    0.0278,     0.0082,     0.0963,     0.1643],\n",
      "        [    0.0593,     0.0042,     0.0262,     0.0060],\n",
      "        [    0.0114,     0.0081,     0.0394,     0.0164],\n",
      "        [    0.0264,     0.0538,     0.0135,     0.0294],\n",
      "        [    0.0136,     0.0486,     0.0227,     0.0204],\n",
      "        [    0.0541,     0.0320,     0.0270,     0.0190],\n",
      "        [    0.1265,     0.0834,     0.0447,     0.1022],\n",
      "        [    0.0429,     0.0264,     0.0094,     0.0161],\n",
      "        [    0.0310,     0.0132,     0.0311,     0.0466],\n",
      "        [    0.0088,     0.0490,     0.0225,     0.0088],\n",
      "        [    0.0546,     0.0317,     0.0146,     0.0193],\n",
      "        [    0.0372,     0.0239,     0.0155,     0.0060],\n",
      "        [    0.0065,     0.0142,     0.0399,     0.0752],\n",
      "        [    0.0012,     0.0262,     0.0644,     0.0391],\n",
      "        [    0.0266,     0.0494,     0.0752,     0.0110],\n",
      "        [    0.0375,     0.0363,     0.0255,     0.0038],\n",
      "        [    0.1517,     0.0223,     0.0175,     0.0950],\n",
      "        [    0.0797,     0.0516,     0.0011,     0.0107],\n",
      "        [    0.0715,     0.0658,     0.0345,     0.0141],\n",
      "        [    0.0783,     0.0450,     0.0665,     0.0880],\n",
      "        [    0.0508,     0.1150,     0.0996,     0.0542],\n",
      "        [    0.1205,     0.1089,     0.0631,     0.0987],\n",
      "        [    0.1144,     0.0724,     0.1106,     0.1206]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 16.630544662475586\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 57\n",
      "X 資料 torch.Size([50, 18])\n",
      "Y 資料 torch.Size([50, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.012580983340740204, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.6143, 0.6585, 0.6657, 0.5997])\n",
      "目前模型的Data torch.Size([57, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7847, 0.7862, 0.7886, 0.7325],\n",
      "        [0.7996, 0.8018, 0.8052, 0.7480],\n",
      "        [0.7964, 0.7984, 0.8017, 0.7447],\n",
      "        [0.8101, 0.8128, 0.8171, 0.7590],\n",
      "        [0.7767, 0.7779, 0.7797, 0.7241],\n",
      "        [0.7550, 0.7551, 0.7553, 0.7014],\n",
      "        [0.7338, 0.7330, 0.7316, 0.6793],\n",
      "        [0.7101, 0.7082, 0.7049, 0.6545],\n",
      "        [0.7000, 0.6976, 0.6936, 0.6439],\n",
      "        [0.6966, 0.6941, 0.6899, 0.6404],\n",
      "        [0.6962, 0.6937, 0.6894, 0.6400],\n",
      "        [0.6898, 0.6870, 0.6822, 0.6333],\n",
      "        [0.6894, 0.6865, 0.6817, 0.6329],\n",
      "        [0.6843, 0.6813, 0.6761, 0.6276],\n",
      "        [0.7314, 0.7305, 0.7289, 0.6768],\n",
      "        [0.7795, 0.7808, 0.7828, 0.7271],\n",
      "        [0.8046, 0.8070, 0.8109, 0.7532],\n",
      "        [0.7887, 0.7904, 0.7931, 0.7366],\n",
      "        [0.8358, 0.8396, 0.8459, 0.7858],\n",
      "        [0.8855, 0.8916, 0.9015, 0.8377],\n",
      "        [0.6909, 0.6882, 0.6835, 0.6345],\n",
      "        [0.6752, 0.6718, 0.6659, 0.6181],\n",
      "        [0.8273, 0.8307, 0.8363, 0.7769],\n",
      "        [0.6302, 0.6247, 0.6154, 0.5711],\n",
      "        [0.6302, 0.6247, 0.6154, 0.5711],\n",
      "        [0.7460, 0.7457, 0.7452, 0.6920],\n",
      "        [0.6833, 0.6803, 0.6750, 0.6266],\n",
      "        [0.7893, 0.7911, 0.7938, 0.7373],\n",
      "        [0.6302, 0.6247, 0.6154, 0.5711],\n",
      "        [0.7804, 0.7817, 0.7837, 0.7279],\n",
      "        [0.7677, 0.7684, 0.7695, 0.7146],\n",
      "        [0.7626, 0.7630, 0.7638, 0.7093],\n",
      "        [0.6302, 0.6247, 0.6154, 0.5711],\n",
      "        [0.6302, 0.6247, 0.6154, 0.5711],\n",
      "        [0.6302, 0.6247, 0.6154, 0.5711],\n",
      "        [0.6302, 0.6247, 0.6154, 0.5711],\n",
      "        [0.6302, 0.6247, 0.6154, 0.5711],\n",
      "        [0.6302, 0.6247, 0.6154, 0.5711],\n",
      "        [0.6302, 0.6247, 0.6154, 0.5711],\n",
      "        [0.6379, 0.6327, 0.6241, 0.5791],\n",
      "        [0.6557, 0.6513, 0.6440, 0.5977],\n",
      "        [0.7135, 0.7118, 0.7088, 0.6581],\n",
      "        [0.6302, 0.6247, 0.6154, 0.5711],\n",
      "        [0.6302, 0.6247, 0.6154, 0.5711],\n",
      "        [0.6302, 0.6247, 0.6154, 0.5711],\n",
      "        [0.6712, 0.6676, 0.6614, 0.6139],\n",
      "        [0.6522, 0.6477, 0.6401, 0.5940],\n",
      "        [0.6575, 0.6532, 0.6460, 0.5996],\n",
      "        [0.6302, 0.6247, 0.6154, 0.5711],\n",
      "        [0.6302, 0.6247, 0.6154, 0.5711],\n",
      "        [0.6696, 0.6659, 0.6596, 0.6122],\n",
      "        [0.6599, 0.6558, 0.6487, 0.6021],\n",
      "        [0.6792, 0.6759, 0.6703, 0.6222],\n",
      "        [0.6302, 0.6247, 0.6154, 0.5711],\n",
      "        [0.6302, 0.6247, 0.6154, 0.5711],\n",
      "        [0.6302, 0.6247, 0.6154, 0.5711],\n",
      "        [0.7581, 0.7584, 0.7587, 0.7046]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0631,     0.0067,     0.0262,     0.0037],\n",
      "        [    0.0067,     0.0130,     0.0265,     0.0187],\n",
      "        [    0.0184,     0.0197,     0.0175,     0.0078],\n",
      "        [    0.0314,     0.0065,     0.0130,     0.0102],\n",
      "        [    0.0425,     0.0262,     0.0423,     0.0166],\n",
      "        [    0.0491,     0.0668,     0.0362,     0.0053],\n",
      "        [    0.0881,     0.0584,     0.0122,     0.0116],\n",
      "        [    0.0814,     0.0356,     0.0085,     0.0212],\n",
      "        [    0.0439,     0.0159,     0.0169,     0.0277],\n",
      "        [    0.0168,     0.0174,     0.0314,     0.0301],\n",
      "        [    0.0195,     0.0351,     0.0372,     0.0257],\n",
      "        [    0.0313,     0.0348,     0.0259,     0.0039],\n",
      "        [    0.0372,     0.0302,     0.0092,     0.0158],\n",
      "        [    0.0280,     0.0087,     0.0170,     0.0296],\n",
      "        [    0.0589,     0.0374,     0.0266,     0.0532],\n",
      "        [    0.0864,     0.0785,     0.0028,     0.0542],\n",
      "        [    0.1023,     0.0270,     0.0239,     0.0326],\n",
      "        [    0.0087,     0.0444,     0.0466,     0.0338],\n",
      "        [    0.0010,     0.0001,     0.0226,     0.0086],\n",
      "        [    0.0458,     0.0683,     0.0527,     0.0903],\n",
      "        [    0.0751,     0.0921,     0.0929,     0.0691],\n",
      "        [    0.1069,     0.0728,     0.0327,     0.0161],\n",
      "        [    0.0342,     0.0391,     0.0308,     0.0449],\n",
      "        [    0.1216,     0.1397,     0.1008,     0.0289],\n",
      "        [    0.1462,     0.1271,     0.1490,     0.0992],\n",
      "        [    0.0456,     0.0598,     0.0370,     0.0048],\n",
      "        [    0.1221,     0.1019,     0.0695,     0.0272],\n",
      "        [    0.0093,     0.0021,     0.0022,     0.0165],\n",
      "        [    0.1501,     0.1517,     0.1364,     0.1443],\n",
      "        [    0.0429,     0.0672,     0.0149,     0.0143],\n",
      "        [    0.0812,     0.0302,     0.0236,     0.0262],\n",
      "        [    0.0189,     0.0029,     0.0166,     0.0173],\n",
      "        [    0.0013,     0.0169,     0.0012,     0.0320],\n",
      "        [    0.0278,     0.0082,     0.0963,     0.1643],\n",
      "        [    0.0593,     0.0042,     0.0262,     0.0060],\n",
      "        [    0.0114,     0.0081,     0.0394,     0.0164],\n",
      "        [    0.0264,     0.0538,     0.0135,     0.0294],\n",
      "        [    0.0136,     0.0486,     0.0227,     0.0204],\n",
      "        [    0.0541,     0.0320,     0.0270,     0.0190],\n",
      "        [    0.1265,     0.0834,     0.0447,     0.1022],\n",
      "        [    0.0429,     0.0264,     0.0094,     0.0161],\n",
      "        [    0.0310,     0.0132,     0.0311,     0.0466],\n",
      "        [    0.0088,     0.0490,     0.0225,     0.0088],\n",
      "        [    0.0546,     0.0317,     0.0146,     0.0193],\n",
      "        [    0.0372,     0.0239,     0.0155,     0.0060],\n",
      "        [    0.0065,     0.0142,     0.0399,     0.0752],\n",
      "        [    0.0012,     0.0262,     0.0644,     0.0391],\n",
      "        [    0.0266,     0.0494,     0.0752,     0.0110],\n",
      "        [    0.0375,     0.0363,     0.0255,     0.0038],\n",
      "        [    0.1517,     0.0223,     0.0175,     0.0950],\n",
      "        [    0.0797,     0.0516,     0.0011,     0.0107],\n",
      "        [    0.0715,     0.0658,     0.0345,     0.0141],\n",
      "        [    0.0783,     0.0450,     0.0665,     0.0880],\n",
      "        [    0.0508,     0.1150,     0.0996,     0.0542],\n",
      "        [    0.1205,     0.1089,     0.0631,     0.0987],\n",
      "        [    0.1144,     0.0724,     0.1106,     0.1206],\n",
      "        [    0.1438,     0.0999,     0.0931,     0.1050]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 63\n",
      "Number of shrink: 37\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 8\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0636, 0.0067, 0.0267, 0.0027],\n",
      "        [0.0065, 0.0128, 0.0261, 0.0196],\n",
      "        [0.0193, 0.0192, 0.0187, 0.0094],\n",
      "        [0.0303, 0.0072, 0.0114, 0.0122],\n",
      "        [0.0437, 0.0269, 0.0435, 0.0181],\n",
      "        [0.0507, 0.0679, 0.0375, 0.0037],\n",
      "        [0.0903, 0.0600, 0.0139, 0.0098],\n",
      "        [0.0836, 0.0372, 0.0098, 0.0197],\n",
      "        [0.0455, 0.0168, 0.0164, 0.0269],\n",
      "        [0.0186, 0.0164, 0.0307, 0.0293],\n",
      "        [0.0186, 0.0350, 0.0375, 0.0258],\n",
      "        [0.0303, 0.0346, 0.0261, 0.0040],\n",
      "        [0.0357, 0.0296, 0.0091, 0.0162],\n",
      "        [0.0261, 0.0076, 0.0176, 0.0304],\n",
      "        [0.0565, 0.0355, 0.0247, 0.0553],\n",
      "        [0.0848, 0.0773, 0.0011, 0.0562],\n",
      "        [0.1015, 0.0266, 0.0251, 0.0342],\n",
      "        [0.0076, 0.0452, 0.0479, 0.0355],\n",
      "        [0.0003, 0.0006, 0.0211, 0.0106],\n",
      "        [0.0453, 0.0678, 0.0506, 0.0876],\n",
      "        [0.0821, 0.0986, 0.0992, 0.0752],\n",
      "        [0.1060, 0.0709, 0.0300, 0.0138],\n",
      "        [0.0362, 0.0415, 0.0324, 0.0458],\n",
      "        [0.1246, 0.1417, 0.1017, 0.0279],\n",
      "        [0.1492, 0.1291, 0.1499, 0.1001],\n",
      "        [0.0437, 0.0572, 0.0343, 0.0027],\n",
      "        [0.1209, 0.0998, 0.0667, 0.0247],\n",
      "        [0.0074, 0.0004, 0.0042, 0.0151],\n",
      "        [0.1531, 0.1537, 0.1374, 0.1453],\n",
      "        [0.0434, 0.0672, 0.0154, 0.0152],\n",
      "        [0.0808, 0.0293, 0.0230, 0.0260],\n",
      "        [0.0113, 0.0103, 0.0246, 0.0252],\n",
      "        [0.0017, 0.0189, 0.0021, 0.0310],\n",
      "        [0.0248, 0.0102, 0.0973, 0.1652],\n",
      "        [0.0564, 0.0062, 0.0271, 0.0069],\n",
      "        [0.0144, 0.0061, 0.0384, 0.0155],\n",
      "        [0.0234, 0.0518, 0.0144, 0.0303],\n",
      "        [0.0106, 0.0466, 0.0218, 0.0195],\n",
      "        [0.0511, 0.0300, 0.0261, 0.0180],\n",
      "        [0.1300, 0.0860, 0.0430, 0.1005],\n",
      "        [0.0422, 0.0246, 0.0066, 0.0185],\n",
      "        [0.0302, 0.0148, 0.0331, 0.0482],\n",
      "        [0.0058, 0.0470, 0.0215, 0.0078],\n",
      "        [0.0516, 0.0297, 0.0136, 0.0203],\n",
      "        [0.0343, 0.0219, 0.0164, 0.0050],\n",
      "        [0.0056, 0.0161, 0.0426, 0.0775],\n",
      "        [0.0012, 0.0272, 0.0664, 0.0408],\n",
      "        [0.0225, 0.0461, 0.0725, 0.0084],\n",
      "        [0.0345, 0.0343, 0.0245, 0.0048],\n",
      "        [0.1488, 0.0203, 0.0184, 0.0960],\n",
      "        [0.0728, 0.0454, 0.0048, 0.0164],\n",
      "        [0.0654, 0.0604, 0.0296, 0.0188],\n",
      "        [0.0744, 0.0418, 0.0638, 0.0853],\n",
      "        [0.0481, 0.1133, 0.0990, 0.0535],\n",
      "        [0.1176, 0.1069, 0.0622, 0.0977],\n",
      "        [0.1114, 0.0704, 0.1097, 0.1197],\n",
      "        [0.1331, 0.0893, 0.0816, 0.0939]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 17.15800166130066\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 58\n",
      "X 資料 torch.Size([49, 18])\n",
      "Y 資料 torch.Size([49, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.010827342048287392, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引1，y= tensor([0.6657, 0.6408, 0.6414, 0.5846])\n",
      "目前模型的Data torch.Size([58, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7843, 0.7862, 0.7881, 0.7315],\n",
      "        [0.7994, 0.8020, 0.8049, 0.7471],\n",
      "        [0.7955, 0.7979, 0.8005, 0.7431],\n",
      "        [0.8091, 0.8120, 0.8155, 0.7570],\n",
      "        [0.7756, 0.7771, 0.7785, 0.7226],\n",
      "        [0.7534, 0.7541, 0.7540, 0.6998],\n",
      "        [0.7317, 0.7314, 0.7300, 0.6775],\n",
      "        [0.7079, 0.7067, 0.7036, 0.6530],\n",
      "        [0.6983, 0.6967, 0.6930, 0.6432],\n",
      "        [0.6949, 0.6931, 0.6892, 0.6396],\n",
      "        [0.6953, 0.6935, 0.6897, 0.6401],\n",
      "        [0.6888, 0.6868, 0.6825, 0.6334],\n",
      "        [0.6879, 0.6859, 0.6816, 0.6325],\n",
      "        [0.6824, 0.6802, 0.6755, 0.6268],\n",
      "        [0.7290, 0.7286, 0.7270, 0.6747],\n",
      "        [0.7780, 0.7797, 0.7811, 0.7250],\n",
      "        [0.8038, 0.8066, 0.8097, 0.7516],\n",
      "        [0.7876, 0.7897, 0.7918, 0.7349],\n",
      "        [0.8351, 0.8391, 0.8443, 0.7838],\n",
      "        [0.8850, 0.8910, 0.8994, 0.8350],\n",
      "        [0.6839, 0.6817, 0.6772, 0.6284],\n",
      "        [0.6762, 0.6737, 0.6686, 0.6204],\n",
      "        [0.8293, 0.8331, 0.8379, 0.7778],\n",
      "        [0.6272, 0.6227, 0.6145, 0.5701],\n",
      "        [0.6272, 0.6227, 0.6145, 0.5701],\n",
      "        [0.7479, 0.7483, 0.7479, 0.6941],\n",
      "        [0.6846, 0.6824, 0.6779, 0.6291],\n",
      "        [0.7912, 0.7935, 0.7958, 0.7387],\n",
      "        [0.6272, 0.6227, 0.6145, 0.5701],\n",
      "        [0.7799, 0.7816, 0.7832, 0.7270],\n",
      "        [0.7680, 0.7693, 0.7701, 0.7148],\n",
      "        [0.7550, 0.7557, 0.7557, 0.7014],\n",
      "        [0.6272, 0.6227, 0.6145, 0.5701],\n",
      "        [0.6272, 0.6227, 0.6145, 0.5701],\n",
      "        [0.6272, 0.6227, 0.6145, 0.5701],\n",
      "        [0.6272, 0.6227, 0.6145, 0.5701],\n",
      "        [0.6272, 0.6227, 0.6145, 0.5701],\n",
      "        [0.6272, 0.6227, 0.6145, 0.5701],\n",
      "        [0.6272, 0.6227, 0.6145, 0.5701],\n",
      "        [0.6344, 0.6302, 0.6224, 0.5775],\n",
      "        [0.6564, 0.6531, 0.6467, 0.6001],\n",
      "        [0.7143, 0.7134, 0.7108, 0.6596],\n",
      "        [0.6272, 0.6227, 0.6145, 0.5701],\n",
      "        [0.6272, 0.6227, 0.6145, 0.5701],\n",
      "        [0.6272, 0.6227, 0.6145, 0.5701],\n",
      "        [0.6721, 0.6694, 0.6641, 0.6162],\n",
      "        [0.6522, 0.6487, 0.6421, 0.5958],\n",
      "        [0.6533, 0.6499, 0.6434, 0.5970],\n",
      "        [0.6272, 0.6227, 0.6145, 0.5701],\n",
      "        [0.6272, 0.6227, 0.6145, 0.5701],\n",
      "        [0.6627, 0.6596, 0.6537, 0.6066],\n",
      "        [0.6538, 0.6504, 0.6439, 0.5974],\n",
      "        [0.6753, 0.6727, 0.6676, 0.6195],\n",
      "        [0.6275, 0.6230, 0.6148, 0.5704],\n",
      "        [0.6272, 0.6227, 0.6145, 0.5701],\n",
      "        [0.6272, 0.6227, 0.6145, 0.5701],\n",
      "        [0.7473, 0.7478, 0.7473, 0.6936],\n",
      "        [0.7498, 0.7503, 0.7500, 0.6961]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0636, 0.0067, 0.0267, 0.0027],\n",
      "        [0.0065, 0.0128, 0.0261, 0.0196],\n",
      "        [0.0193, 0.0192, 0.0187, 0.0094],\n",
      "        [0.0303, 0.0072, 0.0114, 0.0122],\n",
      "        [0.0437, 0.0269, 0.0435, 0.0181],\n",
      "        [0.0507, 0.0679, 0.0375, 0.0037],\n",
      "        [0.0903, 0.0600, 0.0139, 0.0098],\n",
      "        [0.0836, 0.0372, 0.0098, 0.0197],\n",
      "        [0.0455, 0.0168, 0.0164, 0.0269],\n",
      "        [0.0186, 0.0164, 0.0307, 0.0293],\n",
      "        [0.0186, 0.0350, 0.0375, 0.0258],\n",
      "        [0.0303, 0.0346, 0.0261, 0.0040],\n",
      "        [0.0357, 0.0296, 0.0091, 0.0162],\n",
      "        [0.0261, 0.0076, 0.0176, 0.0304],\n",
      "        [0.0565, 0.0355, 0.0247, 0.0553],\n",
      "        [0.0848, 0.0773, 0.0011, 0.0562],\n",
      "        [0.1015, 0.0266, 0.0251, 0.0342],\n",
      "        [0.0076, 0.0452, 0.0479, 0.0355],\n",
      "        [0.0003, 0.0006, 0.0211, 0.0106],\n",
      "        [0.0453, 0.0678, 0.0506, 0.0876],\n",
      "        [0.0821, 0.0986, 0.0992, 0.0752],\n",
      "        [0.1060, 0.0709, 0.0300, 0.0138],\n",
      "        [0.0362, 0.0415, 0.0324, 0.0458],\n",
      "        [0.1246, 0.1417, 0.1017, 0.0279],\n",
      "        [0.1492, 0.1291, 0.1499, 0.1001],\n",
      "        [0.0437, 0.0572, 0.0343, 0.0027],\n",
      "        [0.1209, 0.0998, 0.0667, 0.0247],\n",
      "        [0.0074, 0.0004, 0.0042, 0.0151],\n",
      "        [0.1531, 0.1537, 0.1374, 0.1453],\n",
      "        [0.0434, 0.0672, 0.0154, 0.0152],\n",
      "        [0.0808, 0.0293, 0.0230, 0.0260],\n",
      "        [0.0113, 0.0103, 0.0246, 0.0252],\n",
      "        [0.0017, 0.0189, 0.0021, 0.0310],\n",
      "        [0.0248, 0.0102, 0.0973, 0.1652],\n",
      "        [0.0564, 0.0062, 0.0271, 0.0069],\n",
      "        [0.0144, 0.0061, 0.0384, 0.0155],\n",
      "        [0.0234, 0.0518, 0.0144, 0.0303],\n",
      "        [0.0106, 0.0466, 0.0218, 0.0195],\n",
      "        [0.0511, 0.0300, 0.0261, 0.0180],\n",
      "        [0.1300, 0.0860, 0.0430, 0.1005],\n",
      "        [0.0422, 0.0246, 0.0066, 0.0185],\n",
      "        [0.0302, 0.0148, 0.0331, 0.0482],\n",
      "        [0.0058, 0.0470, 0.0215, 0.0078],\n",
      "        [0.0516, 0.0297, 0.0136, 0.0203],\n",
      "        [0.0343, 0.0219, 0.0164, 0.0050],\n",
      "        [0.0056, 0.0161, 0.0426, 0.0775],\n",
      "        [0.0012, 0.0272, 0.0664, 0.0408],\n",
      "        [0.0225, 0.0461, 0.0725, 0.0084],\n",
      "        [0.0345, 0.0343, 0.0245, 0.0048],\n",
      "        [0.1488, 0.0203, 0.0184, 0.0960],\n",
      "        [0.0728, 0.0454, 0.0048, 0.0164],\n",
      "        [0.0654, 0.0604, 0.0296, 0.0188],\n",
      "        [0.0744, 0.0418, 0.0638, 0.0853],\n",
      "        [0.0481, 0.1133, 0.0990, 0.0535],\n",
      "        [0.1176, 0.1069, 0.0622, 0.0977],\n",
      "        [0.1114, 0.0704, 0.1097, 0.1197],\n",
      "        [0.1331, 0.0893, 0.0816, 0.0939],\n",
      "        [0.0841, 0.1096, 0.1086, 0.1115]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 14\n",
      "Number of shrink: 14\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module>>\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 9\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0646, 0.0083, 0.0282, 0.0009],\n",
      "        [0.0057, 0.0142, 0.0248, 0.0213],\n",
      "        [0.0204, 0.0174, 0.0204, 0.0115],\n",
      "        [0.0290, 0.0092, 0.0096, 0.0145],\n",
      "        [0.0448, 0.0286, 0.0451, 0.0200],\n",
      "        [0.0518, 0.0696, 0.0391, 0.0019],\n",
      "        [0.0917, 0.0619, 0.0157, 0.0078],\n",
      "        [0.0848, 0.0387, 0.0113, 0.0181],\n",
      "        [0.0461, 0.0178, 0.0155, 0.0259],\n",
      "        [0.0192, 0.0155, 0.0299, 0.0283],\n",
      "        [0.0183, 0.0345, 0.0370, 0.0252],\n",
      "        [0.0300, 0.0339, 0.0256, 0.0034],\n",
      "        [0.0352, 0.0287, 0.0083, 0.0170],\n",
      "        [0.0252, 0.0064, 0.0187, 0.0315],\n",
      "        [0.0549, 0.0334, 0.0227, 0.0574],\n",
      "        [0.0833, 0.0752, 0.0009, 0.0586],\n",
      "        [0.1001, 0.0245, 0.0271, 0.0366],\n",
      "        [0.0061, 0.0472, 0.0499, 0.0378],\n",
      "        [0.0014, 0.0030, 0.0187, 0.0135],\n",
      "        [0.0432, 0.0649, 0.0477, 0.0841],\n",
      "        [0.0868, 0.1038, 0.1046, 0.0803],\n",
      "        [0.1061, 0.0713, 0.0303, 0.0141],\n",
      "        [0.0359, 0.0405, 0.0316, 0.0444],\n",
      "        [0.1263, 0.1437, 0.1037, 0.0262],\n",
      "        [0.1509, 0.1311, 0.1519, 0.1018],\n",
      "        [0.0436, 0.0575, 0.0345, 0.0032],\n",
      "        [0.1211, 0.1002, 0.0670, 0.0251],\n",
      "        [0.0076, 0.0005, 0.0036, 0.0162],\n",
      "        [0.1548, 0.1556, 0.1393, 0.1470],\n",
      "        [0.0449, 0.0693, 0.0174, 0.0176],\n",
      "        [0.0819, 0.0310, 0.0245, 0.0278],\n",
      "        [0.0057, 0.0166, 0.0311, 0.0315],\n",
      "        [0.0034, 0.0209, 0.0040, 0.0293],\n",
      "        [0.0231, 0.0121, 0.0992, 0.1669],\n",
      "        [0.0547, 0.0081, 0.0291, 0.0086],\n",
      "        [0.0161, 0.0042, 0.0365, 0.0138],\n",
      "        [0.0217, 0.0499, 0.0164, 0.0320],\n",
      "        [0.0089, 0.0447, 0.0199, 0.0178],\n",
      "        [0.0494, 0.0281, 0.0241, 0.0163],\n",
      "        [0.1325, 0.0888, 0.0403, 0.0980],\n",
      "        [0.0424, 0.0251, 0.0070, 0.0182],\n",
      "        [0.0306, 0.0140, 0.0324, 0.0474],\n",
      "        [0.0041, 0.0451, 0.0196, 0.0061],\n",
      "        [0.0499, 0.0278, 0.0117, 0.0220],\n",
      "        [0.0326, 0.0199, 0.0184, 0.0033],\n",
      "        [0.0057, 0.0157, 0.0424, 0.0772],\n",
      "        [0.0017, 0.0265, 0.0658, 0.0402],\n",
      "        [0.0198, 0.0431, 0.0695, 0.0056],\n",
      "        [0.0328, 0.0324, 0.0226, 0.0065],\n",
      "        [0.1471, 0.0183, 0.0204, 0.0977],\n",
      "        [0.0673, 0.0394, 0.0110, 0.0222],\n",
      "        [0.0604, 0.0550, 0.0240, 0.0240],\n",
      "        [0.0718, 0.0388, 0.0607, 0.0824],\n",
      "        [0.0462, 0.1112, 0.0968, 0.0516],\n",
      "        [0.1159, 0.1049, 0.0602, 0.0960],\n",
      "        [0.1097, 0.0684, 0.1077, 0.1180],\n",
      "        [0.1249, 0.0803, 0.0723, 0.0849],\n",
      "        [0.0747, 0.0993, 0.0979, 0.1012]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 17.408624410629272\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 59\n",
      "X 資料 torch.Size([48, 18])\n",
      "Y 資料 torch.Size([48, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.016152692958712578, 27)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引27，y= tensor([0.4165, 0.4785, 0.6024, 0.5923])\n",
      "目前模型的Data torch.Size([59, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7832, 0.7846, 0.7866, 0.7297],\n",
      "        [0.7986, 0.8006, 0.8036, 0.7454],\n",
      "        [0.7944, 0.7962, 0.7989, 0.7410],\n",
      "        [0.8077, 0.8101, 0.8136, 0.7547],\n",
      "        [0.7744, 0.7755, 0.7769, 0.7207],\n",
      "        [0.7522, 0.7524, 0.7524, 0.6980],\n",
      "        [0.7303, 0.7296, 0.7281, 0.6755],\n",
      "        [0.7067, 0.7051, 0.7021, 0.6514],\n",
      "        [0.6977, 0.6957, 0.6922, 0.6422],\n",
      "        [0.6942, 0.6921, 0.6884, 0.6387],\n",
      "        [0.6950, 0.6930, 0.6892, 0.6395],\n",
      "        [0.6885, 0.6861, 0.6820, 0.6328],\n",
      "        [0.6874, 0.6851, 0.6809, 0.6317],\n",
      "        [0.6816, 0.6790, 0.6744, 0.6257],\n",
      "        [0.7274, 0.7266, 0.7250, 0.6726],\n",
      "        [0.7764, 0.7775, 0.7791, 0.7227],\n",
      "        [0.8024, 0.8045, 0.8077, 0.7492],\n",
      "        [0.7861, 0.7876, 0.7898, 0.7326],\n",
      "        [0.8334, 0.8367, 0.8420, 0.7809],\n",
      "        [0.8829, 0.8881, 0.8966, 0.8315],\n",
      "        [0.6792, 0.6765, 0.6717, 0.6233],\n",
      "        [0.6761, 0.6732, 0.6683, 0.6201],\n",
      "        [0.8290, 0.8321, 0.8371, 0.7764],\n",
      "        [0.6255, 0.6207, 0.6125, 0.5684],\n",
      "        [0.6255, 0.6207, 0.6125, 0.5684],\n",
      "        [0.7480, 0.7480, 0.7477, 0.6936],\n",
      "        [0.6844, 0.6820, 0.6776, 0.6287],\n",
      "        [0.7910, 0.7927, 0.7952, 0.7376],\n",
      "        [0.6255, 0.6207, 0.6125, 0.5684],\n",
      "        [0.7784, 0.7795, 0.7812, 0.7247],\n",
      "        [0.7669, 0.7677, 0.7686, 0.7130],\n",
      "        [0.7494, 0.7494, 0.7492, 0.6950],\n",
      "        [0.6255, 0.6207, 0.6125, 0.5684],\n",
      "        [0.6255, 0.6207, 0.6125, 0.5684],\n",
      "        [0.6255, 0.6207, 0.6125, 0.5684],\n",
      "        [0.6255, 0.6207, 0.6125, 0.5684],\n",
      "        [0.6255, 0.6207, 0.6125, 0.5684],\n",
      "        [0.6255, 0.6207, 0.6125, 0.5684],\n",
      "        [0.6255, 0.6207, 0.6125, 0.5684],\n",
      "        [0.6320, 0.6274, 0.6196, 0.5750],\n",
      "        [0.6562, 0.6526, 0.6463, 0.5997],\n",
      "        [0.7139, 0.7126, 0.7101, 0.6588],\n",
      "        [0.6255, 0.6207, 0.6125, 0.5684],\n",
      "        [0.6255, 0.6207, 0.6125, 0.5684],\n",
      "        [0.6255, 0.6207, 0.6125, 0.5684],\n",
      "        [0.6720, 0.6690, 0.6638, 0.6159],\n",
      "        [0.6517, 0.6479, 0.6414, 0.5952],\n",
      "        [0.6507, 0.6469, 0.6403, 0.5942],\n",
      "        [0.6255, 0.6207, 0.6125, 0.5684],\n",
      "        [0.6255, 0.6207, 0.6125, 0.5684],\n",
      "        [0.6572, 0.6537, 0.6475, 0.6008],\n",
      "        [0.6488, 0.6449, 0.6382, 0.5922],\n",
      "        [0.6727, 0.6697, 0.6645, 0.6166],\n",
      "        [0.6256, 0.6208, 0.6126, 0.5685],\n",
      "        [0.6255, 0.6207, 0.6125, 0.5684],\n",
      "        [0.6255, 0.6207, 0.6125, 0.5684],\n",
      "        [0.7391, 0.7388, 0.7379, 0.6846],\n",
      "        [0.7404, 0.7401, 0.7393, 0.6858],\n",
      "        [0.6255, 0.6207, 0.6125, 0.5684]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0646, 0.0083, 0.0282, 0.0009],\n",
      "        [0.0057, 0.0142, 0.0248, 0.0213],\n",
      "        [0.0204, 0.0174, 0.0204, 0.0115],\n",
      "        [0.0290, 0.0092, 0.0096, 0.0145],\n",
      "        [0.0448, 0.0286, 0.0451, 0.0200],\n",
      "        [0.0518, 0.0696, 0.0391, 0.0019],\n",
      "        [0.0917, 0.0619, 0.0157, 0.0078],\n",
      "        [0.0848, 0.0387, 0.0113, 0.0181],\n",
      "        [0.0461, 0.0178, 0.0155, 0.0259],\n",
      "        [0.0192, 0.0155, 0.0299, 0.0283],\n",
      "        [0.0183, 0.0345, 0.0370, 0.0252],\n",
      "        [0.0300, 0.0339, 0.0256, 0.0034],\n",
      "        [0.0352, 0.0287, 0.0083, 0.0170],\n",
      "        [0.0252, 0.0064, 0.0187, 0.0315],\n",
      "        [0.0549, 0.0334, 0.0227, 0.0574],\n",
      "        [0.0833, 0.0752, 0.0009, 0.0586],\n",
      "        [0.1001, 0.0245, 0.0271, 0.0366],\n",
      "        [0.0061, 0.0472, 0.0499, 0.0378],\n",
      "        [0.0014, 0.0030, 0.0187, 0.0135],\n",
      "        [0.0432, 0.0649, 0.0477, 0.0841],\n",
      "        [0.0868, 0.1038, 0.1046, 0.0803],\n",
      "        [0.1061, 0.0713, 0.0303, 0.0141],\n",
      "        [0.0359, 0.0405, 0.0316, 0.0444],\n",
      "        [0.1263, 0.1437, 0.1037, 0.0262],\n",
      "        [0.1509, 0.1311, 0.1519, 0.1018],\n",
      "        [0.0436, 0.0575, 0.0345, 0.0032],\n",
      "        [0.1211, 0.1002, 0.0670, 0.0251],\n",
      "        [0.0076, 0.0005, 0.0036, 0.0162],\n",
      "        [0.1548, 0.1556, 0.1393, 0.1470],\n",
      "        [0.0449, 0.0693, 0.0174, 0.0176],\n",
      "        [0.0819, 0.0310, 0.0245, 0.0278],\n",
      "        [0.0057, 0.0166, 0.0311, 0.0315],\n",
      "        [0.0034, 0.0209, 0.0040, 0.0293],\n",
      "        [0.0231, 0.0121, 0.0992, 0.1669],\n",
      "        [0.0547, 0.0081, 0.0291, 0.0086],\n",
      "        [0.0161, 0.0042, 0.0365, 0.0138],\n",
      "        [0.0217, 0.0499, 0.0164, 0.0320],\n",
      "        [0.0089, 0.0447, 0.0199, 0.0178],\n",
      "        [0.0494, 0.0281, 0.0241, 0.0163],\n",
      "        [0.1325, 0.0888, 0.0403, 0.0980],\n",
      "        [0.0424, 0.0251, 0.0070, 0.0182],\n",
      "        [0.0306, 0.0140, 0.0324, 0.0474],\n",
      "        [0.0041, 0.0451, 0.0196, 0.0061],\n",
      "        [0.0499, 0.0278, 0.0117, 0.0220],\n",
      "        [0.0326, 0.0199, 0.0184, 0.0033],\n",
      "        [0.0057, 0.0157, 0.0424, 0.0772],\n",
      "        [0.0017, 0.0265, 0.0658, 0.0402],\n",
      "        [0.0198, 0.0431, 0.0695, 0.0056],\n",
      "        [0.0328, 0.0324, 0.0226, 0.0065],\n",
      "        [0.1471, 0.0183, 0.0204, 0.0977],\n",
      "        [0.0673, 0.0394, 0.0110, 0.0222],\n",
      "        [0.0604, 0.0550, 0.0240, 0.0240],\n",
      "        [0.0718, 0.0388, 0.0607, 0.0824],\n",
      "        [0.0462, 0.1112, 0.0968, 0.0516],\n",
      "        [0.1159, 0.1049, 0.0602, 0.0960],\n",
      "        [0.1097, 0.0684, 0.1077, 0.1180],\n",
      "        [0.1249, 0.0803, 0.0723, 0.0849],\n",
      "        [0.0747, 0.0993, 0.0979, 0.1012],\n",
      "        [0.2090, 0.1423, 0.0101, 0.0239]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 62\n",
      "Number of shrink: 38\n",
      "<<Matching module>>\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 39\n",
      "Number of shrink: 27\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0632,     0.0068,     0.0266,     0.0029],\n",
      "        [    0.0082,     0.0118,     0.0271,     0.0188],\n",
      "        [    0.0192,     0.0186,     0.0193,     0.0100],\n",
      "        [    0.0304,     0.0080,     0.0103,     0.0134],\n",
      "        [    0.0441,     0.0277,     0.0438,     0.0184],\n",
      "        [    0.0518,     0.0690,     0.0376,     0.0037],\n",
      "        [    0.0927,     0.0622,     0.0146,     0.0094],\n",
      "        [    0.0862,     0.0391,     0.0097,     0.0202],\n",
      "        [    0.0469,     0.0174,     0.0181,     0.0290],\n",
      "        [    0.0203,     0.0156,     0.0323,     0.0312],\n",
      "        [    0.0184,     0.0358,     0.0407,     0.0292],\n",
      "        [    0.0297,     0.0350,     0.0292,     0.0073],\n",
      "        [    0.0346,     0.0294,     0.0115,     0.0134],\n",
      "        [    0.0238,     0.0065,     0.0161,     0.0285],\n",
      "        [    0.0537,     0.0331,     0.0238,     0.0558],\n",
      "        [    0.0838,     0.0759,     0.0000,     0.0572],\n",
      "        [    0.1015,     0.0257,     0.0262,     0.0353],\n",
      "        [    0.0071,     0.0462,     0.0488,     0.0363],\n",
      "        [    0.0006,     0.0016,     0.0191,     0.0128],\n",
      "        [    0.0459,     0.0663,     0.0469,     0.0837],\n",
      "        [    0.0966,     0.1124,     0.1108,     0.0854],\n",
      "        [    0.1060,     0.0696,     0.0258,     0.0093],\n",
      "        [    0.0395,     0.0436,     0.0338,     0.0469],\n",
      "        [    0.1329,     0.1482,     0.1044,     0.0263],\n",
      "        [    0.1574,     0.1356,     0.1526,     0.1017],\n",
      "        [    0.0414,     0.0547,     0.0305,     0.0010],\n",
      "        [    0.1207,     0.0984,     0.0626,     0.0204],\n",
      "        [    0.0044,     0.0027,     0.0068,     0.0128],\n",
      "        [    0.1614,     0.1602,     0.1400,     0.1469],\n",
      "        [    0.0442,     0.0685,     0.0163,     0.0161],\n",
      "        [    0.0808,     0.0296,     0.0226,     0.0255],\n",
      "        [    0.0037,     0.0257,     0.0396,     0.0389],\n",
      "        [    0.0100,     0.0254,     0.0048,     0.0294],\n",
      "        [    0.0165,     0.0167,     0.0999,     0.1668],\n",
      "        [    0.0481,     0.0127,     0.0298,     0.0085],\n",
      "        [    0.0227,     0.0004,     0.0357,     0.0138],\n",
      "        [    0.0151,     0.0454,     0.0171,     0.0320],\n",
      "        [    0.0024,     0.0401,     0.0191,     0.0179],\n",
      "        [    0.0429,     0.0235,     0.0234,     0.0164],\n",
      "        [    0.1397,     0.0940,     0.0386,     0.0972],\n",
      "        [    0.0433,     0.0242,     0.0028,     0.0228],\n",
      "        [    0.0300,     0.0156,     0.0359,     0.0511],\n",
      "        [    0.0025,     0.0406,     0.0189,     0.0062],\n",
      "        [    0.0433,     0.0233,     0.0110,     0.0219],\n",
      "        [    0.0260,     0.0154,     0.0191,     0.0034],\n",
      "        [    0.0059,     0.0170,     0.0466,     0.0818],\n",
      "        [    0.0029,     0.0271,     0.0697,     0.0446],\n",
      "        [    0.0145,     0.0395,     0.0692,     0.0060],\n",
      "        [    0.0263,     0.0278,     0.0219,     0.0064],\n",
      "        [    0.1405,     0.0138,     0.0211,     0.0976],\n",
      "        [    0.0570,     0.0307,     0.0168,     0.0269],\n",
      "        [    0.0510,     0.0472,     0.0193,     0.0277],\n",
      "        [    0.0671,     0.0356,     0.0602,     0.0825],\n",
      "        [    0.0397,     0.1067,     0.0962,     0.0518],\n",
      "        [    0.1093,     0.1004,     0.0595,     0.0961],\n",
      "        [    0.1031,     0.0639,     0.1070,     0.1180],\n",
      "        [    0.1118,     0.0675,     0.0602,     0.0743],\n",
      "        [    0.0597,     0.0845,     0.0837,     0.0887],\n",
      "        [    0.2024,     0.1378,     0.0094,     0.0238]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 18.165708303451538\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 60\n",
      "X 資料 torch.Size([47, 18])\n",
      "Y 資料 torch.Size([47, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.015713613480329514, 12)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引12，y= tensor([0.7162, 0.5794, 0.5097, 0.4827])\n",
      "目前模型的Data torch.Size([60, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7846, 0.7861, 0.7882, 0.7316],\n",
      "        [0.8011, 0.8030, 0.8058, 0.7479],\n",
      "        [0.7956, 0.7973, 0.8000, 0.7425],\n",
      "        [0.8091, 0.8112, 0.8143, 0.7558],\n",
      "        [0.7752, 0.7764, 0.7782, 0.7223],\n",
      "        [0.7523, 0.7529, 0.7538, 0.6998],\n",
      "        [0.7292, 0.7293, 0.7292, 0.6771],\n",
      "        [0.7053, 0.7047, 0.7038, 0.6535],\n",
      "        [0.6969, 0.6961, 0.6948, 0.6452],\n",
      "        [0.6932, 0.6923, 0.6908, 0.6416],\n",
      "        [0.6951, 0.6943, 0.6929, 0.6435],\n",
      "        [0.6882, 0.6873, 0.6856, 0.6367],\n",
      "        [0.6868, 0.6858, 0.6840, 0.6353],\n",
      "        [0.6802, 0.6790, 0.6770, 0.6288],\n",
      "        [0.7263, 0.7263, 0.7261, 0.6742],\n",
      "        [0.7769, 0.7782, 0.7800, 0.7241],\n",
      "        [0.8038, 0.8058, 0.8087, 0.7506],\n",
      "        [0.7871, 0.7886, 0.7909, 0.7341],\n",
      "        [0.8354, 0.8381, 0.8423, 0.7816],\n",
      "        [0.8856, 0.8896, 0.8957, 0.8311],\n",
      "        [0.6694, 0.6680, 0.6656, 0.6182],\n",
      "        [0.6762, 0.6749, 0.6728, 0.6249],\n",
      "        [0.8326, 0.8352, 0.8393, 0.7789],\n",
      "        [0.6189, 0.6162, 0.6118, 0.5685],\n",
      "        [0.6189, 0.6162, 0.6118, 0.5685],\n",
      "        [0.7503, 0.7508, 0.7516, 0.6978],\n",
      "        [0.6848, 0.6838, 0.6820, 0.6334],\n",
      "        [0.7942, 0.7958, 0.7984, 0.7410],\n",
      "        [0.6189, 0.6162, 0.6118, 0.5685],\n",
      "        [0.7791, 0.7804, 0.7823, 0.7262],\n",
      "        [0.7680, 0.7690, 0.7706, 0.7153],\n",
      "        [0.7400, 0.7403, 0.7407, 0.6877],\n",
      "        [0.6189, 0.6162, 0.6118, 0.5685],\n",
      "        [0.6189, 0.6162, 0.6118, 0.5685],\n",
      "        [0.6189, 0.6162, 0.6118, 0.5685],\n",
      "        [0.6189, 0.6162, 0.6118, 0.5685],\n",
      "        [0.6189, 0.6162, 0.6118, 0.5685],\n",
      "        [0.6189, 0.6162, 0.6118, 0.5685],\n",
      "        [0.6189, 0.6162, 0.6118, 0.5685],\n",
      "        [0.6247, 0.6221, 0.6180, 0.5742],\n",
      "        [0.6553, 0.6535, 0.6506, 0.6043],\n",
      "        [0.7145, 0.7142, 0.7135, 0.6626],\n",
      "        [0.6189, 0.6162, 0.6118, 0.5685],\n",
      "        [0.6189, 0.6162, 0.6118, 0.5685],\n",
      "        [0.6189, 0.6162, 0.6118, 0.5685],\n",
      "        [0.6718, 0.6704, 0.6681, 0.6205],\n",
      "        [0.6504, 0.6485, 0.6453, 0.5995],\n",
      "        [0.6454, 0.6434, 0.6400, 0.5946],\n",
      "        [0.6189, 0.6162, 0.6118, 0.5685],\n",
      "        [0.6189, 0.6162, 0.6118, 0.5685],\n",
      "        [0.6470, 0.6450, 0.6417, 0.5961],\n",
      "        [0.6393, 0.6371, 0.6335, 0.5886],\n",
      "        [0.6679, 0.6665, 0.6640, 0.6168],\n",
      "        [0.6191, 0.6164, 0.6120, 0.5687],\n",
      "        [0.6189, 0.6162, 0.6118, 0.5685],\n",
      "        [0.6189, 0.6162, 0.6118, 0.5685],\n",
      "        [0.7261, 0.7260, 0.7259, 0.6740],\n",
      "        [0.7253, 0.7253, 0.7251, 0.6733],\n",
      "        [0.6189, 0.6162, 0.6118, 0.5685],\n",
      "        [0.6831, 0.6820, 0.6801, 0.6316]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0632,     0.0068,     0.0266,     0.0029],\n",
      "        [    0.0082,     0.0118,     0.0271,     0.0188],\n",
      "        [    0.0192,     0.0186,     0.0193,     0.0100],\n",
      "        [    0.0304,     0.0080,     0.0103,     0.0134],\n",
      "        [    0.0441,     0.0277,     0.0438,     0.0184],\n",
      "        [    0.0518,     0.0690,     0.0376,     0.0037],\n",
      "        [    0.0927,     0.0622,     0.0146,     0.0094],\n",
      "        [    0.0862,     0.0391,     0.0097,     0.0202],\n",
      "        [    0.0469,     0.0174,     0.0181,     0.0290],\n",
      "        [    0.0203,     0.0156,     0.0323,     0.0312],\n",
      "        [    0.0184,     0.0358,     0.0407,     0.0292],\n",
      "        [    0.0297,     0.0350,     0.0292,     0.0073],\n",
      "        [    0.0346,     0.0294,     0.0115,     0.0134],\n",
      "        [    0.0238,     0.0065,     0.0161,     0.0285],\n",
      "        [    0.0537,     0.0331,     0.0238,     0.0558],\n",
      "        [    0.0838,     0.0759,     0.0000,     0.0572],\n",
      "        [    0.1015,     0.0257,     0.0262,     0.0353],\n",
      "        [    0.0071,     0.0462,     0.0488,     0.0363],\n",
      "        [    0.0006,     0.0016,     0.0191,     0.0128],\n",
      "        [    0.0459,     0.0663,     0.0469,     0.0837],\n",
      "        [    0.0966,     0.1124,     0.1108,     0.0854],\n",
      "        [    0.1060,     0.0696,     0.0258,     0.0093],\n",
      "        [    0.0395,     0.0436,     0.0338,     0.0469],\n",
      "        [    0.1329,     0.1482,     0.1044,     0.0263],\n",
      "        [    0.1574,     0.1356,     0.1526,     0.1017],\n",
      "        [    0.0414,     0.0547,     0.0305,     0.0010],\n",
      "        [    0.1207,     0.0984,     0.0626,     0.0204],\n",
      "        [    0.0044,     0.0027,     0.0068,     0.0128],\n",
      "        [    0.1614,     0.1602,     0.1400,     0.1469],\n",
      "        [    0.0442,     0.0685,     0.0163,     0.0161],\n",
      "        [    0.0808,     0.0296,     0.0226,     0.0255],\n",
      "        [    0.0037,     0.0257,     0.0396,     0.0389],\n",
      "        [    0.0100,     0.0254,     0.0048,     0.0294],\n",
      "        [    0.0165,     0.0167,     0.0999,     0.1668],\n",
      "        [    0.0481,     0.0127,     0.0298,     0.0085],\n",
      "        [    0.0227,     0.0004,     0.0357,     0.0138],\n",
      "        [    0.0151,     0.0454,     0.0171,     0.0320],\n",
      "        [    0.0024,     0.0401,     0.0191,     0.0179],\n",
      "        [    0.0429,     0.0235,     0.0234,     0.0164],\n",
      "        [    0.1397,     0.0940,     0.0386,     0.0972],\n",
      "        [    0.0433,     0.0242,     0.0028,     0.0228],\n",
      "        [    0.0300,     0.0156,     0.0359,     0.0511],\n",
      "        [    0.0025,     0.0406,     0.0189,     0.0062],\n",
      "        [    0.0433,     0.0233,     0.0110,     0.0219],\n",
      "        [    0.0260,     0.0154,     0.0191,     0.0034],\n",
      "        [    0.0059,     0.0170,     0.0466,     0.0818],\n",
      "        [    0.0029,     0.0271,     0.0697,     0.0446],\n",
      "        [    0.0145,     0.0395,     0.0692,     0.0060],\n",
      "        [    0.0263,     0.0278,     0.0219,     0.0064],\n",
      "        [    0.1405,     0.0138,     0.0211,     0.0976],\n",
      "        [    0.0570,     0.0307,     0.0168,     0.0269],\n",
      "        [    0.0510,     0.0472,     0.0193,     0.0277],\n",
      "        [    0.0671,     0.0356,     0.0602,     0.0825],\n",
      "        [    0.0397,     0.1067,     0.0962,     0.0518],\n",
      "        [    0.1093,     0.1004,     0.0595,     0.0961],\n",
      "        [    0.1031,     0.0639,     0.1070,     0.1180],\n",
      "        [    0.1118,     0.0675,     0.0602,     0.0743],\n",
      "        [    0.0597,     0.0845,     0.0837,     0.0887],\n",
      "        [    0.2024,     0.1378,     0.0094,     0.0238],\n",
      "        [    0.0331,     0.1026,     0.1704,     0.1489]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module>>\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 38\n",
      "Number of shrink: 26\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0585,     0.0056,     0.0282,     0.0005],\n",
      "        [    0.0146,     0.0091,     0.0266,     0.0202],\n",
      "        [    0.0137,     0.0205,     0.0205,     0.0121],\n",
      "        [    0.0357,     0.0065,     0.0085,     0.0162],\n",
      "        [    0.0388,     0.0258,     0.0446,     0.0199],\n",
      "        [    0.0462,     0.0665,     0.0375,     0.0032],\n",
      "        [    0.0893,     0.0615,     0.0160,     0.0077],\n",
      "        [    0.0821,     0.0375,     0.0098,     0.0200],\n",
      "        [    0.0415,     0.0143,     0.0197,     0.0303],\n",
      "        [    0.0149,     0.0186,     0.0340,     0.0326],\n",
      "        [    0.0256,     0.0406,     0.0441,     0.0322],\n",
      "        [    0.0359,     0.0390,     0.0319,     0.0097],\n",
      "        [    0.0401,     0.0327,     0.0135,     0.0116],\n",
      "        [    0.0283,     0.0087,     0.0151,     0.0275],\n",
      "        [    0.0564,     0.0330,     0.0217,     0.0581],\n",
      "        [    0.0874,     0.0761,     0.0026,     0.0604],\n",
      "        [    0.1057,     0.0262,     0.0289,     0.0389],\n",
      "        [    0.0111,     0.0458,     0.0513,     0.0395],\n",
      "        [    0.0050,     0.0012,     0.0157,     0.0172],\n",
      "        [    0.0493,     0.0650,     0.0410,     0.0765],\n",
      "        [    0.1042,     0.1222,     0.1220,     0.0956],\n",
      "        [    0.0992,     0.0649,     0.0222,     0.0060],\n",
      "        [    0.0487,     0.0489,     0.0355,     0.0471],\n",
      "        [    0.1339,     0.1508,     0.1073,     0.0241],\n",
      "        [    0.1585,     0.1382,     0.1555,     0.1039],\n",
      "        [    0.0326,     0.0489,     0.0270,     0.0037],\n",
      "        [    0.1147,     0.0947,     0.0601,     0.0182],\n",
      "        [    0.0031,     0.0067,     0.0078,     0.0128],\n",
      "        [    0.1624,     0.1627,     0.1429,     0.1490],\n",
      "        [    0.0408,     0.0686,     0.0193,     0.0196],\n",
      "        [    0.0766,     0.0287,     0.0243,     0.0279],\n",
      "        [    0.0123,     0.0374,     0.0538,     0.0524],\n",
      "        [    0.0110,     0.0280,     0.0077,     0.0272],\n",
      "        [    0.0155,     0.0192,     0.1028,     0.1690],\n",
      "        [    0.0471,     0.0152,     0.0327,     0.0107],\n",
      "        [    0.0237,     0.0029,     0.0328,     0.0117],\n",
      "        [    0.0141,     0.0428,     0.0200,     0.0341],\n",
      "        [    0.0013,     0.0376,     0.0162,     0.0157],\n",
      "        [    0.0418,     0.0210,     0.0205,     0.0142],\n",
      "        [    0.1421,     0.0981,     0.0341,     0.0935],\n",
      "        [    0.0381,     0.0209,     0.0003,     0.0252],\n",
      "        [    0.0238,     0.0192,     0.0378,     0.0526],\n",
      "        [    0.0035,     0.0380,     0.0160,     0.0040],\n",
      "        [    0.0423,     0.0207,     0.0081,     0.0241],\n",
      "        [    0.0250,     0.0128,     0.0220,     0.0012],\n",
      "        [    0.0000,     0.0209,     0.0495,     0.0845],\n",
      "        [    0.0023,     0.0304,     0.0724,     0.0472],\n",
      "        [    0.0130,     0.0362,     0.0650,     0.0025],\n",
      "        [    0.0252,     0.0253,     0.0190,     0.0085],\n",
      "        [    0.1395,     0.0113,     0.0240,     0.0998],\n",
      "        [    0.0430,     0.0146,     0.0340,     0.0423],\n",
      "        [    0.0377,     0.0320,     0.0031,     0.0422],\n",
      "        [    0.0656,     0.0320,     0.0554,     0.0782],\n",
      "        [    0.0386,     0.1040,     0.0931,     0.0495],\n",
      "        [    0.1083,     0.0978,     0.0566,     0.0939],\n",
      "        [    0.1021,     0.0613,     0.1041,     0.1159],\n",
      "        [    0.0916,     0.0443,     0.0344,     0.0503],\n",
      "        [    0.0346,     0.0563,     0.0529,     0.0600],\n",
      "        [    0.2014,     0.1352,     0.0065,     0.0260],\n",
      "        [    0.0362,     0.0972,     0.1636,     0.1426]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 18.88837742805481\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 61\n",
      "X 資料 torch.Size([46, 18])\n",
      "Y 資料 torch.Size([46, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.013714257627725601, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.6585, 0.6657, 0.6408, 0.6002])\n",
      "目前模型的Data torch.Size([61, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7894, 0.7873, 0.7866, 0.7292],\n",
      "        [0.8075, 0.8057, 0.8053, 0.7464],\n",
      "        [0.8011, 0.7992, 0.7987, 0.7404],\n",
      "        [0.8144, 0.8127, 0.8126, 0.7531],\n",
      "        [0.7805, 0.7783, 0.7773, 0.7208],\n",
      "        [0.7579, 0.7554, 0.7540, 0.6993],\n",
      "        [0.7327, 0.7299, 0.7279, 0.6754],\n",
      "        [0.7094, 0.7063, 0.7037, 0.6533],\n",
      "        [0.7024, 0.6992, 0.6964, 0.6466],\n",
      "        [0.6985, 0.6953, 0.6925, 0.6429],\n",
      "        [0.7022, 0.6991, 0.6963, 0.6465],\n",
      "        [0.6944, 0.6912, 0.6882, 0.6390],\n",
      "        [0.6923, 0.6891, 0.6860, 0.6371],\n",
      "        [0.6846, 0.6812, 0.6780, 0.6297],\n",
      "        [0.7290, 0.7262, 0.7240, 0.6719],\n",
      "        [0.7805, 0.7784, 0.7774, 0.7208],\n",
      "        [0.8080, 0.8062, 0.8059, 0.7470],\n",
      "        [0.7911, 0.7891, 0.7884, 0.7309],\n",
      "        [0.8399, 0.8385, 0.8389, 0.7772],\n",
      "        [0.8890, 0.8883, 0.8898, 0.8239],\n",
      "        [0.6618, 0.6581, 0.6544, 0.6080],\n",
      "        [0.6830, 0.6796, 0.6764, 0.6282],\n",
      "        [0.8419, 0.8405, 0.8410, 0.7791],\n",
      "        [0.6179, 0.6137, 0.6089, 0.5663],\n",
      "        [0.6179, 0.6137, 0.6089, 0.5663],\n",
      "        [0.7590, 0.7566, 0.7552, 0.7004],\n",
      "        [0.6908, 0.6875, 0.6844, 0.6356],\n",
      "        [0.8017, 0.7999, 0.7994, 0.7410],\n",
      "        [0.6179, 0.6137, 0.6089, 0.5663],\n",
      "        [0.7824, 0.7803, 0.7794, 0.7226],\n",
      "        [0.7722, 0.7700, 0.7688, 0.7130],\n",
      "        [0.7313, 0.7286, 0.7265, 0.6741],\n",
      "        [0.6179, 0.6137, 0.6089, 0.5663],\n",
      "        [0.6179, 0.6137, 0.6089, 0.5663],\n",
      "        [0.6179, 0.6137, 0.6089, 0.5663],\n",
      "        [0.6179, 0.6137, 0.6089, 0.5663],\n",
      "        [0.6179, 0.6137, 0.6089, 0.5663],\n",
      "        [0.6179, 0.6137, 0.6089, 0.5663],\n",
      "        [0.6179, 0.6137, 0.6089, 0.5663],\n",
      "        [0.6223, 0.6181, 0.6135, 0.5705],\n",
      "        [0.6605, 0.6568, 0.6530, 0.6068],\n",
      "        [0.7207, 0.7178, 0.7155, 0.6640],\n",
      "        [0.6179, 0.6137, 0.6089, 0.5663],\n",
      "        [0.6179, 0.6137, 0.6089, 0.5663],\n",
      "        [0.6179, 0.6137, 0.6089, 0.5663],\n",
      "        [0.6777, 0.6742, 0.6709, 0.6232],\n",
      "        [0.6556, 0.6519, 0.6480, 0.6022],\n",
      "        [0.6439, 0.6400, 0.6359, 0.5910],\n",
      "        [0.6179, 0.6137, 0.6089, 0.5663],\n",
      "        [0.6179, 0.6137, 0.6089, 0.5663],\n",
      "        [0.6329, 0.6289, 0.6245, 0.5806],\n",
      "        [0.6261, 0.6219, 0.6174, 0.5741],\n",
      "        [0.6665, 0.6628, 0.6592, 0.6125],\n",
      "        [0.6179, 0.6137, 0.6089, 0.5663],\n",
      "        [0.6179, 0.6137, 0.6089, 0.5663],\n",
      "        [0.6179, 0.6137, 0.6089, 0.5663],\n",
      "        [0.7059, 0.7028, 0.7001, 0.6499],\n",
      "        [0.7003, 0.6971, 0.6943, 0.6446],\n",
      "        [0.6179, 0.6137, 0.6089, 0.5663],\n",
      "        [0.6800, 0.6765, 0.6733, 0.6253],\n",
      "        [0.7743, 0.7721, 0.7710, 0.7149]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0585,     0.0056,     0.0282,     0.0005],\n",
      "        [    0.0146,     0.0091,     0.0266,     0.0202],\n",
      "        [    0.0137,     0.0205,     0.0205,     0.0121],\n",
      "        [    0.0357,     0.0065,     0.0085,     0.0162],\n",
      "        [    0.0388,     0.0258,     0.0446,     0.0199],\n",
      "        [    0.0462,     0.0665,     0.0375,     0.0032],\n",
      "        [    0.0893,     0.0615,     0.0160,     0.0077],\n",
      "        [    0.0821,     0.0375,     0.0098,     0.0200],\n",
      "        [    0.0415,     0.0143,     0.0197,     0.0303],\n",
      "        [    0.0149,     0.0186,     0.0340,     0.0326],\n",
      "        [    0.0256,     0.0406,     0.0441,     0.0322],\n",
      "        [    0.0359,     0.0390,     0.0319,     0.0097],\n",
      "        [    0.0401,     0.0327,     0.0135,     0.0116],\n",
      "        [    0.0283,     0.0087,     0.0151,     0.0275],\n",
      "        [    0.0564,     0.0330,     0.0217,     0.0581],\n",
      "        [    0.0874,     0.0761,     0.0026,     0.0604],\n",
      "        [    0.1057,     0.0262,     0.0289,     0.0389],\n",
      "        [    0.0111,     0.0458,     0.0513,     0.0395],\n",
      "        [    0.0050,     0.0012,     0.0157,     0.0172],\n",
      "        [    0.0493,     0.0650,     0.0410,     0.0765],\n",
      "        [    0.1042,     0.1222,     0.1220,     0.0956],\n",
      "        [    0.0992,     0.0649,     0.0222,     0.0060],\n",
      "        [    0.0487,     0.0489,     0.0355,     0.0471],\n",
      "        [    0.1339,     0.1508,     0.1073,     0.0241],\n",
      "        [    0.1585,     0.1382,     0.1555,     0.1039],\n",
      "        [    0.0326,     0.0489,     0.0270,     0.0037],\n",
      "        [    0.1147,     0.0947,     0.0601,     0.0182],\n",
      "        [    0.0031,     0.0067,     0.0078,     0.0128],\n",
      "        [    0.1624,     0.1627,     0.1429,     0.1490],\n",
      "        [    0.0408,     0.0686,     0.0193,     0.0196],\n",
      "        [    0.0766,     0.0287,     0.0243,     0.0279],\n",
      "        [    0.0123,     0.0374,     0.0538,     0.0524],\n",
      "        [    0.0110,     0.0280,     0.0077,     0.0272],\n",
      "        [    0.0155,     0.0192,     0.1028,     0.1690],\n",
      "        [    0.0471,     0.0152,     0.0327,     0.0107],\n",
      "        [    0.0237,     0.0029,     0.0328,     0.0117],\n",
      "        [    0.0141,     0.0428,     0.0200,     0.0341],\n",
      "        [    0.0013,     0.0376,     0.0162,     0.0157],\n",
      "        [    0.0418,     0.0210,     0.0205,     0.0142],\n",
      "        [    0.1421,     0.0981,     0.0341,     0.0935],\n",
      "        [    0.0381,     0.0209,     0.0003,     0.0252],\n",
      "        [    0.0238,     0.0192,     0.0378,     0.0526],\n",
      "        [    0.0035,     0.0380,     0.0160,     0.0040],\n",
      "        [    0.0423,     0.0207,     0.0081,     0.0241],\n",
      "        [    0.0250,     0.0128,     0.0220,     0.0012],\n",
      "        [    0.0000,     0.0209,     0.0495,     0.0845],\n",
      "        [    0.0023,     0.0304,     0.0724,     0.0472],\n",
      "        [    0.0130,     0.0362,     0.0650,     0.0025],\n",
      "        [    0.0252,     0.0253,     0.0190,     0.0085],\n",
      "        [    0.1395,     0.0113,     0.0240,     0.0998],\n",
      "        [    0.0430,     0.0146,     0.0340,     0.0423],\n",
      "        [    0.0377,     0.0320,     0.0031,     0.0422],\n",
      "        [    0.0656,     0.0320,     0.0554,     0.0782],\n",
      "        [    0.0386,     0.1040,     0.0931,     0.0495],\n",
      "        [    0.1083,     0.0978,     0.0566,     0.0939],\n",
      "        [    0.1021,     0.0613,     0.1041,     0.1159],\n",
      "        [    0.0916,     0.0443,     0.0344,     0.0503],\n",
      "        [    0.0346,     0.0563,     0.0529,     0.0600],\n",
      "        [    0.2014,     0.1352,     0.0065,     0.0260],\n",
      "        [    0.0362,     0.0972,     0.1636,     0.1426],\n",
      "        [    0.1158,     0.1064,     0.1302,     0.1147]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 33\n",
      "Number of shrink: 24\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0621,     0.0092,     0.0328,     0.0034],\n",
      "        [    0.0122,     0.0116,     0.0232,     0.0230],\n",
      "        [    0.0165,     0.0176,     0.0243,     0.0153],\n",
      "        [    0.0323,     0.0100,     0.0040,     0.0200],\n",
      "        [    0.0412,     0.0282,     0.0479,     0.0226],\n",
      "        [    0.0476,     0.0680,     0.0397,     0.0015],\n",
      "        [    0.0934,     0.0658,     0.0209,     0.0034],\n",
      "        [    0.0851,     0.0405,     0.0133,     0.0169],\n",
      "        [    0.0438,     0.0167,     0.0168,     0.0279],\n",
      "        [    0.0168,     0.0168,     0.0316,     0.0306],\n",
      "        [    0.0255,     0.0405,     0.0436,     0.0320],\n",
      "        [    0.0362,     0.0392,     0.0317,     0.0097],\n",
      "        [    0.0404,     0.0329,     0.0134,     0.0115],\n",
      "        [    0.0276,     0.0080,     0.0162,     0.0283],\n",
      "        [    0.0538,     0.0304,     0.0184,     0.0609],\n",
      "        [    0.0850,     0.0736,     0.0059,     0.0631],\n",
      "        [    0.1039,     0.0243,     0.0318,     0.0411],\n",
      "        [    0.0083,     0.0486,     0.0551,     0.0427],\n",
      "        [    0.0009,     0.0054,     0.0103,     0.0217],\n",
      "        [    0.0425,     0.0581,     0.0325,     0.0692],\n",
      "        [    0.1149,     0.1331,     0.1333,     0.1058],\n",
      "        [    0.0990,     0.0648,     0.0225,     0.0061],\n",
      "        [    0.0499,     0.0500,     0.0355,     0.0476],\n",
      "        [    0.1324,     0.1492,     0.1057,     0.0257],\n",
      "        [    0.1569,     0.1366,     0.1540,     0.1024],\n",
      "        [    0.0311,     0.0474,     0.0263,     0.0047],\n",
      "        [    0.1159,     0.0960,     0.0618,     0.0195],\n",
      "        [    0.0009,     0.0044,     0.0045,     0.0155],\n",
      "        [    0.1609,     0.1612,     0.1414,     0.1475],\n",
      "        [    0.0465,     0.0743,     0.0260,     0.0254],\n",
      "        [    0.0825,     0.0347,     0.0312,     0.0339],\n",
      "        [    0.0255,     0.0508,     0.0680,     0.0652],\n",
      "        [    0.0094,     0.0264,     0.0061,     0.0288],\n",
      "        [    0.0170,     0.0177,     0.1013,     0.1675],\n",
      "        [    0.0486,     0.0137,     0.0312,     0.0091],\n",
      "        [    0.0222,     0.0014,     0.0344,     0.0132],\n",
      "        [    0.0156,     0.0443,     0.0184,     0.0326],\n",
      "        [    0.0029,     0.0391,     0.0178,     0.0172],\n",
      "        [    0.0434,     0.0225,     0.0221,     0.0158],\n",
      "        [    0.1450,     0.1010,     0.0311,     0.0909],\n",
      "        [    0.0398,     0.0226,     0.0023,     0.0236],\n",
      "        [    0.0246,     0.0184,     0.0364,     0.0516],\n",
      "        [    0.0020,     0.0396,     0.0175,     0.0056],\n",
      "        [    0.0438,     0.0222,     0.0096,     0.0225],\n",
      "        [    0.0265,     0.0144,     0.0204,     0.0028],\n",
      "        [    0.0001,     0.0209,     0.0492,     0.0844],\n",
      "        [    0.0025,     0.0307,     0.0724,     0.0474],\n",
      "        [    0.0087,     0.0317,     0.0603,     0.0016],\n",
      "        [    0.0268,     0.0268,     0.0205,     0.0070],\n",
      "        [    0.1410,     0.0128,     0.0224,     0.0982],\n",
      "        [    0.0295,     0.0009,     0.0481,     0.0551],\n",
      "        [    0.0311,     0.0252,     0.0038,     0.0484],\n",
      "        [    0.0608,     0.0271,     0.0501,     0.0736],\n",
      "        [    0.0401,     0.1055,     0.0946,     0.0510],\n",
      "        [    0.1098,     0.0994,     0.0581,     0.0955],\n",
      "        [    0.1036,     0.0629,     0.1057,     0.1174],\n",
      "        [    0.0610,     0.0132,     0.0023,     0.0210],\n",
      "        [    0.0024,     0.0188,     0.0142,     0.0247],\n",
      "        [    0.2030,     0.1367,     0.0081,     0.0244],\n",
      "        [    0.0444,     0.0889,     0.1548,     0.1347],\n",
      "        [    0.0806,     0.0707,     0.0931,     0.0809]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 19.657827854156494\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 62\n",
      "X 資料 torch.Size([45, 18])\n",
      "Y 資料 torch.Size([45, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.011752130463719368, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.6408, 0.6414, 0.6247, 0.5804])\n",
      "目前模型的Data torch.Size([62, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7858, 0.7837, 0.7820, 0.7254],\n",
      "        [0.8051, 0.8032, 0.8019, 0.7437],\n",
      "        [0.7983, 0.7964, 0.7949, 0.7372],\n",
      "        [0.8110, 0.8092, 0.8080, 0.7493],\n",
      "        [0.7781, 0.7759, 0.7740, 0.7181],\n",
      "        [0.7565, 0.7540, 0.7518, 0.6976],\n",
      "        [0.7285, 0.7257, 0.7229, 0.6711],\n",
      "        [0.7064, 0.7033, 0.7001, 0.6502],\n",
      "        [0.7000, 0.6968, 0.6935, 0.6441],\n",
      "        [0.6967, 0.6934, 0.6901, 0.6410],\n",
      "        [0.7022, 0.6990, 0.6958, 0.6462],\n",
      "        [0.6947, 0.6914, 0.6881, 0.6391],\n",
      "        [0.6926, 0.6893, 0.6859, 0.6371],\n",
      "        [0.6840, 0.6805, 0.6770, 0.6290],\n",
      "        [0.7264, 0.7235, 0.7207, 0.6691],\n",
      "        [0.7782, 0.7759, 0.7741, 0.7181],\n",
      "        [0.8062, 0.8043, 0.8030, 0.7447],\n",
      "        [0.7883, 0.7862, 0.7846, 0.7277],\n",
      "        [0.8358, 0.8343, 0.8335, 0.7727],\n",
      "        [0.8822, 0.8813, 0.8814, 0.8166],\n",
      "        [0.6511, 0.6472, 0.6431, 0.5978],\n",
      "        [0.6831, 0.6797, 0.6761, 0.6282],\n",
      "        [0.8430, 0.8417, 0.8410, 0.7796],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.7605, 0.7581, 0.7559, 0.7014],\n",
      "        [0.6895, 0.6862, 0.6827, 0.6342],\n",
      "        [0.7995, 0.7975, 0.7961, 0.7383],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.7768, 0.7745, 0.7727, 0.7168],\n",
      "        [0.7663, 0.7640, 0.7619, 0.7069],\n",
      "        [0.7182, 0.7152, 0.7123, 0.6614],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6588, 0.6551, 0.6511, 0.6051],\n",
      "        [0.7199, 0.7170, 0.7141, 0.6630],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6778, 0.6743, 0.6706, 0.6231],\n",
      "        [0.6559, 0.6521, 0.6480, 0.6024],\n",
      "        [0.6396, 0.6356, 0.6312, 0.5869],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6617, 0.6579, 0.6540, 0.6078],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6753, 0.6717, 0.6680, 0.6207],\n",
      "        [0.6632, 0.6595, 0.6556, 0.6093],\n",
      "        [0.6195, 0.6152, 0.6105, 0.5679],\n",
      "        [0.6718, 0.6682, 0.6644, 0.6174],\n",
      "        [0.7391, 0.7364, 0.7338, 0.6811],\n",
      "        [0.7466, 0.7440, 0.7415, 0.6882]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0621,     0.0092,     0.0328,     0.0034],\n",
      "        [    0.0122,     0.0116,     0.0232,     0.0230],\n",
      "        [    0.0165,     0.0176,     0.0243,     0.0153],\n",
      "        [    0.0323,     0.0100,     0.0040,     0.0200],\n",
      "        [    0.0412,     0.0282,     0.0479,     0.0226],\n",
      "        [    0.0476,     0.0680,     0.0397,     0.0015],\n",
      "        [    0.0934,     0.0658,     0.0209,     0.0034],\n",
      "        [    0.0851,     0.0405,     0.0133,     0.0169],\n",
      "        [    0.0438,     0.0167,     0.0168,     0.0279],\n",
      "        [    0.0168,     0.0168,     0.0316,     0.0306],\n",
      "        [    0.0255,     0.0405,     0.0436,     0.0320],\n",
      "        [    0.0362,     0.0392,     0.0317,     0.0097],\n",
      "        [    0.0404,     0.0329,     0.0134,     0.0115],\n",
      "        [    0.0276,     0.0080,     0.0162,     0.0283],\n",
      "        [    0.0538,     0.0304,     0.0184,     0.0609],\n",
      "        [    0.0850,     0.0736,     0.0059,     0.0631],\n",
      "        [    0.1039,     0.0243,     0.0318,     0.0411],\n",
      "        [    0.0083,     0.0486,     0.0551,     0.0427],\n",
      "        [    0.0009,     0.0054,     0.0103,     0.0217],\n",
      "        [    0.0425,     0.0581,     0.0325,     0.0692],\n",
      "        [    0.1149,     0.1331,     0.1333,     0.1058],\n",
      "        [    0.0990,     0.0648,     0.0225,     0.0061],\n",
      "        [    0.0499,     0.0500,     0.0355,     0.0476],\n",
      "        [    0.1324,     0.1492,     0.1057,     0.0257],\n",
      "        [    0.1569,     0.1366,     0.1540,     0.1024],\n",
      "        [    0.0311,     0.0474,     0.0263,     0.0047],\n",
      "        [    0.1159,     0.0960,     0.0618,     0.0195],\n",
      "        [    0.0009,     0.0044,     0.0045,     0.0155],\n",
      "        [    0.1609,     0.1612,     0.1414,     0.1475],\n",
      "        [    0.0465,     0.0743,     0.0260,     0.0254],\n",
      "        [    0.0825,     0.0347,     0.0312,     0.0339],\n",
      "        [    0.0255,     0.0508,     0.0680,     0.0652],\n",
      "        [    0.0094,     0.0264,     0.0061,     0.0288],\n",
      "        [    0.0170,     0.0177,     0.1013,     0.1675],\n",
      "        [    0.0486,     0.0137,     0.0312,     0.0091],\n",
      "        [    0.0222,     0.0014,     0.0344,     0.0132],\n",
      "        [    0.0156,     0.0443,     0.0184,     0.0326],\n",
      "        [    0.0029,     0.0391,     0.0178,     0.0172],\n",
      "        [    0.0434,     0.0225,     0.0221,     0.0158],\n",
      "        [    0.1450,     0.1010,     0.0311,     0.0909],\n",
      "        [    0.0398,     0.0226,     0.0023,     0.0236],\n",
      "        [    0.0246,     0.0184,     0.0364,     0.0516],\n",
      "        [    0.0020,     0.0396,     0.0175,     0.0056],\n",
      "        [    0.0438,     0.0222,     0.0096,     0.0225],\n",
      "        [    0.0265,     0.0144,     0.0204,     0.0028],\n",
      "        [    0.0001,     0.0209,     0.0492,     0.0844],\n",
      "        [    0.0025,     0.0307,     0.0724,     0.0474],\n",
      "        [    0.0087,     0.0317,     0.0603,     0.0016],\n",
      "        [    0.0268,     0.0268,     0.0205,     0.0070],\n",
      "        [    0.1410,     0.0128,     0.0224,     0.0982],\n",
      "        [    0.0295,     0.0009,     0.0481,     0.0551],\n",
      "        [    0.0311,     0.0252,     0.0038,     0.0484],\n",
      "        [    0.0608,     0.0271,     0.0501,     0.0736],\n",
      "        [    0.0401,     0.1055,     0.0946,     0.0510],\n",
      "        [    0.1098,     0.0994,     0.0581,     0.0955],\n",
      "        [    0.1036,     0.0629,     0.1057,     0.1174],\n",
      "        [    0.0610,     0.0132,     0.0023,     0.0210],\n",
      "        [    0.0024,     0.0188,     0.0142,     0.0247],\n",
      "        [    0.2030,     0.1367,     0.0081,     0.0244],\n",
      "        [    0.0444,     0.0889,     0.1548,     0.1347],\n",
      "        [    0.0806,     0.0707,     0.0931,     0.0809],\n",
      "        [    0.1058,     0.1026,     0.1169,     0.1079]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 34\n",
      "Number of shrink: 24\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0634,     0.0099,     0.0342,     0.0046],\n",
      "        [    0.0121,     0.0109,     0.0230,     0.0230],\n",
      "        [    0.0168,     0.0180,     0.0247,     0.0154],\n",
      "        [    0.0315,     0.0101,     0.0031,     0.0206],\n",
      "        [    0.0412,     0.0276,     0.0480,     0.0225],\n",
      "        [    0.0464,     0.0662,     0.0385,     0.0027],\n",
      "        [    0.0951,     0.0671,     0.0227,     0.0019],\n",
      "        [    0.0858,     0.0409,     0.0141,     0.0164],\n",
      "        [    0.0439,     0.0165,     0.0167,     0.0279],\n",
      "        [    0.0166,     0.0172,     0.0317,     0.0309],\n",
      "        [    0.0279,     0.0433,     0.0460,     0.0343],\n",
      "        [    0.0384,     0.0417,     0.0339,     0.0119],\n",
      "        [    0.0426,     0.0355,     0.0156,     0.0093],\n",
      "        [    0.0291,     0.0098,     0.0146,     0.0268],\n",
      "        [    0.0535,     0.0304,     0.0180,     0.0611],\n",
      "        [    0.0848,     0.0741,     0.0061,     0.0632],\n",
      "        [    0.1040,     0.0252,     0.0317,     0.0409],\n",
      "        [    0.0078,     0.0484,     0.0557,     0.0430],\n",
      "        [    0.0001,     0.0056,     0.0091,     0.0226],\n",
      "        [    0.0386,     0.0552,     0.0285,     0.0657],\n",
      "        [    0.1195,     0.1377,     0.1381,     0.1101],\n",
      "        [    0.0955,     0.0610,     0.0189,     0.0026],\n",
      "        [    0.0539,     0.0550,     0.0396,     0.0515],\n",
      "        [    0.1310,     0.1479,     0.1044,     0.0270],\n",
      "        [    0.1556,     0.1353,     0.1526,     0.1010],\n",
      "        [    0.0267,     0.0424,     0.0217,     0.0089],\n",
      "        [    0.1142,     0.0939,     0.0600,     0.0178],\n",
      "        [    0.0016,     0.0059,     0.0052,     0.0147],\n",
      "        [    0.1595,     0.1598,     0.1400,     0.1462],\n",
      "        [    0.0494,     0.0767,     0.0290,     0.0281],\n",
      "        [    0.0854,     0.0370,     0.0342,     0.0365],\n",
      "        [    0.0321,     0.0571,     0.0749,     0.0714],\n",
      "        [    0.0081,     0.0251,     0.0048,     0.0301],\n",
      "        [    0.0184,     0.0163,     0.0999,     0.1661],\n",
      "        [    0.0500,     0.0123,     0.0298,     0.0078],\n",
      "        [    0.0208,     0.0000,     0.0357,     0.0146],\n",
      "        [    0.0170,     0.0457,     0.0171,     0.0312],\n",
      "        [    0.0042,     0.0405,     0.0191,     0.0186],\n",
      "        [    0.0447,     0.0239,     0.0234,     0.0171],\n",
      "        [    0.1436,     0.0996,     0.0324,     0.0923],\n",
      "        [    0.0383,     0.0210,     0.0009,     0.0250],\n",
      "        [    0.0223,     0.0211,     0.0387,     0.0538],\n",
      "        [    0.0006,     0.0409,     0.0188,     0.0069],\n",
      "        [    0.0452,     0.0236,     0.0110,     0.0212],\n",
      "        [    0.0278,     0.0157,     0.0191,     0.0041],\n",
      "        [    0.0029,     0.0239,     0.0520,     0.0871],\n",
      "        [    0.0057,     0.0340,     0.0756,     0.0505],\n",
      "        [    0.0074,     0.0305,     0.0590,     0.0028],\n",
      "        [    0.0281,     0.0282,     0.0219,     0.0057],\n",
      "        [    0.1423,     0.0141,     0.0211,     0.0969],\n",
      "        [    0.0308,     0.0023,     0.0467,     0.0537],\n",
      "        [    0.0324,     0.0266,     0.0025,     0.0470],\n",
      "        [    0.0588,     0.0251,     0.0480,     0.0717],\n",
      "        [    0.0414,     0.1069,     0.0960,     0.0523],\n",
      "        [    0.1111,     0.1007,     0.0595,     0.0968],\n",
      "        [    0.1050,     0.0642,     0.1070,     0.1188],\n",
      "        [    0.0363,     0.0117,     0.0231,     0.0022],\n",
      "        [    0.0331,     0.0122,     0.0174,     0.0042],\n",
      "        [    0.2043,     0.1381,     0.0094,     0.0231],\n",
      "        [    0.0481,     0.0853,     0.1509,     0.1313],\n",
      "        [    0.0520,     0.0421,     0.0635,     0.0539],\n",
      "        [    0.0692,     0.0658,     0.0790,     0.0732]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 20.357112646102905\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 63\n",
      "X 資料 torch.Size([44, 18])\n",
      "Y 資料 torch.Size([44, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.012118581682443619, 9)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引9，y= tensor([0.6465, 0.7437, 0.7660, 0.7302])\n",
      "目前模型的Data torch.Size([63, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7844, 0.7830, 0.7806, 0.7242],\n",
      "        [0.8050, 0.8039, 0.8017, 0.7436],\n",
      "        [0.7980, 0.7968, 0.7946, 0.7370],\n",
      "        [0.8102, 0.8092, 0.8071, 0.7486],\n",
      "        [0.7781, 0.7765, 0.7740, 0.7181],\n",
      "        [0.7576, 0.7557, 0.7529, 0.6988],\n",
      "        [0.7268, 0.7244, 0.7211, 0.6696],\n",
      "        [0.7057, 0.7029, 0.6994, 0.6496],\n",
      "        [0.6999, 0.6970, 0.6934, 0.6441],\n",
      "        [0.6968, 0.6939, 0.6902, 0.6412],\n",
      "        [0.7046, 0.7018, 0.6982, 0.6486],\n",
      "        [0.6969, 0.6939, 0.6903, 0.6413],\n",
      "        [0.6949, 0.6919, 0.6882, 0.6394],\n",
      "        [0.6855, 0.6823, 0.6785, 0.6305],\n",
      "        [0.7260, 0.7235, 0.7203, 0.6688],\n",
      "        [0.7780, 0.7764, 0.7739, 0.7181],\n",
      "        [0.8063, 0.8052, 0.8031, 0.7449],\n",
      "        [0.7878, 0.7864, 0.7840, 0.7274],\n",
      "        [0.8347, 0.8341, 0.8324, 0.7718],\n",
      "        [0.8783, 0.8784, 0.8773, 0.8131],\n",
      "        [0.6465, 0.6426, 0.6383, 0.5935],\n",
      "        [0.6866, 0.6835, 0.6797, 0.6316],\n",
      "        [0.8471, 0.8467, 0.8451, 0.7835],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.7649, 0.7631, 0.7604, 0.7057],\n",
      "        [0.6913, 0.6882, 0.6845, 0.6360],\n",
      "        [0.8002, 0.7990, 0.7968, 0.7391],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.7738, 0.7722, 0.7696, 0.7141],\n",
      "        [0.7634, 0.7616, 0.7589, 0.7043],\n",
      "        [0.7116, 0.7089, 0.7054, 0.6552],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6602, 0.6567, 0.6525, 0.6066],\n",
      "        [0.7222, 0.7197, 0.7164, 0.6653],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6805, 0.6773, 0.6734, 0.6258],\n",
      "        [0.6590, 0.6554, 0.6512, 0.6054],\n",
      "        [0.6383, 0.6343, 0.6298, 0.5857],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6596, 0.6560, 0.6518, 0.6060],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6506, 0.6469, 0.6425, 0.5974],\n",
      "        [0.6326, 0.6286, 0.6240, 0.5804],\n",
      "        [0.6208, 0.6165, 0.6118, 0.5692],\n",
      "        [0.6681, 0.6646, 0.6606, 0.6140],\n",
      "        [0.7105, 0.7078, 0.7043, 0.6541],\n",
      "        [0.7099, 0.7072, 0.7037, 0.6536],\n",
      "        [0.8331, 0.8324, 0.8307, 0.7702]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0634,     0.0099,     0.0342,     0.0046],\n",
      "        [    0.0121,     0.0109,     0.0230,     0.0230],\n",
      "        [    0.0168,     0.0180,     0.0247,     0.0154],\n",
      "        [    0.0315,     0.0101,     0.0031,     0.0206],\n",
      "        [    0.0412,     0.0276,     0.0480,     0.0225],\n",
      "        [    0.0464,     0.0662,     0.0385,     0.0027],\n",
      "        [    0.0951,     0.0671,     0.0227,     0.0019],\n",
      "        [    0.0858,     0.0409,     0.0141,     0.0164],\n",
      "        [    0.0439,     0.0165,     0.0167,     0.0279],\n",
      "        [    0.0166,     0.0172,     0.0317,     0.0309],\n",
      "        [    0.0279,     0.0433,     0.0460,     0.0343],\n",
      "        [    0.0384,     0.0417,     0.0339,     0.0119],\n",
      "        [    0.0426,     0.0355,     0.0156,     0.0093],\n",
      "        [    0.0291,     0.0098,     0.0146,     0.0268],\n",
      "        [    0.0535,     0.0304,     0.0180,     0.0611],\n",
      "        [    0.0848,     0.0741,     0.0061,     0.0632],\n",
      "        [    0.1040,     0.0252,     0.0317,     0.0409],\n",
      "        [    0.0078,     0.0484,     0.0557,     0.0430],\n",
      "        [    0.0001,     0.0056,     0.0091,     0.0226],\n",
      "        [    0.0386,     0.0552,     0.0285,     0.0657],\n",
      "        [    0.1195,     0.1377,     0.1381,     0.1101],\n",
      "        [    0.0955,     0.0610,     0.0189,     0.0026],\n",
      "        [    0.0539,     0.0550,     0.0396,     0.0515],\n",
      "        [    0.1310,     0.1479,     0.1044,     0.0270],\n",
      "        [    0.1556,     0.1353,     0.1526,     0.1010],\n",
      "        [    0.0267,     0.0424,     0.0217,     0.0089],\n",
      "        [    0.1142,     0.0939,     0.0600,     0.0178],\n",
      "        [    0.0016,     0.0059,     0.0052,     0.0147],\n",
      "        [    0.1595,     0.1598,     0.1400,     0.1462],\n",
      "        [    0.0494,     0.0767,     0.0290,     0.0281],\n",
      "        [    0.0854,     0.0370,     0.0342,     0.0365],\n",
      "        [    0.0321,     0.0571,     0.0749,     0.0714],\n",
      "        [    0.0081,     0.0251,     0.0048,     0.0301],\n",
      "        [    0.0184,     0.0163,     0.0999,     0.1661],\n",
      "        [    0.0500,     0.0123,     0.0298,     0.0078],\n",
      "        [    0.0208,     0.0000,     0.0357,     0.0146],\n",
      "        [    0.0170,     0.0457,     0.0171,     0.0312],\n",
      "        [    0.0042,     0.0405,     0.0191,     0.0186],\n",
      "        [    0.0447,     0.0239,     0.0234,     0.0171],\n",
      "        [    0.1436,     0.0996,     0.0324,     0.0923],\n",
      "        [    0.0383,     0.0210,     0.0009,     0.0250],\n",
      "        [    0.0223,     0.0211,     0.0387,     0.0538],\n",
      "        [    0.0006,     0.0409,     0.0188,     0.0069],\n",
      "        [    0.0452,     0.0236,     0.0110,     0.0212],\n",
      "        [    0.0278,     0.0157,     0.0191,     0.0041],\n",
      "        [    0.0029,     0.0239,     0.0520,     0.0871],\n",
      "        [    0.0057,     0.0340,     0.0756,     0.0505],\n",
      "        [    0.0074,     0.0305,     0.0590,     0.0028],\n",
      "        [    0.0281,     0.0282,     0.0219,     0.0057],\n",
      "        [    0.1423,     0.0141,     0.0211,     0.0969],\n",
      "        [    0.0308,     0.0023,     0.0467,     0.0537],\n",
      "        [    0.0324,     0.0266,     0.0025,     0.0470],\n",
      "        [    0.0588,     0.0251,     0.0480,     0.0717],\n",
      "        [    0.0414,     0.1069,     0.0960,     0.0523],\n",
      "        [    0.1111,     0.1007,     0.0595,     0.0968],\n",
      "        [    0.1050,     0.0642,     0.1070,     0.1188],\n",
      "        [    0.0363,     0.0117,     0.0231,     0.0022],\n",
      "        [    0.0331,     0.0122,     0.0174,     0.0042],\n",
      "        [    0.2043,     0.1381,     0.0094,     0.0231],\n",
      "        [    0.0481,     0.0853,     0.1509,     0.1313],\n",
      "        [    0.0520,     0.0421,     0.0635,     0.0539],\n",
      "        [    0.0692,     0.0658,     0.0790,     0.0732],\n",
      "        [    0.1866,     0.0888,     0.0647,     0.0400]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 38\n",
      "Number of shrink: 26\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0695,     0.0117,     0.0347,     0.0039],\n",
      "        [    0.0052,     0.0130,     0.0223,     0.0225],\n",
      "        [    0.0239,     0.0155,     0.0258,     0.0153],\n",
      "        [    0.0230,     0.0137,     0.0008,     0.0215],\n",
      "        [    0.0473,     0.0297,     0.0487,     0.0222],\n",
      "        [    0.0492,     0.0654,     0.0364,     0.0057],\n",
      "        [    0.0970,     0.0662,     0.0205,     0.0047],\n",
      "        [    0.0853,     0.0381,     0.0101,     0.0207],\n",
      "        [    0.0436,     0.0140,     0.0204,     0.0319],\n",
      "        [    0.0162,     0.0197,     0.0355,     0.0349],\n",
      "        [    0.0291,     0.0468,     0.0508,     0.0394],\n",
      "        [    0.0395,     0.0450,     0.0384,     0.0167],\n",
      "        [    0.0441,     0.0391,     0.0205,     0.0043],\n",
      "        [    0.0308,     0.0133,     0.0099,     0.0219],\n",
      "        [    0.0517,     0.0315,     0.0203,     0.0582],\n",
      "        [    0.0795,     0.0728,     0.0061,     0.0621],\n",
      "        [    0.0966,     0.0226,     0.0329,     0.0408],\n",
      "        [    0.0015,     0.0504,     0.0563,     0.0425],\n",
      "        [    0.0099,     0.0099,     0.0063,     0.0239],\n",
      "        [    0.0243,     0.0474,     0.0222,     0.0615],\n",
      "        [    0.1254,     0.1432,     0.1426,     0.1140],\n",
      "        [    0.0951,     0.0588,     0.0154,     0.0011],\n",
      "        [    0.0435,     0.0504,     0.0365,     0.0500],\n",
      "        [    0.1303,     0.1471,     0.1026,     0.0288],\n",
      "        [    0.1548,     0.1345,     0.1508,     0.0992],\n",
      "        [    0.0316,     0.0435,     0.0215,     0.0101],\n",
      "        [    0.1156,     0.0935,     0.0584,     0.0157],\n",
      "        [    0.0066,     0.0023,     0.0030,     0.0156],\n",
      "        [    0.1587,     0.1591,     0.1382,     0.1444],\n",
      "        [    0.0562,     0.0796,     0.0306,     0.0285],\n",
      "        [    0.0929,     0.0409,     0.0368,     0.0379],\n",
      "        [    0.0443,     0.0674,     0.0841,     0.0792],\n",
      "        [    0.0073,     0.0243,     0.0030,     0.0319],\n",
      "        [    0.0192,     0.0156,     0.0982,     0.1643],\n",
      "        [    0.0507,     0.0116,     0.0280,     0.0060],\n",
      "        [    0.0201,     0.0007,     0.0375,     0.0164],\n",
      "        [    0.0177,     0.0465,     0.0153,     0.0294],\n",
      "        [    0.0050,     0.0412,     0.0209,     0.0204],\n",
      "        [    0.0455,     0.0246,     0.0252,     0.0189],\n",
      "        [    0.1429,     0.0989,     0.0342,     0.0941],\n",
      "        [    0.0385,     0.0201,     0.0011,     0.0272],\n",
      "        [    0.0255,     0.0206,     0.0394,     0.0552],\n",
      "        [    0.0001,     0.0417,     0.0206,     0.0087],\n",
      "        [    0.0459,     0.0244,     0.0127,     0.0194],\n",
      "        [    0.0286,     0.0165,     0.0173,     0.0059],\n",
      "        [    0.0024,     0.0251,     0.0543,     0.0897],\n",
      "        [    0.0075,     0.0369,     0.0797,     0.0547],\n",
      "        [    0.0084,     0.0320,     0.0615,     0.0002],\n",
      "        [    0.0289,     0.0289,     0.0236,     0.0039],\n",
      "        [    0.1431,     0.0149,     0.0193,     0.0951],\n",
      "        [    0.0316,     0.0030,     0.0449,     0.0519],\n",
      "        [    0.0332,     0.0274,     0.0007,     0.0452],\n",
      "        [    0.0575,     0.0249,     0.0488,     0.0729],\n",
      "        [    0.0422,     0.1077,     0.0978,     0.0541],\n",
      "        [    0.1119,     0.1015,     0.0613,     0.0986],\n",
      "        [    0.1058,     0.0650,     0.1088,     0.1206],\n",
      "        [    0.0197,     0.0282,     0.0389,     0.0165],\n",
      "        [    0.0441,     0.0235,     0.0278,     0.0136],\n",
      "        [    0.2051,     0.1389,     0.0112,     0.0213],\n",
      "        [    0.0581,     0.0761,     0.1427,     0.1241],\n",
      "        [    0.0289,     0.0204,     0.0427,     0.0353],\n",
      "        [    0.0420,     0.0398,     0.0539,     0.0507],\n",
      "        [    0.1608,     0.0677,     0.0448,     0.0230]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 21.014506816864014\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 64\n",
      "X 資料 torch.Size([43, 18])\n",
      "Y 資料 torch.Size([43, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.018050577491521835, 7)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引7，y= tensor([0.6305, 0.6469, 0.6465, 0.6960])\n",
      "目前模型的Data torch.Size([64, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7784, 0.7812, 0.7801, 0.7249],\n",
      "        [0.7981, 0.8018, 0.8011, 0.7442],\n",
      "        [0.7909, 0.7942, 0.7934, 0.7371],\n",
      "        [0.8017, 0.8055, 0.8049, 0.7477],\n",
      "        [0.7719, 0.7744, 0.7733, 0.7185],\n",
      "        [0.7548, 0.7565, 0.7551, 0.7017],\n",
      "        [0.7249, 0.7253, 0.7233, 0.6724],\n",
      "        [0.7062, 0.7057, 0.7034, 0.6540],\n",
      "        [0.7002, 0.6995, 0.6971, 0.6482],\n",
      "        [0.6973, 0.6964, 0.6940, 0.6453],\n",
      "        [0.7058, 0.7053, 0.7030, 0.6536],\n",
      "        [0.6981, 0.6972, 0.6948, 0.6460],\n",
      "        [0.6964, 0.6954, 0.6930, 0.6444],\n",
      "        [0.6872, 0.6859, 0.6832, 0.6354],\n",
      "        [0.7243, 0.7246, 0.7226, 0.6718],\n",
      "        [0.7726, 0.7751, 0.7740, 0.7192],\n",
      "        [0.7990, 0.8026, 0.8020, 0.7450],\n",
      "        [0.7815, 0.7844, 0.7834, 0.7279],\n",
      "        [0.8249, 0.8298, 0.8295, 0.7705],\n",
      "        [0.8640, 0.8706, 0.8710, 0.8088],\n",
      "        [0.6406, 0.6371, 0.6337, 0.5896],\n",
      "        [0.6871, 0.6857, 0.6831, 0.6353],\n",
      "        [0.8366, 0.8420, 0.8420, 0.7820],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.7600, 0.7620, 0.7606, 0.7069],\n",
      "        [0.6899, 0.6887, 0.6861, 0.6380],\n",
      "        [0.7920, 0.7954, 0.7946, 0.7382],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.7670, 0.7693, 0.7680, 0.7137],\n",
      "        [0.7560, 0.7578, 0.7564, 0.7029],\n",
      "        [0.6994, 0.6986, 0.6962, 0.6473],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6601, 0.6575, 0.6545, 0.6088],\n",
      "        [0.7191, 0.7192, 0.7171, 0.6667],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6801, 0.6784, 0.6757, 0.6284],\n",
      "        [0.6609, 0.6584, 0.6553, 0.6096],\n",
      "        [0.6393, 0.6358, 0.6324, 0.5884],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6584, 0.6557, 0.6526, 0.6071],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6340, 0.6303, 0.6267, 0.5832],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6216, 0.6173, 0.6136, 0.5710],\n",
      "        [0.6580, 0.6554, 0.6523, 0.6068],\n",
      "        [0.6874, 0.6861, 0.6835, 0.6356],\n",
      "        [0.6827, 0.6812, 0.6785, 0.6310],\n",
      "        [0.8073, 0.8114, 0.8108, 0.7532],\n",
      "        [0.7923, 0.7957, 0.7949, 0.7385]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0695,     0.0117,     0.0347,     0.0039],\n",
      "        [    0.0052,     0.0130,     0.0223,     0.0225],\n",
      "        [    0.0239,     0.0155,     0.0258,     0.0153],\n",
      "        [    0.0230,     0.0137,     0.0008,     0.0215],\n",
      "        [    0.0473,     0.0297,     0.0487,     0.0222],\n",
      "        [    0.0492,     0.0654,     0.0364,     0.0057],\n",
      "        [    0.0970,     0.0662,     0.0205,     0.0047],\n",
      "        [    0.0853,     0.0381,     0.0101,     0.0207],\n",
      "        [    0.0436,     0.0140,     0.0204,     0.0319],\n",
      "        [    0.0162,     0.0197,     0.0355,     0.0349],\n",
      "        [    0.0291,     0.0468,     0.0508,     0.0394],\n",
      "        [    0.0395,     0.0450,     0.0384,     0.0167],\n",
      "        [    0.0441,     0.0391,     0.0205,     0.0043],\n",
      "        [    0.0308,     0.0133,     0.0099,     0.0219],\n",
      "        [    0.0517,     0.0315,     0.0203,     0.0582],\n",
      "        [    0.0795,     0.0728,     0.0061,     0.0621],\n",
      "        [    0.0966,     0.0226,     0.0329,     0.0408],\n",
      "        [    0.0015,     0.0504,     0.0563,     0.0425],\n",
      "        [    0.0099,     0.0099,     0.0063,     0.0239],\n",
      "        [    0.0243,     0.0474,     0.0222,     0.0615],\n",
      "        [    0.1254,     0.1432,     0.1426,     0.1140],\n",
      "        [    0.0951,     0.0588,     0.0154,     0.0011],\n",
      "        [    0.0435,     0.0504,     0.0365,     0.0500],\n",
      "        [    0.1303,     0.1471,     0.1026,     0.0288],\n",
      "        [    0.1548,     0.1345,     0.1508,     0.0992],\n",
      "        [    0.0316,     0.0435,     0.0215,     0.0101],\n",
      "        [    0.1156,     0.0935,     0.0584,     0.0157],\n",
      "        [    0.0066,     0.0023,     0.0030,     0.0156],\n",
      "        [    0.1587,     0.1591,     0.1382,     0.1444],\n",
      "        [    0.0562,     0.0796,     0.0306,     0.0285],\n",
      "        [    0.0929,     0.0409,     0.0368,     0.0379],\n",
      "        [    0.0443,     0.0674,     0.0841,     0.0792],\n",
      "        [    0.0073,     0.0243,     0.0030,     0.0319],\n",
      "        [    0.0192,     0.0156,     0.0982,     0.1643],\n",
      "        [    0.0507,     0.0116,     0.0280,     0.0060],\n",
      "        [    0.0201,     0.0007,     0.0375,     0.0164],\n",
      "        [    0.0177,     0.0465,     0.0153,     0.0294],\n",
      "        [    0.0050,     0.0412,     0.0209,     0.0204],\n",
      "        [    0.0455,     0.0246,     0.0252,     0.0189],\n",
      "        [    0.1429,     0.0989,     0.0342,     0.0941],\n",
      "        [    0.0385,     0.0201,     0.0011,     0.0272],\n",
      "        [    0.0255,     0.0206,     0.0394,     0.0552],\n",
      "        [    0.0001,     0.0417,     0.0206,     0.0087],\n",
      "        [    0.0459,     0.0244,     0.0127,     0.0194],\n",
      "        [    0.0286,     0.0165,     0.0173,     0.0059],\n",
      "        [    0.0024,     0.0251,     0.0543,     0.0897],\n",
      "        [    0.0075,     0.0369,     0.0797,     0.0547],\n",
      "        [    0.0084,     0.0320,     0.0615,     0.0002],\n",
      "        [    0.0289,     0.0289,     0.0236,     0.0039],\n",
      "        [    0.1431,     0.0149,     0.0193,     0.0951],\n",
      "        [    0.0316,     0.0030,     0.0449,     0.0519],\n",
      "        [    0.0332,     0.0274,     0.0007,     0.0452],\n",
      "        [    0.0575,     0.0249,     0.0488,     0.0729],\n",
      "        [    0.0422,     0.1077,     0.0978,     0.0541],\n",
      "        [    0.1119,     0.1015,     0.0613,     0.0986],\n",
      "        [    0.1058,     0.0650,     0.1088,     0.1206],\n",
      "        [    0.0197,     0.0282,     0.0389,     0.0165],\n",
      "        [    0.0441,     0.0235,     0.0278,     0.0136],\n",
      "        [    0.2051,     0.1389,     0.0112,     0.0213],\n",
      "        [    0.0581,     0.0761,     0.1427,     0.1241],\n",
      "        [    0.0289,     0.0204,     0.0427,     0.0353],\n",
      "        [    0.0420,     0.0398,     0.0539,     0.0507],\n",
      "        [    0.1608,     0.0677,     0.0448,     0.0230],\n",
      "        [    0.1619,     0.1488,     0.1484,     0.0426]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 38\n",
      "Number of shrink: 26\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0736, 0.0158, 0.0387, 0.0042],\n",
      "        [0.0011, 0.0171, 0.0183, 0.0223],\n",
      "        [0.0287, 0.0108, 0.0305, 0.0160],\n",
      "        [0.0174, 0.0193, 0.0047, 0.0227],\n",
      "        [0.0512, 0.0335, 0.0525, 0.0224],\n",
      "        [0.0495, 0.0655, 0.0363, 0.0087],\n",
      "        [0.0970, 0.0660, 0.0203, 0.0073],\n",
      "        [0.0832, 0.0358, 0.0077, 0.0249],\n",
      "        [0.0414, 0.0116, 0.0229, 0.0361],\n",
      "        [0.0140, 0.0221, 0.0379, 0.0390],\n",
      "        [0.0332, 0.0512, 0.0554, 0.0456],\n",
      "        [0.0431, 0.0488, 0.0423, 0.0221],\n",
      "        [0.0479, 0.0431, 0.0246, 0.0013],\n",
      "        [0.0348, 0.0176, 0.0055, 0.0162],\n",
      "        [0.0532, 0.0332, 0.0221, 0.0542],\n",
      "        [0.0782, 0.0718, 0.0070, 0.0596],\n",
      "        [0.0936, 0.0198, 0.0357, 0.0395],\n",
      "        [0.0007, 0.0525, 0.0583, 0.0408],\n",
      "        [0.0142, 0.0141, 0.0022, 0.0232],\n",
      "        [0.0156, 0.0387, 0.0135, 0.0587],\n",
      "        [0.1335, 0.1516, 0.1513, 0.1216],\n",
      "        [0.0931, 0.0566, 0.0132, 0.0047],\n",
      "        [0.0374, 0.0443, 0.0305, 0.0492],\n",
      "        [0.1292, 0.1461, 0.1016, 0.0298],\n",
      "        [0.1538, 0.1335, 0.1498, 0.0982],\n",
      "        [0.0334, 0.0452, 0.0232, 0.0117],\n",
      "        [0.1156, 0.0934, 0.0583, 0.0141],\n",
      "        [0.0103, 0.0014, 0.0006, 0.0152],\n",
      "        [0.1577, 0.1580, 0.1372, 0.1434],\n",
      "        [0.0592, 0.0825, 0.0335, 0.0280],\n",
      "        [0.0966, 0.0445, 0.0404, 0.0383],\n",
      "        [0.0579, 0.0815, 0.0984, 0.0910],\n",
      "        [0.0063, 0.0233, 0.0020, 0.0329],\n",
      "        [0.0202, 0.0146, 0.0972, 0.1633],\n",
      "        [0.0517, 0.0106, 0.0270, 0.0050],\n",
      "        [0.0190, 0.0017, 0.0385, 0.0174],\n",
      "        [0.0187, 0.0475, 0.0143, 0.0284],\n",
      "        [0.0060, 0.0423, 0.0219, 0.0214],\n",
      "        [0.0465, 0.0257, 0.0262, 0.0199],\n",
      "        [0.1418, 0.0979, 0.0352, 0.0951],\n",
      "        [0.0383, 0.0199, 0.0014, 0.0284],\n",
      "        [0.0270, 0.0191, 0.0380, 0.0561],\n",
      "        [0.0011, 0.0427, 0.0216, 0.0097],\n",
      "        [0.0469, 0.0254, 0.0138, 0.0184],\n",
      "        [0.0296, 0.0175, 0.0163, 0.0069],\n",
      "        [0.0028, 0.0256, 0.0548, 0.0915],\n",
      "        [0.0103, 0.0399, 0.0827, 0.0584],\n",
      "        [0.0089, 0.0325, 0.0620, 0.0008],\n",
      "        [0.0299, 0.0299, 0.0246, 0.0028],\n",
      "        [0.1441, 0.0159, 0.0183, 0.0941],\n",
      "        [0.0326, 0.0040, 0.0439, 0.0509],\n",
      "        [0.0342, 0.0284, 0.0003, 0.0442],\n",
      "        [0.0559, 0.0232, 0.0472, 0.0722],\n",
      "        [0.0432, 0.1087, 0.0988, 0.0551],\n",
      "        [0.1129, 0.1025, 0.0623, 0.0996],\n",
      "        [0.1068, 0.0660, 0.1098, 0.1216],\n",
      "        [0.0083, 0.0402, 0.0511, 0.0276],\n",
      "        [0.0431, 0.0224, 0.0268, 0.0126],\n",
      "        [0.2061, 0.1399, 0.0122, 0.0203],\n",
      "        [0.0702, 0.0635, 0.1299, 0.1129],\n",
      "        [0.0047, 0.0048, 0.0171, 0.0126],\n",
      "        [0.0127, 0.0093, 0.0228, 0.0228],\n",
      "        [0.1350, 0.0410, 0.0178, 0.0016],\n",
      "        [0.1308, 0.1166, 0.1158, 0.0155]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 21.652699947357178\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 65\n",
      "X 資料 torch.Size([42, 18])\n",
      "Y 資料 torch.Size([42, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.012038636952638626, 7)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引7，y= tensor([0.6469, 0.6465, 0.7437, 0.7168])\n",
      "目前模型的Data torch.Size([65, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7742, 0.7771, 0.7761, 0.7245],\n",
      "        [0.7940, 0.7977, 0.7971, 0.7444],\n",
      "        [0.7861, 0.7895, 0.7887, 0.7365],\n",
      "        [0.7961, 0.8000, 0.7994, 0.7466],\n",
      "        [0.7680, 0.7705, 0.7694, 0.7183],\n",
      "        [0.7546, 0.7565, 0.7551, 0.7048],\n",
      "        [0.7249, 0.7254, 0.7236, 0.6750],\n",
      "        [0.7082, 0.7080, 0.7058, 0.6582],\n",
      "        [0.7024, 0.7019, 0.6996, 0.6523],\n",
      "        [0.6995, 0.6988, 0.6964, 0.6493],\n",
      "        [0.7099, 0.7097, 0.7076, 0.6599],\n",
      "        [0.7016, 0.7010, 0.6987, 0.6515],\n",
      "        [0.7001, 0.6995, 0.6972, 0.6500],\n",
      "        [0.6912, 0.6901, 0.6876, 0.6410],\n",
      "        [0.7258, 0.7263, 0.7244, 0.6758],\n",
      "        [0.7714, 0.7741, 0.7730, 0.7217],\n",
      "        [0.7959, 0.7998, 0.7992, 0.7464],\n",
      "        [0.7793, 0.7823, 0.7814, 0.7296],\n",
      "        [0.8206, 0.8256, 0.8254, 0.7712],\n",
      "        [0.8553, 0.8619, 0.8624, 0.8061],\n",
      "        [0.6325, 0.6287, 0.6251, 0.5820],\n",
      "        [0.6891, 0.6879, 0.6854, 0.6389],\n",
      "        [0.8305, 0.8360, 0.8360, 0.7811],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.7582, 0.7603, 0.7590, 0.7084],\n",
      "        [0.6898, 0.6887, 0.6862, 0.6397],\n",
      "        [0.7883, 0.7918, 0.7910, 0.7387],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.7640, 0.7663, 0.7652, 0.7142],\n",
      "        [0.7523, 0.7541, 0.7527, 0.7025],\n",
      "        [0.6858, 0.6845, 0.6819, 0.6356],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6603, 0.6578, 0.6547, 0.6099],\n",
      "        [0.7175, 0.7177, 0.7157, 0.6675],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6805, 0.6789, 0.6762, 0.6303],\n",
      "        [0.6637, 0.6613, 0.6583, 0.6133],\n",
      "        [0.6397, 0.6363, 0.6329, 0.5893],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6568, 0.6541, 0.6510, 0.6064],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6226, 0.6183, 0.6146, 0.5720],\n",
      "        [0.6460, 0.6429, 0.6395, 0.5956],\n",
      "        [0.6632, 0.6608, 0.6578, 0.6129],\n",
      "        [0.6535, 0.6507, 0.6475, 0.6031],\n",
      "        [0.7815, 0.7846, 0.7838, 0.7318],\n",
      "        [0.7613, 0.7635, 0.7623, 0.7115],\n",
      "        [0.7940, 0.7978, 0.7971, 0.7444]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0736, 0.0158, 0.0387, 0.0042],\n",
      "        [0.0011, 0.0171, 0.0183, 0.0223],\n",
      "        [0.0287, 0.0108, 0.0305, 0.0160],\n",
      "        [0.0174, 0.0193, 0.0047, 0.0227],\n",
      "        [0.0512, 0.0335, 0.0525, 0.0224],\n",
      "        [0.0495, 0.0655, 0.0363, 0.0087],\n",
      "        [0.0970, 0.0660, 0.0203, 0.0073],\n",
      "        [0.0832, 0.0358, 0.0077, 0.0249],\n",
      "        [0.0414, 0.0116, 0.0229, 0.0361],\n",
      "        [0.0140, 0.0221, 0.0379, 0.0390],\n",
      "        [0.0332, 0.0512, 0.0554, 0.0456],\n",
      "        [0.0431, 0.0488, 0.0423, 0.0221],\n",
      "        [0.0479, 0.0431, 0.0246, 0.0013],\n",
      "        [0.0348, 0.0176, 0.0055, 0.0162],\n",
      "        [0.0532, 0.0332, 0.0221, 0.0542],\n",
      "        [0.0782, 0.0718, 0.0070, 0.0596],\n",
      "        [0.0936, 0.0198, 0.0357, 0.0395],\n",
      "        [0.0007, 0.0525, 0.0583, 0.0408],\n",
      "        [0.0142, 0.0141, 0.0022, 0.0232],\n",
      "        [0.0156, 0.0387, 0.0135, 0.0587],\n",
      "        [0.1335, 0.1516, 0.1513, 0.1216],\n",
      "        [0.0931, 0.0566, 0.0132, 0.0047],\n",
      "        [0.0374, 0.0443, 0.0305, 0.0492],\n",
      "        [0.1292, 0.1461, 0.1016, 0.0298],\n",
      "        [0.1538, 0.1335, 0.1498, 0.0982],\n",
      "        [0.0334, 0.0452, 0.0232, 0.0117],\n",
      "        [0.1156, 0.0934, 0.0583, 0.0141],\n",
      "        [0.0103, 0.0014, 0.0006, 0.0152],\n",
      "        [0.1577, 0.1580, 0.1372, 0.1434],\n",
      "        [0.0592, 0.0825, 0.0335, 0.0280],\n",
      "        [0.0966, 0.0445, 0.0404, 0.0383],\n",
      "        [0.0579, 0.0815, 0.0984, 0.0910],\n",
      "        [0.0063, 0.0233, 0.0020, 0.0329],\n",
      "        [0.0202, 0.0146, 0.0972, 0.1633],\n",
      "        [0.0517, 0.0106, 0.0270, 0.0050],\n",
      "        [0.0190, 0.0017, 0.0385, 0.0174],\n",
      "        [0.0187, 0.0475, 0.0143, 0.0284],\n",
      "        [0.0060, 0.0423, 0.0219, 0.0214],\n",
      "        [0.0465, 0.0257, 0.0262, 0.0199],\n",
      "        [0.1418, 0.0979, 0.0352, 0.0951],\n",
      "        [0.0383, 0.0199, 0.0014, 0.0284],\n",
      "        [0.0270, 0.0191, 0.0380, 0.0561],\n",
      "        [0.0011, 0.0427, 0.0216, 0.0097],\n",
      "        [0.0469, 0.0254, 0.0138, 0.0184],\n",
      "        [0.0296, 0.0175, 0.0163, 0.0069],\n",
      "        [0.0028, 0.0256, 0.0548, 0.0915],\n",
      "        [0.0103, 0.0399, 0.0827, 0.0584],\n",
      "        [0.0089, 0.0325, 0.0620, 0.0008],\n",
      "        [0.0299, 0.0299, 0.0246, 0.0028],\n",
      "        [0.1441, 0.0159, 0.0183, 0.0941],\n",
      "        [0.0326, 0.0040, 0.0439, 0.0509],\n",
      "        [0.0342, 0.0284, 0.0003, 0.0442],\n",
      "        [0.0559, 0.0232, 0.0472, 0.0722],\n",
      "        [0.0432, 0.1087, 0.0988, 0.0551],\n",
      "        [0.1129, 0.1025, 0.0623, 0.0996],\n",
      "        [0.1068, 0.0660, 0.1098, 0.1216],\n",
      "        [0.0083, 0.0402, 0.0511, 0.0276],\n",
      "        [0.0431, 0.0224, 0.0268, 0.0126],\n",
      "        [0.2061, 0.1399, 0.0122, 0.0203],\n",
      "        [0.0702, 0.0635, 0.1299, 0.1129],\n",
      "        [0.0047, 0.0048, 0.0171, 0.0126],\n",
      "        [0.0127, 0.0093, 0.0228, 0.0228],\n",
      "        [0.1350, 0.0410, 0.0178, 0.0016],\n",
      "        [0.1308, 0.1166, 0.1158, 0.0155],\n",
      "        [0.1471, 0.1513, 0.0535, 0.0276]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 38\n",
      "Number of shrink: 26\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0778, 0.0205, 0.0399, 0.0048],\n",
      "        [0.0034, 0.0220, 0.0172, 0.0227],\n",
      "        [0.0334, 0.0056, 0.0320, 0.0168],\n",
      "        [0.0120, 0.0253, 0.0068, 0.0240],\n",
      "        [0.0552, 0.0379, 0.0535, 0.0229],\n",
      "        [0.0497, 0.0659, 0.0335, 0.0118],\n",
      "        [0.0968, 0.0660, 0.0175, 0.0101],\n",
      "        [0.0812, 0.0338, 0.0032, 0.0293],\n",
      "        [0.0399, 0.0102, 0.0266, 0.0396],\n",
      "        [0.0126, 0.0235, 0.0416, 0.0425],\n",
      "        [0.0358, 0.0538, 0.0604, 0.0505],\n",
      "        [0.0449, 0.0506, 0.0465, 0.0261],\n",
      "        [0.0503, 0.0455, 0.0293, 0.0058],\n",
      "        [0.0378, 0.0206, 0.0004, 0.0114],\n",
      "        [0.0543, 0.0342, 0.0259, 0.0504],\n",
      "        [0.0765, 0.0697, 0.0055, 0.0577],\n",
      "        [0.0903, 0.0159, 0.0356, 0.0387],\n",
      "        [0.0033, 0.0555, 0.0576, 0.0396],\n",
      "        [0.0182, 0.0186, 0.0021, 0.0225],\n",
      "        [0.0079, 0.0302, 0.0100, 0.0564],\n",
      "        [0.1348, 0.1530, 0.1517, 0.1224],\n",
      "        [0.0917, 0.0553, 0.0098, 0.0079],\n",
      "        [0.0311, 0.0374, 0.0280, 0.0477],\n",
      "        [0.1298, 0.1467, 0.1015, 0.0295],\n",
      "        [0.1544, 0.1341, 0.1497, 0.0986],\n",
      "        [0.0360, 0.0481, 0.0228, 0.0124],\n",
      "        [0.1164, 0.0943, 0.0572, 0.0130],\n",
      "        [0.0146, 0.0061, 0.0016, 0.0155],\n",
      "        [0.1583, 0.1586, 0.1371, 0.1437],\n",
      "        [0.0616, 0.0853, 0.0328, 0.0269],\n",
      "        [0.1000, 0.0484, 0.0411, 0.0387],\n",
      "        [0.0640, 0.0880, 0.1032, 0.0956],\n",
      "        [0.0069, 0.0239, 0.0019, 0.0326],\n",
      "        [0.0196, 0.0152, 0.0970, 0.1637],\n",
      "        [0.0511, 0.0112, 0.0269, 0.0053],\n",
      "        [0.0196, 0.0012, 0.0387, 0.0170],\n",
      "        [0.0182, 0.0469, 0.0142, 0.0288],\n",
      "        [0.0054, 0.0417, 0.0221, 0.0210],\n",
      "        [0.0459, 0.0251, 0.0263, 0.0196],\n",
      "        [0.1424, 0.0985, 0.0354, 0.0947],\n",
      "        [0.0389, 0.0206, 0.0022, 0.0289],\n",
      "        [0.0289, 0.0170, 0.0384, 0.0566],\n",
      "        [0.0005, 0.0421, 0.0218, 0.0094],\n",
      "        [0.0463, 0.0248, 0.0139, 0.0187],\n",
      "        [0.0290, 0.0169, 0.0162, 0.0066],\n",
      "        [0.0020, 0.0246, 0.0557, 0.0923],\n",
      "        [0.0120, 0.0416, 0.0860, 0.0613],\n",
      "        [0.0100, 0.0336, 0.0643, 0.0026],\n",
      "        [0.0293, 0.0294, 0.0248, 0.0032],\n",
      "        [0.1435, 0.0153, 0.0182, 0.0944],\n",
      "        [0.0320, 0.0034, 0.0438, 0.0513],\n",
      "        [0.0336, 0.0278, 0.0004, 0.0446],\n",
      "        [0.0549, 0.0221, 0.0474, 0.0721],\n",
      "        [0.0426, 0.1081, 0.0989, 0.0548],\n",
      "        [0.1123, 0.1019, 0.0624, 0.0993],\n",
      "        [0.1062, 0.0654, 0.1099, 0.1212],\n",
      "        [0.0077, 0.0408, 0.0509, 0.0280],\n",
      "        [0.0437, 0.0230, 0.0267, 0.0129],\n",
      "        [0.2055, 0.1393, 0.0123, 0.0206],\n",
      "        [0.0773, 0.0561, 0.1234, 0.1064],\n",
      "        [0.0102, 0.0204, 0.0025, 0.0015],\n",
      "        [0.0048, 0.0091, 0.0051, 0.0057],\n",
      "        [0.1176, 0.0225, 0.0025, 0.0124],\n",
      "        [0.1096, 0.0942, 0.0960, 0.0029],\n",
      "        [0.1253, 0.1282, 0.0336, 0.0094]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 22.240466833114624\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 66\n",
      "X 資料 torch.Size([41, 18])\n",
      "Y 資料 torch.Size([41, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.01492576114833355, 6)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引6，y= tensor([0.6324, 0.6305, 0.6469, 0.6050])\n",
      "目前模型的Data torch.Size([66, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7700, 0.7724, 0.7749, 0.7239],\n",
      "        [0.7895, 0.7928, 0.7960, 0.7440],\n",
      "        [0.7814, 0.7843, 0.7872, 0.7357],\n",
      "        [0.7907, 0.7940, 0.7973, 0.7452],\n",
      "        [0.7641, 0.7662, 0.7684, 0.7178],\n",
      "        [0.7544, 0.7560, 0.7580, 0.7079],\n",
      "        [0.7251, 0.7255, 0.7263, 0.6778],\n",
      "        [0.7103, 0.7100, 0.7103, 0.6625],\n",
      "        [0.7039, 0.7033, 0.7033, 0.6559],\n",
      "        [0.7009, 0.7002, 0.7001, 0.6528],\n",
      "        [0.7125, 0.7123, 0.7126, 0.6647],\n",
      "        [0.7034, 0.7028, 0.7028, 0.6554],\n",
      "        [0.7025, 0.7018, 0.7018, 0.6545],\n",
      "        [0.6941, 0.6931, 0.6928, 0.6459],\n",
      "        [0.7269, 0.7273, 0.7282, 0.6796],\n",
      "        [0.7697, 0.7720, 0.7745, 0.7236],\n",
      "        [0.7926, 0.7959, 0.7993, 0.7471],\n",
      "        [0.7767, 0.7794, 0.7821, 0.7308],\n",
      "        [0.8167, 0.8211, 0.8253, 0.7719],\n",
      "        [0.8476, 0.8534, 0.8588, 0.8038],\n",
      "        [0.6312, 0.6274, 0.6247, 0.5811],\n",
      "        [0.6905, 0.6893, 0.6888, 0.6421],\n",
      "        [0.8242, 0.8290, 0.8335, 0.7797],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.7556, 0.7573, 0.7593, 0.7091],\n",
      "        [0.6891, 0.6879, 0.6874, 0.6407],\n",
      "        [0.7840, 0.7870, 0.7900, 0.7383],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.7616, 0.7636, 0.7658, 0.7153],\n",
      "        [0.7489, 0.7503, 0.7520, 0.7022],\n",
      "        [0.6797, 0.6780, 0.6771, 0.6310],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6597, 0.6571, 0.6555, 0.6105],\n",
      "        [0.7156, 0.7156, 0.7161, 0.6680],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6796, 0.6780, 0.6771, 0.6310],\n",
      "        [0.6653, 0.6630, 0.6616, 0.6163],\n",
      "        [0.6409, 0.6375, 0.6352, 0.5911],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6557, 0.6530, 0.6512, 0.6064],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6220, 0.6177, 0.6147, 0.5717],\n",
      "        [0.6389, 0.6354, 0.6330, 0.5891],\n",
      "        [0.6483, 0.6453, 0.6432, 0.5988],\n",
      "        [0.6359, 0.6323, 0.6298, 0.5860],\n",
      "        [0.7641, 0.7662, 0.7685, 0.7179],\n",
      "        [0.7400, 0.7411, 0.7425, 0.6931],\n",
      "        [0.7722, 0.7747, 0.7773, 0.7262],\n",
      "        [0.7606, 0.7626, 0.7647, 0.7143]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0778, 0.0205, 0.0399, 0.0048],\n",
      "        [0.0034, 0.0220, 0.0172, 0.0227],\n",
      "        [0.0334, 0.0056, 0.0320, 0.0168],\n",
      "        [0.0120, 0.0253, 0.0068, 0.0240],\n",
      "        [0.0552, 0.0379, 0.0535, 0.0229],\n",
      "        [0.0497, 0.0659, 0.0335, 0.0118],\n",
      "        [0.0968, 0.0660, 0.0175, 0.0101],\n",
      "        [0.0812, 0.0338, 0.0032, 0.0293],\n",
      "        [0.0399, 0.0102, 0.0266, 0.0396],\n",
      "        [0.0126, 0.0235, 0.0416, 0.0425],\n",
      "        [0.0358, 0.0538, 0.0604, 0.0505],\n",
      "        [0.0449, 0.0506, 0.0465, 0.0261],\n",
      "        [0.0503, 0.0455, 0.0293, 0.0058],\n",
      "        [0.0378, 0.0206, 0.0004, 0.0114],\n",
      "        [0.0543, 0.0342, 0.0259, 0.0504],\n",
      "        [0.0765, 0.0697, 0.0055, 0.0577],\n",
      "        [0.0903, 0.0159, 0.0356, 0.0387],\n",
      "        [0.0033, 0.0555, 0.0576, 0.0396],\n",
      "        [0.0182, 0.0186, 0.0021, 0.0225],\n",
      "        [0.0079, 0.0302, 0.0100, 0.0564],\n",
      "        [0.1348, 0.1530, 0.1517, 0.1224],\n",
      "        [0.0917, 0.0553, 0.0098, 0.0079],\n",
      "        [0.0311, 0.0374, 0.0280, 0.0477],\n",
      "        [0.1298, 0.1467, 0.1015, 0.0295],\n",
      "        [0.1544, 0.1341, 0.1497, 0.0986],\n",
      "        [0.0360, 0.0481, 0.0228, 0.0124],\n",
      "        [0.1164, 0.0943, 0.0572, 0.0130],\n",
      "        [0.0146, 0.0061, 0.0016, 0.0155],\n",
      "        [0.1583, 0.1586, 0.1371, 0.1437],\n",
      "        [0.0616, 0.0853, 0.0328, 0.0269],\n",
      "        [0.1000, 0.0484, 0.0411, 0.0387],\n",
      "        [0.0640, 0.0880, 0.1032, 0.0956],\n",
      "        [0.0069, 0.0239, 0.0019, 0.0326],\n",
      "        [0.0196, 0.0152, 0.0970, 0.1637],\n",
      "        [0.0511, 0.0112, 0.0269, 0.0053],\n",
      "        [0.0196, 0.0012, 0.0387, 0.0170],\n",
      "        [0.0182, 0.0469, 0.0142, 0.0288],\n",
      "        [0.0054, 0.0417, 0.0221, 0.0210],\n",
      "        [0.0459, 0.0251, 0.0263, 0.0196],\n",
      "        [0.1424, 0.0985, 0.0354, 0.0947],\n",
      "        [0.0389, 0.0206, 0.0022, 0.0289],\n",
      "        [0.0289, 0.0170, 0.0384, 0.0566],\n",
      "        [0.0005, 0.0421, 0.0218, 0.0094],\n",
      "        [0.0463, 0.0248, 0.0139, 0.0187],\n",
      "        [0.0290, 0.0169, 0.0162, 0.0066],\n",
      "        [0.0020, 0.0246, 0.0557, 0.0923],\n",
      "        [0.0120, 0.0416, 0.0860, 0.0613],\n",
      "        [0.0100, 0.0336, 0.0643, 0.0026],\n",
      "        [0.0293, 0.0294, 0.0248, 0.0032],\n",
      "        [0.1435, 0.0153, 0.0182, 0.0944],\n",
      "        [0.0320, 0.0034, 0.0438, 0.0513],\n",
      "        [0.0336, 0.0278, 0.0004, 0.0446],\n",
      "        [0.0549, 0.0221, 0.0474, 0.0721],\n",
      "        [0.0426, 0.1081, 0.0989, 0.0548],\n",
      "        [0.1123, 0.1019, 0.0624, 0.0993],\n",
      "        [0.1062, 0.0654, 0.1099, 0.1212],\n",
      "        [0.0077, 0.0408, 0.0509, 0.0280],\n",
      "        [0.0437, 0.0230, 0.0267, 0.0129],\n",
      "        [0.2055, 0.1393, 0.0123, 0.0206],\n",
      "        [0.0773, 0.0561, 0.1234, 0.1064],\n",
      "        [0.0102, 0.0204, 0.0025, 0.0015],\n",
      "        [0.0048, 0.0091, 0.0051, 0.0057],\n",
      "        [0.1176, 0.0225, 0.0025, 0.0124],\n",
      "        [0.1096, 0.0942, 0.0960, 0.0029],\n",
      "        [0.1253, 0.1282, 0.0336, 0.0094],\n",
      "        [0.1282, 0.1321, 0.1178, 0.1093]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 38\n",
      "Number of shrink: 26\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0793, 0.0225, 0.0419, 0.0074],\n",
      "        [0.0044, 0.0237, 0.0156, 0.0250],\n",
      "        [0.0358, 0.0025, 0.0351, 0.0205],\n",
      "        [0.0089, 0.0290, 0.0107, 0.0285],\n",
      "        [0.0575, 0.0408, 0.0565, 0.0264],\n",
      "        [0.0490, 0.0657, 0.0332, 0.0114],\n",
      "        [0.0961, 0.0656, 0.0171, 0.0100],\n",
      "        [0.0795, 0.0323, 0.0016, 0.0303],\n",
      "        [0.0385, 0.0089, 0.0279, 0.0405],\n",
      "        [0.0112, 0.0246, 0.0428, 0.0432],\n",
      "        [0.0398, 0.0576, 0.0644, 0.0539],\n",
      "        [0.0479, 0.0534, 0.0494, 0.0284],\n",
      "        [0.0536, 0.0487, 0.0326, 0.0086],\n",
      "        [0.0415, 0.0242, 0.0034, 0.0082],\n",
      "        [0.0566, 0.0362, 0.0280, 0.0489],\n",
      "        [0.0776, 0.0704, 0.0048, 0.0577],\n",
      "        [0.0907, 0.0158, 0.0356, 0.0396],\n",
      "        [0.0024, 0.0551, 0.0571, 0.0399],\n",
      "        [0.0176, 0.0186, 0.0021, 0.0234],\n",
      "        [0.0053, 0.0267, 0.0064, 0.0519],\n",
      "        [0.1394, 0.1578, 0.1568, 0.1273],\n",
      "        [0.0873, 0.0509, 0.0052, 0.0119],\n",
      "        [0.0302, 0.0358, 0.0264, 0.0452],\n",
      "        [0.1295, 0.1463, 0.1011, 0.0299],\n",
      "        [0.1540, 0.1337, 0.1493, 0.0982],\n",
      "        [0.0341, 0.0467, 0.0213, 0.0132],\n",
      "        [0.1135, 0.0915, 0.0543, 0.0106],\n",
      "        [0.0135, 0.0055, 0.0009, 0.0156],\n",
      "        [0.1579, 0.1583, 0.1367, 0.1433],\n",
      "        [0.0609, 0.0849, 0.0324, 0.0272],\n",
      "        [0.0996, 0.0483, 0.0411, 0.0392],\n",
      "        [0.0726, 0.0971, 0.1126, 0.1048],\n",
      "        [0.0065, 0.0235, 0.0015, 0.0329],\n",
      "        [0.0200, 0.0148, 0.0966, 0.1633],\n",
      "        [0.0515, 0.0108, 0.0265, 0.0050],\n",
      "        [0.0192, 0.0015, 0.0390, 0.0174],\n",
      "        [0.0185, 0.0473, 0.0138, 0.0284],\n",
      "        [0.0058, 0.0420, 0.0224, 0.0214],\n",
      "        [0.0463, 0.0254, 0.0267, 0.0200],\n",
      "        [0.1420, 0.0981, 0.0357, 0.0951],\n",
      "        [0.0367, 0.0184, 0.0044, 0.0308],\n",
      "        [0.0274, 0.0182, 0.0397, 0.0574],\n",
      "        [0.0009, 0.0425, 0.0221, 0.0098],\n",
      "        [0.0467, 0.0252, 0.0143, 0.0184],\n",
      "        [0.0294, 0.0173, 0.0158, 0.0070],\n",
      "        [0.0044, 0.0269, 0.0581, 0.0943],\n",
      "        [0.0160, 0.0456, 0.0902, 0.0651],\n",
      "        [0.0100, 0.0336, 0.0643, 0.0024],\n",
      "        [0.0297, 0.0297, 0.0252, 0.0028],\n",
      "        [0.1439, 0.0157, 0.0178, 0.0940],\n",
      "        [0.0324, 0.0038, 0.0434, 0.0509],\n",
      "        [0.0340, 0.0282, 0.0008, 0.0442],\n",
      "        [0.0530, 0.0200, 0.0452, 0.0699],\n",
      "        [0.0430, 0.1085, 0.0993, 0.0552],\n",
      "        [0.1127, 0.1023, 0.0628, 0.0996],\n",
      "        [0.1066, 0.0658, 0.1103, 0.1216],\n",
      "        [0.0081, 0.0404, 0.0506, 0.0276],\n",
      "        [0.0433, 0.0226, 0.0263, 0.0126],\n",
      "        [0.2059, 0.1397, 0.0127, 0.0202],\n",
      "        [0.0851, 0.0478, 0.1148, 0.0982],\n",
      "        [0.0281, 0.0392, 0.0170, 0.0200],\n",
      "        [0.0184, 0.0233, 0.0096, 0.0083],\n",
      "        [0.1000, 0.0037, 0.0170, 0.0315],\n",
      "        [0.0864, 0.0696, 0.0706, 0.0274],\n",
      "        [0.1024, 0.1039, 0.0085, 0.0152],\n",
      "        [0.1033, 0.1057, 0.0904, 0.0827]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 22.85949158668518\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 67\n",
      "X 資料 torch.Size([40, 18])\n",
      "Y 資料 torch.Size([40, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.014144961722195148, 2)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引2，y= tensor([0.6202, 0.6423, 0.6471, 0.6019])\n",
      "目前模型的Data torch.Size([67, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7686, 0.7704, 0.7729, 0.7213],\n",
      "        [0.7885, 0.7911, 0.7943, 0.7416],\n",
      "        [0.7790, 0.7813, 0.7841, 0.7320],\n",
      "        [0.7876, 0.7902, 0.7934, 0.7407],\n",
      "        [0.7617, 0.7632, 0.7654, 0.7143],\n",
      "        [0.7550, 0.7563, 0.7583, 0.7075],\n",
      "        [0.7258, 0.7259, 0.7267, 0.6777],\n",
      "        [0.7120, 0.7115, 0.7118, 0.6636],\n",
      "        [0.7053, 0.7045, 0.7046, 0.6568],\n",
      "        [0.7022, 0.7013, 0.7013, 0.6536],\n",
      "        [0.7165, 0.7161, 0.7166, 0.6681],\n",
      "        [0.7064, 0.7056, 0.7058, 0.6578],\n",
      "        [0.7058, 0.7051, 0.7052, 0.6573],\n",
      "        [0.6978, 0.6967, 0.6965, 0.6491],\n",
      "        [0.7292, 0.7294, 0.7304, 0.6811],\n",
      "        [0.7708, 0.7727, 0.7752, 0.7235],\n",
      "        [0.7930, 0.7958, 0.7992, 0.7462],\n",
      "        [0.7776, 0.7798, 0.7826, 0.7305],\n",
      "        [0.8173, 0.8211, 0.8254, 0.7710],\n",
      "        [0.8450, 0.8499, 0.8553, 0.7993],\n",
      "        [0.6265, 0.6225, 0.6196, 0.5763],\n",
      "        [0.6949, 0.6937, 0.6934, 0.6461],\n",
      "        [0.8233, 0.8274, 0.8319, 0.7772],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.7575, 0.7588, 0.7609, 0.7100],\n",
      "        [0.6920, 0.6906, 0.6902, 0.6431],\n",
      "        [0.7851, 0.7876, 0.7907, 0.7382],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.7624, 0.7639, 0.7662, 0.7150],\n",
      "        [0.7493, 0.7503, 0.7520, 0.7016],\n",
      "        [0.6711, 0.6689, 0.6677, 0.6218],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6619, 0.6593, 0.6577, 0.6124],\n",
      "        [0.7171, 0.7168, 0.7174, 0.6688],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6821, 0.6803, 0.6795, 0.6330],\n",
      "        [0.6694, 0.6671, 0.6658, 0.6200],\n",
      "        [0.6409, 0.6374, 0.6351, 0.5910],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6538, 0.6509, 0.6490, 0.6041],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.6310, 0.6271, 0.6245, 0.5809],\n",
      "        [0.6304, 0.6265, 0.6238, 0.5803],\n",
      "        [0.6224, 0.6181, 0.6151, 0.5721],\n",
      "        [0.7465, 0.7473, 0.7490, 0.6987],\n",
      "        [0.7169, 0.7165, 0.7171, 0.6685],\n",
      "        [0.7494, 0.7504, 0.7521, 0.7017],\n",
      "        [0.7357, 0.7361, 0.7373, 0.6877],\n",
      "        [0.7570, 0.7583, 0.7604, 0.7095]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0793, 0.0225, 0.0419, 0.0074],\n",
      "        [0.0044, 0.0237, 0.0156, 0.0250],\n",
      "        [0.0358, 0.0025, 0.0351, 0.0205],\n",
      "        [0.0089, 0.0290, 0.0107, 0.0285],\n",
      "        [0.0575, 0.0408, 0.0565, 0.0264],\n",
      "        [0.0490, 0.0657, 0.0332, 0.0114],\n",
      "        [0.0961, 0.0656, 0.0171, 0.0100],\n",
      "        [0.0795, 0.0323, 0.0016, 0.0303],\n",
      "        [0.0385, 0.0089, 0.0279, 0.0405],\n",
      "        [0.0112, 0.0246, 0.0428, 0.0432],\n",
      "        [0.0398, 0.0576, 0.0644, 0.0539],\n",
      "        [0.0479, 0.0534, 0.0494, 0.0284],\n",
      "        [0.0536, 0.0487, 0.0326, 0.0086],\n",
      "        [0.0415, 0.0242, 0.0034, 0.0082],\n",
      "        [0.0566, 0.0362, 0.0280, 0.0489],\n",
      "        [0.0776, 0.0704, 0.0048, 0.0577],\n",
      "        [0.0907, 0.0158, 0.0356, 0.0396],\n",
      "        [0.0024, 0.0551, 0.0571, 0.0399],\n",
      "        [0.0176, 0.0186, 0.0021, 0.0234],\n",
      "        [0.0053, 0.0267, 0.0064, 0.0519],\n",
      "        [0.1394, 0.1578, 0.1568, 0.1273],\n",
      "        [0.0873, 0.0509, 0.0052, 0.0119],\n",
      "        [0.0302, 0.0358, 0.0264, 0.0452],\n",
      "        [0.1295, 0.1463, 0.1011, 0.0299],\n",
      "        [0.1540, 0.1337, 0.1493, 0.0982],\n",
      "        [0.0341, 0.0467, 0.0213, 0.0132],\n",
      "        [0.1135, 0.0915, 0.0543, 0.0106],\n",
      "        [0.0135, 0.0055, 0.0009, 0.0156],\n",
      "        [0.1579, 0.1583, 0.1367, 0.1433],\n",
      "        [0.0609, 0.0849, 0.0324, 0.0272],\n",
      "        [0.0996, 0.0483, 0.0411, 0.0392],\n",
      "        [0.0726, 0.0971, 0.1126, 0.1048],\n",
      "        [0.0065, 0.0235, 0.0015, 0.0329],\n",
      "        [0.0200, 0.0148, 0.0966, 0.1633],\n",
      "        [0.0515, 0.0108, 0.0265, 0.0050],\n",
      "        [0.0192, 0.0015, 0.0390, 0.0174],\n",
      "        [0.0185, 0.0473, 0.0138, 0.0284],\n",
      "        [0.0058, 0.0420, 0.0224, 0.0214],\n",
      "        [0.0463, 0.0254, 0.0267, 0.0200],\n",
      "        [0.1420, 0.0981, 0.0357, 0.0951],\n",
      "        [0.0367, 0.0184, 0.0044, 0.0308],\n",
      "        [0.0274, 0.0182, 0.0397, 0.0574],\n",
      "        [0.0009, 0.0425, 0.0221, 0.0098],\n",
      "        [0.0467, 0.0252, 0.0143, 0.0184],\n",
      "        [0.0294, 0.0173, 0.0158, 0.0070],\n",
      "        [0.0044, 0.0269, 0.0581, 0.0943],\n",
      "        [0.0160, 0.0456, 0.0902, 0.0651],\n",
      "        [0.0100, 0.0336, 0.0643, 0.0024],\n",
      "        [0.0297, 0.0297, 0.0252, 0.0028],\n",
      "        [0.1439, 0.0157, 0.0178, 0.0940],\n",
      "        [0.0324, 0.0038, 0.0434, 0.0509],\n",
      "        [0.0340, 0.0282, 0.0008, 0.0442],\n",
      "        [0.0530, 0.0200, 0.0452, 0.0699],\n",
      "        [0.0430, 0.1085, 0.0993, 0.0552],\n",
      "        [0.1127, 0.1023, 0.0628, 0.0996],\n",
      "        [0.1066, 0.0658, 0.1103, 0.1216],\n",
      "        [0.0081, 0.0404, 0.0506, 0.0276],\n",
      "        [0.0433, 0.0226, 0.0263, 0.0126],\n",
      "        [0.2059, 0.1397, 0.0127, 0.0202],\n",
      "        [0.0851, 0.0478, 0.1148, 0.0982],\n",
      "        [0.0281, 0.0392, 0.0170, 0.0200],\n",
      "        [0.0184, 0.0233, 0.0096, 0.0083],\n",
      "        [0.1000, 0.0037, 0.0170, 0.0315],\n",
      "        [0.0864, 0.0696, 0.0706, 0.0274],\n",
      "        [0.1024, 0.1039, 0.0085, 0.0152],\n",
      "        [0.1033, 0.1057, 0.0904, 0.0827],\n",
      "        [0.1368, 0.1160, 0.1133, 0.1076]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 30\n",
      "Number of shrink: 22\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0788, 0.0221, 0.0421, 0.0077],\n",
      "        [0.0020, 0.0214, 0.0173, 0.0235],\n",
      "        [0.0355, 0.0026, 0.0356, 0.0210],\n",
      "        [0.0091, 0.0290, 0.0113, 0.0292],\n",
      "        [0.0579, 0.0413, 0.0576, 0.0274],\n",
      "        [0.0493, 0.0660, 0.0341, 0.0106],\n",
      "        [0.0995, 0.0690, 0.0210, 0.0063],\n",
      "        [0.0829, 0.0357, 0.0056, 0.0267],\n",
      "        [0.0400, 0.0103, 0.0262, 0.0389],\n",
      "        [0.0127, 0.0234, 0.0411, 0.0418],\n",
      "        [0.0428, 0.0609, 0.0675, 0.0568],\n",
      "        [0.0507, 0.0566, 0.0523, 0.0313],\n",
      "        [0.0559, 0.0513, 0.0349, 0.0109],\n",
      "        [0.0421, 0.0251, 0.0040, 0.0075],\n",
      "        [0.0567, 0.0364, 0.0278, 0.0491],\n",
      "        [0.0811, 0.0738, 0.0018, 0.0550],\n",
      "        [0.0962, 0.0212, 0.0307, 0.0350],\n",
      "        [0.0013, 0.0514, 0.0539, 0.0370],\n",
      "        [0.0130, 0.0143, 0.0059, 0.0200],\n",
      "        [0.0092, 0.0301, 0.0092, 0.0543],\n",
      "        [0.1389, 0.1565, 0.1556, 0.1258],\n",
      "        [0.0849, 0.0481, 0.0027, 0.0144],\n",
      "        [0.0398, 0.0452, 0.0355, 0.0536],\n",
      "        [0.1247, 0.1406, 0.0954, 0.0356],\n",
      "        [0.1492, 0.1280, 0.1436, 0.0925],\n",
      "        [0.0268, 0.0391, 0.0140, 0.0200],\n",
      "        [0.1115, 0.0891, 0.0522, 0.0085],\n",
      "        [0.0055, 0.0026, 0.0068, 0.0084],\n",
      "        [0.1532, 0.1525, 0.1310, 0.1376],\n",
      "        [0.0593, 0.0835, 0.0315, 0.0264],\n",
      "        [0.0974, 0.0461, 0.0392, 0.0375],\n",
      "        [0.1007, 0.1257, 0.1425, 0.1328],\n",
      "        [0.0018, 0.0178, 0.0042, 0.0387],\n",
      "        [0.0247, 0.0091, 0.0909, 0.1576],\n",
      "        [0.0563, 0.0051, 0.0208, 0.0007],\n",
      "        [0.0145, 0.0073, 0.0447, 0.0231],\n",
      "        [0.0233, 0.0530, 0.0081, 0.0227],\n",
      "        [0.0106, 0.0478, 0.0281, 0.0271],\n",
      "        [0.0511, 0.0312, 0.0324, 0.0257],\n",
      "        [0.1373, 0.0924, 0.0415, 0.1008],\n",
      "        [0.0374, 0.0186, 0.0039, 0.0306],\n",
      "        [0.0257, 0.0201, 0.0412, 0.0589],\n",
      "        [0.0057, 0.0482, 0.0279, 0.0155],\n",
      "        [0.0515, 0.0309, 0.0200, 0.0126],\n",
      "        [0.0342, 0.0230, 0.0101, 0.0127],\n",
      "        [0.0061, 0.0291, 0.0600, 0.0962],\n",
      "        [0.0159, 0.0460, 0.0902, 0.0654],\n",
      "        [0.0008, 0.0231, 0.0532, 0.0078],\n",
      "        [0.0345, 0.0354, 0.0309, 0.0029],\n",
      "        [0.1487, 0.0214, 0.0121, 0.0883],\n",
      "        [0.0372, 0.0095, 0.0377, 0.0452],\n",
      "        [0.0388, 0.0339, 0.0065, 0.0385],\n",
      "        [0.0428, 0.0100, 0.0347, 0.0602],\n",
      "        [0.0478, 0.1142, 0.1050, 0.0609],\n",
      "        [0.1175, 0.1080, 0.0685, 0.1054],\n",
      "        [0.1113, 0.0715, 0.1160, 0.1273],\n",
      "        [0.0128, 0.0347, 0.0448, 0.0219],\n",
      "        [0.0385, 0.0169, 0.0206, 0.0068],\n",
      "        [0.2106, 0.1454, 0.0184, 0.0145],\n",
      "        [0.0891, 0.0445, 0.1112, 0.0950],\n",
      "        [0.0314, 0.0418, 0.0199, 0.0225],\n",
      "        [0.0136, 0.0176, 0.0039, 0.0026],\n",
      "        [0.0701, 0.0273, 0.0495, 0.0622],\n",
      "        [0.0465, 0.0285, 0.0276, 0.0679],\n",
      "        [0.0651, 0.0652, 0.0320, 0.0534],\n",
      "        [0.0617, 0.0627, 0.0456, 0.0404],\n",
      "        [0.0907, 0.0681, 0.0633, 0.0604]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 23.316460132598877\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 68\n",
      "X 資料 torch.Size([39, 18])\n",
      "Y 資料 torch.Size([39, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.008914312347769737, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.6414, 0.6247, 0.6202, 0.6011])\n",
      "目前模型的Data torch.Size([68, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7691, 0.7708, 0.7727, 0.7211],\n",
      "        [0.7909, 0.7934, 0.7960, 0.7431],\n",
      "        [0.7793, 0.7814, 0.7836, 0.7314],\n",
      "        [0.7879, 0.7902, 0.7928, 0.7401],\n",
      "        [0.7613, 0.7627, 0.7644, 0.7133],\n",
      "        [0.7548, 0.7559, 0.7574, 0.7066],\n",
      "        [0.7224, 0.7225, 0.7228, 0.6740],\n",
      "        [0.7085, 0.7081, 0.7079, 0.6600],\n",
      "        [0.7038, 0.7032, 0.7028, 0.6552],\n",
      "        [0.7008, 0.7001, 0.6996, 0.6521],\n",
      "        [0.7195, 0.7195, 0.7197, 0.6711],\n",
      "        [0.7092, 0.7088, 0.7086, 0.6606],\n",
      "        [0.7081, 0.7077, 0.7075, 0.6595],\n",
      "        [0.6984, 0.6976, 0.6971, 0.6498],\n",
      "        [0.7293, 0.7296, 0.7301, 0.6809],\n",
      "        [0.7743, 0.7761, 0.7782, 0.7263],\n",
      "        [0.7985, 0.8012, 0.8041, 0.7508],\n",
      "        [0.7813, 0.7834, 0.7858, 0.7334],\n",
      "        [0.8219, 0.8254, 0.8291, 0.7744],\n",
      "        [0.8489, 0.8534, 0.8581, 0.8017],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6973, 0.6964, 0.6959, 0.6486],\n",
      "        [0.8329, 0.8368, 0.8410, 0.7855],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.7648, 0.7664, 0.7681, 0.7168],\n",
      "        [0.6940, 0.6931, 0.6924, 0.6453],\n",
      "        [0.7932, 0.7957, 0.7985, 0.7454],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.7639, 0.7654, 0.7671, 0.7159],\n",
      "        [0.7515, 0.7526, 0.7539, 0.7033],\n",
      "        [0.6430, 0.6402, 0.6378, 0.5938],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6612, 0.6591, 0.6573, 0.6122],\n",
      "        [0.7188, 0.7187, 0.7189, 0.6703],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6838, 0.6824, 0.6814, 0.6349],\n",
      "        [0.6692, 0.6674, 0.6659, 0.6203],\n",
      "        [0.6301, 0.6269, 0.6240, 0.5808],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6437, 0.6409, 0.6385, 0.5945],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.6271, 0.6238, 0.6208, 0.5778],\n",
      "        [0.7166, 0.7164, 0.7165, 0.6681],\n",
      "        [0.6770, 0.6754, 0.6741, 0.6281],\n",
      "        [0.7120, 0.7117, 0.7116, 0.6635],\n",
      "        [0.6941, 0.6932, 0.6925, 0.6454],\n",
      "        [0.7109, 0.7105, 0.7104, 0.6623],\n",
      "        [0.7273, 0.7275, 0.7280, 0.6789]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0788, 0.0221, 0.0421, 0.0077],\n",
      "        [0.0020, 0.0214, 0.0173, 0.0235],\n",
      "        [0.0355, 0.0026, 0.0356, 0.0210],\n",
      "        [0.0091, 0.0290, 0.0113, 0.0292],\n",
      "        [0.0579, 0.0413, 0.0576, 0.0274],\n",
      "        [0.0493, 0.0660, 0.0341, 0.0106],\n",
      "        [0.0995, 0.0690, 0.0210, 0.0063],\n",
      "        [0.0829, 0.0357, 0.0056, 0.0267],\n",
      "        [0.0400, 0.0103, 0.0262, 0.0389],\n",
      "        [0.0127, 0.0234, 0.0411, 0.0418],\n",
      "        [0.0428, 0.0609, 0.0675, 0.0568],\n",
      "        [0.0507, 0.0566, 0.0523, 0.0313],\n",
      "        [0.0559, 0.0513, 0.0349, 0.0109],\n",
      "        [0.0421, 0.0251, 0.0040, 0.0075],\n",
      "        [0.0567, 0.0364, 0.0278, 0.0491],\n",
      "        [0.0811, 0.0738, 0.0018, 0.0550],\n",
      "        [0.0962, 0.0212, 0.0307, 0.0350],\n",
      "        [0.0013, 0.0514, 0.0539, 0.0370],\n",
      "        [0.0130, 0.0143, 0.0059, 0.0200],\n",
      "        [0.0092, 0.0301, 0.0092, 0.0543],\n",
      "        [0.1389, 0.1565, 0.1556, 0.1258],\n",
      "        [0.0849, 0.0481, 0.0027, 0.0144],\n",
      "        [0.0398, 0.0452, 0.0355, 0.0536],\n",
      "        [0.1247, 0.1406, 0.0954, 0.0356],\n",
      "        [0.1492, 0.1280, 0.1436, 0.0925],\n",
      "        [0.0268, 0.0391, 0.0140, 0.0200],\n",
      "        [0.1115, 0.0891, 0.0522, 0.0085],\n",
      "        [0.0055, 0.0026, 0.0068, 0.0084],\n",
      "        [0.1532, 0.1525, 0.1310, 0.1376],\n",
      "        [0.0593, 0.0835, 0.0315, 0.0264],\n",
      "        [0.0974, 0.0461, 0.0392, 0.0375],\n",
      "        [0.1007, 0.1257, 0.1425, 0.1328],\n",
      "        [0.0018, 0.0178, 0.0042, 0.0387],\n",
      "        [0.0247, 0.0091, 0.0909, 0.1576],\n",
      "        [0.0563, 0.0051, 0.0208, 0.0007],\n",
      "        [0.0145, 0.0073, 0.0447, 0.0231],\n",
      "        [0.0233, 0.0530, 0.0081, 0.0227],\n",
      "        [0.0106, 0.0478, 0.0281, 0.0271],\n",
      "        [0.0511, 0.0312, 0.0324, 0.0257],\n",
      "        [0.1373, 0.0924, 0.0415, 0.1008],\n",
      "        [0.0374, 0.0186, 0.0039, 0.0306],\n",
      "        [0.0257, 0.0201, 0.0412, 0.0589],\n",
      "        [0.0057, 0.0482, 0.0279, 0.0155],\n",
      "        [0.0515, 0.0309, 0.0200, 0.0126],\n",
      "        [0.0342, 0.0230, 0.0101, 0.0127],\n",
      "        [0.0061, 0.0291, 0.0600, 0.0962],\n",
      "        [0.0159, 0.0460, 0.0902, 0.0654],\n",
      "        [0.0008, 0.0231, 0.0532, 0.0078],\n",
      "        [0.0345, 0.0354, 0.0309, 0.0029],\n",
      "        [0.1487, 0.0214, 0.0121, 0.0883],\n",
      "        [0.0372, 0.0095, 0.0377, 0.0452],\n",
      "        [0.0388, 0.0339, 0.0065, 0.0385],\n",
      "        [0.0428, 0.0100, 0.0347, 0.0602],\n",
      "        [0.0478, 0.1142, 0.1050, 0.0609],\n",
      "        [0.1175, 0.1080, 0.0685, 0.1054],\n",
      "        [0.1113, 0.0715, 0.1160, 0.1273],\n",
      "        [0.0128, 0.0347, 0.0448, 0.0219],\n",
      "        [0.0385, 0.0169, 0.0206, 0.0068],\n",
      "        [0.2106, 0.1454, 0.0184, 0.0145],\n",
      "        [0.0891, 0.0445, 0.1112, 0.0950],\n",
      "        [0.0314, 0.0418, 0.0199, 0.0225],\n",
      "        [0.0136, 0.0176, 0.0039, 0.0026],\n",
      "        [0.0701, 0.0273, 0.0495, 0.0622],\n",
      "        [0.0465, 0.0285, 0.0276, 0.0679],\n",
      "        [0.0651, 0.0652, 0.0320, 0.0534],\n",
      "        [0.0617, 0.0627, 0.0456, 0.0404],\n",
      "        [0.0907, 0.0681, 0.0633, 0.0604],\n",
      "        [0.0860, 0.1029, 0.1079, 0.0778]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module>>\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 33\n",
      "Number of shrink: 24\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0772, 0.0215, 0.0411, 0.0073],\n",
      "        [0.0011, 0.0196, 0.0194, 0.0222],\n",
      "        [0.0327, 0.0042, 0.0336, 0.0198],\n",
      "        [0.0114, 0.0280, 0.0100, 0.0285],\n",
      "        [0.0557, 0.0399, 0.0557, 0.0262],\n",
      "        [0.0475, 0.0649, 0.0325, 0.0115],\n",
      "        [0.1015, 0.0713, 0.0228, 0.0043],\n",
      "        [0.0849, 0.0378, 0.0070, 0.0250],\n",
      "        [0.0416, 0.0118, 0.0252, 0.0378],\n",
      "        [0.0140, 0.0222, 0.0406, 0.0410],\n",
      "        [0.0434, 0.0613, 0.0684, 0.0574],\n",
      "        [0.0515, 0.0574, 0.0537, 0.0324],\n",
      "        [0.0568, 0.0522, 0.0365, 0.0121],\n",
      "        [0.0417, 0.0249, 0.0044, 0.0073],\n",
      "        [0.0555, 0.0348, 0.0267, 0.0505],\n",
      "        [0.0817, 0.0734, 0.0019, 0.0556],\n",
      "        [0.0983, 0.0219, 0.0298, 0.0348],\n",
      "        [0.0020, 0.0519, 0.0541, 0.0377],\n",
      "        [0.0120, 0.0152, 0.0051, 0.0215],\n",
      "        [0.0094, 0.0280, 0.0070, 0.0513],\n",
      "        [0.1400, 0.1563, 0.1543, 0.1246],\n",
      "        [0.0823, 0.0453, 0.0008, 0.0175],\n",
      "        [0.0476, 0.0511, 0.0416, 0.0585],\n",
      "        [0.1258, 0.1404, 0.0941, 0.0368],\n",
      "        [0.1503, 0.1278, 0.1424, 0.0912],\n",
      "        [0.0209, 0.0341, 0.0084, 0.0248],\n",
      "        [0.1099, 0.0872, 0.0495, 0.0062],\n",
      "        [0.0024, 0.0043, 0.0088, 0.0071],\n",
      "        [0.1543, 0.1523, 0.1298, 0.1364],\n",
      "        [0.0612, 0.0863, 0.0340, 0.0293],\n",
      "        [0.0991, 0.0486, 0.0414, 0.0400],\n",
      "        [0.1059, 0.1300, 0.1460, 0.1360],\n",
      "        [0.0029, 0.0176, 0.0055, 0.0399],\n",
      "        [0.0236, 0.0089, 0.0897, 0.1563],\n",
      "        [0.0552, 0.0048, 0.0196, 0.0020],\n",
      "        [0.0156, 0.0075, 0.0460, 0.0244],\n",
      "        [0.0222, 0.0532, 0.0068, 0.0215],\n",
      "        [0.0095, 0.0480, 0.0294, 0.0284],\n",
      "        [0.0500, 0.0314, 0.0337, 0.0269],\n",
      "        [0.1384, 0.0922, 0.0427, 0.1020],\n",
      "        [0.0371, 0.0175, 0.0059, 0.0324],\n",
      "        [0.0232, 0.0226, 0.0443, 0.0615],\n",
      "        [0.0046, 0.0484, 0.0291, 0.0167],\n",
      "        [0.0504, 0.0311, 0.0212, 0.0114],\n",
      "        [0.0331, 0.0232, 0.0088, 0.0139],\n",
      "        [0.0080, 0.0315, 0.0632, 0.0991],\n",
      "        [0.0168, 0.0475, 0.0927, 0.0676],\n",
      "        [0.0048, 0.0203, 0.0513, 0.0095],\n",
      "        [0.0334, 0.0357, 0.0321, 0.0041],\n",
      "        [0.1476, 0.0216, 0.0108, 0.0871],\n",
      "        [0.0361, 0.0098, 0.0365, 0.0440],\n",
      "        [0.0377, 0.0341, 0.0078, 0.0373],\n",
      "        [0.0389, 0.0072, 0.0326, 0.0583],\n",
      "        [0.0467, 0.1144, 0.1062, 0.0621],\n",
      "        [0.1164, 0.1082, 0.0697, 0.1066],\n",
      "        [0.1102, 0.0717, 0.1173, 0.1286],\n",
      "        [0.0117, 0.0345, 0.0436, 0.0206],\n",
      "        [0.0396, 0.0167, 0.0193, 0.0056],\n",
      "        [0.2095, 0.1456, 0.0197, 0.0133],\n",
      "        [0.0902, 0.0447, 0.1124, 0.0963],\n",
      "        [0.0325, 0.0416, 0.0187, 0.0212],\n",
      "        [0.0147, 0.0173, 0.0026, 0.0014],\n",
      "        [0.0624, 0.0352, 0.0571, 0.0696],\n",
      "        [0.0286, 0.0108, 0.0102, 0.0844],\n",
      "        [0.0502, 0.0499, 0.0471, 0.0678],\n",
      "        [0.0423, 0.0432, 0.0262, 0.0219],\n",
      "        [0.0658, 0.0427, 0.0378, 0.0361],\n",
      "        [0.0553, 0.0713, 0.0760, 0.0475]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 23.823241472244263\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 69\n",
      "X 資料 torch.Size([38, 18])\n",
      "Y 資料 torch.Size([38, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.004905433394014835, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引1，y= tensor([0.6423, 0.6471, 0.6432, 0.5918])\n",
      "目前模型的Data torch.Size([69, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7707, 0.7714, 0.7737, 0.7215],\n",
      "        [0.7940, 0.7952, 0.7982, 0.7445],\n",
      "        [0.7820, 0.7830, 0.7856, 0.7327],\n",
      "        [0.7902, 0.7912, 0.7941, 0.7407],\n",
      "        [0.7636, 0.7642, 0.7662, 0.7145],\n",
      "        [0.7566, 0.7570, 0.7589, 0.7076],\n",
      "        [0.7204, 0.7202, 0.7210, 0.6720],\n",
      "        [0.7065, 0.7061, 0.7064, 0.6583],\n",
      "        [0.7022, 0.7017, 0.7019, 0.6541],\n",
      "        [0.6995, 0.6989, 0.6991, 0.6514],\n",
      "        [0.7200, 0.7198, 0.7206, 0.6716],\n",
      "        [0.7100, 0.7096, 0.7101, 0.6618],\n",
      "        [0.7090, 0.7086, 0.7090, 0.6608],\n",
      "        [0.6981, 0.6974, 0.6976, 0.6500],\n",
      "        [0.7280, 0.7279, 0.7290, 0.6795],\n",
      "        [0.7749, 0.7757, 0.7781, 0.7256],\n",
      "        [0.8006, 0.8019, 0.8051, 0.7510],\n",
      "        [0.7821, 0.7830, 0.7856, 0.7327],\n",
      "        [0.8228, 0.8245, 0.8283, 0.7729],\n",
      "        [0.8491, 0.8512, 0.8559, 0.7987],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6998, 0.6992, 0.6994, 0.6517],\n",
      "        [0.8407, 0.8427, 0.8471, 0.7905],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.7707, 0.7714, 0.7737, 0.7215],\n",
      "        [0.6956, 0.6949, 0.6950, 0.6476],\n",
      "        [0.7962, 0.7974, 0.8005, 0.7467],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.7620, 0.7626, 0.7646, 0.7130],\n",
      "        [0.7497, 0.7500, 0.7517, 0.7009],\n",
      "        [0.6377, 0.6360, 0.6343, 0.5905],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6615, 0.6602, 0.6592, 0.6139],\n",
      "        [0.7214, 0.7211, 0.7220, 0.6729],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6857, 0.6848, 0.6846, 0.6378],\n",
      "        [0.6701, 0.6690, 0.6683, 0.6225],\n",
      "        [0.6261, 0.6241, 0.6221, 0.5791],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6398, 0.6380, 0.6365, 0.5925],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5790],\n",
      "        [0.7089, 0.7085, 0.7089, 0.6607],\n",
      "        [0.6591, 0.6577, 0.6567, 0.6116],\n",
      "        [0.6971, 0.6964, 0.6965, 0.6490],\n",
      "        [0.6747, 0.6736, 0.6731, 0.6270],\n",
      "        [0.6859, 0.6851, 0.6849, 0.6380],\n",
      "        [0.6967, 0.6960, 0.6961, 0.6486],\n",
      "        [0.7132, 0.7128, 0.7134, 0.6649]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0772, 0.0215, 0.0411, 0.0073],\n",
      "        [0.0011, 0.0196, 0.0194, 0.0222],\n",
      "        [0.0327, 0.0042, 0.0336, 0.0198],\n",
      "        [0.0114, 0.0280, 0.0100, 0.0285],\n",
      "        [0.0557, 0.0399, 0.0557, 0.0262],\n",
      "        [0.0475, 0.0649, 0.0325, 0.0115],\n",
      "        [0.1015, 0.0713, 0.0228, 0.0043],\n",
      "        [0.0849, 0.0378, 0.0070, 0.0250],\n",
      "        [0.0416, 0.0118, 0.0252, 0.0378],\n",
      "        [0.0140, 0.0222, 0.0406, 0.0410],\n",
      "        [0.0434, 0.0613, 0.0684, 0.0574],\n",
      "        [0.0515, 0.0574, 0.0537, 0.0324],\n",
      "        [0.0568, 0.0522, 0.0365, 0.0121],\n",
      "        [0.0417, 0.0249, 0.0044, 0.0073],\n",
      "        [0.0555, 0.0348, 0.0267, 0.0505],\n",
      "        [0.0817, 0.0734, 0.0019, 0.0556],\n",
      "        [0.0983, 0.0219, 0.0298, 0.0348],\n",
      "        [0.0020, 0.0519, 0.0541, 0.0377],\n",
      "        [0.0120, 0.0152, 0.0051, 0.0215],\n",
      "        [0.0094, 0.0280, 0.0070, 0.0513],\n",
      "        [0.1400, 0.1563, 0.1543, 0.1246],\n",
      "        [0.0823, 0.0453, 0.0008, 0.0175],\n",
      "        [0.0476, 0.0511, 0.0416, 0.0585],\n",
      "        [0.1258, 0.1404, 0.0941, 0.0368],\n",
      "        [0.1503, 0.1278, 0.1424, 0.0912],\n",
      "        [0.0209, 0.0341, 0.0084, 0.0248],\n",
      "        [0.1099, 0.0872, 0.0495, 0.0062],\n",
      "        [0.0024, 0.0043, 0.0088, 0.0071],\n",
      "        [0.1543, 0.1523, 0.1298, 0.1364],\n",
      "        [0.0612, 0.0863, 0.0340, 0.0293],\n",
      "        [0.0991, 0.0486, 0.0414, 0.0400],\n",
      "        [0.1059, 0.1300, 0.1460, 0.1360],\n",
      "        [0.0029, 0.0176, 0.0055, 0.0399],\n",
      "        [0.0236, 0.0089, 0.0897, 0.1563],\n",
      "        [0.0552, 0.0048, 0.0196, 0.0020],\n",
      "        [0.0156, 0.0075, 0.0460, 0.0244],\n",
      "        [0.0222, 0.0532, 0.0068, 0.0215],\n",
      "        [0.0095, 0.0480, 0.0294, 0.0284],\n",
      "        [0.0500, 0.0314, 0.0337, 0.0269],\n",
      "        [0.1384, 0.0922, 0.0427, 0.1020],\n",
      "        [0.0371, 0.0175, 0.0059, 0.0324],\n",
      "        [0.0232, 0.0226, 0.0443, 0.0615],\n",
      "        [0.0046, 0.0484, 0.0291, 0.0167],\n",
      "        [0.0504, 0.0311, 0.0212, 0.0114],\n",
      "        [0.0331, 0.0232, 0.0088, 0.0139],\n",
      "        [0.0080, 0.0315, 0.0632, 0.0991],\n",
      "        [0.0168, 0.0475, 0.0927, 0.0676],\n",
      "        [0.0048, 0.0203, 0.0513, 0.0095],\n",
      "        [0.0334, 0.0357, 0.0321, 0.0041],\n",
      "        [0.1476, 0.0216, 0.0108, 0.0871],\n",
      "        [0.0361, 0.0098, 0.0365, 0.0440],\n",
      "        [0.0377, 0.0341, 0.0078, 0.0373],\n",
      "        [0.0389, 0.0072, 0.0326, 0.0583],\n",
      "        [0.0467, 0.1144, 0.1062, 0.0621],\n",
      "        [0.1164, 0.1082, 0.0697, 0.1066],\n",
      "        [0.1102, 0.0717, 0.1173, 0.1286],\n",
      "        [0.0117, 0.0345, 0.0436, 0.0206],\n",
      "        [0.0396, 0.0167, 0.0193, 0.0056],\n",
      "        [0.2095, 0.1456, 0.0197, 0.0133],\n",
      "        [0.0902, 0.0447, 0.1124, 0.0963],\n",
      "        [0.0325, 0.0416, 0.0187, 0.0212],\n",
      "        [0.0147, 0.0173, 0.0026, 0.0014],\n",
      "        [0.0624, 0.0352, 0.0571, 0.0696],\n",
      "        [0.0286, 0.0108, 0.0102, 0.0844],\n",
      "        [0.0502, 0.0499, 0.0471, 0.0678],\n",
      "        [0.0423, 0.0432, 0.0262, 0.0219],\n",
      "        [0.0658, 0.0427, 0.0378, 0.0361],\n",
      "        [0.0553, 0.0713, 0.0760, 0.0475],\n",
      "        [0.0709, 0.0658, 0.0702, 0.0731]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module>>\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 28\n",
      "Number of shrink: 21\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0746,     0.0189,     0.0397,     0.0069],\n",
      "        [    0.0042,     0.0165,     0.0213,     0.0218],\n",
      "        [    0.0300,     0.0070,     0.0320,     0.0194],\n",
      "        [    0.0137,     0.0257,     0.0089,     0.0288],\n",
      "        [    0.0533,     0.0375,     0.0545,     0.0259],\n",
      "        [    0.0451,     0.0625,     0.0313,     0.0119],\n",
      "        [    0.1016,     0.0713,     0.0238,     0.0031],\n",
      "        [    0.0849,     0.0377,     0.0079,     0.0242],\n",
      "        [    0.0416,     0.0118,     0.0243,     0.0369],\n",
      "        [    0.0139,     0.0223,     0.0397,     0.0403],\n",
      "        [    0.0438,     0.0618,     0.0679,     0.0566],\n",
      "        [    0.0522,     0.0581,     0.0535,     0.0321],\n",
      "        [    0.0578,     0.0532,     0.0366,     0.0121],\n",
      "        [    0.0420,     0.0252,     0.0038,     0.0078],\n",
      "        [    0.0548,     0.0341,     0.0249,     0.0524],\n",
      "        [    0.0819,     0.0735,     0.0030,     0.0577],\n",
      "        [    0.0993,     0.0229,     0.0301,     0.0366],\n",
      "        [    0.0023,     0.0516,     0.0552,     0.0398],\n",
      "        [    0.0120,     0.0152,     0.0036,     0.0246],\n",
      "        [    0.0086,     0.0272,     0.0046,     0.0470],\n",
      "        [    0.1408,     0.1571,     0.1557,     0.1248],\n",
      "        [    0.0800,     0.0429,     0.0024,     0.0190],\n",
      "        [    0.0522,     0.0558,     0.0449,     0.0596],\n",
      "        [    0.1266,     0.1412,     0.0956,     0.0366],\n",
      "        [    0.1511,     0.1286,     0.1438,     0.0914],\n",
      "        [    0.0171,     0.0302,     0.0058,     0.0263],\n",
      "        [    0.1083,     0.0856,     0.0488,     0.0054],\n",
      "        [    0.0012,     0.0055,     0.0087,     0.0086],\n",
      "        [    0.1551,     0.1531,     0.1312,     0.1366],\n",
      "        [    0.0626,     0.0877,     0.0366,     0.0325],\n",
      "        [    0.1009,     0.0504,     0.0444,     0.0434],\n",
      "        [    0.1053,     0.1294,     0.1460,     0.1351],\n",
      "        [    0.0037,     0.0184,     0.0041,     0.0397],\n",
      "        [    0.0228,     0.0097,     0.0911,     0.1565],\n",
      "        [    0.0544,     0.0057,     0.0210,     0.0018],\n",
      "        [    0.0164,     0.0067,     0.0446,     0.0242],\n",
      "        [    0.0214,     0.0524,     0.0082,     0.0217],\n",
      "        [    0.0086,     0.0472,     0.0280,     0.0282],\n",
      "        [    0.0492,     0.0306,     0.0323,     0.0267],\n",
      "        [    0.1392,     0.0930,     0.0413,     0.1018],\n",
      "        [    0.0361,     0.0165,     0.0061,     0.0332],\n",
      "        [    0.0210,     0.0248,     0.0455,     0.0624],\n",
      "        [    0.0038,     0.0476,     0.0277,     0.0165],\n",
      "        [    0.0496,     0.0303,     0.0198,     0.0116],\n",
      "        [    0.0323,     0.0224,     0.0102,     0.0137],\n",
      "        [    0.0097,     0.0332,     0.0641,     0.1002],\n",
      "        [    0.0179,     0.0487,     0.0930,     0.0684],\n",
      "        [    0.0057,     0.0194,     0.0498,     0.0097],\n",
      "        [    0.0325,     0.0349,     0.0307,     0.0039],\n",
      "        [    0.1468,     0.0208,     0.0123,     0.0873],\n",
      "        [    0.0353,     0.0089,     0.0379,     0.0442],\n",
      "        [    0.0368,     0.0333,     0.0064,     0.0375],\n",
      "        [    0.0376,     0.0058,     0.0306,     0.0573],\n",
      "        [    0.0459,     0.1136,     0.1048,     0.0619],\n",
      "        [    0.1156,     0.1074,     0.0683,     0.1064],\n",
      "        [    0.1094,     0.0709,     0.1158,     0.1284],\n",
      "        [    0.0109,     0.0353,     0.0450,     0.0208],\n",
      "        [    0.0404,     0.0175,     0.0207,     0.0058],\n",
      "        [    0.2087,     0.1448,     0.0182,     0.0135],\n",
      "        [    0.0910,     0.0439,     0.1110,     0.0961],\n",
      "        [    0.0333,     0.0424,     0.0201,     0.0214],\n",
      "        [    0.0155,     0.0182,     0.0040,     0.0016],\n",
      "        [    0.0605,     0.0372,     0.0600,     0.0724],\n",
      "        [    0.0194,     0.0014,     0.0001,     0.0933],\n",
      "        [    0.0427,     0.0424,     0.0558,     0.0758],\n",
      "        [    0.0321,     0.0327,     0.0147,     0.0117],\n",
      "        [    0.0510,     0.0277,     0.0215,     0.0213],\n",
      "        [    0.0370,     0.0526,     0.0559,     0.0290],\n",
      "        [    0.0563,     0.0509,     0.0540,     0.0579]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 24.272995710372925\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 70\n",
      "X 資料 torch.Size([37, 18])\n",
      "Y 資料 torch.Size([37, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.008160719648003578, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.6247, 0.6202, 0.6423, 0.6055])\n",
      "目前模型的Data torch.Size([70, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7732, 0.7740, 0.7751, 0.7218],\n",
      "        [0.7971, 0.7983, 0.8000, 0.7449],\n",
      "        [0.7848, 0.7858, 0.7872, 0.7330],\n",
      "        [0.7924, 0.7935, 0.7951, 0.7404],\n",
      "        [0.7659, 0.7666, 0.7675, 0.7148],\n",
      "        [0.7589, 0.7594, 0.7602, 0.7080],\n",
      "        [0.7204, 0.7202, 0.7200, 0.6708],\n",
      "        [0.7066, 0.7061, 0.7056, 0.6575],\n",
      "        [0.7022, 0.7016, 0.7010, 0.6532],\n",
      "        [0.6996, 0.6990, 0.6982, 0.6507],\n",
      "        [0.7205, 0.7203, 0.7201, 0.6709],\n",
      "        [0.7107, 0.7103, 0.7099, 0.6615],\n",
      "        [0.7100, 0.7096, 0.7091, 0.6608],\n",
      "        [0.6984, 0.6977, 0.6970, 0.6495],\n",
      "        [0.7274, 0.7273, 0.7272, 0.6775],\n",
      "        [0.7750, 0.7758, 0.7770, 0.7236],\n",
      "        [0.8016, 0.8029, 0.8047, 0.7493],\n",
      "        [0.7823, 0.7832, 0.7845, 0.7306],\n",
      "        [0.8228, 0.8245, 0.8269, 0.7698],\n",
      "        [0.8483, 0.8504, 0.8534, 0.7944],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.7022, 0.7016, 0.7009, 0.6532],\n",
      "        [0.8453, 0.8474, 0.8504, 0.7915],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.7745, 0.7753, 0.7764, 0.7230],\n",
      "        [0.6972, 0.6966, 0.6958, 0.6484],\n",
      "        [0.7974, 0.7986, 0.8004, 0.7452],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.7607, 0.7612, 0.7620, 0.7097],\n",
      "        [0.7479, 0.7482, 0.7487, 0.6974],\n",
      "        [0.6383, 0.6366, 0.6343, 0.5915],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6625, 0.6612, 0.6595, 0.6148],\n",
      "        [0.7235, 0.7233, 0.7232, 0.6738],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6874, 0.6866, 0.6855, 0.6389],\n",
      "        [0.6712, 0.6701, 0.6687, 0.6233],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6384, 0.6367, 0.6344, 0.5916],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.6252, 0.6232, 0.6206, 0.5788],\n",
      "        [0.7070, 0.7065, 0.7060, 0.6578],\n",
      "        [0.6499, 0.6483, 0.6464, 0.6026],\n",
      "        [0.6896, 0.6888, 0.6879, 0.6411],\n",
      "        [0.6645, 0.6632, 0.6616, 0.6167],\n",
      "        [0.6712, 0.6700, 0.6686, 0.6232],\n",
      "        [0.6783, 0.6773, 0.6761, 0.6301],\n",
      "        [0.6986, 0.6980, 0.6972, 0.6497],\n",
      "        [0.7249, 0.7248, 0.7247, 0.6752]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0746,     0.0189,     0.0397,     0.0069],\n",
      "        [    0.0042,     0.0165,     0.0213,     0.0218],\n",
      "        [    0.0300,     0.0070,     0.0320,     0.0194],\n",
      "        [    0.0137,     0.0257,     0.0089,     0.0288],\n",
      "        [    0.0533,     0.0375,     0.0545,     0.0259],\n",
      "        [    0.0451,     0.0625,     0.0313,     0.0119],\n",
      "        [    0.1016,     0.0713,     0.0238,     0.0031],\n",
      "        [    0.0849,     0.0377,     0.0079,     0.0242],\n",
      "        [    0.0416,     0.0118,     0.0243,     0.0369],\n",
      "        [    0.0139,     0.0223,     0.0397,     0.0403],\n",
      "        [    0.0438,     0.0618,     0.0679,     0.0566],\n",
      "        [    0.0522,     0.0581,     0.0535,     0.0321],\n",
      "        [    0.0578,     0.0532,     0.0366,     0.0121],\n",
      "        [    0.0420,     0.0252,     0.0038,     0.0078],\n",
      "        [    0.0548,     0.0341,     0.0249,     0.0524],\n",
      "        [    0.0819,     0.0735,     0.0030,     0.0577],\n",
      "        [    0.0993,     0.0229,     0.0301,     0.0366],\n",
      "        [    0.0023,     0.0516,     0.0552,     0.0398],\n",
      "        [    0.0120,     0.0152,     0.0036,     0.0246],\n",
      "        [    0.0086,     0.0272,     0.0046,     0.0470],\n",
      "        [    0.1408,     0.1571,     0.1557,     0.1248],\n",
      "        [    0.0800,     0.0429,     0.0024,     0.0190],\n",
      "        [    0.0522,     0.0558,     0.0449,     0.0596],\n",
      "        [    0.1266,     0.1412,     0.0956,     0.0366],\n",
      "        [    0.1511,     0.1286,     0.1438,     0.0914],\n",
      "        [    0.0171,     0.0302,     0.0058,     0.0263],\n",
      "        [    0.1083,     0.0856,     0.0488,     0.0054],\n",
      "        [    0.0012,     0.0055,     0.0087,     0.0086],\n",
      "        [    0.1551,     0.1531,     0.1312,     0.1366],\n",
      "        [    0.0626,     0.0877,     0.0366,     0.0325],\n",
      "        [    0.1009,     0.0504,     0.0444,     0.0434],\n",
      "        [    0.1053,     0.1294,     0.1460,     0.1351],\n",
      "        [    0.0037,     0.0184,     0.0041,     0.0397],\n",
      "        [    0.0228,     0.0097,     0.0911,     0.1565],\n",
      "        [    0.0544,     0.0057,     0.0210,     0.0018],\n",
      "        [    0.0164,     0.0067,     0.0446,     0.0242],\n",
      "        [    0.0214,     0.0524,     0.0082,     0.0217],\n",
      "        [    0.0086,     0.0472,     0.0280,     0.0282],\n",
      "        [    0.0492,     0.0306,     0.0323,     0.0267],\n",
      "        [    0.1392,     0.0930,     0.0413,     0.1018],\n",
      "        [    0.0361,     0.0165,     0.0061,     0.0332],\n",
      "        [    0.0210,     0.0248,     0.0455,     0.0624],\n",
      "        [    0.0038,     0.0476,     0.0277,     0.0165],\n",
      "        [    0.0496,     0.0303,     0.0198,     0.0116],\n",
      "        [    0.0323,     0.0224,     0.0102,     0.0137],\n",
      "        [    0.0097,     0.0332,     0.0641,     0.1002],\n",
      "        [    0.0179,     0.0487,     0.0930,     0.0684],\n",
      "        [    0.0057,     0.0194,     0.0498,     0.0097],\n",
      "        [    0.0325,     0.0349,     0.0307,     0.0039],\n",
      "        [    0.1468,     0.0208,     0.0123,     0.0873],\n",
      "        [    0.0353,     0.0089,     0.0379,     0.0442],\n",
      "        [    0.0368,     0.0333,     0.0064,     0.0375],\n",
      "        [    0.0376,     0.0058,     0.0306,     0.0573],\n",
      "        [    0.0459,     0.1136,     0.1048,     0.0619],\n",
      "        [    0.1156,     0.1074,     0.0683,     0.1064],\n",
      "        [    0.1094,     0.0709,     0.1158,     0.1284],\n",
      "        [    0.0109,     0.0353,     0.0450,     0.0208],\n",
      "        [    0.0404,     0.0175,     0.0207,     0.0058],\n",
      "        [    0.2087,     0.1448,     0.0182,     0.0135],\n",
      "        [    0.0910,     0.0439,     0.1110,     0.0961],\n",
      "        [    0.0333,     0.0424,     0.0201,     0.0214],\n",
      "        [    0.0155,     0.0182,     0.0040,     0.0016],\n",
      "        [    0.0605,     0.0372,     0.0600,     0.0724],\n",
      "        [    0.0194,     0.0014,     0.0001,     0.0933],\n",
      "        [    0.0427,     0.0424,     0.0558,     0.0758],\n",
      "        [    0.0321,     0.0327,     0.0147,     0.0117],\n",
      "        [    0.0510,     0.0277,     0.0215,     0.0213],\n",
      "        [    0.0370,     0.0526,     0.0559,     0.0290],\n",
      "        [    0.0563,     0.0509,     0.0540,     0.0579],\n",
      "        [    0.1003,     0.1047,     0.0824,     0.0696]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module>>\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 34\n",
      "Number of shrink: 24\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0745,     0.0187,     0.0395,     0.0072],\n",
      "        [    0.0053,     0.0154,     0.0225,     0.0215],\n",
      "        [    0.0285,     0.0085,     0.0305,     0.0187],\n",
      "        [    0.0153,     0.0240,     0.0072,     0.0280],\n",
      "        [    0.0510,     0.0351,     0.0520,     0.0240],\n",
      "        [    0.0420,     0.0593,     0.0280,     0.0147],\n",
      "        [    0.1010,     0.0707,     0.0232,     0.0041],\n",
      "        [    0.0837,     0.0365,     0.0066,     0.0260],\n",
      "        [    0.0400,     0.0101,     0.0260,     0.0392],\n",
      "        [    0.0120,     0.0242,     0.0417,     0.0428],\n",
      "        [    0.0461,     0.0641,     0.0703,     0.0593],\n",
      "        [    0.0549,     0.0608,     0.0563,     0.0352],\n",
      "        [    0.0607,     0.0562,     0.0396,     0.0154],\n",
      "        [    0.0449,     0.0281,     0.0068,     0.0042],\n",
      "        [    0.0567,     0.0361,     0.0269,     0.0503],\n",
      "        [    0.0835,     0.0751,     0.0014,     0.0566],\n",
      "        [    0.1008,     0.0244,     0.0286,     0.0360],\n",
      "        [    0.0031,     0.0508,     0.0543,     0.0396],\n",
      "        [    0.0115,     0.0147,     0.0042,     0.0254],\n",
      "        [    0.0071,     0.0257,     0.0031,     0.0440],\n",
      "        [    0.1410,     0.1573,     0.1560,     0.1230],\n",
      "        [    0.0772,     0.0401,     0.0053,     0.0223],\n",
      "        [    0.0559,     0.0595,     0.0487,     0.0614],\n",
      "        [    0.1269,     0.1414,     0.0958,     0.0384],\n",
      "        [    0.1514,     0.1288,     0.1440,     0.0897],\n",
      "        [    0.0135,     0.0265,     0.0019,     0.0293],\n",
      "        [    0.1067,     0.0840,     0.0471,     0.0031],\n",
      "        [    0.0004,     0.0063,     0.0096,     0.0087],\n",
      "        [    0.1553,     0.1534,     0.1314,     0.1348],\n",
      "        [    0.0634,     0.0885,     0.0375,     0.0336],\n",
      "        [    0.1021,     0.0516,     0.0456,     0.0445],\n",
      "        [    0.1011,     0.1251,     0.1416,     0.1293],\n",
      "        [    0.0039,     0.0186,     0.0038,     0.0414],\n",
      "        [    0.0226,     0.0099,     0.0914,     0.1548],\n",
      "        [    0.0541,     0.0059,     0.0212,     0.0035],\n",
      "        [    0.0166,     0.0064,     0.0443,     0.0259],\n",
      "        [    0.0211,     0.0521,     0.0085,     0.0199],\n",
      "        [    0.0084,     0.0469,     0.0277,     0.0299],\n",
      "        [    0.0489,     0.0303,     0.0320,     0.0285],\n",
      "        [    0.1394,     0.0932,     0.0410,     0.1036],\n",
      "        [    0.0351,     0.0155,     0.0072,     0.0355],\n",
      "        [    0.0191,     0.0267,     0.0476,     0.0646],\n",
      "        [    0.0035,     0.0473,     0.0274,     0.0183],\n",
      "        [    0.0493,     0.0300,     0.0196,     0.0099],\n",
      "        [    0.0320,     0.0221,     0.0105,     0.0155],\n",
      "        [    0.0114,     0.0349,     0.0658,     0.1027],\n",
      "        [    0.0200,     0.0508,     0.0952,     0.0716],\n",
      "        [    0.0046,     0.0204,     0.0509,     0.0068],\n",
      "        [    0.0323,     0.0346,     0.0304,     0.0057],\n",
      "        [    0.1465,     0.0206,     0.0125,     0.0855],\n",
      "        [    0.0350,     0.0087,     0.0381,     0.0424],\n",
      "        [    0.0366,     0.0330,     0.0061,     0.0357],\n",
      "        [    0.0383,     0.0065,     0.0313,     0.0598],\n",
      "        [    0.0456,     0.1133,     0.1046,     0.0637],\n",
      "        [    0.1153,     0.1072,     0.0681,     0.1081],\n",
      "        [    0.1092,     0.0707,     0.1156,     0.1301],\n",
      "        [    0.0107,     0.0355,     0.0453,     0.0191],\n",
      "        [    0.0407,     0.0178,     0.0210,     0.0041],\n",
      "        [    0.2085,     0.1445,     0.0180,     0.0117],\n",
      "        [    0.0912,     0.0436,     0.1107,     0.0978],\n",
      "        [    0.0335,     0.0427,     0.0204,     0.0197],\n",
      "        [    0.0158,     0.0184,     0.0043,     0.0002],\n",
      "        [    0.0603,     0.0373,     0.0602,     0.0719],\n",
      "        [    0.0122,     0.0059,     0.0077,     0.0986],\n",
      "        [    0.0371,     0.0366,     0.0617,     0.0802],\n",
      "        [    0.0236,     0.0241,     0.0058,     0.0050],\n",
      "        [    0.0374,     0.0138,     0.0073,     0.0096],\n",
      "        [    0.0203,     0.0357,     0.0386,     0.0143],\n",
      "        [    0.0433,     0.0377,     0.0405,     0.0463],\n",
      "        [    0.0853,     0.0894,     0.0668,     0.0558]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 24.782801866531372\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 71\n",
      "X 資料 torch.Size([36, 18])\n",
      "Y 資料 torch.Size([36, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.007402294315397739, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.6471, 0.6432, 0.6324, 0.5900])\n",
      "目前模型的Data torch.Size([71, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7734, 0.7742, 0.7753, 0.7216],\n",
      "        [0.7982, 0.7994, 0.8012, 0.7452],\n",
      "        [0.7863, 0.7873, 0.7887, 0.7338],\n",
      "        [0.7941, 0.7952, 0.7969, 0.7412],\n",
      "        [0.7683, 0.7689, 0.7699, 0.7167],\n",
      "        [0.7621, 0.7626, 0.7635, 0.7108],\n",
      "        [0.7210, 0.7208, 0.7206, 0.6718],\n",
      "        [0.7078, 0.7073, 0.7068, 0.6592],\n",
      "        [0.7038, 0.7033, 0.7027, 0.6555],\n",
      "        [0.7014, 0.7009, 0.7002, 0.6532],\n",
      "        [0.7228, 0.7226, 0.7225, 0.6735],\n",
      "        [0.7134, 0.7130, 0.7126, 0.6645],\n",
      "        [0.7129, 0.7126, 0.7122, 0.6641],\n",
      "        [0.7012, 0.7006, 0.7000, 0.6530],\n",
      "        [0.7293, 0.7292, 0.7292, 0.6796],\n",
      "        [0.7766, 0.7774, 0.7787, 0.7246],\n",
      "        [0.8031, 0.8044, 0.8063, 0.7498],\n",
      "        [0.7831, 0.7840, 0.7854, 0.7308],\n",
      "        [0.8233, 0.8250, 0.8274, 0.7690],\n",
      "        [0.8468, 0.8489, 0.8519, 0.7913],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.7050, 0.7044, 0.7039, 0.6566],\n",
      "        [0.8490, 0.8511, 0.8542, 0.7934],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.7782, 0.7790, 0.7803, 0.7261],\n",
      "        [0.6988, 0.6981, 0.6974, 0.6507],\n",
      "        [0.7982, 0.7994, 0.8012, 0.7452],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.7598, 0.7603, 0.7611, 0.7087],\n",
      "        [0.7468, 0.7471, 0.7475, 0.6963],\n",
      "        [0.6426, 0.6409, 0.6388, 0.5973],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6634, 0.6622, 0.6605, 0.6171],\n",
      "        [0.7254, 0.7253, 0.7253, 0.6760],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6890, 0.6882, 0.6873, 0.6414],\n",
      "        [0.6733, 0.6722, 0.6709, 0.6265],\n",
      "        [0.6262, 0.6243, 0.6217, 0.5818],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6391, 0.6374, 0.6351, 0.5940],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.6250, 0.6230, 0.6204, 0.5806],\n",
      "        [0.7068, 0.7063, 0.7058, 0.6583],\n",
      "        [0.6426, 0.6410, 0.6388, 0.5973],\n",
      "        [0.6840, 0.6831, 0.6820, 0.6367],\n",
      "        [0.6560, 0.6545, 0.6527, 0.6100],\n",
      "        [0.6575, 0.6561, 0.6544, 0.6115],\n",
      "        [0.6617, 0.6604, 0.6587, 0.6154],\n",
      "        [0.6856, 0.6847, 0.6837, 0.6381],\n",
      "        [0.7100, 0.7095, 0.7091, 0.6613],\n",
      "        [0.7265, 0.7264, 0.7263, 0.6770]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0745,     0.0187,     0.0395,     0.0072],\n",
      "        [    0.0053,     0.0154,     0.0225,     0.0215],\n",
      "        [    0.0285,     0.0085,     0.0305,     0.0187],\n",
      "        [    0.0153,     0.0240,     0.0072,     0.0280],\n",
      "        [    0.0510,     0.0351,     0.0520,     0.0240],\n",
      "        [    0.0420,     0.0593,     0.0280,     0.0147],\n",
      "        [    0.1010,     0.0707,     0.0232,     0.0041],\n",
      "        [    0.0837,     0.0365,     0.0066,     0.0260],\n",
      "        [    0.0400,     0.0101,     0.0260,     0.0392],\n",
      "        [    0.0120,     0.0242,     0.0417,     0.0428],\n",
      "        [    0.0461,     0.0641,     0.0703,     0.0593],\n",
      "        [    0.0549,     0.0608,     0.0563,     0.0352],\n",
      "        [    0.0607,     0.0562,     0.0396,     0.0154],\n",
      "        [    0.0449,     0.0281,     0.0068,     0.0042],\n",
      "        [    0.0567,     0.0361,     0.0269,     0.0503],\n",
      "        [    0.0835,     0.0751,     0.0014,     0.0566],\n",
      "        [    0.1008,     0.0244,     0.0286,     0.0360],\n",
      "        [    0.0031,     0.0508,     0.0543,     0.0396],\n",
      "        [    0.0115,     0.0147,     0.0042,     0.0254],\n",
      "        [    0.0071,     0.0257,     0.0031,     0.0440],\n",
      "        [    0.1410,     0.1573,     0.1560,     0.1230],\n",
      "        [    0.0772,     0.0401,     0.0053,     0.0223],\n",
      "        [    0.0559,     0.0595,     0.0487,     0.0614],\n",
      "        [    0.1269,     0.1414,     0.0958,     0.0384],\n",
      "        [    0.1514,     0.1288,     0.1440,     0.0897],\n",
      "        [    0.0135,     0.0265,     0.0019,     0.0293],\n",
      "        [    0.1067,     0.0840,     0.0471,     0.0031],\n",
      "        [    0.0004,     0.0063,     0.0096,     0.0087],\n",
      "        [    0.1553,     0.1534,     0.1314,     0.1348],\n",
      "        [    0.0634,     0.0885,     0.0375,     0.0336],\n",
      "        [    0.1021,     0.0516,     0.0456,     0.0445],\n",
      "        [    0.1011,     0.1251,     0.1416,     0.1293],\n",
      "        [    0.0039,     0.0186,     0.0038,     0.0414],\n",
      "        [    0.0226,     0.0099,     0.0914,     0.1548],\n",
      "        [    0.0541,     0.0059,     0.0212,     0.0035],\n",
      "        [    0.0166,     0.0064,     0.0443,     0.0259],\n",
      "        [    0.0211,     0.0521,     0.0085,     0.0199],\n",
      "        [    0.0084,     0.0469,     0.0277,     0.0299],\n",
      "        [    0.0489,     0.0303,     0.0320,     0.0285],\n",
      "        [    0.1394,     0.0932,     0.0410,     0.1036],\n",
      "        [    0.0351,     0.0155,     0.0072,     0.0355],\n",
      "        [    0.0191,     0.0267,     0.0476,     0.0646],\n",
      "        [    0.0035,     0.0473,     0.0274,     0.0183],\n",
      "        [    0.0493,     0.0300,     0.0196,     0.0099],\n",
      "        [    0.0320,     0.0221,     0.0105,     0.0155],\n",
      "        [    0.0114,     0.0349,     0.0658,     0.1027],\n",
      "        [    0.0200,     0.0508,     0.0952,     0.0716],\n",
      "        [    0.0046,     0.0204,     0.0509,     0.0068],\n",
      "        [    0.0323,     0.0346,     0.0304,     0.0057],\n",
      "        [    0.1465,     0.0206,     0.0125,     0.0855],\n",
      "        [    0.0350,     0.0087,     0.0381,     0.0424],\n",
      "        [    0.0366,     0.0330,     0.0061,     0.0357],\n",
      "        [    0.0383,     0.0065,     0.0313,     0.0598],\n",
      "        [    0.0456,     0.1133,     0.1046,     0.0637],\n",
      "        [    0.1153,     0.1072,     0.0681,     0.1081],\n",
      "        [    0.1092,     0.0707,     0.1156,     0.1301],\n",
      "        [    0.0107,     0.0355,     0.0453,     0.0191],\n",
      "        [    0.0407,     0.0178,     0.0210,     0.0041],\n",
      "        [    0.2085,     0.1445,     0.0180,     0.0117],\n",
      "        [    0.0912,     0.0436,     0.1107,     0.0978],\n",
      "        [    0.0335,     0.0427,     0.0204,     0.0197],\n",
      "        [    0.0158,     0.0184,     0.0043,     0.0002],\n",
      "        [    0.0603,     0.0373,     0.0602,     0.0719],\n",
      "        [    0.0122,     0.0059,     0.0077,     0.0986],\n",
      "        [    0.0371,     0.0366,     0.0617,     0.0802],\n",
      "        [    0.0236,     0.0241,     0.0058,     0.0050],\n",
      "        [    0.0374,     0.0138,     0.0073,     0.0096],\n",
      "        [    0.0203,     0.0357,     0.0386,     0.0143],\n",
      "        [    0.0433,     0.0377,     0.0405,     0.0463],\n",
      "        [    0.0853,     0.0894,     0.0668,     0.0558],\n",
      "        [    0.0794,     0.0832,     0.0939,     0.0870]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module>>\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 26\n",
      "Number of shrink: 20\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0750,     0.0193,     0.0398,     0.0087],\n",
      "        [    0.0052,     0.0155,     0.0225,     0.0228],\n",
      "        [    0.0291,     0.0080,     0.0309,     0.0203],\n",
      "        [    0.0145,     0.0248,     0.0079,     0.0299],\n",
      "        [    0.0513,     0.0355,     0.0522,     0.0254],\n",
      "        [    0.0420,     0.0594,     0.0278,     0.0137],\n",
      "        [    0.1025,     0.0723,     0.0245,     0.0019],\n",
      "        [    0.0852,     0.0380,     0.0078,     0.0240],\n",
      "        [    0.0413,     0.0115,     0.0250,     0.0374],\n",
      "        [    0.0133,     0.0229,     0.0408,     0.0411],\n",
      "        [    0.0457,     0.0637,     0.0702,     0.0582],\n",
      "        [    0.0548,     0.0608,     0.0566,     0.0345],\n",
      "        [    0.0611,     0.0566,     0.0404,     0.0151],\n",
      "        [    0.0452,     0.0285,     0.0076,     0.0044],\n",
      "        [    0.0564,     0.0358,     0.0269,     0.0513],\n",
      "        [    0.0834,     0.0751,     0.0012,     0.0578],\n",
      "        [    0.1010,     0.0246,     0.0282,     0.0371],\n",
      "        [    0.0026,     0.0512,     0.0545,     0.0411],\n",
      "        [    0.0122,     0.0154,     0.0035,     0.0274],\n",
      "        [    0.0046,     0.0232,     0.0005,     0.0401],\n",
      "        [    0.1410,     0.1574,     0.1554,     0.1231],\n",
      "        [    0.0756,     0.0384,     0.0074,     0.0233],\n",
      "        [    0.0574,     0.0611,     0.0503,     0.0613],\n",
      "        [    0.1269,     0.1415,     0.0952,     0.0383],\n",
      "        [    0.1514,     0.1289,     0.1435,     0.0897],\n",
      "        [    0.0115,     0.0245,     0.0003,     0.0301],\n",
      "        [    0.1057,     0.0830,     0.0456,     0.0026],\n",
      "        [    0.0009,     0.0058,     0.0092,     0.0103],\n",
      "        [    0.1554,     0.1534,     0.1309,     0.1348],\n",
      "        [    0.0656,     0.0907,     0.0395,     0.0365],\n",
      "        [    0.1044,     0.0540,     0.0478,     0.0476],\n",
      "        [    0.0996,     0.1235,     0.1394,     0.1280],\n",
      "        [    0.0039,     0.0187,     0.0044,     0.0414],\n",
      "        [    0.0225,     0.0099,     0.0908,     0.1548],\n",
      "        [    0.0541,     0.0059,     0.0207,     0.0035],\n",
      "        [    0.0167,     0.0064,     0.0449,     0.0259],\n",
      "        [    0.0211,     0.0521,     0.0079,     0.0199],\n",
      "        [    0.0084,     0.0469,     0.0283,     0.0299],\n",
      "        [    0.0489,     0.0303,     0.0326,     0.0284],\n",
      "        [    0.1395,     0.0932,     0.0416,     0.1036],\n",
      "        [    0.0343,     0.0147,     0.0085,     0.0360],\n",
      "        [    0.0180,     0.0279,     0.0490,     0.0649],\n",
      "        [    0.0035,     0.0473,     0.0280,     0.0182],\n",
      "        [    0.0493,     0.0300,     0.0201,     0.0099],\n",
      "        [    0.0320,     0.0221,     0.0099,     0.0154],\n",
      "        [    0.0128,     0.0364,     0.0678,     0.1037],\n",
      "        [    0.0215,     0.0523,     0.0973,     0.0727],\n",
      "        [    0.0049,     0.0202,     0.0512,     0.0070],\n",
      "        [    0.0323,     0.0346,     0.0310,     0.0057],\n",
      "        [    0.1465,     0.0206,     0.0119,     0.0856],\n",
      "        [    0.0350,     0.0087,     0.0376,     0.0424],\n",
      "        [    0.0366,     0.0330,     0.0067,     0.0357],\n",
      "        [    0.0375,     0.0057,     0.0310,     0.0589],\n",
      "        [    0.0456,     0.1133,     0.1051,     0.0637],\n",
      "        [    0.1153,     0.1071,     0.0686,     0.1081],\n",
      "        [    0.1091,     0.0706,     0.1162,     0.1301],\n",
      "        [    0.0107,     0.0356,     0.0447,     0.0191],\n",
      "        [    0.0407,     0.0178,     0.0204,     0.0041],\n",
      "        [    0.2085,     0.1445,     0.0186,     0.0118],\n",
      "        [    0.0905,     0.0443,     0.1120,     0.0985],\n",
      "        [    0.0336,     0.0427,     0.0198,     0.0197],\n",
      "        [    0.0158,     0.0184,     0.0037,     0.0002],\n",
      "        [    0.0587,     0.0390,     0.0615,     0.0741],\n",
      "        [    0.0045,     0.0138,     0.0151,     0.1060],\n",
      "        [    0.0308,     0.0302,     0.0678,     0.0866],\n",
      "        [    0.0147,     0.0150,     0.0029,     0.0036],\n",
      "        [    0.0244,     0.0006,     0.0057,     0.0029],\n",
      "        [    0.0046,     0.0197,     0.0227,     0.0008],\n",
      "        [    0.0302,     0.0244,     0.0273,     0.0336],\n",
      "        [    0.0713,     0.0752,     0.0526,     0.0420],\n",
      "        [    0.0674,     0.0709,     0.0818,     0.0749]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 25.254212856292725\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 72\n",
      "X 資料 torch.Size([35, 18])\n",
      "Y 資料 torch.Size([35, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0058331843465566635, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.6432, 0.6324, 0.6305, 0.6054])\n",
      "目前模型的Data torch.Size([72, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7729, 0.7736, 0.7750, 0.7201],\n",
      "        [0.7981, 0.7993, 0.8012, 0.7438],\n",
      "        [0.7857, 0.7867, 0.7884, 0.7322],\n",
      "        [0.7933, 0.7944, 0.7962, 0.7393],\n",
      "        [0.7679, 0.7686, 0.7698, 0.7153],\n",
      "        [0.7620, 0.7626, 0.7637, 0.7098],\n",
      "        [0.7194, 0.7192, 0.7193, 0.6696],\n",
      "        [0.7063, 0.7058, 0.7056, 0.6573],\n",
      "        [0.7025, 0.7020, 0.7017, 0.6537],\n",
      "        [0.7002, 0.6996, 0.6993, 0.6515],\n",
      "        [0.7224, 0.7222, 0.7224, 0.6724],\n",
      "        [0.7133, 0.7130, 0.7130, 0.6639],\n",
      "        [0.7133, 0.7129, 0.7129, 0.6638],\n",
      "        [0.7016, 0.7010, 0.7008, 0.6528],\n",
      "        [0.7290, 0.7289, 0.7293, 0.6786],\n",
      "        [0.7766, 0.7774, 0.7788, 0.7235],\n",
      "        [0.8033, 0.8046, 0.8066, 0.7487],\n",
      "        [0.7827, 0.7836, 0.7852, 0.7293],\n",
      "        [0.8226, 0.8243, 0.8268, 0.7670],\n",
      "        [0.8443, 0.8464, 0.8494, 0.7874],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.7066, 0.7061, 0.7060, 0.6575],\n",
      "        [0.8505, 0.8527, 0.8558, 0.7933],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.7801, 0.7810, 0.7825, 0.7268],\n",
      "        [0.6998, 0.6992, 0.6989, 0.6511],\n",
      "        [0.7977, 0.7990, 0.8008, 0.7435],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.7577, 0.7581, 0.7591, 0.7057],\n",
      "        [0.7444, 0.7447, 0.7454, 0.6932],\n",
      "        [0.6441, 0.6425, 0.6409, 0.5986],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6643, 0.6630, 0.6619, 0.6176],\n",
      "        [0.7266, 0.7264, 0.7267, 0.6764],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6905, 0.6897, 0.6892, 0.6424],\n",
      "        [0.6748, 0.6738, 0.6729, 0.6276],\n",
      "        [0.6260, 0.6240, 0.6221, 0.5815],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6383, 0.6366, 0.6349, 0.5931],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6257, 0.6237, 0.6217, 0.5812],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.6249, 0.6230, 0.6210, 0.5805],\n",
      "        [0.7052, 0.7047, 0.7045, 0.6562],\n",
      "        [0.6350, 0.6331, 0.6314, 0.5900],\n",
      "        [0.6777, 0.6767, 0.6758, 0.6302],\n",
      "        [0.6471, 0.6455, 0.6440, 0.6014],\n",
      "        [0.6445, 0.6429, 0.6414, 0.5990],\n",
      "        [0.6460, 0.6444, 0.6428, 0.6004],\n",
      "        [0.6725, 0.6714, 0.6705, 0.6254],\n",
      "        [0.6960, 0.6953, 0.6949, 0.6475],\n",
      "        [0.7145, 0.7141, 0.7141, 0.6649],\n",
      "        [0.7162, 0.7159, 0.7159, 0.6666]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0750,     0.0193,     0.0398,     0.0087],\n",
      "        [    0.0052,     0.0155,     0.0225,     0.0228],\n",
      "        [    0.0291,     0.0080,     0.0309,     0.0203],\n",
      "        [    0.0145,     0.0248,     0.0079,     0.0299],\n",
      "        [    0.0513,     0.0355,     0.0522,     0.0254],\n",
      "        [    0.0420,     0.0594,     0.0278,     0.0137],\n",
      "        [    0.1025,     0.0723,     0.0245,     0.0019],\n",
      "        [    0.0852,     0.0380,     0.0078,     0.0240],\n",
      "        [    0.0413,     0.0115,     0.0250,     0.0374],\n",
      "        [    0.0133,     0.0229,     0.0408,     0.0411],\n",
      "        [    0.0457,     0.0637,     0.0702,     0.0582],\n",
      "        [    0.0548,     0.0608,     0.0566,     0.0345],\n",
      "        [    0.0611,     0.0566,     0.0404,     0.0151],\n",
      "        [    0.0452,     0.0285,     0.0076,     0.0044],\n",
      "        [    0.0564,     0.0358,     0.0269,     0.0513],\n",
      "        [    0.0834,     0.0751,     0.0012,     0.0578],\n",
      "        [    0.1010,     0.0246,     0.0282,     0.0371],\n",
      "        [    0.0026,     0.0512,     0.0545,     0.0411],\n",
      "        [    0.0122,     0.0154,     0.0035,     0.0274],\n",
      "        [    0.0046,     0.0232,     0.0005,     0.0401],\n",
      "        [    0.1410,     0.1574,     0.1554,     0.1231],\n",
      "        [    0.0756,     0.0384,     0.0074,     0.0233],\n",
      "        [    0.0574,     0.0611,     0.0503,     0.0613],\n",
      "        [    0.1269,     0.1415,     0.0952,     0.0383],\n",
      "        [    0.1514,     0.1289,     0.1435,     0.0897],\n",
      "        [    0.0115,     0.0245,     0.0003,     0.0301],\n",
      "        [    0.1057,     0.0830,     0.0456,     0.0026],\n",
      "        [    0.0009,     0.0058,     0.0092,     0.0103],\n",
      "        [    0.1554,     0.1534,     0.1309,     0.1348],\n",
      "        [    0.0656,     0.0907,     0.0395,     0.0365],\n",
      "        [    0.1044,     0.0540,     0.0478,     0.0476],\n",
      "        [    0.0996,     0.1235,     0.1394,     0.1280],\n",
      "        [    0.0039,     0.0187,     0.0044,     0.0414],\n",
      "        [    0.0225,     0.0099,     0.0908,     0.1548],\n",
      "        [    0.0541,     0.0059,     0.0207,     0.0035],\n",
      "        [    0.0167,     0.0064,     0.0449,     0.0259],\n",
      "        [    0.0211,     0.0521,     0.0079,     0.0199],\n",
      "        [    0.0084,     0.0469,     0.0283,     0.0299],\n",
      "        [    0.0489,     0.0303,     0.0326,     0.0284],\n",
      "        [    0.1395,     0.0932,     0.0416,     0.1036],\n",
      "        [    0.0343,     0.0147,     0.0085,     0.0360],\n",
      "        [    0.0180,     0.0279,     0.0490,     0.0649],\n",
      "        [    0.0035,     0.0473,     0.0280,     0.0182],\n",
      "        [    0.0493,     0.0300,     0.0201,     0.0099],\n",
      "        [    0.0320,     0.0221,     0.0099,     0.0154],\n",
      "        [    0.0128,     0.0364,     0.0678,     0.1037],\n",
      "        [    0.0215,     0.0523,     0.0973,     0.0727],\n",
      "        [    0.0049,     0.0202,     0.0512,     0.0070],\n",
      "        [    0.0323,     0.0346,     0.0310,     0.0057],\n",
      "        [    0.1465,     0.0206,     0.0119,     0.0856],\n",
      "        [    0.0350,     0.0087,     0.0376,     0.0424],\n",
      "        [    0.0366,     0.0330,     0.0067,     0.0357],\n",
      "        [    0.0375,     0.0057,     0.0310,     0.0589],\n",
      "        [    0.0456,     0.1133,     0.1051,     0.0637],\n",
      "        [    0.1153,     0.1071,     0.0686,     0.1081],\n",
      "        [    0.1091,     0.0706,     0.1162,     0.1301],\n",
      "        [    0.0107,     0.0356,     0.0447,     0.0191],\n",
      "        [    0.0407,     0.0178,     0.0204,     0.0041],\n",
      "        [    0.2085,     0.1445,     0.0186,     0.0118],\n",
      "        [    0.0905,     0.0443,     0.1120,     0.0985],\n",
      "        [    0.0336,     0.0427,     0.0198,     0.0197],\n",
      "        [    0.0158,     0.0184,     0.0037,     0.0002],\n",
      "        [    0.0587,     0.0390,     0.0615,     0.0741],\n",
      "        [    0.0045,     0.0138,     0.0151,     0.1060],\n",
      "        [    0.0308,     0.0302,     0.0678,     0.0866],\n",
      "        [    0.0147,     0.0150,     0.0029,     0.0036],\n",
      "        [    0.0244,     0.0006,     0.0057,     0.0029],\n",
      "        [    0.0046,     0.0197,     0.0227,     0.0008],\n",
      "        [    0.0302,     0.0244,     0.0273,     0.0336],\n",
      "        [    0.0713,     0.0752,     0.0526,     0.0420],\n",
      "        [    0.0674,     0.0709,     0.0818,     0.0749],\n",
      "        [    0.0730,     0.0835,     0.0855,     0.0611]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 44\n",
      "Number of shrink: 29\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module>>\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 33\n",
      "Number of shrink: 24\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "看一下 hidden node\n",
      "tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0747,     0.0196,     0.0410,     0.0092],\n",
      "        [    0.0053,     0.0161,     0.0209,     0.0237],\n",
      "        [    0.0296,     0.0068,     0.0330,     0.0216],\n",
      "        [    0.0138,     0.0264,     0.0103,     0.0316],\n",
      "        [    0.0520,     0.0368,     0.0542,     0.0266],\n",
      "        [    0.0428,     0.0607,     0.0299,     0.0124],\n",
      "        [    0.1038,     0.0739,     0.0265,     0.0006],\n",
      "        [    0.0867,     0.0397,     0.0099,     0.0226],\n",
      "        [    0.0424,     0.0129,     0.0234,     0.0364],\n",
      "        [    0.0145,     0.0214,     0.0390,     0.0401],\n",
      "        [    0.0453,     0.0630,     0.0691,     0.0577],\n",
      "        [    0.0548,     0.0605,     0.0560,     0.0344],\n",
      "        [    0.0612,     0.0564,     0.0399,     0.0152],\n",
      "        [    0.0453,     0.0284,     0.0072,     0.0043],\n",
      "        [    0.0562,     0.0351,     0.0259,     0.0518],\n",
      "        [    0.0836,     0.0747,     0.0024,     0.0583],\n",
      "        [    0.1014,     0.0242,     0.0296,     0.0378],\n",
      "        [    0.0027,     0.0518,     0.0560,     0.0419],\n",
      "        [    0.0124,     0.0165,     0.0012,     0.0289],\n",
      "        [    0.0036,     0.0211,     0.0029,     0.0376],\n",
      "        [    0.1409,     0.1569,     0.1547,     0.1220],\n",
      "        [    0.0745,     0.0376,     0.0079,     0.0243],\n",
      "        [    0.0580,     0.0607,     0.0485,     0.0603],\n",
      "        [    0.1267,     0.1411,     0.0945,     0.0394],\n",
      "        [    0.1513,     0.1285,     0.1428,     0.0886],\n",
      "        [    0.0104,     0.0240,     0.0000,     0.0303],\n",
      "        [    0.1046,     0.0820,     0.0449,     0.0015],\n",
      "        [    0.0005,     0.0055,     0.0080,     0.0109],\n",
      "        [    0.1552,     0.1530,     0.1302,     0.1338],\n",
      "        [    0.0665,     0.0921,     0.0416,     0.0379],\n",
      "        [    0.1052,     0.0552,     0.0496,     0.0487],\n",
      "        [    0.1026,     0.1265,     0.1423,     0.1301],\n",
      "        [    0.0038,     0.0183,     0.0051,     0.0425],\n",
      "        [    0.0227,     0.0095,     0.0901,     0.1537],\n",
      "        [    0.0542,     0.0055,     0.0200,     0.0046],\n",
      "        [    0.0165,     0.0068,     0.0456,     0.0270],\n",
      "        [    0.0213,     0.0525,     0.0072,     0.0188],\n",
      "        [    0.0085,     0.0473,     0.0290,     0.0310],\n",
      "        [    0.0490,     0.0307,     0.0333,     0.0295],\n",
      "        [    0.1393,     0.0928,     0.0423,     0.1047],\n",
      "        [    0.0333,     0.0137,     0.0096,     0.0375],\n",
      "        [    0.0174,     0.0282,     0.0489,     0.0653],\n",
      "        [    0.0036,     0.0477,     0.0287,     0.0193],\n",
      "        [    0.0494,     0.0304,     0.0208,     0.0088],\n",
      "        [    0.0321,     0.0225,     0.0092,     0.0165],\n",
      "        [    0.0141,     0.0376,     0.0688,     0.1051],\n",
      "        [    0.0223,     0.0532,     0.0980,     0.0739],\n",
      "        [    0.0058,     0.0195,     0.0508,     0.0069],\n",
      "        [    0.0324,     0.0350,     0.0317,     0.0067],\n",
      "        [    0.1466,     0.0210,     0.0112,     0.0845],\n",
      "        [    0.0351,     0.0091,     0.0368,     0.0413],\n",
      "        [    0.0367,     0.0334,     0.0074,     0.0346],\n",
      "        [    0.0362,     0.0046,     0.0301,     0.0586],\n",
      "        [    0.0457,     0.1137,     0.1058,     0.0647],\n",
      "        [    0.1154,     0.1075,     0.0693,     0.1092],\n",
      "        [    0.1093,     0.0710,     0.1169,     0.1312],\n",
      "        [    0.0108,     0.0351,     0.0440,     0.0180],\n",
      "        [    0.0406,     0.0174,     0.0197,     0.0030],\n",
      "        [    0.2086,     0.1449,     0.0193,     0.0107],\n",
      "        [    0.0911,     0.0440,     0.1120,     0.0989],\n",
      "        [    0.0334,     0.0423,     0.0191,     0.0186],\n",
      "        [    0.0157,     0.0180,     0.0030,     0.0013],\n",
      "        [    0.0545,     0.0434,     0.0663,     0.0779],\n",
      "        [    0.0024,     0.0206,     0.0218,     0.1116],\n",
      "        [    0.0243,     0.0236,     0.0745,     0.0922],\n",
      "        [    0.0070,     0.0073,     0.0106,     0.0101],\n",
      "        [    0.0148,     0.0089,     0.0152,     0.0111],\n",
      "        [    0.0070,     0.0081,     0.0110,     0.0109],\n",
      "        [    0.0201,     0.0141,     0.0168,     0.0246],\n",
      "        [    0.0613,     0.0648,     0.0419,     0.0328],\n",
      "        [    0.0570,     0.0601,     0.0705,     0.0652],\n",
      "        [    0.0630,     0.0731,     0.0745,     0.0518]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 25.7155544757843\n",
      "------------------------------------------------------------------------------------------\n",
      "確認threshold_for_error: 0.21468441391155002\n",
      "現在訓練到第幾筆資料: 73\n",
      "X 資料 torch.Size([34, 18])\n",
      "Y 資料 torch.Size([34, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.019275803118944168, 14)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引14，y= tensor([0.6329, 0.7118, 0.7857, 0.7873])\n",
      "目前模型的Data torch.Size([73, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.7731, 0.7733, 0.7738, 0.7196],\n",
      "        [0.7982, 0.7987, 0.7996, 0.7430],\n",
      "        [0.7852, 0.7855, 0.7863, 0.7309],\n",
      "        [0.7925, 0.7929, 0.7937, 0.7376],\n",
      "        [0.7672, 0.7673, 0.7677, 0.7141],\n",
      "        [0.7612, 0.7612, 0.7616, 0.7085],\n",
      "        [0.7181, 0.7176, 0.7173, 0.6683],\n",
      "        [0.7048, 0.7041, 0.7036, 0.6559],\n",
      "        [0.7014, 0.7006, 0.7001, 0.6527],\n",
      "        [0.6989, 0.6981, 0.6976, 0.6504],\n",
      "        [0.7220, 0.7215, 0.7213, 0.6719],\n",
      "        [0.7133, 0.7127, 0.7123, 0.6638],\n",
      "        [0.7134, 0.7128, 0.7124, 0.6639],\n",
      "        [0.7017, 0.7009, 0.7004, 0.6530],\n",
      "        [0.7287, 0.7283, 0.7282, 0.6782],\n",
      "        [0.7768, 0.7770, 0.7776, 0.7230],\n",
      "        [0.8037, 0.8043, 0.8053, 0.7481],\n",
      "        [0.7827, 0.7830, 0.7837, 0.7285],\n",
      "        [0.8224, 0.8232, 0.8245, 0.7655],\n",
      "        [0.8434, 0.8444, 0.8460, 0.7850],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.7077, 0.7070, 0.7065, 0.6586],\n",
      "        [0.8511, 0.8523, 0.8540, 0.7923],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.7812, 0.7814, 0.7821, 0.7271],\n",
      "        [0.7009, 0.7002, 0.6996, 0.6523],\n",
      "        [0.7982, 0.7986, 0.7996, 0.7429],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.7568, 0.7567, 0.7570, 0.7043],\n",
      "        [0.7437, 0.7434, 0.7435, 0.6921],\n",
      "        [0.6410, 0.6395, 0.6380, 0.5965],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6652, 0.6640, 0.6629, 0.6190],\n",
      "        [0.7272, 0.7267, 0.7266, 0.6767],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6918, 0.6909, 0.6903, 0.6438],\n",
      "        [0.6757, 0.6746, 0.6737, 0.6288],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6371, 0.6355, 0.6340, 0.5928],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816],\n",
      "        [0.7010, 0.7002, 0.6997, 0.6523],\n",
      "        [0.6280, 0.6264, 0.6247, 0.5844],\n",
      "        [0.6713, 0.6701, 0.6691, 0.6246],\n",
      "        [0.6394, 0.6378, 0.6363, 0.5949],\n",
      "        [0.6350, 0.6334, 0.6318, 0.5908],\n",
      "        [0.6344, 0.6328, 0.6312, 0.5903],\n",
      "        [0.6624, 0.6612, 0.6600, 0.6164],\n",
      "        [0.6860, 0.6850, 0.6842, 0.6383],\n",
      "        [0.7041, 0.7033, 0.7028, 0.6552],\n",
      "        [0.7062, 0.7055, 0.7050, 0.6572],\n",
      "        [0.6251, 0.6234, 0.6217, 0.5816]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0747,     0.0196,     0.0410,     0.0092],\n",
      "        [    0.0053,     0.0161,     0.0209,     0.0237],\n",
      "        [    0.0296,     0.0068,     0.0330,     0.0216],\n",
      "        [    0.0138,     0.0264,     0.0103,     0.0316],\n",
      "        [    0.0520,     0.0368,     0.0542,     0.0266],\n",
      "        [    0.0428,     0.0607,     0.0299,     0.0124],\n",
      "        [    0.1038,     0.0739,     0.0265,     0.0006],\n",
      "        [    0.0867,     0.0397,     0.0099,     0.0226],\n",
      "        [    0.0424,     0.0129,     0.0234,     0.0364],\n",
      "        [    0.0145,     0.0214,     0.0390,     0.0401],\n",
      "        [    0.0453,     0.0630,     0.0691,     0.0577],\n",
      "        [    0.0548,     0.0605,     0.0560,     0.0344],\n",
      "        [    0.0612,     0.0564,     0.0399,     0.0152],\n",
      "        [    0.0453,     0.0284,     0.0072,     0.0043],\n",
      "        [    0.0562,     0.0351,     0.0259,     0.0518],\n",
      "        [    0.0836,     0.0747,     0.0024,     0.0583],\n",
      "        [    0.1014,     0.0242,     0.0296,     0.0378],\n",
      "        [    0.0027,     0.0518,     0.0560,     0.0419],\n",
      "        [    0.0124,     0.0165,     0.0012,     0.0289],\n",
      "        [    0.0036,     0.0211,     0.0029,     0.0376],\n",
      "        [    0.1409,     0.1569,     0.1547,     0.1220],\n",
      "        [    0.0745,     0.0376,     0.0079,     0.0243],\n",
      "        [    0.0580,     0.0607,     0.0485,     0.0603],\n",
      "        [    0.1267,     0.1411,     0.0945,     0.0394],\n",
      "        [    0.1513,     0.1285,     0.1428,     0.0886],\n",
      "        [    0.0104,     0.0240,     0.0000,     0.0303],\n",
      "        [    0.1046,     0.0820,     0.0449,     0.0015],\n",
      "        [    0.0005,     0.0055,     0.0080,     0.0109],\n",
      "        [    0.1552,     0.1530,     0.1302,     0.1338],\n",
      "        [    0.0665,     0.0921,     0.0416,     0.0379],\n",
      "        [    0.1052,     0.0552,     0.0496,     0.0487],\n",
      "        [    0.1026,     0.1265,     0.1423,     0.1301],\n",
      "        [    0.0038,     0.0183,     0.0051,     0.0425],\n",
      "        [    0.0227,     0.0095,     0.0901,     0.1537],\n",
      "        [    0.0542,     0.0055,     0.0200,     0.0046],\n",
      "        [    0.0165,     0.0068,     0.0456,     0.0270],\n",
      "        [    0.0213,     0.0525,     0.0072,     0.0188],\n",
      "        [    0.0085,     0.0473,     0.0290,     0.0310],\n",
      "        [    0.0490,     0.0307,     0.0333,     0.0295],\n",
      "        [    0.1393,     0.0928,     0.0423,     0.1047],\n",
      "        [    0.0333,     0.0137,     0.0096,     0.0375],\n",
      "        [    0.0174,     0.0282,     0.0489,     0.0653],\n",
      "        [    0.0036,     0.0477,     0.0287,     0.0193],\n",
      "        [    0.0494,     0.0304,     0.0208,     0.0088],\n",
      "        [    0.0321,     0.0225,     0.0092,     0.0165],\n",
      "        [    0.0141,     0.0376,     0.0688,     0.1051],\n",
      "        [    0.0223,     0.0532,     0.0980,     0.0739],\n",
      "        [    0.0058,     0.0195,     0.0508,     0.0069],\n",
      "        [    0.0324,     0.0350,     0.0317,     0.0067],\n",
      "        [    0.1466,     0.0210,     0.0112,     0.0845],\n",
      "        [    0.0351,     0.0091,     0.0368,     0.0413],\n",
      "        [    0.0367,     0.0334,     0.0074,     0.0346],\n",
      "        [    0.0362,     0.0046,     0.0301,     0.0586],\n",
      "        [    0.0457,     0.1137,     0.1058,     0.0647],\n",
      "        [    0.1154,     0.1075,     0.0693,     0.1092],\n",
      "        [    0.1093,     0.0710,     0.1169,     0.1312],\n",
      "        [    0.0108,     0.0351,     0.0440,     0.0180],\n",
      "        [    0.0406,     0.0174,     0.0197,     0.0030],\n",
      "        [    0.2086,     0.1449,     0.0193,     0.0107],\n",
      "        [    0.0911,     0.0440,     0.1120,     0.0989],\n",
      "        [    0.0334,     0.0423,     0.0191,     0.0186],\n",
      "        [    0.0157,     0.0180,     0.0030,     0.0013],\n",
      "        [    0.0545,     0.0434,     0.0663,     0.0779],\n",
      "        [    0.0024,     0.0206,     0.0218,     0.1116],\n",
      "        [    0.0243,     0.0236,     0.0745,     0.0922],\n",
      "        [    0.0070,     0.0073,     0.0106,     0.0101],\n",
      "        [    0.0148,     0.0089,     0.0152,     0.0111],\n",
      "        [    0.0070,     0.0081,     0.0110,     0.0109],\n",
      "        [    0.0201,     0.0141,     0.0168,     0.0246],\n",
      "        [    0.0613,     0.0648,     0.0419,     0.0328],\n",
      "        [    0.0570,     0.0601,     0.0705,     0.0652],\n",
      "        [    0.0630,     0.0731,     0.0745,     0.0518],\n",
      "        [    0.0078,     0.0884,     0.1641,     0.2057]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.21468441391155002\n",
      "Loss值\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "<<Regularizing module>>\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_keep_alive\u001b[0;34m(x, memo)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 140236790494912",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-30980124d598>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mnb_step4\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreorganizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_node_acceptable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_node_acceptable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"看一下 hidden node\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-c9f5f964d611>\u001b[0m in \u001b[0;36mreorganizing\u001b[0;34m(network)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m## Using the regularizing module to adjust the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m## Store the network and w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-a16ab162c3b8>\u001b[0m in \u001b[0;36mregularizing\u001b[0;34m(network)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m## Store the parameter of the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mnetwork_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0myo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0m_keep_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Make sure x lives at least as long as d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_keep_alive\u001b[0;34m(x, memo)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \"\"\"\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# aha, this is the first one :-)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_data, y_data = get_data(4)\n",
    "\n",
    "data = range(x_data.shape[0])\n",
    "# window_size => the length of training block\n",
    "window_size = 106\n",
    "# step_window => step size of each window\n",
    "step_window = 4\n",
    "# the split data\n",
    "splits = []\n",
    "\n",
    "## Moving window mechnism\n",
    "for i in range(window_size, len(data), step_window):\n",
    "    train = np.array(data[i-window_size:i])\n",
    "    test = np.array(data[i-window_size:i+step_window])\n",
    "#     test = np.array(data[i:i+step_window])\n",
    "    splits.append(('TRAIN:', train, 'TEST:', test))\n",
    "\n",
    "## Record program start time\n",
    "start = time.time()\n",
    "# for i in range(len(splits)):\n",
    "for i_block in range(-2,0,1):\n",
    "    block_start = time.time()\n",
    "    ## Record the number of each step\n",
    "    nb_step4 = 0\n",
    "    nb_step6_1 = 0\n",
    "    nb_step6_2 = 0\n",
    "    print(\"The <<%d>> Block\" %(len(splits)+i_block+1))\n",
    "#     print(\"The training block\\n\", y_data[splits[i_block][1]])\n",
    "#     print(\"The testing block\\n\", y_data[splits[i_block][3]])\n",
    "    \n",
    "    x_train = x_data[splits[i_block][1]]\n",
    "    x_test = x_data[splits[i_block][3]]\n",
    "    y_train = y_data[splits[i_block][1]]\n",
    "    y_test = y_data[splits[i_block][3]]\n",
    "    \n",
    "    x_train_scaled = torch.FloatTensor(sc.fit_transform(x_train))\n",
    "    x_test_scaled = torch.FloatTensor(sc.transform(x_test))\n",
    "    y_train_scaled = torch.FloatTensor(sc.fit_transform(y_train))\n",
    "    \n",
    "    threshold_for_error = 3000/(sc.data_max_-sc.data_min_)\n",
    "    threshold_for_error = threshold_for_error[0]\n",
    "#     print(\"確認threshold_for_error:\",threshold_for_error)\n",
    "    # 如果是第一個 Block的話\n",
    "    if i_block == -2:\n",
    "        initial_x = torch.FloatTensor(x_train_scaled[:x_train_scaled.shape[1]+1])\n",
    "        initial_y = torch.FloatTensor(y_train_scaled[:x_train_scaled.shape[1]+1])\n",
    "        \n",
    "        x_train_scaled = torch.FloatTensor(x_train_scaled[x_train_scaled.shape[1]+1:])\n",
    "        y_train_scaled = torch.FloatTensor(y_train_scaled[x_train_scaled.shape[1]+1:])\n",
    "        \n",
    "        \n",
    "        network = Network(4,initial_x,initial_y)\n",
    "        initializing(network, initial_x, initial_y)\n",
    "        print(\"<<Initializing後看一下差異>>\")\n",
    "        yo,loss = network.forward()\n",
    "        print(torch.abs(network.y-yo))\n",
    "        print(\"threshold_for_error:\",threshold_for_error)\n",
    "    network.threshold_for_error = threshold_for_error\n",
    "#     print(\"(後)確認threshold_for_error:\",network.threshold_for_error)\n",
    "#     print(\"看一下模型\")\n",
    "#     print(network.state_dict())\n",
    "    \n",
    "    for i in range(int(x_train_scaled.shape[0]*0.9624)):\n",
    "#     for i in range(40):\n",
    "        print(\"確認threshold_for_error:\",threshold_for_error)\n",
    "        if i_block == -2:\n",
    "            print(\"現在訓練到第幾筆資料: %d\"%(i+x_train_scaled.shape[1]+2))\n",
    "        \n",
    "        else:\n",
    "            print(\"現在訓練到第幾筆資料: %d\"%(i+1))\n",
    "        \n",
    "        print(\"X 資料\",x_train_scaled.shape)\n",
    "        print(\"Y 資料\",y_train_scaled.shape)\n",
    "        \n",
    "        sorted_index = selecting(network, x_train_scaled, y_train_scaled)\n",
    "        \n",
    "        if i==0 and i_block > -2:\n",
    "            print(\"除了N=0外，第一筆資料\")\n",
    "            network.setData(x_train_scaled[sorted_index[0]].reshape(1,-1), y_train_scaled[sorted_index[0]].reshape(1,-1))\n",
    "            network.nb_node_acceptable = torch.IntTensor([network.nb_node_acceptable[-1]])\n",
    "        \n",
    "        else:    \n",
    "        ## Add new data for training\n",
    "            network.addData(x_train_scaled[sorted_index[0]], y_train_scaled[sorted_index[0]])\n",
    "        \n",
    "        print(\"現在要進去模型的數據，索引%d，y=\"%(sorted_index[0]),y_train_scaled[sorted_index[0]].data)\n",
    "        print(\"目前模型的Data\",network.x.shape)\n",
    "        \n",
    "        x_train_scaled = np.delete(x_train_scaled, sorted_index[0], 0)\n",
    "        y_train_scaled = np.delete(y_train_scaled, sorted_index[0], 0)\n",
    "\n",
    "        \n",
    "        yo,loss = network.forward()\n",
    "        print(\"<<預測值>>\")\n",
    "        print(yo)\n",
    "        print(\"<<差異>>\")\n",
    "        print(torch.abs(yo-network.y))\n",
    "        print(\"threshold_for_error:\",threshold_for_error)\n",
    "        print(\"Loss值\")\n",
    "        print(loss)\n",
    "\n",
    "        pre_network = copy.deepcopy(network)\n",
    "        \n",
    "        if not torch.all(torch.abs(network.y-yo)<network.threshold_for_error):\n",
    "\n",
    "            network.acceptable = False\n",
    "            network = matching(network)\n",
    "            \n",
    "            print(\"<<Matching後看一下差異>>\")\n",
    "            yo,loss = network.forward()\n",
    "            print(torch.abs(yo-network.y))\n",
    "            print(\"threshold_for_error:\",threshold_for_error)\n",
    "            if network.acceptable == False:\n",
    "                \n",
    "                network = pre_network\n",
    "                cramming(network)\n",
    "\n",
    "                print(\"<<Cramming後看一下差異>>\")\n",
    "                yo,loss = network.forward()\n",
    "                print(torch.abs(yo-network.y))\n",
    "                print(\"threshold_for_error:\",threshold_for_error)\n",
    "                nb_step6_2 += 1\n",
    "\n",
    "            else:\n",
    "                nb_step6_1 += 1\n",
    "\n",
    "        else:\n",
    "            nb_step4 += 1\n",
    "\n",
    "        network = reorganizing(network)\n",
    "        network.nb_node_acceptable = torch.cat([network.nb_node_acceptable, torch.IntTensor([network.linear1.bias.data.shape[0]])],0)\n",
    "        print(\"看一下 hidden node\")\n",
    "        print(network.nb_node_acceptable)\n",
    "        print(\"<<Reorganizing後看一下差異>>\")\n",
    "        yo,loss = network.forward()\n",
    "        print(torch.abs(yo-network.y))\n",
    "        print(\"threshold_for_error:\",threshold_for_error)\n",
    "        print(\"使用裝置\",(list(network.parameters())[0].device))\n",
    "        print(\"累計時間(s)\",time.time()-start)\n",
    "        print(\"-\"*90)\n",
    "\n",
    "    \n",
    "    block_end = time.time()\n",
    "    print(\"到第 %d 個區塊累積花費時間(s)\"%(len(splits)+i_block+1),block_end-block_start)\n",
    "    print(\"<<The performance of %d block>>\"%(len(splits)+i_block+1))\n",
    "    \n",
    "    validation(network, nb_step4, nb_step6_1, nb_step6_2, x_test_scaled, y_test, block_start, block_end,(len(splits)+i_block+1))\n",
    "    end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
