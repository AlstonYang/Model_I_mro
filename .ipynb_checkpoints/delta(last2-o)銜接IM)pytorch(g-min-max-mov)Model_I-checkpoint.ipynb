{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import related package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import tensorflow package for modeling\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "## Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Min-max normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "## Plot the graph\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## Initializing module\n",
    "from sklearn.linear_model import LinearRegression\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "## Copy module\n",
    "import copy\n",
    "\n",
    "## Used to calculate the training time\n",
    "import time\n",
    "\n",
    "## Set the GUP environment\n",
    "import os\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the display\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 編寫結果在note中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Setup logging.\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%m/%d/%Y %I:%M:%S %p',\n",
    "    level=logging.DEBUG,\n",
    "    filename='log.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control memory usage space for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前設備： 0\n",
      "目前設備名： GeForce GTX 1070 Ti\n"
     ]
    }
   ],
   "source": [
    "## 查詢有無可用 GPU\n",
    "torch.cuda.is_available()\n",
    "## 查詢可用 GPU 的數量\n",
    "torch.cuda.device_count()\n",
    "##目前設備\n",
    "print(\"目前設備：\",torch.cuda.current_device())\n",
    "## 目前設備名\n",
    "print(\"目前設備名：\",torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices(device_type='GPU')\n",
    "\n",
    "# tf.config.set_logical_device_configuration(\n",
    "#     gpus[0],\n",
    "#     [tf.config.LogicalDeviceConfiguration(memory_limit=2048),\n",
    "#      tf.config.LogicalDeviceConfiguration(memory_limit=2048)]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = tf.compat.v1.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction =0.1\n",
    "# tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "# tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out some info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_cacl(pred_value, actual_value):\n",
    "    \n",
    "#     yo, loss, tape = network.forward()\n",
    "    accuracy = []\n",
    "\n",
    "    for i in range(pred_value.shape[1]):\n",
    "        \n",
    "        correct_times = torch.nonzero(torch.abs(pred_value[:,i] - actual_value[:,i]) < 3000)\n",
    "        accuracy.append(correct_times.shape[0]/pred_value.shape[0])   \n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(name, pred_value, actual_value,block_index):\n",
    "    \n",
    "    fig, ax = plt.subplots(2,2,figsize=(20,10), sharex=True, sharey=True)\n",
    "#     ax.set_xlim(0,pred_value.shape[0])  \n",
    "    \n",
    "    \n",
    "    for i in range(yo.shape[1]):\n",
    "        ax[i//2,i%2].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax[i//2,i%2].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax[i//2,i%2].plot(pred_value[:,i], label=\"LLAAT\")\n",
    "        ax[i//2,i%2].plot(actual_value[:,i], label=\"Actual\")\n",
    "        ax[i//2,i%2].set_title(\"Forecasted performance for l=%d\" %(i+1))\n",
    "        ax[i//2,i%2].legend()\n",
    "        \n",
    "    #fig.text(0.5, 0, \"Stage of training\", ha='center', fontsize=20)\n",
    "    #fig.text(0, 0.5, \"Copper price value\", va='center', rotation='vertical')\n",
    "\n",
    "    \n",
    "    fig.suptitle(\"In the %s process in the M=%d window\"%(name, block_index))\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_adopted_node(network,block_index):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20,5))\n",
    "    ax.set_xticklabels([i for i in range(network.nb_node_acceptable.shape[0]+1)])\n",
    "    \n",
    "    ax.set_title(\"Total amount of adopted hidden nodes in the training process in the M=%d window\"%(block_index))\n",
    "    ax.plot(network.nb_node_acceptable,\"-o\")\n",
    "\n",
    "    ax.set_xlabel(\"Stage of training\")\n",
    "    ax.set_ylabel(\"Hidden nodes\")\n",
    "    \n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(network, nb_step4, nb_step6_1, nb_step6_2, x_test, y_test, start, end, block_index):\n",
    "\n",
    "    ## Training_Step\n",
    "    print(\"<<Training step>>\")\n",
    "    print(\"The training time(s):\",end - start)\n",
    "    yo, loss= network.forward()\n",
    "    \n",
    "    pre_train = yo.data.cpu()\n",
    "    true_train = network.y.data.cpu()\n",
    "    \n",
    "    pred_value_train = torch.FloatTensor(sc.inverse_transform(pre_train))\n",
    "    actual_value_train = torch.FloatTensor(sc.inverse_transform(true_train))\n",
    "    accuracy_train = accuracy_cacl(pred_value_train,actual_value_train)\n",
    "\n",
    "    ## Test_step\n",
    "#     print(\"<<Testing step>>\")\n",
    "    pred_value_test = torch.FloatTensor(sc.inverse_transform(network.forecast(x_test).data.cpu()))\n",
    "    accuracy_test = accuracy_cacl(pred_value_test, y_test)\n",
    "    \n",
    "    total_time = nb_step4 + nb_step6_1 + nb_step6_2\n",
    "    print(\"<<The percentage of each step>>\")\n",
    "    print(\"Step 4: %.2f%%\"%((nb_step4/total_time)*100))\n",
    "    print(\"Step 6.1: %.2f%%\"%((nb_step6_1/total_time)*100))\n",
    "    print(\"Step 6.2: %.2f%%\"%((nb_step6_2/total_time)*100))\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"Total frequency of cramming occurrences:\",nb_step6_2)\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"The amount of hidden node that be pruned:\",network.nb_node_pruned)\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"The amount of adopted hidden nodes:\",network.nb_node_acceptable[-1].item())\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"<<Accuracy in training step>>\")\n",
    "    print(\"The accuracy for l = 1: %.1f%%\" %(accuracy_train[0]*100))\n",
    "    print(\"The accuracy for l = 2: %.1f%%\" %(accuracy_train[1]*100))\n",
    "    print(\"The accuracy for l = 3: %.1f%%\" %(accuracy_train[2]*100))\n",
    "    print(\"The accuracy for l = 4: %.1f%%\" %(accuracy_train[3]*100))\n",
    "\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"<<Accuracy in inferencing step>>\")\n",
    "    print(\"The accuracy for l = 1: %.1f%%\" %(accuracy_test[0]*100))\n",
    "    print(\"The accuracy for l = 2: %.1f%%\" %(accuracy_test[1]*100))\n",
    "    print(\"The accuracy for l = 3: %.1f%%\" %(accuracy_test[2]*100))\n",
    "    print(\"The accuracy for l = 4: %.1f%%\" %(accuracy_test[3]*100))\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    plot_result(\"training\",pred_value_train, actual_value_train,block_index)\n",
    "    plot_result(\"inferencing\",pred_value_test, y_test,block_index)\n",
    "    plot_adopted_node(network,block_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTrain(train, pastWeek=4, futureWeek=4, defaultWeek=1):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(train.shape[0]-futureWeek-pastWeek):\n",
    "        X = np.array(train.iloc[i:i+defaultWeek])\n",
    "        X = np.append(X,train[\"CCSP\"].iloc[i+defaultWeek:i+pastWeek])\n",
    "        X_train.append(X.reshape(X.size))\n",
    "        Y_train.append(np.array(train.iloc[i+pastWeek:i+pastWeek+futureWeek][\"CCSP\"]))\n",
    "    return np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use min-max normalization to scale the data to the range from 1 to 0\n",
    "sc = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design get_data() to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_data(futureWeek):\n",
    "    \n",
    "#     ## Read weekly copper price data\n",
    "#     path = \"WeeklyFinalData.csv\"\n",
    "#     data = read(path)\n",
    "    \n",
    "#     date = data[\"Date\"]\n",
    "#     data.drop(\"Date\", axis=1, inplace=True)\n",
    "    \n",
    "#     ## Add time lag (pastWeek=4, futureWeek=1)\n",
    "#     x_data, y_data = buildTrain(data, futureWeek=futureWeek)\n",
    "\n",
    "    \n",
    "#     ## Split the data to training data and test data\n",
    "#     x_train_data = x_data[:int(x_data.shape[0]*0.8)]\n",
    "#     x_test_data = x_data[int(x_data.shape[0]*0.8):]\n",
    "#     y_train_data = y_data[:int(x_data.shape[0]*0.8)]\n",
    "#     y_test_data = y_data[int(x_data.shape[0]*0.8):]\n",
    "\n",
    "\n",
    "#     return (x_train_data, x_test_data, y_train_data, y_test_data)\n",
    "\n",
    "# #     return (x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(futureWeek):\n",
    "    \n",
    "    ## Read weekly copper price data\n",
    "    path = \"WeeklyFinalData.csv\"\n",
    "    data = read(path)\n",
    "    \n",
    "    date = data[\"Date\"]\n",
    "    data.drop(\"Date\", axis=1, inplace=True)\n",
    "    \n",
    "    ## Add time lag (pastWeek=4, futureWeek=1)\n",
    "    x_data, y_data = buildTrain(data, futureWeek=futureWeek)\n",
    "\n",
    "\n",
    "    return (x_data, y_data)\n",
    "\n",
    "#     return (x_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializing(network, initial_x, initial_y):\n",
    "    print(\"Initializing module\")\n",
    "    ## Find each minimum output value y\n",
    "    min_y = torch.min(initial_y, axis=0)\n",
    "\n",
    "    ## Subtract min_y from each y\n",
    "    res_y = initial_y-min_y.values\n",
    "    \n",
    "    ## Use linear regression to find the initial W1,b1,Wo,bo\n",
    "    reg = LinearRegression().fit(initial_x, res_y)\n",
    "#     ## Set up the initial parameter of the network\n",
    "    network.linear1.weight = torch.nn.Parameter(torch.FloatTensor(reg.coef_).cuda())\n",
    "#     network.linear1.weight = network.linear1.weight.cuda()\n",
    "    network.linear1.bias = torch.nn.Parameter(torch.FloatTensor(reg.intercept_).cuda())\n",
    "    network.linear2.weight=torch.nn.Parameter(torch.FloatTensor([[1,0,0,0], [0,1,0,0],[0,0,1,0],[0,0,0,1]]).cuda())\n",
    "    network.linear2.bias = torch.nn.Parameter(torch.FloatTensor(min_y.values).cuda())\n",
    "    ## Set up the acceptable of the initial network as True\n",
    "    network.acceptable =True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecting(network, x_train_scaled, y_train_scaled):\n",
    "    \n",
    "    print(\"<<Selecting module>>\")\n",
    "    loss = []\n",
    "    temp_network = copy.deepcopy(network)\n",
    "    \n",
    "    ## Put each data into network to calculate the loss value\n",
    "    for i in range(x_train_scaled.shape[0]):\n",
    "        temp_network.setData(x_train_scaled[i].reshape(1,-1), y_train_scaled[i].reshape(1,-1))\n",
    "        loss.append((temp_network.forward()[1].item(),i))\n",
    "\n",
    "#     ## Sort the data according to the loss value from smallest to largest, and save the data index in sorted_index\n",
    "    sorted_index = [sorted_data[1] for sorted_data in sorted(loss, key = lambda x:x[0])]\n",
    "    \n",
    "    \n",
    "    ## Print out some info for debug\n",
    "    print(\"The loss value of k:\",loss[sorted_index[0]])\n",
    "#     print(\"The second_loss value of k:\",loss[sorted_index[1]])\n",
    "    print(\"Selecting module finish!\")\n",
    "    \n",
    "    return sorted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching(network):\n",
    "\n",
    "    times_enlarge=0\n",
    "    times_shrink=0\n",
    "    print(\"<<Matching module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "#     yo, loss = network.forward()\n",
    "    network.acceptable = False\n",
    "    initial_network = copy.deepcopy(network)\n",
    "#     while True:\n",
    "        \n",
    "#         print(\"最後審判\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "#         print(\"你的Loss值\")\n",
    "#         print(loss)\n",
    "#         if torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "\n",
    "#             ## If true, set the acceptable of the network as true and return it\n",
    "#             network.acceptable = True\n",
    "#             print(\"Matching finished - the network is acceptable\")\n",
    "#             print(\"<<Final Network>>\")\n",
    "#             print(network.state_dict())\n",
    "# #             print(\"<<Pre-network>>\")\n",
    "# #             print(network_pre.state_dict())\n",
    "#             return(network)\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "\n",
    "        yo, loss = network.forward()\n",
    "        network_pre = copy.deepcopy(network)\n",
    "        loss_pre = loss\n",
    "\n",
    "#         print(\"<<再次確認一下要調整的network\")\n",
    "#             print(network.state_dict())\n",
    "#         print(torch.abs(yo-network.y))\n",
    "#         print(\"你的Loss值\",loss)\n",
    "#         print(\"loss2\", loss_pre)\n",
    "#         print(\"<<Before>>\")\n",
    "#             print(\"lr\",network.learning_rate)\n",
    "#         print(\"W1\",network.linear1.weight)\n",
    "\n",
    "            # Backward and check the loss performance of the network with new learning rate\n",
    "        network.backward_Adam(loss)\n",
    "        yo, loss = network.forward()\n",
    "\n",
    "#         print(\"調整後看一下\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "#         print(\"我看一下Loss值\",loss)\n",
    "#             print(\"<<更新後的network\")\n",
    "#             print(network.state_dict())\n",
    "#         print(\"los3\", loss)\n",
    "\n",
    "#         print(\"<<After>>\")\n",
    "#             print(\"lr\",network.learning_rate)\n",
    "#         print(\"W1\",network.linear1.weight)\n",
    "              ## Identify that all forecast value has met the error term\n",
    "\n",
    "            # Confirm whether the loss value of the adjusted network is smaller than the current one\n",
    "        if loss < loss_pre and torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "            \n",
    "#             print(\"我成功了\")\n",
    "            # If true, multiply the learning rate by 1.2\n",
    "            network.acceptable = True\n",
    "            print(\"Matching finished - the network is acceptable\")\n",
    "#             print(\"<<Final Network>>\")\n",
    "#             print(network.state_dict())\n",
    "#             print(\"<<Pre-network>>\")\n",
    "#             print(network_pre.state_dict())\n",
    "            print(\"Number of enlarge:\",times_enlarge)\n",
    "            print(\"Number of shrink:\",times_shrink)\n",
    "            return(network)\n",
    "\n",
    "\n",
    "#                 print(\"<<Enlarge>>\")\n",
    "        # On the contrary, reduce the learning rate\n",
    "        elif loss < loss_pre:\n",
    "#             print(\"快成功了，加油\")\n",
    "            times_enlarge+=1\n",
    "            network.learning_rate *= 1.2\n",
    "            \n",
    "    \n",
    "        else:         \n",
    "\n",
    "            # Identify whether the current learning rate is less than the threshold\n",
    "            if network.learning_rate <= network.threshold_for_lr:\n",
    "\n",
    "                # If true, set the acceptable of the network as false and return it\n",
    "                network.acceptable = False\n",
    "                print(\"Matching finished - the network is Unacceptable\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "                return(initial_network)\n",
    "\n",
    "            # On the contrary, restore w and adjust the learning rate\n",
    "            else:\n",
    "#                 print(\"我在縮小\")\n",
    "                # Restore the papameter of the network\n",
    "                network = copy.deepcopy(network_pre)\n",
    "                times_shrink+=1\n",
    "                network.learning_rate *= 0.7\n",
    "\n",
    "#                     print(\"<<After>>\")\n",
    "#                     print(network.learning_rate)\n",
    "#                     print(\"<<Shrink>>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching for reorganizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_for_reorganizing(network):\n",
    "\n",
    "    times_enlarge=0\n",
    "    times_shrink=0\n",
    "    print(\"<<Matching module for reorganizing>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "#     yo, loss = network.forward()\n",
    "    network.acceptable = False\n",
    "    initial_network = copy.deepcopy(network)\n",
    "#     while True:\n",
    "        \n",
    "#         print(\"最後審判\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "#         print(\"你的Loss值\")\n",
    "#         print(loss)\n",
    "#         if torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "\n",
    "#             ## If true, set the acceptable of the network as true and return it\n",
    "#             network.acceptable = True\n",
    "#             print(\"Matching finished - the network is acceptable\")\n",
    "#             print(\"<<Final Network>>\")\n",
    "#             print(network.state_dict())\n",
    "# #             print(\"<<Pre-network>>\")\n",
    "# #             print(network_pre.state_dict())\n",
    "#             return(network)\n",
    "    \n",
    "    \n",
    "    for i in range(1000):\n",
    "\n",
    "        yo, loss = network.forward()\n",
    "        network_pre = copy.deepcopy(network)\n",
    "        loss_pre = loss\n",
    "\n",
    "#         print(\"<<再次確認一下要調整的network\")\n",
    "#             print(network.state_dict())\n",
    "#         print(\"誤差值\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "#         print(\"你的Loss值\",loss)\n",
    "#         print(\"loss2\", loss_pre)\n",
    "#         print(\"<<Before>>\")\n",
    "#             print(\"lr\",network.learning_rate)\n",
    "#         print(\"W1\",network.linear1.weight)\n",
    "\n",
    "            # Backward and check the loss performance of the network with new learning rate\n",
    "        network.backward_Adam(loss)\n",
    "        yo, loss = network.forward()\n",
    "\n",
    "#         print(\"調整後看一下\")\n",
    "#         print(\"誤差值\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "#         print(\"我看一下Loss值\",loss)\n",
    "#             print(\"<<更新後的network\")\n",
    "#             print(network.state_dict())\n",
    "#         print(\"loss\", loss)\n",
    "\n",
    "#         print(\"<<After>>\")\n",
    "#             print(\"lr\",network.learning_rate)\n",
    "#         print(\"W1\",network.linear1.weight)\n",
    "              ## Identify that all forecast value has met the error term\n",
    "\n",
    "            # Confirm whether the loss value of the adjusted network is smaller than the current one\n",
    "        if loss < loss_pre and torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "            \n",
    "            print(\"我成功了\")\n",
    "            # If true, multiply the learning rate by 1.2\n",
    "            network.acceptable = True\n",
    "            print(\"Matching finished - the network is acceptable\")\n",
    "#             print(\"<<Final Network>>\")\n",
    "#             print(network.state_dict())\n",
    "#             print(\"<<Pre-network>>\")\n",
    "#             print(network_pre.state_dict())\n",
    "            print(\"Number of enlarge:\",times_enlarge)\n",
    "            print(\"Number of shrink:\",times_shrink)\n",
    "            return(network)\n",
    "\n",
    "\n",
    "#                 print(\"<<Enlarge>>\")\n",
    "        # On the contrary, reduce the learning rate\n",
    "        elif loss < loss_pre:\n",
    "            #print(\"快成功了，加油\")\n",
    "            times_enlarge+=1\n",
    "            network.learning_rate *= 1.2\n",
    "            \n",
    "    \n",
    "        else:         \n",
    "\n",
    "            # Identify whether the current learning rate is less than the threshold\n",
    "            if network.learning_rate <= network.threshold_for_lr:\n",
    "\n",
    "                # If true, set the acceptable of the network as false and return it\n",
    "                network.acceptable = False\n",
    "                print(\"Matching finished - the network is Unacceptable\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "                return(initial_network)\n",
    "\n",
    "            # On the contrary, restore w and adjust the learning rate\n",
    "            else:\n",
    "                #print(\"我在縮小\")\n",
    "                # Restore the papameter of the network\n",
    "                network = copy.deepcopy(network_pre)\n",
    "                times_shrink+=1\n",
    "                network.learning_rate *= 0.7\n",
    "\n",
    "                \n",
    "    network.acceptable = False\n",
    "    print(\"Matching的第%d回合\"%(i+1))\n",
    "    print(\"Matching finished - the network is Unacceptable\")\n",
    "    print(\"Number of enlarge:\",times_enlarge)\n",
    "    print(\"Number of shrink:\",times_shrink)\n",
    "    return(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cramming module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramming(network):\n",
    "    \n",
    "    torch.random.manual_seed(0)\n",
    "    print(\"<<Cramming module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    ## Find unsatisfied data:K\n",
    "    yo, loss = network.forward()\n",
    "    undesired_index = torch.nonzero(torch.abs(yo-network.y) > network.threshold_for_error)\n",
    "\n",
    "    ## Print out the undesired_index for debug\n",
    "    print(\"The index of the undesired data:\",undesired_index)\n",
    "\n",
    "\n",
    "    # Unsatisfied situation\n",
    "    ## Find the index of the unsatisfied data\n",
    "    k_data_num = undesired_index[0][0]\n",
    "\n",
    "    undesired_data = torch.reshape(network.x[k_data_num,:], [1,-1])\n",
    "\n",
    "    ## Remove the data that does not meet the error term\n",
    "    left_data = network.x[:k_data_num,:]\n",
    "    right_data = network.x[k_data_num+1:,:]\n",
    "    remain_tensor = torch.cat([left_data, right_data], 0)\n",
    "\n",
    "        \n",
    "    ## Use the random method to find out the gamma and zeta\n",
    "    while True:\n",
    "\n",
    "        ## Find m-vector gamma: r\n",
    "        ## Use the random method to generate the gamma that can make the conditions met\n",
    "        gamma = torch.rand(size=[1,network.x.shape[1]]).cuda()\n",
    "        subtract_undesired_data = torch.sub(remain_tensor, undesired_data)\n",
    "        matmul_value = torch.mm(gamma,torch.t(subtract_undesired_data))\n",
    "\n",
    "        if torch.all(matmul_value != 0):\n",
    "            break\n",
    "\n",
    "    while True:\n",
    "\n",
    "        ## Find the tiny value: zeta\n",
    "        ## Use the random method to generate the zeta that can make the conditions met\n",
    "        zeta = torch.rand(size=[1]).cuda()\n",
    "        \n",
    "        if torch.all(torch.mul(torch.add(zeta,matmul_value),torch.sub(zeta,matmul_value))<0):\n",
    "            break\n",
    "\n",
    "    for i in range(undesired_index.shape[0]):\n",
    "        \n",
    "        k_l = undesired_index[i][1]\n",
    "#         print(\"The output node:\",k_l)\n",
    "        ## The weight of input layer to hidden layer I\n",
    "        w10 = gamma\n",
    "        w11 = gamma\n",
    "        w12 = gamma\n",
    "        \n",
    "        W1_new = torch.cat([w10,w11,w12],0)\n",
    "#         print(\"W1_new.shape:\",W1_new.shape)\n",
    "        \n",
    "        ## The bias of input layer to hidden layer I\n",
    "        matual_value = torch.mm(gamma,torch.t(undesired_data))\n",
    "\n",
    "        b10 = torch.sub(zeta,matual_value)\n",
    "        b11 = -1*matual_value\n",
    "        b12 = torch.sub(-1*zeta,matual_value)\n",
    "        \n",
    "        \n",
    "        b1_new = torch.reshape(torch.cat([b10,b11,b12],0),[3])\n",
    "       \n",
    "#         print(\"b1_new\",b1_new)\n",
    "    \n",
    "    \n",
    "        ## The weight of hidden layer I to output layer\n",
    "        gap = network.y[k_data_num, k_l]-yo[k_data_num, k_l]\n",
    "#         print(\"gap:\",gap)\n",
    "        \n",
    "        wo0_value = gap/zeta\n",
    "        wo1_value = (-2*gap)/zeta\n",
    "        wo2_value = gap/zeta\n",
    "\n",
    "        index = torch.tensor([[k_l]])\n",
    "    \n",
    "        wo0 = torch.FloatTensor(torch.zeros(1, 4).scatter_(1, index, 1)).cuda() * wo0_value\n",
    "        wo1 = torch.FloatTensor(torch.zeros(1, 4).scatter_(1, index, 1)).cuda() * wo1_value\n",
    "        wo2 = torch.FloatTensor(torch.zeros(1, 4).scatter_(1, index, 1)).cuda() * wo2_value\n",
    "        \n",
    "        \n",
    "#         print(\"Wo0\",wo0_value)\n",
    "#         print(\"Wo1\",wo1_value)\n",
    "#         print(\"Wo2\",wo2_value)\n",
    "            \n",
    "        Wo_new = torch.t(torch.cat([wo0,wo1,wo2],0))\n",
    "        \n",
    "#         print(\"Wo_new.shape\",Wo_new.shape)\n",
    "        \n",
    "        ## Add new neuroes to the network\n",
    "        network.linear1.weight = torch.nn.Parameter(torch.cat([network.linear1.weight.data, W1_new]))\n",
    "        network.linear1.bias = torch.nn.Parameter(torch.cat([network.linear1.bias.data, b1_new]))\n",
    "        network.linear2.weight = torch.nn.Parameter(torch.cat([network.linear2.weight.data, Wo_new],1))\n",
    "#         print(network.state_dict())\n",
    "#         yo, loss = network.forward()\n",
    "\n",
    "#         print(torch.abs(network.y-yo))\n",
    "    \n",
    "    yo, loss = network.forward()\n",
    "    ## Determine if cramming is successful and print out the corresponding information\n",
    "    if torch.all(torch.abs(yo[k_data_num,k_l]-network.y[k_data_num,k_l]) <= network.threshold_for_error):\n",
    "        network.acceptable = True \n",
    "        print(\"Cramming success!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Cramming failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularizing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularizing(network):\n",
    "\n",
    "    print(\"<<Regularizing module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    ## Record the number of executions\n",
    "    times_enlarge = 0\n",
    "    times_shrink = 0\n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "\n",
    "    ## Set epoch to 100\n",
    "    for i in range(100):\n",
    "\n",
    "        ## Store the parameter of the network\n",
    "        network_pre = copy.deepcopy(network)\n",
    "        yo, loss = network.forward(1e-3)\n",
    "        loss_pre = loss\n",
    "\n",
    "#         print(\"調整前的network\")\n",
    "#         print(\"<<變數>>\")\n",
    "#         print(network.state_dict())\n",
    "#         print(\"<<Loss值>>\")\n",
    "#         print(loss)\n",
    "#         print(\"差異\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "        \n",
    "        ## Backward operation to obtain w'\n",
    "        network.backward_Adam(loss)\n",
    "        yo, loss = network.forward(1e-3)\n",
    "#         print(\"調整後的network\")\n",
    "#         print(\"<<變數>>\")\n",
    "#         print(network.state_dict())\n",
    "#         print(\"<<Loss值>>\")\n",
    "#         print(loss)\n",
    "#         print(\"差異\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "         # Confirm whether the adjusted loss value is smaller than the current one\n",
    "        if loss <= loss_pre:\n",
    "            \n",
    "            ## Identify that all forecast value has met the error term\n",
    "            if torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "                \n",
    "                ## If true, multiply the learning rate by 1.2\n",
    "                network.learning_rate *= 1.2\n",
    "                times_enlarge += 1\n",
    "#                 print(\"Regularizing %d process - Enlarge\"%i)\n",
    "                print(\"第\\\"%d\\\"回合是成功執行regularizing\"%(i+1))\n",
    "#                 print(\"差異\")\n",
    "#                 print(torch.abs(yo-network.y))\n",
    "\n",
    "            else:\n",
    "\n",
    "                ## Else, restore w and end the process\n",
    "                network = network_pre\n",
    "                print(\"Regularizing結束\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "#                 print(\"Regularizing result: Unable to meet the error term\")\n",
    "                print(\"因為沒有顧好預測誤差\")\n",
    "                return(network)\n",
    "\n",
    "        # If the adjusted loss value is not smaller than the current one\n",
    "        else:\n",
    "\n",
    "            ## If the learning rate is greater than the threshold for learning rate\n",
    "            if network.learning_rate > network.threshold_for_lr:\n",
    "                \n",
    "                ## Restore the w and multiply the learning rate by 0.7\n",
    "                network = network_pre\n",
    "                network.learning_rate *= 0.7\n",
    "                times_shrink += 1\n",
    "#                 print(\"把Learning rate變小\")\n",
    "#                 print(\"Regularizing %d process - Shrink\"%i)\n",
    "             ## If the learning rate is smaller than the threshold for learning rate\n",
    "            else:\n",
    "                \n",
    "                ## Restore the w\n",
    "                network = network_pre\n",
    "                print(\"Regularizing結束\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "#                 print(\"Regularizing result: Less than the epsilon for the learning rate\")\n",
    "                print(\"因為Learning不能這麼小啦\")\n",
    "                return(network)\n",
    "\n",
    "    print(\"第\\\"%d\\\"回合Regularizing module完畢\"%(i+1))\n",
    "    print(\"Number of enlarge:\",times_enlarge)\n",
    "    print(\"Number of shrink:\",times_shrink)\n",
    "#             print(\"Regularizing result: The number of rounds has reached\")\n",
    "    return(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorganizing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganizing(network):\n",
    "    print(\"<<Reorganizing module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    ## Set up the k = 1, and p = the number of hidden node\n",
    "    k = 1\n",
    "#     p = network.W1.shape[1]\n",
    "    p = network.linear1.weight.data.shape[0]\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        ## If k > p, end of Process\n",
    "        if k > p:\n",
    "\n",
    "            print(\"Reorganizing result: The final number of neuro is \",p)\n",
    "            return(network)\n",
    "\n",
    "        ## Else, Process is ongoing\n",
    "        else:\n",
    "\n",
    "            ## Using the regularizing module to adjust the network\n",
    "            network = regularizing(network)\n",
    "            \n",
    "            ## Store the network and w\n",
    "            network_pre = copy.deepcopy(network)\n",
    "\n",
    "            ## Set up the acceptable of the network as false\n",
    "            network.acceptable = False\n",
    "\n",
    "            ## Ignore the K hidden node\n",
    "            network.linear1.weight = torch.nn.Parameter(torch.cat([network.linear1.weight[:k-1],network.linear1.weight[k:]],0))\n",
    "            network.linear1.bias = torch.nn.Parameter(torch.cat([network.linear1.bias[:k-1],network.linear1.bias[k:]]))\n",
    "            network.linear2.weight = torch.nn.Parameter(torch.cat([network.linear2.weight[:,:k-1],network.linear2.weight[:,k:]],1))\n",
    "\n",
    "            ## Using the matching module to adjust the network\n",
    "            network = matching_for_reorganizing(network)\n",
    "            \n",
    "            print(\"是不是可以不要你:\",network.acceptable)\n",
    "            \n",
    "            ## If the resulting network is acceptable, this means that the k hidden node can be removed\n",
    "            if network.acceptable and p!=1:\n",
    "\n",
    "                print(\"Drop out the nero number: %d / %d\" %(k, p))\n",
    "                network.nb_node_pruned += 1\n",
    "                ## p--\n",
    "                p-=1\n",
    "\n",
    "            ## Else, it means that the k hidden node cannot be removed\n",
    "            else:\n",
    "                \n",
    "                ## Restore the network and w\n",
    "                network = network_pre\n",
    "                print(\"Cannot drop out the nero number: %d / %d\" %(k, p))\n",
    "                \n",
    "                ## k++\n",
    "                k+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, nb_neuro, x_train_scaled, y_train_scaled):\n",
    "        \n",
    "        super(Network, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(x_train_scaled.shape[1], nb_neuro).cuda()\n",
    "        self.linear2 = torch.nn.Linear(nb_neuro, y_train_scaled.shape[1]).cuda()\n",
    "        \n",
    "        \n",
    "        # Stop criteria - threshold\n",
    "        self.threshold_for_error = 0.07\n",
    "        self.threshold_for_lr = 1e-4\n",
    "        \n",
    "        # Input data \n",
    "        self.x = torch.FloatTensor(x_train_scaled).cuda()\n",
    "        self.y = torch.FloatTensor(y_train_scaled).cuda()\n",
    "        \n",
    "        # Learning rate\n",
    "        self.learning_rate = 1e-2\n",
    "        \n",
    "        # Whether the network is acceptable, default as False\n",
    "        self.acceptable = False\n",
    "        \n",
    "        # Some record for experiment\n",
    "        self.nb_node_pruned = 0\n",
    "        self.nb_node_acceptable=torch.IntTensor([nb_neuro])\n",
    "        \n",
    "    ## Forecast the test data\n",
    "    def forecast(self, x_test):\n",
    "    \n",
    "        x_test = torch.FloatTensor(x_test).cuda()\n",
    "        activation_value = self.linear1(x_test).clamp(min=0)\n",
    "        forecast_value = self.linear2(activation_value)\n",
    "       \n",
    "        return forecast_value\n",
    "\n",
    "    ## Reset the x and y data\n",
    "    def setData(self, x_train_scaled, y_train_scaled):\n",
    "        self.x = torch.FloatTensor(x_train_scaled).cuda()\n",
    "        self.y = torch.FloatTensor(y_train_scaled).cuda()\n",
    "    \n",
    "    ## Add the new data to the x and y data\n",
    "    def addData(self, new_x_train, new_y_train):\n",
    "\n",
    "        self.x = torch.cat([self.x, new_x_train.reshape(1,-1).cuda()],0)\n",
    "        self.y = torch.cat([self.y, new_y_train.reshape(1,-1).cuda()],0)\n",
    "    \n",
    "    ## forward operation\n",
    "    def forward(self, reg_strength=0):\n",
    "       \n",
    "        y1 = self.linear1(self.x).clamp(min=0)\n",
    "        yo = self.linear2(y1)\n",
    "\n",
    "        # performance measure\n",
    "        param_val= torch.sum(torch.pow(self.linear2.bias.data,2))+torch.sum(torch.pow(self.linear2.weight.data,2))+torch.sum(torch.pow(self.linear1.bias.data,2))+torch.sum(torch.pow(self.linear1.weight.data,2))\n",
    "        reg_term= reg_strength/((self.linear2.bias.data.shape[0]*(self.linear2.weight.data.shape[1]+1)) +(self.linear1.bias.data.shape[0]*(self.linear1.weight.data.shape[1]+1)))*param_val\n",
    "        loss = torch.nn.functional.mse_loss(yo,self.y)+reg_term\n",
    "        loss = loss.cuda()\n",
    "        return(yo, loss)\n",
    "\n",
    "    # backward operation\n",
    "    def backward_Adam(self,loss):    \n",
    "\n",
    "        optimizer = optim.Adagrad(self.parameters(), lr=self.learning_rate)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The <<91>> Block\n",
      "Initializing module\n",
      "<<Initializing後看一下差異>>\n",
      "tensor([[    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.11750881 0.11750881 0.11750881 0.11750881]\n",
      "現在訓練到第幾筆資料: 20\n",
      "X 資料 torch.Size([87, 18])\n",
      "Y 資料 torch.Size([87, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.010356849990785122, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.6104, 0.6014, 0.6154, 0.5879])\n",
      "目前模型的Data torch.Size([20, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.6148, 0.5848, 0.5967, 0.5770],\n",
      "        [0.5848, 0.5967, 0.5770, 0.5992],\n",
      "        [0.5967, 0.5770, 0.5992, 0.5909],\n",
      "        [0.5770, 0.5992, 0.5909, 0.6007],\n",
      "        [0.5992, 0.5909, 0.6007, 0.5840],\n",
      "        [0.5909, 0.6007, 0.5840, 0.5579],\n",
      "        [0.6007, 0.5840, 0.5579, 0.5413],\n",
      "        [0.5840, 0.5579, 0.5413, 0.5212],\n",
      "        [0.5579, 0.5413, 0.5212, 0.5112],\n",
      "        [0.5413, 0.5212, 0.5112, 0.5078],\n",
      "        [0.5212, 0.5112, 0.5078, 0.5100],\n",
      "        [0.5112, 0.5078, 0.5100, 0.5189],\n",
      "        [0.5078, 0.5100, 0.5189, 0.5302],\n",
      "        [0.5100, 0.5189, 0.5302, 0.5352],\n",
      "        [0.5189, 0.5302, 0.5352, 0.5777],\n",
      "        [0.5302, 0.5352, 0.5777, 0.6077],\n",
      "        [0.5352, 0.5777, 0.6077, 0.6104],\n",
      "        [0.5777, 0.6077, 0.6104, 0.6014],\n",
      "        [0.6077, 0.6104, 0.6014, 0.6154],\n",
      "        [0.6825, 0.7856, 0.6535, 0.6165]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0722,     0.1843,     0.0381,     0.0286]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 355\n",
      "Number of shrink: 188\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[0.0035, 0.0083, 0.0026, 0.0024],\n",
      "        [0.0015, 0.0049, 0.0024, 0.0024],\n",
      "        [0.0031, 0.0049, 0.0024, 0.0020],\n",
      "        [0.0041, 0.0061, 0.0035, 0.0029],\n",
      "        [0.0062, 0.0063, 0.0041, 0.0032],\n",
      "        [0.0058, 0.0031, 0.0045, 0.0037],\n",
      "        [0.0040, 0.0046, 0.0029, 0.0024],\n",
      "        [0.0004, 0.0024, 0.0008, 0.0007],\n",
      "        [0.0024, 0.0046, 0.0010, 0.0009],\n",
      "        [0.0049, 0.0103, 0.0025, 0.0022],\n",
      "        [0.0063, 0.0015, 0.0044, 0.0038],\n",
      "        [0.0065, 0.0046, 0.0045, 0.0039],\n",
      "        [0.0054, 0.0043, 0.0041, 0.0037],\n",
      "        [0.0032, 0.0017, 0.0032, 0.0031],\n",
      "        [0.0008, 0.0070, 0.0024, 0.0025],\n",
      "        [0.0023, 0.0167, 0.0015, 0.0020],\n",
      "        [0.0067, 0.0242, 0.0016, 0.0006],\n",
      "        [0.0111, 0.0304, 0.0045, 0.0030],\n",
      "        [0.0133, 0.0417, 0.0049, 0.0031],\n",
      "        [0.0406, 0.1173, 0.0195, 0.0139]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.11750881 0.11750881 0.11750881 0.11750881]\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為沒有顧好預測誤差\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 5\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Drop out the nero number: 1 / 4\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"1\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 1\n",
      "Number of shrink: 0\n",
      "因為沒有顧好預測誤差\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Drop out the nero number: 1 / 3\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Drop out the nero number: 1 / 2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0496, 0.0207, 0.0317, 0.0022],\n",
      "        [0.0165, 0.0307, 0.0105, 0.0025],\n",
      "        [0.0297, 0.0117, 0.0333, 0.0028],\n",
      "        [0.0087, 0.0330, 0.0244, 0.0032],\n",
      "        [0.0331, 0.0263, 0.0352, 0.0034],\n",
      "        [0.0284, 0.0384, 0.0202, 0.0033],\n",
      "        [0.0405, 0.0232, 0.0048, 0.0029],\n",
      "        [0.0265, 0.0011, 0.0202, 0.0029],\n",
      "        [0.0019, 0.0167, 0.0396, 0.0034],\n",
      "        [0.0145, 0.0367, 0.0495, 0.0013],\n",
      "        [0.0347, 0.0467, 0.0529, 0.0036],\n",
      "        [0.0458, 0.0509, 0.0512, 0.0038],\n",
      "        [0.0508, 0.0497, 0.0431, 0.0037],\n",
      "        [0.0492, 0.0413, 0.0321, 0.0038],\n",
      "        [0.0462, 0.0338, 0.0298, 0.0041],\n",
      "        [0.0390, 0.0315, 0.0108, 0.0043],\n",
      "        [0.0344, 0.0108, 0.0406, 0.0044],\n",
      "        [0.0094, 0.0416, 0.0439, 0.0042],\n",
      "        [0.0375, 0.0430, 0.0340, 0.0047],\n",
      "        [0.0401, 0.0339, 0.0480, 0.0238]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.272650480270386\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 21\n",
      "X 資料 torch.Size([86, 18])\n",
      "Y 資料 torch.Size([86, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.00018523373000789434, 40)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引40，y= tensor([0.5700, 0.5779, 0.5757, 0.5623])\n",
      "目前模型的Data torch.Size([21, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5652, 0.5641, 0.5651, 0.5748],\n",
      "        [0.5682, 0.5661, 0.5665, 0.5966],\n",
      "        [0.5671, 0.5653, 0.5659, 0.5880],\n",
      "        [0.5684, 0.5661, 0.5665, 0.5974],\n",
      "        [0.5660, 0.5646, 0.5654, 0.5806],\n",
      "        [0.5625, 0.5623, 0.5638, 0.5546],\n",
      "        [0.5602, 0.5608, 0.5627, 0.5384],\n",
      "        [0.5574, 0.5590, 0.5614, 0.5182],\n",
      "        [0.5560, 0.5580, 0.5608, 0.5078],\n",
      "        [0.5558, 0.5579, 0.5607, 0.5064],\n",
      "        [0.5558, 0.5579, 0.5607, 0.5064],\n",
      "        [0.5570, 0.5587, 0.5612, 0.5151],\n",
      "        [0.5586, 0.5597, 0.5620, 0.5264],\n",
      "        [0.5592, 0.5601, 0.5623, 0.5314],\n",
      "        [0.5651, 0.5640, 0.5650, 0.5736],\n",
      "        [0.5692, 0.5667, 0.5669, 0.6034],\n",
      "        [0.5695, 0.5669, 0.5671, 0.6060],\n",
      "        [0.5683, 0.5661, 0.5665, 0.5971],\n",
      "        [0.5702, 0.5674, 0.5674, 0.6107],\n",
      "        [0.5703, 0.5674, 0.5674, 0.6117],\n",
      "        [0.5665, 0.5649, 0.5656, 0.5837]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0496, 0.0207, 0.0317, 0.0022],\n",
      "        [0.0165, 0.0307, 0.0105, 0.0025],\n",
      "        [0.0297, 0.0117, 0.0333, 0.0028],\n",
      "        [0.0087, 0.0330, 0.0244, 0.0032],\n",
      "        [0.0331, 0.0263, 0.0352, 0.0034],\n",
      "        [0.0284, 0.0384, 0.0202, 0.0033],\n",
      "        [0.0405, 0.0232, 0.0048, 0.0029],\n",
      "        [0.0265, 0.0011, 0.0202, 0.0029],\n",
      "        [0.0019, 0.0167, 0.0396, 0.0034],\n",
      "        [0.0145, 0.0367, 0.0495, 0.0013],\n",
      "        [0.0347, 0.0467, 0.0529, 0.0036],\n",
      "        [0.0458, 0.0509, 0.0512, 0.0038],\n",
      "        [0.0508, 0.0497, 0.0431, 0.0037],\n",
      "        [0.0492, 0.0413, 0.0321, 0.0038],\n",
      "        [0.0462, 0.0338, 0.0298, 0.0041],\n",
      "        [0.0390, 0.0315, 0.0108, 0.0043],\n",
      "        [0.0344, 0.0108, 0.0406, 0.0044],\n",
      "        [0.0094, 0.0416, 0.0439, 0.0042],\n",
      "        [0.0375, 0.0430, 0.0340, 0.0047],\n",
      "        [0.0401, 0.0339, 0.0480, 0.0238],\n",
      "        [0.0036, 0.0130, 0.0101, 0.0214]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0489, 0.0196, 0.0304, 0.0007],\n",
      "        [0.0155, 0.0293, 0.0089, 0.0013],\n",
      "        [0.0288, 0.0105, 0.0318, 0.0016],\n",
      "        [0.0077, 0.0317, 0.0227, 0.0025],\n",
      "        [0.0325, 0.0252, 0.0339, 0.0026],\n",
      "        [0.0282, 0.0378, 0.0193, 0.0022],\n",
      "        [0.0405, 0.0228, 0.0055, 0.0017],\n",
      "        [0.0269, 0.0011, 0.0204, 0.0014],\n",
      "        [0.0024, 0.0166, 0.0397, 0.0020],\n",
      "        [0.0138, 0.0364, 0.0495, 0.0011],\n",
      "        [0.0340, 0.0465, 0.0530, 0.0025],\n",
      "        [0.0453, 0.0508, 0.0514, 0.0028],\n",
      "        [0.0505, 0.0498, 0.0434, 0.0030],\n",
      "        [0.0489, 0.0414, 0.0325, 0.0035],\n",
      "        [0.0466, 0.0346, 0.0309, 0.0045],\n",
      "        [0.0399, 0.0328, 0.0092, 0.0051],\n",
      "        [0.0353, 0.0094, 0.0390, 0.0052],\n",
      "        [0.0086, 0.0404, 0.0424, 0.0048],\n",
      "        [0.0366, 0.0416, 0.0323, 0.0057],\n",
      "        [0.0391, 0.0325, 0.0462, 0.0229],\n",
      "        [0.0033, 0.0122, 0.0089, 0.0194]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.574032306671143\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 22\n",
      "X 資料 torch.Size([85, 18])\n",
      "Y 資料 torch.Size([85, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0003877367125824094, 6)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引6，y= tensor([0.5789, 0.5583, 0.5331, 0.5217])\n",
      "目前模型的Data torch.Size([22, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5659, 0.5651, 0.5663, 0.5763],\n",
      "        [0.5693, 0.5675, 0.5681, 0.5979],\n",
      "        [0.5679, 0.5665, 0.5674, 0.5892],\n",
      "        [0.5693, 0.5675, 0.5681, 0.5982],\n",
      "        [0.5667, 0.5657, 0.5668, 0.5814],\n",
      "        [0.5627, 0.5629, 0.5647, 0.5557],\n",
      "        [0.5602, 0.5611, 0.5633, 0.5396],\n",
      "        [0.5571, 0.5590, 0.5617, 0.5197],\n",
      "        [0.5554, 0.5578, 0.5609, 0.5092],\n",
      "        [0.5551, 0.5576, 0.5607, 0.5067],\n",
      "        [0.5552, 0.5577, 0.5607, 0.5075],\n",
      "        [0.5565, 0.5586, 0.5614, 0.5161],\n",
      "        [0.5582, 0.5598, 0.5623, 0.5271],\n",
      "        [0.5589, 0.5603, 0.5627, 0.5317],\n",
      "        [0.5654, 0.5648, 0.5661, 0.5732],\n",
      "        [0.5700, 0.5680, 0.5685, 0.6026],\n",
      "        [0.5704, 0.5683, 0.5687, 0.6052],\n",
      "        [0.5691, 0.5673, 0.5680, 0.5966],\n",
      "        [0.5711, 0.5688, 0.5691, 0.6097],\n",
      "        [0.5713, 0.5689, 0.5692, 0.6108],\n",
      "        [0.5668, 0.5657, 0.5668, 0.5817],\n",
      "        [0.5551, 0.5576, 0.5607, 0.5067]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0489, 0.0196, 0.0304, 0.0007],\n",
      "        [0.0155, 0.0293, 0.0089, 0.0013],\n",
      "        [0.0288, 0.0105, 0.0318, 0.0016],\n",
      "        [0.0077, 0.0317, 0.0227, 0.0025],\n",
      "        [0.0325, 0.0252, 0.0339, 0.0026],\n",
      "        [0.0282, 0.0378, 0.0193, 0.0022],\n",
      "        [0.0405, 0.0228, 0.0055, 0.0017],\n",
      "        [0.0269, 0.0011, 0.0204, 0.0014],\n",
      "        [0.0024, 0.0166, 0.0397, 0.0020],\n",
      "        [0.0138, 0.0364, 0.0495, 0.0011],\n",
      "        [0.0340, 0.0465, 0.0530, 0.0025],\n",
      "        [0.0453, 0.0508, 0.0514, 0.0028],\n",
      "        [0.0505, 0.0498, 0.0434, 0.0030],\n",
      "        [0.0489, 0.0414, 0.0325, 0.0035],\n",
      "        [0.0466, 0.0346, 0.0309, 0.0045],\n",
      "        [0.0399, 0.0328, 0.0092, 0.0051],\n",
      "        [0.0353, 0.0094, 0.0390, 0.0052],\n",
      "        [0.0086, 0.0404, 0.0424, 0.0048],\n",
      "        [0.0366, 0.0416, 0.0323, 0.0057],\n",
      "        [0.0391, 0.0325, 0.0462, 0.0229],\n",
      "        [0.0033, 0.0122, 0.0089, 0.0194],\n",
      "        [0.0238, 0.0007, 0.0275, 0.0150]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 63\n",
      "Number of shrink: 37\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0469,     0.0190,     0.0313,     0.0020],\n",
      "        [    0.0131,     0.0283,     0.0094,     0.0013],\n",
      "        [    0.0266,     0.0097,     0.0325,     0.0008],\n",
      "        [    0.0054,     0.0308,     0.0233,     0.0004],\n",
      "        [    0.0305,     0.0246,     0.0348,     0.0005],\n",
      "        [    0.0267,     0.0376,     0.0206,     0.0001],\n",
      "        [    0.0392,     0.0229,     0.0039,     0.0005],\n",
      "        [    0.0260,     0.0007,     0.0185,     0.0009],\n",
      "        [    0.0018,     0.0159,     0.0376,     0.0002],\n",
      "        [    0.0142,     0.0356,     0.0472,     0.0002],\n",
      "        [    0.0346,     0.0458,     0.0508,     0.0006],\n",
      "        [    0.0461,     0.0503,     0.0494,     0.0010],\n",
      "        [    0.0514,     0.0494,     0.0416,     0.0014],\n",
      "        [    0.0499,     0.0411,     0.0307,     0.0022],\n",
      "        [    0.0482,     0.0350,     0.0298,     0.0036],\n",
      "        [    0.0420,     0.0336,     0.0098,     0.0043],\n",
      "        [    0.0374,     0.0086,     0.0396,     0.0044],\n",
      "        [    0.0066,     0.0397,     0.0431,     0.0039],\n",
      "        [    0.0344,     0.0407,     0.0328,     0.0052],\n",
      "        [    0.0368,     0.0315,     0.0467,     0.0236],\n",
      "        [    0.0016,     0.0118,     0.0100,     0.0197],\n",
      "        [    0.0235,     0.0016,     0.0252,     0.0147]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.858438014984131\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 23\n",
      "X 資料 torch.Size([84, 18])\n",
      "Y 資料 torch.Size([84, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0004618419916369021, 40)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引40，y= tensor([0.5757, 0.5623, 0.5692, 0.5428])\n",
      "目前模型的Data torch.Size([23, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5679, 0.5657, 0.5655, 0.5791],\n",
      "        [0.5716, 0.5684, 0.5676, 0.6005],\n",
      "        [0.5701, 0.5673, 0.5667, 0.5917],\n",
      "        [0.5716, 0.5684, 0.5676, 0.6003],\n",
      "        [0.5687, 0.5663, 0.5659, 0.5835],\n",
      "        [0.5642, 0.5631, 0.5634, 0.5578],\n",
      "        [0.5614, 0.5610, 0.5618, 0.5418],\n",
      "        [0.5580, 0.5586, 0.5598, 0.5221],\n",
      "        [0.5561, 0.5572, 0.5588, 0.5114],\n",
      "        [0.5555, 0.5568, 0.5584, 0.5080],\n",
      "        [0.5558, 0.5570, 0.5586, 0.5095],\n",
      "        [0.5573, 0.5580, 0.5594, 0.5179],\n",
      "        [0.5591, 0.5594, 0.5605, 0.5287],\n",
      "        [0.5599, 0.5599, 0.5609, 0.5330],\n",
      "        [0.5671, 0.5651, 0.5650, 0.5742],\n",
      "        [0.5722, 0.5688, 0.5679, 0.6034],\n",
      "        [0.5726, 0.5691, 0.5681, 0.6060],\n",
      "        [0.5711, 0.5681, 0.5673, 0.5974],\n",
      "        [0.5733, 0.5697, 0.5685, 0.6102],\n",
      "        [0.5736, 0.5698, 0.5687, 0.6114],\n",
      "        [0.5684, 0.5661, 0.5657, 0.5820],\n",
      "        [0.5554, 0.5566, 0.5583, 0.5070],\n",
      "        [0.5554, 0.5566, 0.5583, 0.5070]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0469,     0.0190,     0.0313,     0.0020],\n",
      "        [    0.0131,     0.0283,     0.0094,     0.0013],\n",
      "        [    0.0266,     0.0097,     0.0325,     0.0008],\n",
      "        [    0.0054,     0.0308,     0.0233,     0.0004],\n",
      "        [    0.0305,     0.0246,     0.0348,     0.0005],\n",
      "        [    0.0267,     0.0376,     0.0206,     0.0001],\n",
      "        [    0.0392,     0.0229,     0.0039,     0.0005],\n",
      "        [    0.0260,     0.0007,     0.0185,     0.0009],\n",
      "        [    0.0018,     0.0159,     0.0376,     0.0002],\n",
      "        [    0.0142,     0.0356,     0.0472,     0.0002],\n",
      "        [    0.0346,     0.0458,     0.0508,     0.0006],\n",
      "        [    0.0461,     0.0503,     0.0494,     0.0010],\n",
      "        [    0.0514,     0.0494,     0.0416,     0.0014],\n",
      "        [    0.0499,     0.0411,     0.0307,     0.0022],\n",
      "        [    0.0482,     0.0350,     0.0298,     0.0036],\n",
      "        [    0.0420,     0.0336,     0.0098,     0.0043],\n",
      "        [    0.0374,     0.0086,     0.0396,     0.0044],\n",
      "        [    0.0066,     0.0397,     0.0431,     0.0039],\n",
      "        [    0.0344,     0.0407,     0.0328,     0.0052],\n",
      "        [    0.0368,     0.0315,     0.0467,     0.0236],\n",
      "        [    0.0016,     0.0118,     0.0100,     0.0197],\n",
      "        [    0.0235,     0.0016,     0.0252,     0.0147],\n",
      "        [    0.0204,     0.0056,     0.0109,     0.0358]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0457,     0.0181,     0.0301,     0.0040],\n",
      "        [    0.0115,     0.0270,     0.0080,     0.0029],\n",
      "        [    0.0252,     0.0085,     0.0311,     0.0024],\n",
      "        [    0.0039,     0.0295,     0.0219,     0.0008],\n",
      "        [    0.0293,     0.0236,     0.0336,     0.0007],\n",
      "        [    0.0258,     0.0370,     0.0199,     0.0014],\n",
      "        [    0.0386,     0.0226,     0.0044,     0.0023],\n",
      "        [    0.0257,     0.0007,     0.0188,     0.0030],\n",
      "        [    0.0016,     0.0158,     0.0377,     0.0022],\n",
      "        [    0.0145,     0.0356,     0.0473,     0.0034],\n",
      "        [    0.0347,     0.0456,     0.0508,     0.0013],\n",
      "        [    0.0462,     0.0502,     0.0495,     0.0007],\n",
      "        [    0.0517,     0.0494,     0.0419,     0.0000],\n",
      "        [    0.0502,     0.0411,     0.0310,     0.0011],\n",
      "        [    0.0491,     0.0356,     0.0307,     0.0031],\n",
      "        [    0.0434,     0.0348,     0.0085,     0.0041],\n",
      "        [    0.0388,     0.0074,     0.0382,     0.0042],\n",
      "        [    0.0053,     0.0386,     0.0418,     0.0036],\n",
      "        [    0.0329,     0.0395,     0.0314,     0.0052],\n",
      "        [    0.0354,     0.0303,     0.0453,     0.0236],\n",
      "        [    0.0009,     0.0112,     0.0091,     0.0183],\n",
      "        [    0.0231,     0.0016,     0.0254,     0.0105],\n",
      "        [    0.0199,     0.0055,     0.0106,     0.0316]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.162156581878662\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 24\n",
      "X 資料 torch.Size([83, 18])\n",
      "Y 資料 torch.Size([83, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.000561487628147006, 6)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引6，y= tensor([0.5583, 0.5331, 0.5217, 0.5084])\n",
      "目前模型的Data torch.Size([24, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5692, 0.5667, 0.5666, 0.5810],\n",
      "        [0.5732, 0.5697, 0.5691, 0.6021],\n",
      "        [0.5715, 0.5685, 0.5680, 0.5933],\n",
      "        [0.5731, 0.5696, 0.5690, 0.6015],\n",
      "        [0.5699, 0.5672, 0.5670, 0.5847],\n",
      "        [0.5650, 0.5636, 0.5641, 0.5593],\n",
      "        [0.5620, 0.5614, 0.5623, 0.5436],\n",
      "        [0.5583, 0.5586, 0.5601, 0.5242],\n",
      "        [0.5563, 0.5571, 0.5588, 0.5134],\n",
      "        [0.5558, 0.5567, 0.5585, 0.5112],\n",
      "        [0.5559, 0.5568, 0.5586, 0.5114],\n",
      "        [0.5574, 0.5579, 0.5595, 0.5196],\n",
      "        [0.5595, 0.5594, 0.5607, 0.5302],\n",
      "        [0.5602, 0.5600, 0.5612, 0.5341],\n",
      "        [0.5680, 0.5658, 0.5659, 0.5746],\n",
      "        [0.5735, 0.5699, 0.5692, 0.6036],\n",
      "        [0.5740, 0.5703, 0.5695, 0.6062],\n",
      "        [0.5724, 0.5691, 0.5686, 0.5978],\n",
      "        [0.5748, 0.5709, 0.5700, 0.6102],\n",
      "        [0.5750, 0.5711, 0.5701, 0.6115],\n",
      "        [0.5691, 0.5667, 0.5666, 0.5806],\n",
      "        [0.5558, 0.5567, 0.5585, 0.5112],\n",
      "        [0.5558, 0.5567, 0.5585, 0.5112],\n",
      "        [0.5578, 0.5582, 0.5597, 0.5215]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0457,     0.0181,     0.0301,     0.0040],\n",
      "        [    0.0115,     0.0270,     0.0080,     0.0029],\n",
      "        [    0.0252,     0.0085,     0.0311,     0.0024],\n",
      "        [    0.0039,     0.0295,     0.0219,     0.0008],\n",
      "        [    0.0293,     0.0236,     0.0336,     0.0007],\n",
      "        [    0.0258,     0.0370,     0.0199,     0.0014],\n",
      "        [    0.0386,     0.0226,     0.0044,     0.0023],\n",
      "        [    0.0257,     0.0007,     0.0188,     0.0030],\n",
      "        [    0.0016,     0.0158,     0.0377,     0.0022],\n",
      "        [    0.0145,     0.0356,     0.0473,     0.0034],\n",
      "        [    0.0347,     0.0456,     0.0508,     0.0013],\n",
      "        [    0.0462,     0.0502,     0.0495,     0.0007],\n",
      "        [    0.0517,     0.0494,     0.0419,     0.0000],\n",
      "        [    0.0502,     0.0411,     0.0310,     0.0011],\n",
      "        [    0.0491,     0.0356,     0.0307,     0.0031],\n",
      "        [    0.0434,     0.0348,     0.0085,     0.0041],\n",
      "        [    0.0388,     0.0074,     0.0382,     0.0042],\n",
      "        [    0.0053,     0.0386,     0.0418,     0.0036],\n",
      "        [    0.0329,     0.0395,     0.0314,     0.0052],\n",
      "        [    0.0354,     0.0303,     0.0453,     0.0236],\n",
      "        [    0.0009,     0.0112,     0.0091,     0.0183],\n",
      "        [    0.0231,     0.0016,     0.0254,     0.0105],\n",
      "        [    0.0199,     0.0055,     0.0106,     0.0316],\n",
      "        [    0.0005,     0.0251,     0.0380,     0.0131]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 63\n",
      "Number of shrink: 37\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0455, 0.0192, 0.0317, 0.0036],\n",
      "        [0.0110, 0.0279, 0.0092, 0.0026],\n",
      "        [0.0250, 0.0096, 0.0326, 0.0013],\n",
      "        [0.0037, 0.0306, 0.0233, 0.0008],\n",
      "        [0.0294, 0.0250, 0.0353, 0.0012],\n",
      "        [0.0263, 0.0388, 0.0219, 0.0004],\n",
      "        [0.0393, 0.0246, 0.0021, 0.0007],\n",
      "        [0.0267, 0.0016, 0.0162, 0.0014],\n",
      "        [0.0029, 0.0133, 0.0349, 0.0002],\n",
      "        [0.0136, 0.0333, 0.0447, 0.0032],\n",
      "        [0.0337, 0.0433, 0.0482, 0.0009],\n",
      "        [0.0450, 0.0477, 0.0467, 0.0017],\n",
      "        [0.0506, 0.0471, 0.0392, 0.0026],\n",
      "        [0.0490, 0.0388, 0.0284, 0.0041],\n",
      "        [0.0485, 0.0339, 0.0287, 0.0065],\n",
      "        [0.0432, 0.0334, 0.0101, 0.0077],\n",
      "        [0.0387, 0.0087, 0.0398, 0.0077],\n",
      "        [0.0055, 0.0400, 0.0435, 0.0068],\n",
      "        [0.0330, 0.0408, 0.0329, 0.0089],\n",
      "        [0.0354, 0.0315, 0.0467, 0.0200],\n",
      "        [0.0016, 0.0131, 0.0112, 0.0138],\n",
      "        [0.0240, 0.0038, 0.0228, 0.0108],\n",
      "        [0.0208, 0.0078, 0.0132, 0.0318],\n",
      "        [0.0016, 0.0228, 0.0354, 0.0115]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.481619834899902\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 25\n",
      "X 資料 torch.Size([82, 18])\n",
      "Y 資料 torch.Size([82, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0005743989022448659, 39)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引39，y= tensor([0.5623, 0.5692, 0.5428, 0.4679])\n",
      "目前模型的Data torch.Size([25, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5693, 0.5655, 0.5651, 0.5806],\n",
      "        [0.5737, 0.5689, 0.5678, 0.6018],\n",
      "        [0.5717, 0.5674, 0.5666, 0.5922],\n",
      "        [0.5733, 0.5686, 0.5676, 0.5998],\n",
      "        [0.5698, 0.5659, 0.5654, 0.5828],\n",
      "        [0.5645, 0.5619, 0.5620, 0.5575],\n",
      "        [0.5613, 0.5594, 0.5600, 0.5420],\n",
      "        [0.5573, 0.5563, 0.5575, 0.5226],\n",
      "        [0.5550, 0.5545, 0.5560, 0.5114],\n",
      "        [0.5549, 0.5545, 0.5559, 0.5109],\n",
      "        [0.5549, 0.5545, 0.5559, 0.5109],\n",
      "        [0.5562, 0.5555, 0.5568, 0.5172],\n",
      "        [0.5583, 0.5571, 0.5581, 0.5276],\n",
      "        [0.5591, 0.5577, 0.5586, 0.5311],\n",
      "        [0.5674, 0.5640, 0.5638, 0.5712],\n",
      "        [0.5734, 0.5686, 0.5676, 0.6001],\n",
      "        [0.5739, 0.5690, 0.5680, 0.6026],\n",
      "        [0.5722, 0.5677, 0.5669, 0.5946],\n",
      "        [0.5747, 0.5696, 0.5685, 0.6064],\n",
      "        [0.5750, 0.5698, 0.5686, 0.6079],\n",
      "        [0.5684, 0.5648, 0.5645, 0.5761],\n",
      "        [0.5549, 0.5545, 0.5559, 0.5109],\n",
      "        [0.5549, 0.5545, 0.5559, 0.5109],\n",
      "        [0.5567, 0.5559, 0.5571, 0.5199],\n",
      "        [0.5549, 0.5545, 0.5559, 0.5109]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0455, 0.0192, 0.0317, 0.0036],\n",
      "        [0.0110, 0.0279, 0.0092, 0.0026],\n",
      "        [0.0250, 0.0096, 0.0326, 0.0013],\n",
      "        [0.0037, 0.0306, 0.0233, 0.0008],\n",
      "        [0.0294, 0.0250, 0.0353, 0.0012],\n",
      "        [0.0263, 0.0388, 0.0219, 0.0004],\n",
      "        [0.0393, 0.0246, 0.0021, 0.0007],\n",
      "        [0.0267, 0.0016, 0.0162, 0.0014],\n",
      "        [0.0029, 0.0133, 0.0349, 0.0002],\n",
      "        [0.0136, 0.0333, 0.0447, 0.0032],\n",
      "        [0.0337, 0.0433, 0.0482, 0.0009],\n",
      "        [0.0450, 0.0477, 0.0467, 0.0017],\n",
      "        [0.0506, 0.0471, 0.0392, 0.0026],\n",
      "        [0.0490, 0.0388, 0.0284, 0.0041],\n",
      "        [0.0485, 0.0339, 0.0287, 0.0065],\n",
      "        [0.0432, 0.0334, 0.0101, 0.0077],\n",
      "        [0.0387, 0.0087, 0.0398, 0.0077],\n",
      "        [0.0055, 0.0400, 0.0435, 0.0068],\n",
      "        [0.0330, 0.0408, 0.0329, 0.0089],\n",
      "        [0.0354, 0.0315, 0.0467, 0.0200],\n",
      "        [0.0016, 0.0131, 0.0112, 0.0138],\n",
      "        [0.0240, 0.0038, 0.0228, 0.0108],\n",
      "        [0.0208, 0.0078, 0.0132, 0.0318],\n",
      "        [0.0016, 0.0228, 0.0354, 0.0115],\n",
      "        [0.0074, 0.0147, 0.0132, 0.0430]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 63\n",
      "Number of shrink: 37\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0439,     0.0176,     0.0313,     0.0052],\n",
      "        [    0.0092,     0.0260,     0.0085,     0.0040],\n",
      "        [    0.0233,     0.0079,     0.0321,     0.0027],\n",
      "        [    0.0019,     0.0288,     0.0227,     0.0004],\n",
      "        [    0.0279,     0.0234,     0.0350,     0.0001],\n",
      "        [    0.0252,     0.0376,     0.0219,     0.0007],\n",
      "        [    0.0383,     0.0235,     0.0019,     0.0019],\n",
      "        [    0.0260,     0.0008,     0.0157,     0.0026],\n",
      "        [    0.0024,     0.0139,     0.0342,     0.0012],\n",
      "        [    0.0136,     0.0335,     0.0438,     0.0018],\n",
      "        [    0.0339,     0.0436,     0.0473,     0.0001],\n",
      "        [    0.0456,     0.0484,     0.0462,     0.0009],\n",
      "        [    0.0513,     0.0479,     0.0388,     0.0018],\n",
      "        [    0.0498,     0.0396,     0.0280,     0.0033],\n",
      "        [    0.0498,     0.0352,     0.0288,     0.0058],\n",
      "        [    0.0449,     0.0352,     0.0096,     0.0069],\n",
      "        [    0.0404,     0.0069,     0.0392,     0.0070],\n",
      "        [    0.0039,     0.0383,     0.0430,     0.0060],\n",
      "        [    0.0312,     0.0389,     0.0323,     0.0081],\n",
      "        [    0.0336,     0.0297,     0.0461,     0.0209],\n",
      "        [    0.0001,     0.0115,     0.0109,     0.0154],\n",
      "        [    0.0240,     0.0036,     0.0218,     0.0122],\n",
      "        [    0.0208,     0.0076,     0.0142,     0.0333],\n",
      "        [    0.0008,     0.0235,     0.0349,     0.0127],\n",
      "        [    0.0074,     0.0145,     0.0122,     0.0416]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.76661229133606\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 26\n",
      "X 資料 torch.Size([81, 18])\n",
      "Y 資料 torch.Size([81, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0006271551246754825, 5)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引5，y= tensor([0.5917, 0.5789, 0.5583, 0.5331])\n",
      "目前模型的Data torch.Size([26, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5709, 0.5671, 0.5654, 0.5822],\n",
      "        [0.5756, 0.5707, 0.5685, 0.6032],\n",
      "        [0.5734, 0.5691, 0.5671, 0.5935],\n",
      "        [0.5751, 0.5704, 0.5682, 0.6010],\n",
      "        [0.5713, 0.5674, 0.5657, 0.5839],\n",
      "        [0.5657, 0.5631, 0.5620, 0.5586],\n",
      "        [0.5623, 0.5604, 0.5598, 0.5432],\n",
      "        [0.5580, 0.5571, 0.5570, 0.5237],\n",
      "        [0.5555, 0.5552, 0.5554, 0.5124],\n",
      "        [0.5549, 0.5547, 0.5550, 0.5095],\n",
      "        [0.5550, 0.5548, 0.5551, 0.5101],\n",
      "        [0.5568, 0.5561, 0.5562, 0.5180],\n",
      "        [0.5590, 0.5579, 0.5577, 0.5284],\n",
      "        [0.5598, 0.5585, 0.5582, 0.5319],\n",
      "        [0.5687, 0.5654, 0.5640, 0.5720],\n",
      "        [0.5750, 0.5703, 0.5681, 0.6008],\n",
      "        [0.5756, 0.5708, 0.5685, 0.6034],\n",
      "        [0.5738, 0.5694, 0.5674, 0.5954],\n",
      "        [0.5765, 0.5715, 0.5691, 0.6073],\n",
      "        [0.5768, 0.5717, 0.5693, 0.6088],\n",
      "        [0.5699, 0.5664, 0.5648, 0.5777],\n",
      "        [0.5549, 0.5547, 0.5550, 0.5095],\n",
      "        [0.5549, 0.5547, 0.5550, 0.5095],\n",
      "        [0.5575, 0.5566, 0.5566, 0.5211],\n",
      "        [0.5549, 0.5547, 0.5550, 0.5095],\n",
      "        [0.5549, 0.5547, 0.5550, 0.5095]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0439,     0.0176,     0.0313,     0.0052],\n",
      "        [    0.0092,     0.0260,     0.0085,     0.0040],\n",
      "        [    0.0233,     0.0079,     0.0321,     0.0027],\n",
      "        [    0.0019,     0.0288,     0.0227,     0.0004],\n",
      "        [    0.0279,     0.0234,     0.0350,     0.0001],\n",
      "        [    0.0252,     0.0376,     0.0219,     0.0007],\n",
      "        [    0.0383,     0.0235,     0.0019,     0.0019],\n",
      "        [    0.0260,     0.0008,     0.0157,     0.0026],\n",
      "        [    0.0024,     0.0139,     0.0342,     0.0012],\n",
      "        [    0.0136,     0.0335,     0.0438,     0.0018],\n",
      "        [    0.0339,     0.0436,     0.0473,     0.0001],\n",
      "        [    0.0456,     0.0484,     0.0462,     0.0009],\n",
      "        [    0.0513,     0.0479,     0.0388,     0.0018],\n",
      "        [    0.0498,     0.0396,     0.0280,     0.0033],\n",
      "        [    0.0498,     0.0352,     0.0288,     0.0058],\n",
      "        [    0.0449,     0.0352,     0.0096,     0.0069],\n",
      "        [    0.0404,     0.0069,     0.0392,     0.0070],\n",
      "        [    0.0039,     0.0383,     0.0430,     0.0060],\n",
      "        [    0.0312,     0.0389,     0.0323,     0.0081],\n",
      "        [    0.0336,     0.0297,     0.0461,     0.0209],\n",
      "        [    0.0001,     0.0115,     0.0109,     0.0154],\n",
      "        [    0.0240,     0.0036,     0.0218,     0.0122],\n",
      "        [    0.0208,     0.0076,     0.0142,     0.0333],\n",
      "        [    0.0008,     0.0235,     0.0349,     0.0127],\n",
      "        [    0.0074,     0.0145,     0.0122,     0.0416],\n",
      "        [    0.0368,     0.0242,     0.0033,     0.0236]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 63\n",
      "Number of shrink: 37\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0422,     0.0163,     0.0311,     0.0065],\n",
      "        [    0.0072,     0.0245,     0.0081,     0.0055],\n",
      "        [    0.0216,     0.0066,     0.0319,     0.0033],\n",
      "        [    0.0003,     0.0275,     0.0225,     0.0004],\n",
      "        [    0.0266,     0.0224,     0.0350,     0.0006],\n",
      "        [    0.0242,     0.0369,     0.0223,     0.0001],\n",
      "        [    0.0375,     0.0230,     0.0015,     0.0015],\n",
      "        [    0.0254,     0.0005,     0.0150,     0.0017],\n",
      "        [    0.0020,     0.0140,     0.0333,     0.0001],\n",
      "        [    0.0143,     0.0339,     0.0431,     0.0022],\n",
      "        [    0.0344,     0.0438,     0.0465,     0.0001],\n",
      "        [    0.0459,     0.0484,     0.0452,     0.0025],\n",
      "        [    0.0517,     0.0480,     0.0380,     0.0036],\n",
      "        [    0.0501,     0.0397,     0.0272,     0.0056],\n",
      "        [    0.0505,     0.0357,     0.0283,     0.0082],\n",
      "        [    0.0460,     0.0360,     0.0097,     0.0091],\n",
      "        [    0.0416,     0.0060,     0.0393,     0.0090],\n",
      "        [    0.0027,     0.0374,     0.0431,     0.0076],\n",
      "        [    0.0300,     0.0379,     0.0323,     0.0099],\n",
      "        [    0.0322,     0.0286,     0.0460,     0.0195],\n",
      "        [    0.0006,     0.0110,     0.0114,     0.0126],\n",
      "        [    0.0233,     0.0033,     0.0211,     0.0117],\n",
      "        [    0.0201,     0.0073,     0.0149,     0.0328],\n",
      "        [    0.0001,     0.0239,     0.0343,     0.0126],\n",
      "        [    0.0067,     0.0142,     0.0115,     0.0421],\n",
      "        [    0.0361,     0.0239,     0.0040,     0.0232]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.070261478424072\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 27\n",
      "X 資料 torch.Size([80, 18])\n",
      "Y 資料 torch.Size([80, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0008653013501316309, 3)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引3，y= tensor([0.5849, 0.5841, 0.5917, 0.5789])\n",
      "目前模型的Data torch.Size([27, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5726, 0.5684, 0.5657, 0.5835],\n",
      "        [0.5775, 0.5723, 0.5689, 0.6046],\n",
      "        [0.5751, 0.5704, 0.5673, 0.5941],\n",
      "        [0.5767, 0.5716, 0.5684, 0.6011],\n",
      "        [0.5726, 0.5684, 0.5656, 0.5834],\n",
      "        [0.5667, 0.5637, 0.5617, 0.5578],\n",
      "        [0.5632, 0.5610, 0.5594, 0.5428],\n",
      "        [0.5586, 0.5574, 0.5563, 0.5229],\n",
      "        [0.5559, 0.5552, 0.5545, 0.5111],\n",
      "        [0.5556, 0.5550, 0.5543, 0.5100],\n",
      "        [0.5556, 0.5550, 0.5543, 0.5100],\n",
      "        [0.5571, 0.5562, 0.5553, 0.5164],\n",
      "        [0.5595, 0.5581, 0.5569, 0.5266],\n",
      "        [0.5602, 0.5586, 0.5573, 0.5296],\n",
      "        [0.5694, 0.5659, 0.5635, 0.5695],\n",
      "        [0.5761, 0.5712, 0.5680, 0.5986],\n",
      "        [0.5768, 0.5717, 0.5684, 0.6014],\n",
      "        [0.5750, 0.5703, 0.5672, 0.5937],\n",
      "        [0.5777, 0.5725, 0.5691, 0.6055],\n",
      "        [0.5782, 0.5728, 0.5694, 0.6074],\n",
      "        [0.5706, 0.5669, 0.5643, 0.5749],\n",
      "        [0.5556, 0.5550, 0.5543, 0.5100],\n",
      "        [0.5556, 0.5550, 0.5543, 0.5100],\n",
      "        [0.5582, 0.5570, 0.5560, 0.5210],\n",
      "        [0.5556, 0.5550, 0.5543, 0.5100],\n",
      "        [0.5556, 0.5550, 0.5543, 0.5100],\n",
      "        [0.5629, 0.5608, 0.5592, 0.5417]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0422,     0.0163,     0.0311,     0.0065],\n",
      "        [    0.0072,     0.0245,     0.0081,     0.0055],\n",
      "        [    0.0216,     0.0066,     0.0319,     0.0033],\n",
      "        [    0.0003,     0.0275,     0.0225,     0.0004],\n",
      "        [    0.0266,     0.0224,     0.0350,     0.0006],\n",
      "        [    0.0242,     0.0369,     0.0223,     0.0001],\n",
      "        [    0.0375,     0.0230,     0.0015,     0.0015],\n",
      "        [    0.0254,     0.0005,     0.0150,     0.0017],\n",
      "        [    0.0020,     0.0140,     0.0333,     0.0001],\n",
      "        [    0.0143,     0.0339,     0.0431,     0.0022],\n",
      "        [    0.0344,     0.0438,     0.0465,     0.0001],\n",
      "        [    0.0459,     0.0484,     0.0452,     0.0025],\n",
      "        [    0.0517,     0.0480,     0.0380,     0.0036],\n",
      "        [    0.0501,     0.0397,     0.0272,     0.0056],\n",
      "        [    0.0505,     0.0357,     0.0283,     0.0082],\n",
      "        [    0.0460,     0.0360,     0.0097,     0.0091],\n",
      "        [    0.0416,     0.0060,     0.0393,     0.0090],\n",
      "        [    0.0027,     0.0374,     0.0431,     0.0076],\n",
      "        [    0.0300,     0.0379,     0.0323,     0.0099],\n",
      "        [    0.0322,     0.0286,     0.0460,     0.0195],\n",
      "        [    0.0006,     0.0110,     0.0114,     0.0126],\n",
      "        [    0.0233,     0.0033,     0.0211,     0.0117],\n",
      "        [    0.0201,     0.0073,     0.0149,     0.0328],\n",
      "        [    0.0001,     0.0239,     0.0343,     0.0126],\n",
      "        [    0.0067,     0.0142,     0.0115,     0.0421],\n",
      "        [    0.0361,     0.0239,     0.0040,     0.0232],\n",
      "        [    0.0219,     0.0233,     0.0325,     0.0372]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 63\n",
      "Number of shrink: 37\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0405,     0.0146,     0.0290,     0.0095],\n",
      "        [    0.0054,     0.0226,     0.0058,     0.0083],\n",
      "        [    0.0199,     0.0048,     0.0297,     0.0061],\n",
      "        [    0.0015,     0.0257,     0.0202,     0.0031],\n",
      "        [    0.0249,     0.0208,     0.0329,     0.0022],\n",
      "        [    0.0228,     0.0355,     0.0205,     0.0025],\n",
      "        [    0.0363,     0.0217,     0.0031,     0.0042],\n",
      "        [    0.0244,     0.0005,     0.0165,     0.0044],\n",
      "        [    0.0012,     0.0149,     0.0347,     0.0026],\n",
      "        [    0.0148,     0.0345,     0.0442,     0.0034],\n",
      "        [    0.0350,     0.0445,     0.0477,     0.0015],\n",
      "        [    0.0467,     0.0494,     0.0466,     0.0000],\n",
      "        [    0.0526,     0.0491,     0.0394,     0.0012],\n",
      "        [    0.0511,     0.0408,     0.0286,     0.0032],\n",
      "        [    0.0518,     0.0371,     0.0302,     0.0061],\n",
      "        [    0.0476,     0.0377,     0.0076,     0.0070],\n",
      "        [    0.0433,     0.0042,     0.0371,     0.0067],\n",
      "        [    0.0011,     0.0357,     0.0410,     0.0053],\n",
      "        [    0.0282,     0.0361,     0.0300,     0.0073],\n",
      "        [    0.0303,     0.0266,     0.0437,     0.0224],\n",
      "        [    0.0024,     0.0092,     0.0092,     0.0163],\n",
      "        [    0.0228,     0.0026,     0.0222,     0.0106],\n",
      "        [    0.0196,     0.0066,     0.0138,     0.0317],\n",
      "        [    0.0011,     0.0251,     0.0359,     0.0162],\n",
      "        [    0.0062,     0.0135,     0.0126,     0.0432],\n",
      "        [    0.0356,     0.0232,     0.0029,     0.0220],\n",
      "        [    0.0205,     0.0218,     0.0307,     0.0337]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.370847940444946\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 28\n",
      "X 資料 torch.Size([79, 18])\n",
      "Y 資料 torch.Size([79, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0010733185335993767, 4)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引4，y= tensor([0.5331, 0.5217, 0.5084, 0.4909])\n",
      "目前模型的Data torch.Size([28, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5743, 0.5702, 0.5678, 0.5865],\n",
      "        [0.5794, 0.5742, 0.5712, 0.6074],\n",
      "        [0.5769, 0.5722, 0.5695, 0.5970],\n",
      "        [0.5785, 0.5735, 0.5706, 0.6038],\n",
      "        [0.5742, 0.5701, 0.5677, 0.5861],\n",
      "        [0.5680, 0.5651, 0.5635, 0.5604],\n",
      "        [0.5644, 0.5623, 0.5610, 0.5455],\n",
      "        [0.5596, 0.5584, 0.5577, 0.5256],\n",
      "        [0.5567, 0.5562, 0.5558, 0.5138],\n",
      "        [0.5561, 0.5556, 0.5554, 0.5111],\n",
      "        [0.5562, 0.5557, 0.5554, 0.5115],\n",
      "        [0.5580, 0.5571, 0.5566, 0.5189],\n",
      "        [0.5604, 0.5591, 0.5583, 0.5290],\n",
      "        [0.5611, 0.5597, 0.5588, 0.5319],\n",
      "        [0.5707, 0.5673, 0.5653, 0.5716],\n",
      "        [0.5778, 0.5729, 0.5701, 0.6007],\n",
      "        [0.5785, 0.5735, 0.5706, 0.6036],\n",
      "        [0.5767, 0.5720, 0.5694, 0.5961],\n",
      "        [0.5796, 0.5743, 0.5713, 0.6081],\n",
      "        [0.5801, 0.5747, 0.5717, 0.6103],\n",
      "        [0.5724, 0.5686, 0.5665, 0.5786],\n",
      "        [0.5561, 0.5556, 0.5554, 0.5111],\n",
      "        [0.5561, 0.5556, 0.5554, 0.5111],\n",
      "        [0.5593, 0.5582, 0.5576, 0.5246],\n",
      "        [0.5561, 0.5556, 0.5554, 0.5111],\n",
      "        [0.5561, 0.5556, 0.5554, 0.5111],\n",
      "        [0.5643, 0.5622, 0.5610, 0.5452],\n",
      "        [0.5561, 0.5556, 0.5554, 0.5111]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0405,     0.0146,     0.0290,     0.0095],\n",
      "        [    0.0054,     0.0226,     0.0058,     0.0083],\n",
      "        [    0.0199,     0.0048,     0.0297,     0.0061],\n",
      "        [    0.0015,     0.0257,     0.0202,     0.0031],\n",
      "        [    0.0249,     0.0208,     0.0329,     0.0022],\n",
      "        [    0.0228,     0.0355,     0.0205,     0.0025],\n",
      "        [    0.0363,     0.0217,     0.0031,     0.0042],\n",
      "        [    0.0244,     0.0005,     0.0165,     0.0044],\n",
      "        [    0.0012,     0.0149,     0.0347,     0.0026],\n",
      "        [    0.0148,     0.0345,     0.0442,     0.0034],\n",
      "        [    0.0350,     0.0445,     0.0477,     0.0015],\n",
      "        [    0.0467,     0.0494,     0.0466,     0.0000],\n",
      "        [    0.0526,     0.0491,     0.0394,     0.0012],\n",
      "        [    0.0511,     0.0408,     0.0286,     0.0032],\n",
      "        [    0.0518,     0.0371,     0.0302,     0.0061],\n",
      "        [    0.0476,     0.0377,     0.0076,     0.0070],\n",
      "        [    0.0433,     0.0042,     0.0371,     0.0067],\n",
      "        [    0.0011,     0.0357,     0.0410,     0.0053],\n",
      "        [    0.0282,     0.0361,     0.0300,     0.0073],\n",
      "        [    0.0303,     0.0266,     0.0437,     0.0224],\n",
      "        [    0.0024,     0.0092,     0.0092,     0.0163],\n",
      "        [    0.0228,     0.0026,     0.0222,     0.0106],\n",
      "        [    0.0196,     0.0066,     0.0138,     0.0317],\n",
      "        [    0.0011,     0.0251,     0.0359,     0.0162],\n",
      "        [    0.0062,     0.0135,     0.0126,     0.0432],\n",
      "        [    0.0356,     0.0232,     0.0029,     0.0220],\n",
      "        [    0.0205,     0.0218,     0.0307,     0.0337],\n",
      "        [    0.0229,     0.0339,     0.0470,     0.0202]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 63\n",
      "Number of shrink: 37\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0413, 0.0158, 0.0304, 0.0085],\n",
      "        [0.0059, 0.0235, 0.0070, 0.0069],\n",
      "        [0.0205, 0.0059, 0.0310, 0.0049],\n",
      "        [0.0009, 0.0267, 0.0215, 0.0016],\n",
      "        [0.0258, 0.0221, 0.0345, 0.0006],\n",
      "        [0.0242, 0.0373, 0.0225, 0.0010],\n",
      "        [0.0378, 0.0237, 0.0009, 0.0027],\n",
      "        [0.0263, 0.0018, 0.0139, 0.0029],\n",
      "        [0.0033, 0.0124, 0.0319, 0.0009],\n",
      "        [0.0128, 0.0321, 0.0415, 0.0025],\n",
      "        [0.0329, 0.0420, 0.0450, 0.0002],\n",
      "        [0.0447, 0.0469, 0.0439, 0.0018],\n",
      "        [0.0507, 0.0467, 0.0369, 0.0031],\n",
      "        [0.0492, 0.0385, 0.0261, 0.0053],\n",
      "        [0.0505, 0.0354, 0.0282, 0.0085],\n",
      "        [0.0467, 0.0364, 0.0091, 0.0094],\n",
      "        [0.0425, 0.0054, 0.0385, 0.0089],\n",
      "        [0.0019, 0.0370, 0.0425, 0.0073],\n",
      "        [0.0288, 0.0372, 0.0314, 0.0093],\n",
      "        [0.0308, 0.0276, 0.0449, 0.0208],\n",
      "        [0.0016, 0.0105, 0.0107, 0.0158],\n",
      "        [0.0248, 0.0050, 0.0196, 0.0115],\n",
      "        [0.0216, 0.0090, 0.0164, 0.0325],\n",
      "        [0.0005, 0.0231, 0.0336, 0.0162],\n",
      "        [0.0082, 0.0159, 0.0100, 0.0423],\n",
      "        [0.0376, 0.0256, 0.0055, 0.0229],\n",
      "        [0.0218, 0.0236, 0.0327, 0.0340],\n",
      "        [0.0210, 0.0316, 0.0444, 0.0193]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.67282772064209\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 29\n",
      "X 資料 torch.Size([78, 18])\n",
      "Y 資料 torch.Size([78, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.001158878905698657, 35)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引35，y= tensor([0.5779, 0.5757, 0.5623, 0.5692])\n",
      "目前模型的Data torch.Size([29, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5736, 0.5690, 0.5663, 0.5856],\n",
      "        [0.5789, 0.5732, 0.5700, 0.6061],\n",
      "        [0.5762, 0.5711, 0.5682, 0.5958],\n",
      "        [0.5779, 0.5724, 0.5693, 0.6023],\n",
      "        [0.5733, 0.5688, 0.5661, 0.5846],\n",
      "        [0.5667, 0.5634, 0.5615, 0.5589],\n",
      "        [0.5628, 0.5603, 0.5588, 0.5440],\n",
      "        [0.5577, 0.5561, 0.5552, 0.5240],\n",
      "        [0.5546, 0.5536, 0.5531, 0.5121],\n",
      "        [0.5541, 0.5533, 0.5527, 0.5102],\n",
      "        [0.5541, 0.5533, 0.5527, 0.5102],\n",
      "        [0.5559, 0.5547, 0.5540, 0.5171],\n",
      "        [0.5585, 0.5568, 0.5558, 0.5271],\n",
      "        [0.5592, 0.5573, 0.5563, 0.5299],\n",
      "        [0.5693, 0.5655, 0.5634, 0.5692],\n",
      "        [0.5769, 0.5716, 0.5686, 0.5983],\n",
      "        [0.5777, 0.5723, 0.5692, 0.6015],\n",
      "        [0.5758, 0.5707, 0.5678, 0.5940],\n",
      "        [0.5789, 0.5732, 0.5700, 0.6061],\n",
      "        [0.5796, 0.5738, 0.5705, 0.6087],\n",
      "        [0.5716, 0.5674, 0.5650, 0.5781],\n",
      "        [0.5541, 0.5533, 0.5527, 0.5102],\n",
      "        [0.5541, 0.5533, 0.5527, 0.5102],\n",
      "        [0.5578, 0.5562, 0.5553, 0.5246],\n",
      "        [0.5541, 0.5533, 0.5527, 0.5102],\n",
      "        [0.5541, 0.5533, 0.5527, 0.5102],\n",
      "        [0.5631, 0.5605, 0.5590, 0.5449],\n",
      "        [0.5541, 0.5533, 0.5527, 0.5102],\n",
      "        [0.5541, 0.5533, 0.5527, 0.5102]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0413, 0.0158, 0.0304, 0.0085],\n",
      "        [0.0059, 0.0235, 0.0070, 0.0069],\n",
      "        [0.0205, 0.0059, 0.0310, 0.0049],\n",
      "        [0.0009, 0.0267, 0.0215, 0.0016],\n",
      "        [0.0258, 0.0221, 0.0345, 0.0006],\n",
      "        [0.0242, 0.0373, 0.0225, 0.0010],\n",
      "        [0.0378, 0.0237, 0.0009, 0.0027],\n",
      "        [0.0263, 0.0018, 0.0139, 0.0029],\n",
      "        [0.0033, 0.0124, 0.0319, 0.0009],\n",
      "        [0.0128, 0.0321, 0.0415, 0.0025],\n",
      "        [0.0329, 0.0420, 0.0450, 0.0002],\n",
      "        [0.0447, 0.0469, 0.0439, 0.0018],\n",
      "        [0.0507, 0.0467, 0.0369, 0.0031],\n",
      "        [0.0492, 0.0385, 0.0261, 0.0053],\n",
      "        [0.0505, 0.0354, 0.0282, 0.0085],\n",
      "        [0.0467, 0.0364, 0.0091, 0.0094],\n",
      "        [0.0425, 0.0054, 0.0385, 0.0089],\n",
      "        [0.0019, 0.0370, 0.0425, 0.0073],\n",
      "        [0.0288, 0.0372, 0.0314, 0.0093],\n",
      "        [0.0308, 0.0276, 0.0449, 0.0208],\n",
      "        [0.0016, 0.0105, 0.0107, 0.0158],\n",
      "        [0.0248, 0.0050, 0.0196, 0.0115],\n",
      "        [0.0216, 0.0090, 0.0164, 0.0325],\n",
      "        [0.0005, 0.0231, 0.0336, 0.0162],\n",
      "        [0.0082, 0.0159, 0.0100, 0.0423],\n",
      "        [0.0376, 0.0256, 0.0055, 0.0229],\n",
      "        [0.0218, 0.0236, 0.0327, 0.0340],\n",
      "        [0.0210, 0.0316, 0.0444, 0.0193],\n",
      "        [0.0238, 0.0225, 0.0095, 0.0589]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 63\n",
      "Number of shrink: 37\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0394, 0.0140, 0.0293, 0.0114],\n",
      "        [0.0038, 0.0215, 0.0056, 0.0089],\n",
      "        [0.0187, 0.0041, 0.0299, 0.0068],\n",
      "        [0.0028, 0.0249, 0.0203, 0.0032],\n",
      "        [0.0244, 0.0206, 0.0337, 0.0020],\n",
      "        [0.0234, 0.0364, 0.0222, 0.0022],\n",
      "        [0.0371, 0.0230, 0.0010, 0.0046],\n",
      "        [0.0262, 0.0016, 0.0135, 0.0043],\n",
      "        [0.0036, 0.0122, 0.0311, 0.0018],\n",
      "        [0.0122, 0.0316, 0.0405, 0.0022],\n",
      "        [0.0325, 0.0417, 0.0441, 0.0006],\n",
      "        [0.0443, 0.0467, 0.0432, 0.0014],\n",
      "        [0.0506, 0.0468, 0.0363, 0.0026],\n",
      "        [0.0492, 0.0387, 0.0257, 0.0044],\n",
      "        [0.0514, 0.0364, 0.0285, 0.0078],\n",
      "        [0.0483, 0.0381, 0.0081, 0.0086],\n",
      "        [0.0443, 0.0036, 0.0374, 0.0076],\n",
      "        [0.0002, 0.0353, 0.0415, 0.0058],\n",
      "        [0.0267, 0.0350, 0.0299, 0.0070],\n",
      "        [0.0285, 0.0253, 0.0433, 0.0236],\n",
      "        [0.0055, 0.0070, 0.0082, 0.0263],\n",
      "        [0.0254, 0.0055, 0.0185, 0.0117],\n",
      "        [0.0223, 0.0095, 0.0175, 0.0328],\n",
      "        [0.0007, 0.0242, 0.0339, 0.0213],\n",
      "        [0.0088, 0.0164, 0.0089, 0.0421],\n",
      "        [0.0382, 0.0261, 0.0066, 0.0231],\n",
      "        [0.0206, 0.0224, 0.0322, 0.0303],\n",
      "        [0.0203, 0.0311, 0.0433, 0.0191],\n",
      "        [0.0217, 0.0207, 0.0086, 0.0495]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.957902908325195\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 30\n",
      "X 資料 torch.Size([77, 18])\n",
      "Y 資料 torch.Size([77, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0013800286687910557, 3)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引3，y= tensor([0.5841, 0.5917, 0.5789, 0.5583])\n",
      "目前模型的Data torch.Size([30, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5755, 0.5708, 0.5674, 0.5885],\n",
      "        [0.5810, 0.5753, 0.5714, 0.6080],\n",
      "        [0.5780, 0.5729, 0.5693, 0.5977],\n",
      "        [0.5798, 0.5743, 0.5705, 0.6038],\n",
      "        [0.5748, 0.5702, 0.5670, 0.5860],\n",
      "        [0.5675, 0.5643, 0.5617, 0.5601],\n",
      "        [0.5635, 0.5610, 0.5589, 0.5459],\n",
      "        [0.5578, 0.5563, 0.5548, 0.5254],\n",
      "        [0.5543, 0.5535, 0.5523, 0.5130],\n",
      "        [0.5534, 0.5528, 0.5517, 0.5100],\n",
      "        [0.5536, 0.5529, 0.5518, 0.5107],\n",
      "        [0.5555, 0.5545, 0.5532, 0.5175],\n",
      "        [0.5584, 0.5568, 0.5552, 0.5276],\n",
      "        [0.5593, 0.5575, 0.5558, 0.5307],\n",
      "        [0.5703, 0.5665, 0.5637, 0.5699],\n",
      "        [0.5784, 0.5732, 0.5696, 0.5991],\n",
      "        [0.5795, 0.5741, 0.5703, 0.6028],\n",
      "        [0.5775, 0.5724, 0.5689, 0.5956],\n",
      "        [0.5811, 0.5754, 0.5715, 0.6084],\n",
      "        [0.5819, 0.5761, 0.5721, 0.6115],\n",
      "        [0.5755, 0.5708, 0.5675, 0.5886],\n",
      "        [0.5534, 0.5528, 0.5517, 0.5100],\n",
      "        [0.5534, 0.5528, 0.5517, 0.5100],\n",
      "        [0.5590, 0.5573, 0.5556, 0.5297],\n",
      "        [0.5534, 0.5528, 0.5517, 0.5100],\n",
      "        [0.5534, 0.5528, 0.5517, 0.5100],\n",
      "        [0.5643, 0.5616, 0.5594, 0.5486],\n",
      "        [0.5534, 0.5528, 0.5517, 0.5100],\n",
      "        [0.5562, 0.5550, 0.5536, 0.5197],\n",
      "        [0.5534, 0.5528, 0.5517, 0.5100]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0394, 0.0140, 0.0293, 0.0114],\n",
      "        [0.0038, 0.0215, 0.0056, 0.0089],\n",
      "        [0.0187, 0.0041, 0.0299, 0.0068],\n",
      "        [0.0028, 0.0249, 0.0203, 0.0032],\n",
      "        [0.0244, 0.0206, 0.0337, 0.0020],\n",
      "        [0.0234, 0.0364, 0.0222, 0.0022],\n",
      "        [0.0371, 0.0230, 0.0010, 0.0046],\n",
      "        [0.0262, 0.0016, 0.0135, 0.0043],\n",
      "        [0.0036, 0.0122, 0.0311, 0.0018],\n",
      "        [0.0122, 0.0316, 0.0405, 0.0022],\n",
      "        [0.0325, 0.0417, 0.0441, 0.0006],\n",
      "        [0.0443, 0.0467, 0.0432, 0.0014],\n",
      "        [0.0506, 0.0468, 0.0363, 0.0026],\n",
      "        [0.0492, 0.0387, 0.0257, 0.0044],\n",
      "        [0.0514, 0.0364, 0.0285, 0.0078],\n",
      "        [0.0483, 0.0381, 0.0081, 0.0086],\n",
      "        [0.0443, 0.0036, 0.0374, 0.0076],\n",
      "        [0.0002, 0.0353, 0.0415, 0.0058],\n",
      "        [0.0267, 0.0350, 0.0299, 0.0070],\n",
      "        [0.0285, 0.0253, 0.0433, 0.0236],\n",
      "        [0.0055, 0.0070, 0.0082, 0.0263],\n",
      "        [0.0254, 0.0055, 0.0185, 0.0117],\n",
      "        [0.0223, 0.0095, 0.0175, 0.0328],\n",
      "        [0.0007, 0.0242, 0.0339, 0.0213],\n",
      "        [0.0088, 0.0164, 0.0089, 0.0421],\n",
      "        [0.0382, 0.0261, 0.0066, 0.0231],\n",
      "        [0.0206, 0.0224, 0.0322, 0.0303],\n",
      "        [0.0203, 0.0311, 0.0433, 0.0191],\n",
      "        [0.0217, 0.0207, 0.0086, 0.0495],\n",
      "        [0.0306, 0.0389, 0.0272, 0.0483]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 63\n",
      "Number of shrink: 37\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0372,     0.0111,     0.0270,     0.0152],\n",
      "        [    0.0016,     0.0183,     0.0030,     0.0122],\n",
      "        [    0.0166,     0.0012,     0.0274,     0.0101],\n",
      "        [    0.0049,     0.0219,     0.0179,     0.0061],\n",
      "        [    0.0225,     0.0181,     0.0316,     0.0049],\n",
      "        [    0.0219,     0.0344,     0.0207,     0.0047],\n",
      "        [    0.0359,     0.0213,     0.0022,     0.0069],\n",
      "        [    0.0253,     0.0005,     0.0142,     0.0062],\n",
      "        [    0.0029,     0.0129,     0.0315,     0.0034],\n",
      "        [    0.0125,     0.0320,     0.0405,     0.0026],\n",
      "        [    0.0332,     0.0425,     0.0444,     0.0022],\n",
      "        [    0.0451,     0.0476,     0.0436,     0.0000],\n",
      "        [    0.0514,     0.0478,     0.0369,     0.0014],\n",
      "        [    0.0500,     0.0397,     0.0263,     0.0032],\n",
      "        [    0.0526,     0.0382,     0.0299,     0.0067],\n",
      "        [    0.0498,     0.0405,     0.0061,     0.0073],\n",
      "        [    0.0461,     0.0010,     0.0352,     0.0058],\n",
      "        [    0.0014,     0.0328,     0.0394,     0.0040],\n",
      "        [    0.0247,     0.0321,     0.0275,     0.0046],\n",
      "        [    0.0262,     0.0222,     0.0407,     0.0267],\n",
      "        [    0.0089,     0.0031,     0.0049,     0.0345],\n",
      "        [    0.0251,     0.0051,     0.0186,     0.0114],\n",
      "        [    0.0220,     0.0091,     0.0174,     0.0325],\n",
      "        [    0.0029,     0.0264,     0.0357,     0.0274],\n",
      "        [    0.0085,     0.0160,     0.0090,     0.0424],\n",
      "        [    0.0379,     0.0257,     0.0066,     0.0228],\n",
      "        [    0.0184,     0.0200,     0.0303,     0.0249],\n",
      "        [    0.0206,     0.0315,     0.0434,     0.0194],\n",
      "        [    0.0188,     0.0180,     0.0065,     0.0406],\n",
      "        [    0.0289,     0.0373,     0.0261,     0.0433]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.229212999343872\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 31\n",
      "X 資料 torch.Size([76, 18])\n",
      "Y 資料 torch.Size([76, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.002457871101796627, 2)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引2，y= tensor([0.5879, 0.5849, 0.5841, 0.5917])\n",
      "目前模型的Data torch.Size([31, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5776, 0.5736, 0.5698, 0.5922],\n",
      "        [0.5832, 0.5784, 0.5740, 0.6114],\n",
      "        [0.5802, 0.5758, 0.5717, 0.6010],\n",
      "        [0.5819, 0.5773, 0.5730, 0.6068],\n",
      "        [0.5766, 0.5728, 0.5691, 0.5888],\n",
      "        [0.5690, 0.5662, 0.5633, 0.5626],\n",
      "        [0.5648, 0.5626, 0.5601, 0.5482],\n",
      "        [0.5587, 0.5574, 0.5555, 0.5273],\n",
      "        [0.5550, 0.5542, 0.5527, 0.5146],\n",
      "        [0.5538, 0.5532, 0.5517, 0.5104],\n",
      "        [0.5543, 0.5537, 0.5522, 0.5122],\n",
      "        [0.5563, 0.5553, 0.5536, 0.5189],\n",
      "        [0.5591, 0.5578, 0.5558, 0.5288],\n",
      "        [0.5601, 0.5586, 0.5565, 0.5320],\n",
      "        [0.5714, 0.5683, 0.5651, 0.5710],\n",
      "        [0.5800, 0.5757, 0.5716, 0.6004],\n",
      "        [0.5812, 0.5767, 0.5725, 0.6046],\n",
      "        [0.5791, 0.5749, 0.5709, 0.5974],\n",
      "        [0.5830, 0.5783, 0.5739, 0.6108],\n",
      "        [0.5841, 0.5792, 0.5747, 0.6146],\n",
      "        [0.5789, 0.5748, 0.5708, 0.5968],\n",
      "        [0.5538, 0.5532, 0.5517, 0.5103],\n",
      "        [0.5538, 0.5532, 0.5517, 0.5103],\n",
      "        [0.5612, 0.5595, 0.5574, 0.5358],\n",
      "        [0.5538, 0.5532, 0.5517, 0.5103],\n",
      "        [0.5538, 0.5532, 0.5517, 0.5103],\n",
      "        [0.5665, 0.5641, 0.5614, 0.5540],\n",
      "        [0.5538, 0.5532, 0.5517, 0.5103],\n",
      "        [0.5591, 0.5577, 0.5558, 0.5285],\n",
      "        [0.5551, 0.5543, 0.5528, 0.5149],\n",
      "        [0.5538, 0.5532, 0.5517, 0.5103]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0372,     0.0111,     0.0270,     0.0152],\n",
      "        [    0.0016,     0.0183,     0.0030,     0.0122],\n",
      "        [    0.0166,     0.0012,     0.0274,     0.0101],\n",
      "        [    0.0049,     0.0219,     0.0179,     0.0061],\n",
      "        [    0.0225,     0.0181,     0.0316,     0.0049],\n",
      "        [    0.0219,     0.0344,     0.0207,     0.0047],\n",
      "        [    0.0359,     0.0213,     0.0022,     0.0069],\n",
      "        [    0.0253,     0.0005,     0.0142,     0.0062],\n",
      "        [    0.0029,     0.0129,     0.0315,     0.0034],\n",
      "        [    0.0125,     0.0320,     0.0405,     0.0026],\n",
      "        [    0.0332,     0.0425,     0.0444,     0.0022],\n",
      "        [    0.0451,     0.0476,     0.0436,     0.0000],\n",
      "        [    0.0514,     0.0478,     0.0369,     0.0014],\n",
      "        [    0.0500,     0.0397,     0.0263,     0.0032],\n",
      "        [    0.0526,     0.0382,     0.0299,     0.0067],\n",
      "        [    0.0498,     0.0405,     0.0061,     0.0073],\n",
      "        [    0.0461,     0.0010,     0.0352,     0.0058],\n",
      "        [    0.0014,     0.0328,     0.0394,     0.0040],\n",
      "        [    0.0247,     0.0321,     0.0275,     0.0046],\n",
      "        [    0.0262,     0.0222,     0.0407,     0.0267],\n",
      "        [    0.0089,     0.0031,     0.0049,     0.0345],\n",
      "        [    0.0251,     0.0051,     0.0186,     0.0114],\n",
      "        [    0.0220,     0.0091,     0.0174,     0.0325],\n",
      "        [    0.0029,     0.0264,     0.0357,     0.0274],\n",
      "        [    0.0085,     0.0160,     0.0090,     0.0424],\n",
      "        [    0.0379,     0.0257,     0.0066,     0.0228],\n",
      "        [    0.0184,     0.0200,     0.0303,     0.0249],\n",
      "        [    0.0206,     0.0315,     0.0434,     0.0194],\n",
      "        [    0.0188,     0.0180,     0.0065,     0.0406],\n",
      "        [    0.0289,     0.0373,     0.0261,     0.0433],\n",
      "        [    0.0341,     0.0317,     0.0323,     0.0813]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"86\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"97\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 63\n",
      "Number of shrink: 37\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0369,     0.0101,     0.0259,     0.0150],\n",
      "        [    0.0014,     0.0171,     0.0016,     0.0116],\n",
      "        [    0.0163,     0.0001,     0.0263,     0.0097],\n",
      "        [    0.0050,     0.0208,     0.0166,     0.0054],\n",
      "        [    0.0224,     0.0173,     0.0307,     0.0041],\n",
      "        [    0.0217,     0.0342,     0.0203,     0.0040],\n",
      "        [    0.0356,     0.0213,     0.0023,     0.0065],\n",
      "        [    0.0250,     0.0009,     0.0139,     0.0057],\n",
      "        [    0.0023,     0.0126,     0.0312,     0.0038],\n",
      "        [    0.0143,     0.0327,     0.0412,     0.0073],\n",
      "        [    0.0344,     0.0427,     0.0446,     0.0050],\n",
      "        [    0.0453,     0.0470,     0.0431,     0.0005],\n",
      "        [    0.0516,     0.0473,     0.0366,     0.0021],\n",
      "        [    0.0502,     0.0393,     0.0261,     0.0040],\n",
      "        [    0.0526,     0.0385,     0.0304,     0.0079],\n",
      "        [    0.0499,     0.0414,     0.0051,     0.0085],\n",
      "        [    0.0462,     0.0001,     0.0340,     0.0065],\n",
      "        [    0.0016,     0.0318,     0.0384,     0.0047],\n",
      "        [    0.0245,     0.0308,     0.0261,     0.0052],\n",
      "        [    0.0259,     0.0207,     0.0391,     0.0266],\n",
      "        [    0.0095,     0.0018,     0.0036,     0.0352],\n",
      "        [    0.0233,     0.0044,     0.0192,     0.0067],\n",
      "        [    0.0201,     0.0084,     0.0168,     0.0278],\n",
      "        [    0.0038,     0.0267,     0.0360,     0.0289],\n",
      "        [    0.0067,     0.0153,     0.0096,     0.0471],\n",
      "        [    0.0361,     0.0250,     0.0059,     0.0181],\n",
      "        [    0.0176,     0.0193,     0.0296,     0.0236],\n",
      "        [    0.0224,     0.0322,     0.0440,     0.0241],\n",
      "        [    0.0179,     0.0178,     0.0063,     0.0392],\n",
      "        [    0.0280,     0.0374,     0.0262,     0.0417],\n",
      "        [    0.0323,     0.0310,     0.0317,     0.0766]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.550746440887451\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 32\n",
      "X 資料 torch.Size([75, 18])\n",
      "Y 資料 torch.Size([75, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.00263961311429739, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引1，y= tensor([0.6154, 0.5879, 0.5849, 0.5841])\n",
      "目前模型的Data torch.Size([32, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5780, 0.5746, 0.5709, 0.5921],\n",
      "        [0.5834, 0.5797, 0.5754, 0.6108],\n",
      "        [0.5804, 0.5769, 0.5729, 0.6005],\n",
      "        [0.5820, 0.5784, 0.5742, 0.6061],\n",
      "        [0.5768, 0.5736, 0.5699, 0.5881],\n",
      "        [0.5692, 0.5665, 0.5636, 0.5619],\n",
      "        [0.5651, 0.5627, 0.5602, 0.5477],\n",
      "        [0.5590, 0.5570, 0.5552, 0.5268],\n",
      "        [0.5556, 0.5539, 0.5524, 0.5150],\n",
      "        [0.5556, 0.5539, 0.5524, 0.5150],\n",
      "        [0.5556, 0.5539, 0.5524, 0.5150],\n",
      "        [0.5565, 0.5547, 0.5532, 0.5183],\n",
      "        [0.5594, 0.5574, 0.5555, 0.5281],\n",
      "        [0.5603, 0.5582, 0.5562, 0.5311],\n",
      "        [0.5715, 0.5686, 0.5655, 0.5698],\n",
      "        [0.5801, 0.5766, 0.5726, 0.5992],\n",
      "        [0.5814, 0.5778, 0.5737, 0.6038],\n",
      "        [0.5793, 0.5759, 0.5720, 0.5967],\n",
      "        [0.5832, 0.5795, 0.5752, 0.6102],\n",
      "        [0.5845, 0.5807, 0.5762, 0.6145],\n",
      "        [0.5795, 0.5761, 0.5722, 0.5974],\n",
      "        [0.5556, 0.5539, 0.5524, 0.5150],\n",
      "        [0.5556, 0.5539, 0.5524, 0.5150],\n",
      "        [0.5620, 0.5599, 0.5577, 0.5372],\n",
      "        [0.5556, 0.5539, 0.5524, 0.5150],\n",
      "        [0.5556, 0.5539, 0.5524, 0.5150],\n",
      "        [0.5673, 0.5647, 0.5620, 0.5553],\n",
      "        [0.5556, 0.5539, 0.5524, 0.5150],\n",
      "        [0.5599, 0.5579, 0.5560, 0.5299],\n",
      "        [0.5560, 0.5543, 0.5527, 0.5165],\n",
      "        [0.5556, 0.5539, 0.5524, 0.5150],\n",
      "        [0.5556, 0.5539, 0.5524, 0.5150]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0369,     0.0101,     0.0259,     0.0150],\n",
      "        [    0.0014,     0.0171,     0.0016,     0.0116],\n",
      "        [    0.0163,     0.0001,     0.0263,     0.0097],\n",
      "        [    0.0050,     0.0208,     0.0166,     0.0054],\n",
      "        [    0.0224,     0.0173,     0.0307,     0.0041],\n",
      "        [    0.0217,     0.0342,     0.0203,     0.0040],\n",
      "        [    0.0356,     0.0213,     0.0023,     0.0065],\n",
      "        [    0.0250,     0.0009,     0.0139,     0.0057],\n",
      "        [    0.0023,     0.0126,     0.0312,     0.0038],\n",
      "        [    0.0143,     0.0327,     0.0412,     0.0073],\n",
      "        [    0.0344,     0.0427,     0.0446,     0.0050],\n",
      "        [    0.0453,     0.0470,     0.0431,     0.0005],\n",
      "        [    0.0516,     0.0473,     0.0366,     0.0021],\n",
      "        [    0.0502,     0.0393,     0.0261,     0.0040],\n",
      "        [    0.0526,     0.0385,     0.0304,     0.0079],\n",
      "        [    0.0499,     0.0414,     0.0051,     0.0085],\n",
      "        [    0.0462,     0.0001,     0.0340,     0.0065],\n",
      "        [    0.0016,     0.0318,     0.0384,     0.0047],\n",
      "        [    0.0245,     0.0308,     0.0261,     0.0052],\n",
      "        [    0.0259,     0.0207,     0.0391,     0.0266],\n",
      "        [    0.0095,     0.0018,     0.0036,     0.0352],\n",
      "        [    0.0233,     0.0044,     0.0192,     0.0067],\n",
      "        [    0.0201,     0.0084,     0.0168,     0.0278],\n",
      "        [    0.0038,     0.0267,     0.0360,     0.0289],\n",
      "        [    0.0067,     0.0153,     0.0096,     0.0471],\n",
      "        [    0.0361,     0.0250,     0.0059,     0.0181],\n",
      "        [    0.0176,     0.0193,     0.0296,     0.0236],\n",
      "        [    0.0224,     0.0322,     0.0440,     0.0241],\n",
      "        [    0.0179,     0.0178,     0.0063,     0.0392],\n",
      "        [    0.0280,     0.0374,     0.0262,     0.0417],\n",
      "        [    0.0323,     0.0310,     0.0317,     0.0766],\n",
      "        [    0.0598,     0.0340,     0.0325,     0.0690]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 63\n",
      "Number of shrink: 37\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0365, 0.0095, 0.0252, 0.0132],\n",
      "        [0.0013, 0.0161, 0.0007, 0.0091],\n",
      "        [0.0161, 0.0007, 0.0254, 0.0075],\n",
      "        [0.0052, 0.0198, 0.0157, 0.0032],\n",
      "        [0.0220, 0.0167, 0.0301, 0.0022],\n",
      "        [0.0210, 0.0341, 0.0202, 0.0025],\n",
      "        [0.0347, 0.0215, 0.0022, 0.0053],\n",
      "        [0.0239, 0.0015, 0.0134, 0.0048],\n",
      "        [0.0016, 0.0146, 0.0330, 0.0128],\n",
      "        [0.0183, 0.0347, 0.0429, 0.0162],\n",
      "        [0.0384, 0.0446, 0.0464, 0.0140],\n",
      "        [0.0483, 0.0481, 0.0441, 0.0051],\n",
      "        [0.0528, 0.0469, 0.0362, 0.0026],\n",
      "        [0.0514, 0.0389, 0.0257, 0.0045],\n",
      "        [0.0534, 0.0389, 0.0308, 0.0088],\n",
      "        [0.0504, 0.0425, 0.0041, 0.0097],\n",
      "        [0.0467, 0.0013, 0.0328, 0.0075],\n",
      "        [0.0022, 0.0308, 0.0373, 0.0056],\n",
      "        [0.0240, 0.0295, 0.0248, 0.0062],\n",
      "        [0.0254, 0.0192, 0.0376, 0.0258],\n",
      "        [0.0101, 0.0007, 0.0025, 0.0342],\n",
      "        [0.0194, 0.0024, 0.0210, 0.0023],\n",
      "        [0.0162, 0.0064, 0.0151, 0.0188],\n",
      "        [0.0050, 0.0266, 0.0359, 0.0289],\n",
      "        [0.0027, 0.0133, 0.0113, 0.0561],\n",
      "        [0.0321, 0.0230, 0.0042, 0.0091],\n",
      "        [0.0165, 0.0190, 0.0293, 0.0235],\n",
      "        [0.0264, 0.0342, 0.0457, 0.0331],\n",
      "        [0.0166, 0.0181, 0.0066, 0.0392],\n",
      "        [0.0245, 0.0358, 0.0248, 0.0343],\n",
      "        [0.0284, 0.0290, 0.0299, 0.0677],\n",
      "        [0.0559, 0.0320, 0.0308, 0.0601]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.835357904434204\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 33\n",
      "X 資料 torch.Size([74, 18])\n",
      "Y 資料 torch.Size([74, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0025358672719448805, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.6014, 0.6154, 0.5879, 0.5849])\n",
      "目前模型的Data torch.Size([33, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5783, 0.5753, 0.5716, 0.5902],\n",
      "        [0.5834, 0.5806, 0.5764, 0.6083],\n",
      "        [0.5807, 0.5777, 0.5738, 0.5984],\n",
      "        [0.5822, 0.5793, 0.5752, 0.6038],\n",
      "        [0.5772, 0.5741, 0.5705, 0.5862],\n",
      "        [0.5699, 0.5666, 0.5637, 0.5604],\n",
      "        [0.5660, 0.5625, 0.5601, 0.5466],\n",
      "        [0.5601, 0.5564, 0.5546, 0.5260],\n",
      "        [0.5595, 0.5559, 0.5541, 0.5240],\n",
      "        [0.5595, 0.5559, 0.5541, 0.5240],\n",
      "        [0.5595, 0.5559, 0.5541, 0.5240],\n",
      "        [0.5595, 0.5559, 0.5541, 0.5240],\n",
      "        [0.5606, 0.5569, 0.5551, 0.5276],\n",
      "        [0.5614, 0.5578, 0.5559, 0.5307],\n",
      "        [0.5723, 0.5690, 0.5660, 0.5689],\n",
      "        [0.5805, 0.5776, 0.5737, 0.5980],\n",
      "        [0.5819, 0.5791, 0.5749, 0.6029],\n",
      "        [0.5799, 0.5770, 0.5731, 0.5958],\n",
      "        [0.5837, 0.5809, 0.5766, 0.6092],\n",
      "        [0.5850, 0.5822, 0.5778, 0.6137],\n",
      "        [0.5801, 0.5772, 0.5733, 0.5965],\n",
      "        [0.5595, 0.5559, 0.5541, 0.5240],\n",
      "        [0.5595, 0.5559, 0.5541, 0.5240],\n",
      "        [0.5633, 0.5598, 0.5576, 0.5373],\n",
      "        [0.5595, 0.5559, 0.5541, 0.5240],\n",
      "        [0.5595, 0.5559, 0.5541, 0.5240],\n",
      "        [0.5684, 0.5651, 0.5624, 0.5553],\n",
      "        [0.5595, 0.5559, 0.5541, 0.5240],\n",
      "        [0.5612, 0.5576, 0.5557, 0.5300],\n",
      "        [0.5595, 0.5559, 0.5541, 0.5240],\n",
      "        [0.5595, 0.5559, 0.5541, 0.5240],\n",
      "        [0.5595, 0.5559, 0.5541, 0.5240],\n",
      "        [0.5595, 0.5559, 0.5541, 0.5240]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0365, 0.0095, 0.0252, 0.0132],\n",
      "        [0.0013, 0.0161, 0.0007, 0.0091],\n",
      "        [0.0161, 0.0007, 0.0254, 0.0075],\n",
      "        [0.0052, 0.0198, 0.0157, 0.0032],\n",
      "        [0.0220, 0.0167, 0.0301, 0.0022],\n",
      "        [0.0210, 0.0341, 0.0202, 0.0025],\n",
      "        [0.0347, 0.0215, 0.0022, 0.0053],\n",
      "        [0.0239, 0.0015, 0.0134, 0.0048],\n",
      "        [0.0016, 0.0146, 0.0330, 0.0128],\n",
      "        [0.0183, 0.0347, 0.0429, 0.0162],\n",
      "        [0.0384, 0.0446, 0.0464, 0.0140],\n",
      "        [0.0483, 0.0481, 0.0441, 0.0051],\n",
      "        [0.0528, 0.0469, 0.0362, 0.0026],\n",
      "        [0.0514, 0.0389, 0.0257, 0.0045],\n",
      "        [0.0534, 0.0389, 0.0308, 0.0088],\n",
      "        [0.0504, 0.0425, 0.0041, 0.0097],\n",
      "        [0.0467, 0.0013, 0.0328, 0.0075],\n",
      "        [0.0022, 0.0308, 0.0373, 0.0056],\n",
      "        [0.0240, 0.0295, 0.0248, 0.0062],\n",
      "        [0.0254, 0.0192, 0.0376, 0.0258],\n",
      "        [0.0101, 0.0007, 0.0025, 0.0342],\n",
      "        [0.0194, 0.0024, 0.0210, 0.0023],\n",
      "        [0.0162, 0.0064, 0.0151, 0.0188],\n",
      "        [0.0050, 0.0266, 0.0359, 0.0289],\n",
      "        [0.0027, 0.0133, 0.0113, 0.0561],\n",
      "        [0.0321, 0.0230, 0.0042, 0.0091],\n",
      "        [0.0165, 0.0190, 0.0293, 0.0235],\n",
      "        [0.0264, 0.0342, 0.0457, 0.0331],\n",
      "        [0.0166, 0.0181, 0.0066, 0.0392],\n",
      "        [0.0245, 0.0358, 0.0248, 0.0343],\n",
      "        [0.0284, 0.0290, 0.0299, 0.0677],\n",
      "        [0.0559, 0.0320, 0.0308, 0.0601],\n",
      "        [0.0418, 0.0595, 0.0338, 0.0609]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 26\n",
      "Number of shrink: 20\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0358,     0.0077,     0.0242,     0.0134],\n",
      "        [    0.0007,     0.0142,     0.0004,     0.0092],\n",
      "        [    0.0154,     0.0025,     0.0244,     0.0077],\n",
      "        [    0.0058,     0.0180,     0.0147,     0.0032],\n",
      "        [    0.0213,     0.0150,     0.0292,     0.0024],\n",
      "        [    0.0201,     0.0326,     0.0195,     0.0029],\n",
      "        [    0.0337,     0.0200,     0.0028,     0.0059],\n",
      "        [    0.0222,     0.0004,     0.0144,     0.0074],\n",
      "        [    0.0039,     0.0170,     0.0345,     0.0173],\n",
      "        [    0.0205,     0.0372,     0.0444,     0.0208],\n",
      "        [    0.0407,     0.0471,     0.0479,     0.0185],\n",
      "        [    0.0506,     0.0506,     0.0456,     0.0096],\n",
      "        [    0.0541,     0.0483,     0.0368,     0.0016],\n",
      "        [    0.0526,     0.0403,     0.0263,     0.0037],\n",
      "        [    0.0543,     0.0406,     0.0316,     0.0083],\n",
      "        [    0.0511,     0.0443,     0.0030,     0.0093],\n",
      "        [    0.0475,     0.0033,     0.0317,     0.0071],\n",
      "        [    0.0029,     0.0289,     0.0363,     0.0052],\n",
      "        [    0.0233,     0.0275,     0.0236,     0.0059],\n",
      "        [    0.0248,     0.0171,     0.0364,     0.0260],\n",
      "        [    0.0108,     0.0012,     0.0014,     0.0345],\n",
      "        [    0.0171,     0.0000,     0.0225,     0.0068],\n",
      "        [    0.0139,     0.0040,     0.0135,     0.0142],\n",
      "        [    0.0062,     0.0281,     0.0365,     0.0296],\n",
      "        [    0.0005,     0.0109,     0.0129,     0.0606],\n",
      "        [    0.0298,     0.0206,     0.0026,     0.0046],\n",
      "        [    0.0154,     0.0174,     0.0285,     0.0228],\n",
      "        [    0.0287,     0.0366,     0.0473,     0.0376],\n",
      "        [    0.0154,     0.0167,     0.0060,     0.0384],\n",
      "        [    0.0222,     0.0333,     0.0232,     0.0298],\n",
      "        [    0.0261,     0.0266,     0.0284,     0.0631],\n",
      "        [    0.0536,     0.0296,     0.0292,     0.0555],\n",
      "        [    0.0396,     0.0571,     0.0322,     0.0564]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.02234435081482\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 34\n",
      "X 資料 torch.Size([73, 18])\n",
      "Y 資料 torch.Size([73, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.002748141996562481, 30)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引30，y= tensor([0.5578, 0.5700, 0.5779, 0.5757])\n",
      "目前模型的Data torch.Size([34, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5790, 0.5771, 0.5725, 0.5904],\n",
      "        [0.5840, 0.5825, 0.5774, 0.6083],\n",
      "        [0.5813, 0.5796, 0.5748, 0.5985],\n",
      "        [0.5828, 0.5812, 0.5762, 0.6039],\n",
      "        [0.5779, 0.5759, 0.5714, 0.5864],\n",
      "        [0.5708, 0.5681, 0.5645, 0.5608],\n",
      "        [0.5670, 0.5640, 0.5607, 0.5472],\n",
      "        [0.5618, 0.5583, 0.5556, 0.5285],\n",
      "        [0.5618, 0.5583, 0.5556, 0.5285],\n",
      "        [0.5618, 0.5583, 0.5556, 0.5285],\n",
      "        [0.5618, 0.5583, 0.5556, 0.5285],\n",
      "        [0.5618, 0.5583, 0.5556, 0.5285],\n",
      "        [0.5618, 0.5583, 0.5556, 0.5285],\n",
      "        [0.5626, 0.5592, 0.5564, 0.5314],\n",
      "        [0.5732, 0.5707, 0.5668, 0.5694],\n",
      "        [0.5813, 0.5795, 0.5747, 0.5984],\n",
      "        [0.5826, 0.5810, 0.5761, 0.6033],\n",
      "        [0.5807, 0.5788, 0.5741, 0.5962],\n",
      "        [0.5844, 0.5829, 0.5778, 0.6095],\n",
      "        [0.5856, 0.5842, 0.5790, 0.6139],\n",
      "        [0.5808, 0.5790, 0.5743, 0.5968],\n",
      "        [0.5618, 0.5583, 0.5556, 0.5285],\n",
      "        [0.5618, 0.5583, 0.5556, 0.5285],\n",
      "        [0.5644, 0.5612, 0.5582, 0.5380],\n",
      "        [0.5618, 0.5583, 0.5556, 0.5285],\n",
      "        [0.5618, 0.5583, 0.5556, 0.5285],\n",
      "        [0.5695, 0.5667, 0.5632, 0.5561],\n",
      "        [0.5618, 0.5583, 0.5556, 0.5285],\n",
      "        [0.5624, 0.5590, 0.5563, 0.5307],\n",
      "        [0.5618, 0.5583, 0.5556, 0.5285],\n",
      "        [0.5618, 0.5583, 0.5556, 0.5285],\n",
      "        [0.5618, 0.5583, 0.5556, 0.5285],\n",
      "        [0.5618, 0.5583, 0.5556, 0.5285],\n",
      "        [0.6000, 0.5999, 0.5931, 0.6656]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0358,     0.0077,     0.0242,     0.0134],\n",
      "        [    0.0007,     0.0142,     0.0004,     0.0092],\n",
      "        [    0.0154,     0.0025,     0.0244,     0.0077],\n",
      "        [    0.0058,     0.0180,     0.0147,     0.0032],\n",
      "        [    0.0213,     0.0150,     0.0292,     0.0024],\n",
      "        [    0.0201,     0.0326,     0.0195,     0.0029],\n",
      "        [    0.0337,     0.0200,     0.0028,     0.0059],\n",
      "        [    0.0222,     0.0004,     0.0144,     0.0074],\n",
      "        [    0.0039,     0.0170,     0.0345,     0.0173],\n",
      "        [    0.0205,     0.0372,     0.0444,     0.0208],\n",
      "        [    0.0407,     0.0471,     0.0479,     0.0185],\n",
      "        [    0.0506,     0.0506,     0.0456,     0.0096],\n",
      "        [    0.0541,     0.0483,     0.0368,     0.0016],\n",
      "        [    0.0526,     0.0403,     0.0263,     0.0037],\n",
      "        [    0.0543,     0.0406,     0.0316,     0.0083],\n",
      "        [    0.0511,     0.0443,     0.0030,     0.0093],\n",
      "        [    0.0475,     0.0033,     0.0317,     0.0071],\n",
      "        [    0.0029,     0.0289,     0.0363,     0.0052],\n",
      "        [    0.0233,     0.0275,     0.0236,     0.0059],\n",
      "        [    0.0248,     0.0171,     0.0364,     0.0260],\n",
      "        [    0.0108,     0.0012,     0.0014,     0.0345],\n",
      "        [    0.0171,     0.0000,     0.0225,     0.0068],\n",
      "        [    0.0139,     0.0040,     0.0135,     0.0142],\n",
      "        [    0.0062,     0.0281,     0.0365,     0.0296],\n",
      "        [    0.0005,     0.0109,     0.0129,     0.0606],\n",
      "        [    0.0298,     0.0206,     0.0026,     0.0046],\n",
      "        [    0.0154,     0.0174,     0.0285,     0.0228],\n",
      "        [    0.0287,     0.0366,     0.0473,     0.0376],\n",
      "        [    0.0154,     0.0167,     0.0060,     0.0384],\n",
      "        [    0.0222,     0.0333,     0.0232,     0.0298],\n",
      "        [    0.0261,     0.0266,     0.0284,     0.0631],\n",
      "        [    0.0536,     0.0296,     0.0292,     0.0555],\n",
      "        [    0.0396,     0.0571,     0.0322,     0.0564],\n",
      "        [    0.0422,     0.0299,     0.0152,     0.0899]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"92\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0370, 0.0062, 0.0223, 0.0130],\n",
      "        [0.0023, 0.0118, 0.0033, 0.0092],\n",
      "        [0.0168, 0.0044, 0.0221, 0.0073],\n",
      "        [0.0042, 0.0161, 0.0122, 0.0024],\n",
      "        [0.0224, 0.0139, 0.0276, 0.0016],\n",
      "        [0.0202, 0.0322, 0.0186, 0.0034],\n",
      "        [0.0334, 0.0202, 0.0032, 0.0067],\n",
      "        [0.0211, 0.0002, 0.0143, 0.0096],\n",
      "        [0.0050, 0.0164, 0.0344, 0.0195],\n",
      "        [0.0216, 0.0366, 0.0443, 0.0230],\n",
      "        [0.0418, 0.0465, 0.0478, 0.0207],\n",
      "        [0.0517, 0.0500, 0.0455, 0.0119],\n",
      "        [0.0552, 0.0477, 0.0367, 0.0007],\n",
      "        [0.0532, 0.0393, 0.0258, 0.0031],\n",
      "        [0.0534, 0.0405, 0.0322, 0.0100],\n",
      "        [0.0492, 0.0455, 0.0013, 0.0117],\n",
      "        [0.0453, 0.0044, 0.0300, 0.0102],\n",
      "        [0.0011, 0.0279, 0.0347, 0.0077],\n",
      "        [0.0259, 0.0264, 0.0219, 0.0097],\n",
      "        [0.0273, 0.0155, 0.0342, 0.0229],\n",
      "        [0.0024, 0.0069, 0.0081, 0.0061],\n",
      "        [0.0160, 0.0006, 0.0224, 0.0090],\n",
      "        [0.0128, 0.0046, 0.0136, 0.0120],\n",
      "        [0.0055, 0.0257, 0.0349, 0.0256],\n",
      "        [0.0006, 0.0115, 0.0128, 0.0629],\n",
      "        [0.0287, 0.0212, 0.0027, 0.0024],\n",
      "        [0.0160, 0.0180, 0.0285, 0.0245],\n",
      "        [0.0298, 0.0360, 0.0472, 0.0398],\n",
      "        [0.0149, 0.0180, 0.0067, 0.0384],\n",
      "        [0.0211, 0.0339, 0.0233, 0.0275],\n",
      "        [0.0250, 0.0272, 0.0285, 0.0609],\n",
      "        [0.0525, 0.0302, 0.0293, 0.0533],\n",
      "        [0.0384, 0.0577, 0.0323, 0.0541],\n",
      "        [0.0312, 0.0240, 0.0107, 0.0584]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.317856550216675\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 35\n",
      "X 資料 torch.Size([72, 18])\n",
      "Y 資料 torch.Size([72, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.002936291741207242, 52)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引52，y= tensor([0.4972, 0.5403, 0.5808, 0.6112])\n",
      "目前模型的Data torch.Size([35, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5779, 0.5785, 0.5745, 0.5900],\n",
      "        [0.5825, 0.5850, 0.5804, 0.6084],\n",
      "        [0.5799, 0.5814, 0.5771, 0.5982],\n",
      "        [0.5812, 0.5831, 0.5787, 0.6031],\n",
      "        [0.5768, 0.5770, 0.5731, 0.5856],\n",
      "        [0.5706, 0.5685, 0.5653, 0.5613],\n",
      "        [0.5673, 0.5638, 0.5611, 0.5480],\n",
      "        [0.5629, 0.5577, 0.5556, 0.5307],\n",
      "        [0.5629, 0.5577, 0.5556, 0.5307],\n",
      "        [0.5629, 0.5577, 0.5556, 0.5307],\n",
      "        [0.5629, 0.5577, 0.5556, 0.5307],\n",
      "        [0.5629, 0.5577, 0.5556, 0.5307],\n",
      "        [0.5630, 0.5577, 0.5556, 0.5308],\n",
      "        [0.5633, 0.5582, 0.5560, 0.5321],\n",
      "        [0.5722, 0.5707, 0.5674, 0.5677],\n",
      "        [0.5794, 0.5806, 0.5764, 0.5960],\n",
      "        [0.5804, 0.5821, 0.5778, 0.6002],\n",
      "        [0.5788, 0.5798, 0.5757, 0.5937],\n",
      "        [0.5818, 0.5840, 0.5795, 0.6057],\n",
      "        [0.5831, 0.5858, 0.5812, 0.6108],\n",
      "        [0.5724, 0.5709, 0.5676, 0.5684],\n",
      "        [0.5629, 0.5577, 0.5556, 0.5307],\n",
      "        [0.5629, 0.5577, 0.5556, 0.5307],\n",
      "        [0.5637, 0.5588, 0.5566, 0.5339],\n",
      "        [0.5629, 0.5577, 0.5556, 0.5307],\n",
      "        [0.5629, 0.5577, 0.5556, 0.5307],\n",
      "        [0.5689, 0.5660, 0.5631, 0.5544],\n",
      "        [0.5629, 0.5577, 0.5556, 0.5307],\n",
      "        [0.5629, 0.5577, 0.5556, 0.5307],\n",
      "        [0.5629, 0.5577, 0.5556, 0.5307],\n",
      "        [0.5629, 0.5577, 0.5556, 0.5307],\n",
      "        [0.5629, 0.5577, 0.5556, 0.5307],\n",
      "        [0.5629, 0.5577, 0.5556, 0.5307],\n",
      "        [0.5890, 0.5940, 0.5886, 0.6341],\n",
      "        [0.5629, 0.5577, 0.5556, 0.5307]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0370, 0.0062, 0.0223, 0.0130],\n",
      "        [0.0023, 0.0118, 0.0033, 0.0092],\n",
      "        [0.0168, 0.0044, 0.0221, 0.0073],\n",
      "        [0.0042, 0.0161, 0.0122, 0.0024],\n",
      "        [0.0224, 0.0139, 0.0276, 0.0016],\n",
      "        [0.0202, 0.0322, 0.0186, 0.0034],\n",
      "        [0.0334, 0.0202, 0.0032, 0.0067],\n",
      "        [0.0211, 0.0002, 0.0143, 0.0096],\n",
      "        [0.0050, 0.0164, 0.0344, 0.0195],\n",
      "        [0.0216, 0.0366, 0.0443, 0.0230],\n",
      "        [0.0418, 0.0465, 0.0478, 0.0207],\n",
      "        [0.0517, 0.0500, 0.0455, 0.0119],\n",
      "        [0.0552, 0.0477, 0.0367, 0.0007],\n",
      "        [0.0532, 0.0393, 0.0258, 0.0031],\n",
      "        [0.0534, 0.0405, 0.0322, 0.0100],\n",
      "        [0.0492, 0.0455, 0.0013, 0.0117],\n",
      "        [0.0453, 0.0044, 0.0300, 0.0102],\n",
      "        [0.0011, 0.0279, 0.0347, 0.0077],\n",
      "        [0.0259, 0.0264, 0.0219, 0.0097],\n",
      "        [0.0273, 0.0155, 0.0342, 0.0229],\n",
      "        [0.0024, 0.0069, 0.0081, 0.0061],\n",
      "        [0.0160, 0.0006, 0.0224, 0.0090],\n",
      "        [0.0128, 0.0046, 0.0136, 0.0120],\n",
      "        [0.0055, 0.0257, 0.0349, 0.0256],\n",
      "        [0.0006, 0.0115, 0.0128, 0.0629],\n",
      "        [0.0287, 0.0212, 0.0027, 0.0024],\n",
      "        [0.0160, 0.0180, 0.0285, 0.0245],\n",
      "        [0.0298, 0.0360, 0.0472, 0.0398],\n",
      "        [0.0149, 0.0180, 0.0067, 0.0384],\n",
      "        [0.0211, 0.0339, 0.0233, 0.0275],\n",
      "        [0.0250, 0.0272, 0.0285, 0.0609],\n",
      "        [0.0525, 0.0302, 0.0293, 0.0533],\n",
      "        [0.0384, 0.0577, 0.0323, 0.0541],\n",
      "        [0.0312, 0.0240, 0.0107, 0.0584],\n",
      "        [0.0657, 0.0174, 0.0253, 0.0805]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 35\n",
      "Number of shrink: 25\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0392, 0.0066, 0.0217, 0.0142],\n",
      "        [0.0043, 0.0119, 0.0042, 0.0104],\n",
      "        [0.0190, 0.0041, 0.0214, 0.0085],\n",
      "        [0.0020, 0.0163, 0.0115, 0.0035],\n",
      "        [0.0247, 0.0144, 0.0271, 0.0027],\n",
      "        [0.0227, 0.0329, 0.0184, 0.0050],\n",
      "        [0.0359, 0.0210, 0.0033, 0.0084],\n",
      "        [0.0234, 0.0008, 0.0145, 0.0125],\n",
      "        [0.0027, 0.0158, 0.0347, 0.0225],\n",
      "        [0.0193, 0.0359, 0.0446, 0.0259],\n",
      "        [0.0394, 0.0459, 0.0481, 0.0237],\n",
      "        [0.0494, 0.0493, 0.0458, 0.0148],\n",
      "        [0.0528, 0.0471, 0.0369, 0.0035],\n",
      "        [0.0505, 0.0382, 0.0257, 0.0015],\n",
      "        [0.0509, 0.0397, 0.0324, 0.0090],\n",
      "        [0.0469, 0.0450, 0.0008, 0.0109],\n",
      "        [0.0430, 0.0040, 0.0294, 0.0095],\n",
      "        [0.0012, 0.0284, 0.0342, 0.0069],\n",
      "        [0.0282, 0.0268, 0.0213, 0.0092],\n",
      "        [0.0294, 0.0158, 0.0336, 0.0236],\n",
      "        [0.0019, 0.0103, 0.0103, 0.0002],\n",
      "        [0.0183, 0.0012, 0.0227, 0.0120],\n",
      "        [0.0151, 0.0052, 0.0133, 0.0091],\n",
      "        [0.0026, 0.0244, 0.0345, 0.0264],\n",
      "        [0.0017, 0.0121, 0.0131, 0.0658],\n",
      "        [0.0311, 0.0218, 0.0025, 0.0006],\n",
      "        [0.0186, 0.0189, 0.0285, 0.0233],\n",
      "        [0.0274, 0.0354, 0.0474, 0.0428],\n",
      "        [0.0173, 0.0186, 0.0065, 0.0355],\n",
      "        [0.0235, 0.0346, 0.0231, 0.0246],\n",
      "        [0.0273, 0.0278, 0.0282, 0.0580],\n",
      "        [0.0548, 0.0308, 0.0291, 0.0504],\n",
      "        [0.0408, 0.0583, 0.0321, 0.0512],\n",
      "        [0.0273, 0.0213, 0.0092, 0.0515],\n",
      "        [0.0634, 0.0167, 0.0250, 0.0775]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.532026767730713\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 36\n",
      "X 資料 torch.Size([71, 18])\n",
      "Y 資料 torch.Size([71, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.003116043284535408, 51)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引51，y= tensor([0.4805, 0.4972, 0.5403, 0.5808])\n",
      "目前模型的Data torch.Size([36, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5756, 0.5782, 0.5751, 0.5912],\n",
      "        [0.5804, 0.5849, 0.5812, 0.6096],\n",
      "        [0.5778, 0.5811, 0.5778, 0.5993],\n",
      "        [0.5790, 0.5829, 0.5794, 0.6042],\n",
      "        [0.5745, 0.5765, 0.5736, 0.5867],\n",
      "        [0.5682, 0.5678, 0.5656, 0.5629],\n",
      "        [0.5648, 0.5630, 0.5612, 0.5497],\n",
      "        [0.5606, 0.5571, 0.5558, 0.5337],\n",
      "        [0.5606, 0.5571, 0.5558, 0.5337],\n",
      "        [0.5606, 0.5571, 0.5558, 0.5337],\n",
      "        [0.5606, 0.5571, 0.5558, 0.5337],\n",
      "        [0.5606, 0.5571, 0.5558, 0.5337],\n",
      "        [0.5606, 0.5571, 0.5558, 0.5337],\n",
      "        [0.5606, 0.5571, 0.5558, 0.5337],\n",
      "        [0.5697, 0.5699, 0.5675, 0.5687],\n",
      "        [0.5771, 0.5802, 0.5769, 0.5968],\n",
      "        [0.5782, 0.5817, 0.5783, 0.6009],\n",
      "        [0.5765, 0.5793, 0.5761, 0.5945],\n",
      "        [0.5795, 0.5836, 0.5801, 0.6062],\n",
      "        [0.5809, 0.5856, 0.5818, 0.6115],\n",
      "        [0.5681, 0.5676, 0.5654, 0.5624],\n",
      "        [0.5606, 0.5571, 0.5558, 0.5337],\n",
      "        [0.5606, 0.5571, 0.5558, 0.5337],\n",
      "        [0.5609, 0.5575, 0.5562, 0.5348],\n",
      "        [0.5606, 0.5571, 0.5558, 0.5337],\n",
      "        [0.5606, 0.5571, 0.5558, 0.5337],\n",
      "        [0.5663, 0.5651, 0.5632, 0.5556],\n",
      "        [0.5606, 0.5571, 0.5558, 0.5337],\n",
      "        [0.5606, 0.5571, 0.5558, 0.5337],\n",
      "        [0.5606, 0.5571, 0.5558, 0.5337],\n",
      "        [0.5606, 0.5571, 0.5558, 0.5337],\n",
      "        [0.5606, 0.5571, 0.5558, 0.5337],\n",
      "        [0.5606, 0.5571, 0.5558, 0.5337],\n",
      "        [0.5851, 0.5914, 0.5871, 0.6273],\n",
      "        [0.5606, 0.5571, 0.5558, 0.5337],\n",
      "        [0.5606, 0.5571, 0.5558, 0.5337]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0392, 0.0066, 0.0217, 0.0142],\n",
      "        [0.0043, 0.0119, 0.0042, 0.0104],\n",
      "        [0.0190, 0.0041, 0.0214, 0.0085],\n",
      "        [0.0020, 0.0163, 0.0115, 0.0035],\n",
      "        [0.0247, 0.0144, 0.0271, 0.0027],\n",
      "        [0.0227, 0.0329, 0.0184, 0.0050],\n",
      "        [0.0359, 0.0210, 0.0033, 0.0084],\n",
      "        [0.0234, 0.0008, 0.0145, 0.0125],\n",
      "        [0.0027, 0.0158, 0.0347, 0.0225],\n",
      "        [0.0193, 0.0359, 0.0446, 0.0259],\n",
      "        [0.0394, 0.0459, 0.0481, 0.0237],\n",
      "        [0.0494, 0.0493, 0.0458, 0.0148],\n",
      "        [0.0528, 0.0471, 0.0369, 0.0035],\n",
      "        [0.0505, 0.0382, 0.0257, 0.0015],\n",
      "        [0.0509, 0.0397, 0.0324, 0.0090],\n",
      "        [0.0469, 0.0450, 0.0008, 0.0109],\n",
      "        [0.0430, 0.0040, 0.0294, 0.0095],\n",
      "        [0.0012, 0.0284, 0.0342, 0.0069],\n",
      "        [0.0282, 0.0268, 0.0213, 0.0092],\n",
      "        [0.0294, 0.0158, 0.0336, 0.0236],\n",
      "        [0.0019, 0.0103, 0.0103, 0.0002],\n",
      "        [0.0183, 0.0012, 0.0227, 0.0120],\n",
      "        [0.0151, 0.0052, 0.0133, 0.0091],\n",
      "        [0.0026, 0.0244, 0.0345, 0.0264],\n",
      "        [0.0017, 0.0121, 0.0131, 0.0658],\n",
      "        [0.0311, 0.0218, 0.0025, 0.0006],\n",
      "        [0.0186, 0.0189, 0.0285, 0.0233],\n",
      "        [0.0274, 0.0354, 0.0474, 0.0428],\n",
      "        [0.0173, 0.0186, 0.0065, 0.0355],\n",
      "        [0.0235, 0.0346, 0.0231, 0.0246],\n",
      "        [0.0273, 0.0278, 0.0282, 0.0580],\n",
      "        [0.0548, 0.0308, 0.0291, 0.0504],\n",
      "        [0.0408, 0.0583, 0.0321, 0.0512],\n",
      "        [0.0273, 0.0213, 0.0092, 0.0515],\n",
      "        [0.0634, 0.0167, 0.0250, 0.0775],\n",
      "        [0.0801, 0.0599, 0.0155, 0.0472]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 16\n",
      "Number of shrink: 15\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0411,     0.0082,     0.0218,     0.0157],\n",
      "        [    0.0061,     0.0134,     0.0042,     0.0119],\n",
      "        [    0.0208,     0.0025,     0.0215,     0.0098],\n",
      "        [    0.0002,     0.0179,     0.0116,     0.0048],\n",
      "        [    0.0266,     0.0161,     0.0273,     0.0041],\n",
      "        [    0.0247,     0.0347,     0.0186,     0.0064],\n",
      "        [    0.0379,     0.0228,     0.0030,     0.0100],\n",
      "        [    0.0255,     0.0027,     0.0142,     0.0141],\n",
      "        [    0.0006,     0.0139,     0.0343,     0.0240],\n",
      "        [    0.0172,     0.0340,     0.0443,     0.0275],\n",
      "        [    0.0373,     0.0440,     0.0477,     0.0252],\n",
      "        [    0.0472,     0.0474,     0.0454,     0.0163],\n",
      "        [    0.0507,     0.0451,     0.0366,     0.0051],\n",
      "        [    0.0484,     0.0363,     0.0253,     0.0001],\n",
      "        [    0.0489,     0.0379,     0.0321,     0.0077],\n",
      "        [    0.0450,     0.0433,     0.0009,     0.0097],\n",
      "        [    0.0411,     0.0023,     0.0296,     0.0084],\n",
      "        [    0.0031,     0.0301,     0.0344,     0.0057],\n",
      "        [    0.0301,     0.0284,     0.0215,     0.0081],\n",
      "        [    0.0313,     0.0175,     0.0337,     0.0247],\n",
      "        [    0.0045,     0.0128,     0.0112,     0.0004],\n",
      "        [    0.0204,     0.0031,     0.0223,     0.0135],\n",
      "        [    0.0173,     0.0071,     0.0137,     0.0076],\n",
      "        [    0.0004,     0.0223,     0.0340,     0.0275],\n",
      "        [    0.0038,     0.0140,     0.0127,     0.0673],\n",
      "        [    0.0332,     0.0237,     0.0028,     0.0021],\n",
      "        [    0.0207,     0.0209,     0.0289,     0.0220],\n",
      "        [    0.0253,     0.0335,     0.0471,     0.0443],\n",
      "        [    0.0194,     0.0205,     0.0068,     0.0340],\n",
      "        [    0.0256,     0.0365,     0.0234,     0.0231],\n",
      "        [    0.0294,     0.0297,     0.0286,     0.0564],\n",
      "        [    0.0569,     0.0327,     0.0294,     0.0488],\n",
      "        [    0.0429,     0.0602,     0.0324,     0.0497],\n",
      "        [    0.0250,     0.0190,     0.0085,     0.0507],\n",
      "        [    0.0613,     0.0148,     0.0254,     0.0760],\n",
      "        [    0.0780,     0.0580,     0.0151,     0.0456]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.68143343925476\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 37\n",
      "X 資料 torch.Size([70, 18])\n",
      "Y 資料 torch.Size([70, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.003129340708255768, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.5217, 0.5084, 0.4909, 0.4658])\n",
      "目前模型的Data torch.Size([37, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5738, 0.5765, 0.5750, 0.5927],\n",
      "        [0.5787, 0.5833, 0.5812, 0.6110],\n",
      "        [0.5759, 0.5795, 0.5777, 0.6007],\n",
      "        [0.5772, 0.5813, 0.5793, 0.6055],\n",
      "        [0.5725, 0.5748, 0.5734, 0.5881],\n",
      "        [0.5662, 0.5660, 0.5653, 0.5643],\n",
      "        [0.5627, 0.5611, 0.5609, 0.5513],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352],\n",
      "        [0.5677, 0.5681, 0.5673, 0.5700],\n",
      "        [0.5752, 0.5785, 0.5768, 0.5980],\n",
      "        [0.5763, 0.5800, 0.5781, 0.6020],\n",
      "        [0.5746, 0.5776, 0.5760, 0.5957],\n",
      "        [0.5777, 0.5819, 0.5799, 0.6073],\n",
      "        [0.5791, 0.5839, 0.5817, 0.6126],\n",
      "        [0.5656, 0.5651, 0.5645, 0.5619],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352],\n",
      "        [0.5586, 0.5554, 0.5557, 0.5359],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352],\n",
      "        [0.5642, 0.5632, 0.5628, 0.5568],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352],\n",
      "        [0.5828, 0.5891, 0.5864, 0.6264],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352],\n",
      "        [0.5585, 0.5552, 0.5555, 0.5352]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0411,     0.0082,     0.0218,     0.0157],\n",
      "        [    0.0061,     0.0134,     0.0042,     0.0119],\n",
      "        [    0.0208,     0.0025,     0.0215,     0.0098],\n",
      "        [    0.0002,     0.0179,     0.0116,     0.0048],\n",
      "        [    0.0266,     0.0161,     0.0273,     0.0041],\n",
      "        [    0.0247,     0.0347,     0.0186,     0.0064],\n",
      "        [    0.0379,     0.0228,     0.0030,     0.0100],\n",
      "        [    0.0255,     0.0027,     0.0142,     0.0141],\n",
      "        [    0.0006,     0.0139,     0.0343,     0.0240],\n",
      "        [    0.0172,     0.0340,     0.0443,     0.0275],\n",
      "        [    0.0373,     0.0440,     0.0477,     0.0252],\n",
      "        [    0.0472,     0.0474,     0.0454,     0.0163],\n",
      "        [    0.0507,     0.0451,     0.0366,     0.0051],\n",
      "        [    0.0484,     0.0363,     0.0253,     0.0001],\n",
      "        [    0.0489,     0.0379,     0.0321,     0.0077],\n",
      "        [    0.0450,     0.0433,     0.0009,     0.0097],\n",
      "        [    0.0411,     0.0023,     0.0296,     0.0084],\n",
      "        [    0.0031,     0.0301,     0.0344,     0.0057],\n",
      "        [    0.0301,     0.0284,     0.0215,     0.0081],\n",
      "        [    0.0313,     0.0175,     0.0337,     0.0247],\n",
      "        [    0.0045,     0.0128,     0.0112,     0.0004],\n",
      "        [    0.0204,     0.0031,     0.0223,     0.0135],\n",
      "        [    0.0173,     0.0071,     0.0137,     0.0076],\n",
      "        [    0.0004,     0.0223,     0.0340,     0.0275],\n",
      "        [    0.0038,     0.0140,     0.0127,     0.0673],\n",
      "        [    0.0332,     0.0237,     0.0028,     0.0021],\n",
      "        [    0.0207,     0.0209,     0.0289,     0.0220],\n",
      "        [    0.0253,     0.0335,     0.0471,     0.0443],\n",
      "        [    0.0194,     0.0205,     0.0068,     0.0340],\n",
      "        [    0.0256,     0.0365,     0.0234,     0.0231],\n",
      "        [    0.0294,     0.0297,     0.0286,     0.0564],\n",
      "        [    0.0569,     0.0327,     0.0294,     0.0488],\n",
      "        [    0.0429,     0.0602,     0.0324,     0.0497],\n",
      "        [    0.0250,     0.0190,     0.0085,     0.0507],\n",
      "        [    0.0613,     0.0148,     0.0254,     0.0760],\n",
      "        [    0.0780,     0.0580,     0.0151,     0.0456],\n",
      "        [    0.0368,     0.0468,     0.0645,     0.0694]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 26\n",
      "Number of shrink: 20\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0418,     0.0092,     0.0232,     0.0142],\n",
      "        [    0.0067,     0.0142,     0.0029,     0.0104],\n",
      "        [    0.0215,     0.0016,     0.0229,     0.0083],\n",
      "        [    0.0004,     0.0188,     0.0130,     0.0033],\n",
      "        [    0.0274,     0.0171,     0.0288,     0.0025],\n",
      "        [    0.0255,     0.0358,     0.0203,     0.0050],\n",
      "        [    0.0389,     0.0240,     0.0013,     0.0085],\n",
      "        [    0.0267,     0.0042,     0.0121,     0.0120],\n",
      "        [    0.0006,     0.0124,     0.0323,     0.0220],\n",
      "        [    0.0160,     0.0325,     0.0422,     0.0254],\n",
      "        [    0.0361,     0.0425,     0.0457,     0.0232],\n",
      "        [    0.0461,     0.0459,     0.0434,     0.0143],\n",
      "        [    0.0495,     0.0436,     0.0345,     0.0030],\n",
      "        [    0.0474,     0.0350,     0.0235,     0.0014],\n",
      "        [    0.0479,     0.0368,     0.0304,     0.0094],\n",
      "        [    0.0443,     0.0423,     0.0025,     0.0115],\n",
      "        [    0.0403,     0.0013,     0.0311,     0.0102],\n",
      "        [    0.0039,     0.0311,     0.0360,     0.0075],\n",
      "        [    0.0308,     0.0294,     0.0230,     0.0100],\n",
      "        [    0.0320,     0.0184,     0.0351,     0.0229],\n",
      "        [    0.0059,     0.0147,     0.0136,     0.0040],\n",
      "        [    0.0216,     0.0046,     0.0203,     0.0115],\n",
      "        [    0.0185,     0.0086,     0.0157,     0.0096],\n",
      "        [    0.0008,     0.0209,     0.0321,     0.0258],\n",
      "        [    0.0050,     0.0155,     0.0107,     0.0653],\n",
      "        [    0.0344,     0.0252,     0.0049,     0.0000],\n",
      "        [    0.0216,     0.0220,     0.0305,     0.0235],\n",
      "        [    0.0241,     0.0320,     0.0450,     0.0423],\n",
      "        [    0.0206,     0.0221,     0.0089,     0.0360],\n",
      "        [    0.0268,     0.0380,     0.0255,     0.0251],\n",
      "        [    0.0306,     0.0312,     0.0306,     0.0585],\n",
      "        [    0.0581,     0.0342,     0.0315,     0.0509],\n",
      "        [    0.0441,     0.0617,     0.0345,     0.0517],\n",
      "        [    0.0238,     0.0174,     0.0064,     0.0467],\n",
      "        [    0.0601,     0.0133,     0.0274,     0.0781],\n",
      "        [    0.0768,     0.0565,     0.0131,     0.0477],\n",
      "        [    0.0356,     0.0453,     0.0625,     0.0673]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.894980669021606\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 38\n",
      "X 資料 torch.Size([69, 18])\n",
      "Y 資料 torch.Size([69, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0038252579979598522, 8)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引8，y= tensor([0.4950, 0.5020, 0.4882, 0.4661])\n",
      "目前模型的Data torch.Size([38, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5731, 0.5756, 0.5735, 0.5912],\n",
      "        [0.5781, 0.5825, 0.5799, 0.6096],\n",
      "        [0.5753, 0.5786, 0.5763, 0.5992],\n",
      "        [0.5766, 0.5804, 0.5779, 0.6040],\n",
      "        [0.5718, 0.5738, 0.5719, 0.5865],\n",
      "        [0.5654, 0.5649, 0.5637, 0.5629],\n",
      "        [0.5618, 0.5599, 0.5592, 0.5498],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332],\n",
      "        [0.5574, 0.5539, 0.5536, 0.5337],\n",
      "        [0.5668, 0.5669, 0.5656, 0.5683],\n",
      "        [0.5745, 0.5775, 0.5752, 0.5962],\n",
      "        [0.5755, 0.5790, 0.5766, 0.6001],\n",
      "        [0.5738, 0.5766, 0.5744, 0.5938],\n",
      "        [0.5769, 0.5809, 0.5784, 0.6053],\n",
      "        [0.5784, 0.5830, 0.5803, 0.6108],\n",
      "        [0.5641, 0.5632, 0.5621, 0.5583],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332],\n",
      "        [0.5575, 0.5540, 0.5538, 0.5342],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332],\n",
      "        [0.5633, 0.5620, 0.5611, 0.5554],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332],\n",
      "        [0.5816, 0.5874, 0.5843, 0.6224],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332],\n",
      "        [0.5573, 0.5537, 0.5534, 0.5332]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0418,     0.0092,     0.0232,     0.0142],\n",
      "        [    0.0067,     0.0142,     0.0029,     0.0104],\n",
      "        [    0.0215,     0.0016,     0.0229,     0.0083],\n",
      "        [    0.0004,     0.0188,     0.0130,     0.0033],\n",
      "        [    0.0274,     0.0171,     0.0288,     0.0025],\n",
      "        [    0.0255,     0.0358,     0.0203,     0.0050],\n",
      "        [    0.0389,     0.0240,     0.0013,     0.0085],\n",
      "        [    0.0267,     0.0042,     0.0121,     0.0120],\n",
      "        [    0.0006,     0.0124,     0.0323,     0.0220],\n",
      "        [    0.0160,     0.0325,     0.0422,     0.0254],\n",
      "        [    0.0361,     0.0425,     0.0457,     0.0232],\n",
      "        [    0.0461,     0.0459,     0.0434,     0.0143],\n",
      "        [    0.0495,     0.0436,     0.0345,     0.0030],\n",
      "        [    0.0474,     0.0350,     0.0235,     0.0014],\n",
      "        [    0.0479,     0.0368,     0.0304,     0.0094],\n",
      "        [    0.0443,     0.0423,     0.0025,     0.0115],\n",
      "        [    0.0403,     0.0013,     0.0311,     0.0102],\n",
      "        [    0.0039,     0.0311,     0.0360,     0.0075],\n",
      "        [    0.0308,     0.0294,     0.0230,     0.0100],\n",
      "        [    0.0320,     0.0184,     0.0351,     0.0229],\n",
      "        [    0.0059,     0.0147,     0.0136,     0.0040],\n",
      "        [    0.0216,     0.0046,     0.0203,     0.0115],\n",
      "        [    0.0185,     0.0086,     0.0157,     0.0096],\n",
      "        [    0.0008,     0.0209,     0.0321,     0.0258],\n",
      "        [    0.0050,     0.0155,     0.0107,     0.0653],\n",
      "        [    0.0344,     0.0252,     0.0049,     0.0000],\n",
      "        [    0.0216,     0.0220,     0.0305,     0.0235],\n",
      "        [    0.0241,     0.0320,     0.0450,     0.0423],\n",
      "        [    0.0206,     0.0221,     0.0089,     0.0360],\n",
      "        [    0.0268,     0.0380,     0.0255,     0.0251],\n",
      "        [    0.0306,     0.0312,     0.0306,     0.0585],\n",
      "        [    0.0581,     0.0342,     0.0315,     0.0509],\n",
      "        [    0.0441,     0.0617,     0.0345,     0.0517],\n",
      "        [    0.0238,     0.0174,     0.0064,     0.0467],\n",
      "        [    0.0601,     0.0133,     0.0274,     0.0781],\n",
      "        [    0.0768,     0.0565,     0.0131,     0.0477],\n",
      "        [    0.0356,     0.0453,     0.0625,     0.0673],\n",
      "        [    0.0623,     0.0517,     0.0652,     0.0671]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 7\n",
      "Number of shrink: 11\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0431,     0.0096,     0.0244,     0.0142],\n",
      "        [    0.0079,     0.0145,     0.0018,     0.0104],\n",
      "        [    0.0228,     0.0013,     0.0240,     0.0084],\n",
      "        [    0.0017,     0.0191,     0.0141,     0.0033],\n",
      "        [    0.0287,     0.0175,     0.0300,     0.0025],\n",
      "        [    0.0269,     0.0363,     0.0215,     0.0051],\n",
      "        [    0.0403,     0.0246,     0.0000,     0.0086],\n",
      "        [    0.0288,     0.0056,     0.0101,     0.0102],\n",
      "        [    0.0027,     0.0110,     0.0302,     0.0201],\n",
      "        [    0.0139,     0.0311,     0.0402,     0.0236],\n",
      "        [    0.0340,     0.0411,     0.0436,     0.0213],\n",
      "        [    0.0440,     0.0445,     0.0413,     0.0125],\n",
      "        [    0.0480,     0.0430,     0.0331,     0.0030],\n",
      "        [    0.0458,     0.0343,     0.0220,     0.0015],\n",
      "        [    0.0465,     0.0362,     0.0291,     0.0096],\n",
      "        [    0.0429,     0.0418,     0.0037,     0.0118],\n",
      "        [    0.0390,     0.0008,     0.0324,     0.0106],\n",
      "        [    0.0053,     0.0316,     0.0372,     0.0078],\n",
      "        [    0.0321,     0.0299,     0.0242,     0.0103],\n",
      "        [    0.0333,     0.0188,     0.0363,     0.0226],\n",
      "        [    0.0074,     0.0153,     0.0150,     0.0042],\n",
      "        [    0.0237,     0.0060,     0.0182,     0.0096],\n",
      "        [    0.0205,     0.0100,     0.0178,     0.0114],\n",
      "        [    0.0023,     0.0203,     0.0307,     0.0258],\n",
      "        [    0.0071,     0.0169,     0.0086,     0.0635],\n",
      "        [    0.0365,     0.0266,     0.0069,     0.0018],\n",
      "        [    0.0230,     0.0226,     0.0319,     0.0235],\n",
      "        [    0.0221,     0.0306,     0.0430,     0.0404],\n",
      "        [    0.0227,     0.0234,     0.0109,     0.0378],\n",
      "        [    0.0289,     0.0394,     0.0275,     0.0270],\n",
      "        [    0.0327,     0.0326,     0.0327,     0.0603],\n",
      "        [    0.0602,     0.0356,     0.0335,     0.0527],\n",
      "        [    0.0462,     0.0631,     0.0365,     0.0535],\n",
      "        [    0.0225,     0.0169,     0.0052,     0.0463],\n",
      "        [    0.0580,     0.0119,     0.0295,     0.0799],\n",
      "        [    0.0747,     0.0551,     0.0110,     0.0495],\n",
      "        [    0.0335,     0.0439,     0.0605,     0.0655],\n",
      "        [    0.0602,     0.0503,     0.0631,     0.0653]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.041590213775635\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 39\n",
      "X 資料 torch.Size([68, 18])\n",
      "Y 資料 torch.Size([68, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.004010220989584923, 7)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引7，y= tensor([0.4632, 0.4950, 0.5020, 0.4882])\n",
      "目前模型的Data torch.Size([39, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5718, 0.5752, 0.5723, 0.5912],\n",
      "        [0.5769, 0.5822, 0.5788, 0.6096],\n",
      "        [0.5740, 0.5783, 0.5752, 0.5992],\n",
      "        [0.5753, 0.5801, 0.5768, 0.6039],\n",
      "        [0.5705, 0.5734, 0.5707, 0.5865],\n",
      "        [0.5640, 0.5644, 0.5624, 0.5630],\n",
      "        [0.5603, 0.5594, 0.5579, 0.5499],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5313],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5313],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5313],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5313],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5313],\n",
      "        [0.5557, 0.5530, 0.5520, 0.5332],\n",
      "        [0.5558, 0.5532, 0.5522, 0.5337],\n",
      "        [0.5654, 0.5664, 0.5642, 0.5681],\n",
      "        [0.5731, 0.5770, 0.5740, 0.5959],\n",
      "        [0.5742, 0.5785, 0.5754, 0.5998],\n",
      "        [0.5724, 0.5761, 0.5732, 0.5936],\n",
      "        [0.5756, 0.5805, 0.5772, 0.6051],\n",
      "        [0.5771, 0.5826, 0.5791, 0.6105],\n",
      "        [0.5626, 0.5625, 0.5607, 0.5581],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5313],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5313],\n",
      "        [0.5560, 0.5534, 0.5524, 0.5342],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5313],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5313],\n",
      "        [0.5619, 0.5615, 0.5598, 0.5554],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5313],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5313],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5313],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5313],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5313],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5313],\n",
      "        [0.5803, 0.5870, 0.5831, 0.6220],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5313],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5313],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5314],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5313],\n",
      "        [0.5552, 0.5523, 0.5514, 0.5313]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0431,     0.0096,     0.0244,     0.0142],\n",
      "        [    0.0079,     0.0145,     0.0018,     0.0104],\n",
      "        [    0.0228,     0.0013,     0.0240,     0.0084],\n",
      "        [    0.0017,     0.0191,     0.0141,     0.0033],\n",
      "        [    0.0287,     0.0175,     0.0300,     0.0025],\n",
      "        [    0.0269,     0.0363,     0.0215,     0.0051],\n",
      "        [    0.0403,     0.0246,     0.0000,     0.0086],\n",
      "        [    0.0288,     0.0056,     0.0101,     0.0102],\n",
      "        [    0.0027,     0.0110,     0.0302,     0.0201],\n",
      "        [    0.0139,     0.0311,     0.0402,     0.0236],\n",
      "        [    0.0340,     0.0411,     0.0436,     0.0213],\n",
      "        [    0.0440,     0.0445,     0.0413,     0.0125],\n",
      "        [    0.0480,     0.0430,     0.0331,     0.0030],\n",
      "        [    0.0458,     0.0343,     0.0220,     0.0015],\n",
      "        [    0.0465,     0.0362,     0.0291,     0.0096],\n",
      "        [    0.0429,     0.0418,     0.0037,     0.0118],\n",
      "        [    0.0390,     0.0008,     0.0324,     0.0106],\n",
      "        [    0.0053,     0.0316,     0.0372,     0.0078],\n",
      "        [    0.0321,     0.0299,     0.0242,     0.0103],\n",
      "        [    0.0333,     0.0188,     0.0363,     0.0226],\n",
      "        [    0.0074,     0.0153,     0.0150,     0.0042],\n",
      "        [    0.0237,     0.0060,     0.0182,     0.0096],\n",
      "        [    0.0205,     0.0100,     0.0178,     0.0114],\n",
      "        [    0.0023,     0.0203,     0.0307,     0.0258],\n",
      "        [    0.0071,     0.0169,     0.0086,     0.0635],\n",
      "        [    0.0365,     0.0266,     0.0069,     0.0018],\n",
      "        [    0.0230,     0.0226,     0.0319,     0.0235],\n",
      "        [    0.0221,     0.0306,     0.0430,     0.0404],\n",
      "        [    0.0227,     0.0234,     0.0109,     0.0378],\n",
      "        [    0.0289,     0.0394,     0.0275,     0.0270],\n",
      "        [    0.0327,     0.0326,     0.0327,     0.0603],\n",
      "        [    0.0602,     0.0356,     0.0335,     0.0527],\n",
      "        [    0.0462,     0.0631,     0.0365,     0.0535],\n",
      "        [    0.0225,     0.0169,     0.0052,     0.0463],\n",
      "        [    0.0580,     0.0119,     0.0295,     0.0799],\n",
      "        [    0.0747,     0.0551,     0.0110,     0.0495],\n",
      "        [    0.0335,     0.0439,     0.0605,     0.0655],\n",
      "        [    0.0602,     0.0503,     0.0631,     0.0653],\n",
      "        [    0.0920,     0.0573,     0.0494,     0.0431]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 21\n",
      "Number of shrink: 18\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0453, 0.0114, 0.0256, 0.0121],\n",
      "        [0.0100, 0.0162, 0.0006, 0.0082],\n",
      "        [0.0249, 0.0005, 0.0252, 0.0062],\n",
      "        [0.0039, 0.0209, 0.0152, 0.0011],\n",
      "        [0.0309, 0.0193, 0.0312, 0.0004],\n",
      "        [0.0293, 0.0382, 0.0229, 0.0030],\n",
      "        [0.0427, 0.0266, 0.0014, 0.0066],\n",
      "        [0.0312, 0.0076, 0.0086, 0.0083],\n",
      "        [0.0052, 0.0090, 0.0288, 0.0183],\n",
      "        [0.0115, 0.0291, 0.0387, 0.0217],\n",
      "        [0.0316, 0.0391, 0.0422, 0.0194],\n",
      "        [0.0415, 0.0425, 0.0399, 0.0106],\n",
      "        [0.0455, 0.0409, 0.0317, 0.0011],\n",
      "        [0.0434, 0.0323, 0.0206, 0.0034],\n",
      "        [0.0442, 0.0343, 0.0277, 0.0117],\n",
      "        [0.0407, 0.0400, 0.0049, 0.0140],\n",
      "        [0.0368, 0.0010, 0.0335, 0.0128],\n",
      "        [0.0075, 0.0334, 0.0384, 0.0100],\n",
      "        [0.0343, 0.0316, 0.0253, 0.0126],\n",
      "        [0.0354, 0.0205, 0.0374, 0.0204],\n",
      "        [0.0098, 0.0173, 0.0164, 0.0064],\n",
      "        [0.0261, 0.0080, 0.0168, 0.0078],\n",
      "        [0.0230, 0.0120, 0.0193, 0.0133],\n",
      "        [0.0048, 0.0182, 0.0292, 0.0238],\n",
      "        [0.0095, 0.0189, 0.0071, 0.0616],\n",
      "        [0.0389, 0.0286, 0.0084, 0.0037],\n",
      "        [0.0254, 0.0245, 0.0333, 0.0256],\n",
      "        [0.0196, 0.0286, 0.0415, 0.0386],\n",
      "        [0.0251, 0.0255, 0.0124, 0.0397],\n",
      "        [0.0313, 0.0414, 0.0290, 0.0288],\n",
      "        [0.0352, 0.0346, 0.0341, 0.0622],\n",
      "        [0.0627, 0.0376, 0.0350, 0.0546],\n",
      "        [0.0486, 0.0651, 0.0380, 0.0554],\n",
      "        [0.0203, 0.0152, 0.0041, 0.0438],\n",
      "        [0.0556, 0.0099, 0.0309, 0.0818],\n",
      "        [0.0722, 0.0531, 0.0096, 0.0514],\n",
      "        [0.0310, 0.0419, 0.0590, 0.0636],\n",
      "        [0.0578, 0.0483, 0.0617, 0.0634],\n",
      "        [0.0895, 0.0553, 0.0480, 0.0412]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.249123334884644\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 40\n",
      "X 資料 torch.Size([67, 18])\n",
      "Y 資料 torch.Size([67, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0040241144597530365, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.5084, 0.4909, 0.4658, 0.4753])\n",
      "目前模型的Data torch.Size([40, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5696, 0.5734, 0.5711, 0.5891],\n",
      "        [0.5747, 0.5805, 0.5776, 0.6074],\n",
      "        [0.5718, 0.5765, 0.5740, 0.5971],\n",
      "        [0.5731, 0.5783, 0.5756, 0.6017],\n",
      "        [0.5682, 0.5716, 0.5695, 0.5844],\n",
      "        [0.5616, 0.5625, 0.5611, 0.5609],\n",
      "        [0.5579, 0.5574, 0.5565, 0.5479],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5532, 0.5509, 0.5506, 0.5313],\n",
      "        [0.5534, 0.5511, 0.5507, 0.5317],\n",
      "        [0.5630, 0.5644, 0.5629, 0.5660],\n",
      "        [0.5709, 0.5752, 0.5728, 0.5937],\n",
      "        [0.5720, 0.5767, 0.5742, 0.5976],\n",
      "        [0.5702, 0.5743, 0.5720, 0.5914],\n",
      "        [0.5734, 0.5787, 0.5760, 0.6028],\n",
      "        [0.5750, 0.5809, 0.5780, 0.6083],\n",
      "        [0.5602, 0.5605, 0.5593, 0.5559],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5535, 0.5513, 0.5509, 0.5322],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5595, 0.5595, 0.5584, 0.5533],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5782, 0.5852, 0.5820, 0.6195],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5527, 0.5503, 0.5499, 0.5295],\n",
      "        [0.5534, 0.5512, 0.5508, 0.5320]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0453, 0.0114, 0.0256, 0.0121],\n",
      "        [0.0100, 0.0162, 0.0006, 0.0082],\n",
      "        [0.0249, 0.0005, 0.0252, 0.0062],\n",
      "        [0.0039, 0.0209, 0.0152, 0.0011],\n",
      "        [0.0309, 0.0193, 0.0312, 0.0004],\n",
      "        [0.0293, 0.0382, 0.0229, 0.0030],\n",
      "        [0.0427, 0.0266, 0.0014, 0.0066],\n",
      "        [0.0312, 0.0076, 0.0086, 0.0083],\n",
      "        [0.0052, 0.0090, 0.0288, 0.0183],\n",
      "        [0.0115, 0.0291, 0.0387, 0.0217],\n",
      "        [0.0316, 0.0391, 0.0422, 0.0194],\n",
      "        [0.0415, 0.0425, 0.0399, 0.0106],\n",
      "        [0.0455, 0.0409, 0.0317, 0.0011],\n",
      "        [0.0434, 0.0323, 0.0206, 0.0034],\n",
      "        [0.0442, 0.0343, 0.0277, 0.0117],\n",
      "        [0.0407, 0.0400, 0.0049, 0.0140],\n",
      "        [0.0368, 0.0010, 0.0335, 0.0128],\n",
      "        [0.0075, 0.0334, 0.0384, 0.0100],\n",
      "        [0.0343, 0.0316, 0.0253, 0.0126],\n",
      "        [0.0354, 0.0205, 0.0374, 0.0204],\n",
      "        [0.0098, 0.0173, 0.0164, 0.0064],\n",
      "        [0.0261, 0.0080, 0.0168, 0.0078],\n",
      "        [0.0230, 0.0120, 0.0193, 0.0133],\n",
      "        [0.0048, 0.0182, 0.0292, 0.0238],\n",
      "        [0.0095, 0.0189, 0.0071, 0.0616],\n",
      "        [0.0389, 0.0286, 0.0084, 0.0037],\n",
      "        [0.0254, 0.0245, 0.0333, 0.0256],\n",
      "        [0.0196, 0.0286, 0.0415, 0.0386],\n",
      "        [0.0251, 0.0255, 0.0124, 0.0397],\n",
      "        [0.0313, 0.0414, 0.0290, 0.0288],\n",
      "        [0.0352, 0.0346, 0.0341, 0.0622],\n",
      "        [0.0627, 0.0376, 0.0350, 0.0546],\n",
      "        [0.0486, 0.0651, 0.0380, 0.0554],\n",
      "        [0.0203, 0.0152, 0.0041, 0.0438],\n",
      "        [0.0556, 0.0099, 0.0309, 0.0818],\n",
      "        [0.0722, 0.0531, 0.0096, 0.0514],\n",
      "        [0.0310, 0.0419, 0.0590, 0.0636],\n",
      "        [0.0578, 0.0483, 0.0617, 0.0634],\n",
      "        [0.0895, 0.0553, 0.0480, 0.0412],\n",
      "        [0.0451, 0.0603, 0.0850, 0.0566]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 19\n",
      "Number of shrink: 17\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0460, 0.0124, 0.0273, 0.0113],\n",
      "        [0.0107, 0.0172, 0.0009, 0.0074],\n",
      "        [0.0257, 0.0015, 0.0268, 0.0054],\n",
      "        [0.0046, 0.0218, 0.0168, 0.0003],\n",
      "        [0.0317, 0.0204, 0.0329, 0.0004],\n",
      "        [0.0301, 0.0394, 0.0246, 0.0024],\n",
      "        [0.0437, 0.0278, 0.0033, 0.0059],\n",
      "        [0.0323, 0.0091, 0.0066, 0.0075],\n",
      "        [0.0064, 0.0074, 0.0266, 0.0171],\n",
      "        [0.0103, 0.0276, 0.0366, 0.0206],\n",
      "        [0.0304, 0.0375, 0.0400, 0.0183],\n",
      "        [0.0403, 0.0410, 0.0378, 0.0094],\n",
      "        [0.0445, 0.0397, 0.0298, 0.0006],\n",
      "        [0.0423, 0.0310, 0.0187, 0.0040],\n",
      "        [0.0433, 0.0331, 0.0260, 0.0125],\n",
      "        [0.0400, 0.0390, 0.0066, 0.0148],\n",
      "        [0.0360, 0.0020, 0.0352, 0.0137],\n",
      "        [0.0083, 0.0345, 0.0401, 0.0108],\n",
      "        [0.0350, 0.0327, 0.0270, 0.0135],\n",
      "        [0.0361, 0.0215, 0.0390, 0.0195],\n",
      "        [0.0111, 0.0190, 0.0186, 0.0083],\n",
      "        [0.0273, 0.0096, 0.0147, 0.0066],\n",
      "        [0.0242, 0.0136, 0.0214, 0.0144],\n",
      "        [0.0059, 0.0167, 0.0272, 0.0229],\n",
      "        [0.0107, 0.0205, 0.0050, 0.0604],\n",
      "        [0.0401, 0.0302, 0.0105, 0.0048],\n",
      "        [0.0263, 0.0258, 0.0351, 0.0262],\n",
      "        [0.0184, 0.0270, 0.0394, 0.0374],\n",
      "        [0.0263, 0.0270, 0.0145, 0.0408],\n",
      "        [0.0325, 0.0429, 0.0311, 0.0300],\n",
      "        [0.0364, 0.0362, 0.0363, 0.0633],\n",
      "        [0.0639, 0.0392, 0.0371, 0.0557],\n",
      "        [0.0498, 0.0667, 0.0401, 0.0566],\n",
      "        [0.0193, 0.0137, 0.0021, 0.0416],\n",
      "        [0.0544, 0.0084, 0.0331, 0.0829],\n",
      "        [0.0710, 0.0515, 0.0074, 0.0525],\n",
      "        [0.0299, 0.0404, 0.0569, 0.0626],\n",
      "        [0.0566, 0.0467, 0.0595, 0.0622],\n",
      "        [0.0883, 0.0537, 0.0458, 0.0401],\n",
      "        [0.0439, 0.0588, 0.0829, 0.0556]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.454201459884644\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 41\n",
      "X 資料 torch.Size([66, 18])\n",
      "Y 資料 torch.Size([66, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.003904217155650258, 6)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引6，y= tensor([0.5020, 0.4882, 0.4661, 0.4752])\n",
      "目前模型的Data torch.Size([41, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5688, 0.5724, 0.5695, 0.5883],\n",
      "        [0.5741, 0.5796, 0.5761, 0.6066],\n",
      "        [0.5711, 0.5755, 0.5724, 0.5963],\n",
      "        [0.5724, 0.5773, 0.5741, 0.6010],\n",
      "        [0.5675, 0.5705, 0.5678, 0.5836],\n",
      "        [0.5607, 0.5613, 0.5593, 0.5603],\n",
      "        [0.5570, 0.5562, 0.5546, 0.5472],\n",
      "        [0.5516, 0.5488, 0.5479, 0.5287],\n",
      "        [0.5515, 0.5487, 0.5478, 0.5283],\n",
      "        [0.5515, 0.5487, 0.5478, 0.5283],\n",
      "        [0.5515, 0.5487, 0.5478, 0.5283],\n",
      "        [0.5515, 0.5487, 0.5478, 0.5283],\n",
      "        [0.5523, 0.5497, 0.5487, 0.5308],\n",
      "        [0.5524, 0.5498, 0.5488, 0.5312],\n",
      "        [0.5622, 0.5633, 0.5611, 0.5652],\n",
      "        [0.5701, 0.5742, 0.5712, 0.5929],\n",
      "        [0.5712, 0.5757, 0.5725, 0.5967],\n",
      "        [0.5694, 0.5732, 0.5703, 0.5905],\n",
      "        [0.5727, 0.5777, 0.5744, 0.6019],\n",
      "        [0.5743, 0.5799, 0.5764, 0.6074],\n",
      "        [0.5589, 0.5588, 0.5571, 0.5540],\n",
      "        [0.5515, 0.5487, 0.5478, 0.5283],\n",
      "        [0.5515, 0.5487, 0.5478, 0.5283],\n",
      "        [0.5524, 0.5499, 0.5489, 0.5313],\n",
      "        [0.5515, 0.5487, 0.5478, 0.5283],\n",
      "        [0.5515, 0.5487, 0.5478, 0.5283],\n",
      "        [0.5585, 0.5583, 0.5566, 0.5527],\n",
      "        [0.5515, 0.5487, 0.5478, 0.5283],\n",
      "        [0.5515, 0.5487, 0.5478, 0.5283],\n",
      "        [0.5515, 0.5487, 0.5478, 0.5283],\n",
      "        [0.5515, 0.5487, 0.5478, 0.5283],\n",
      "        [0.5515, 0.5487, 0.5478, 0.5283],\n",
      "        [0.5515, 0.5487, 0.5478, 0.5283],\n",
      "        [0.5771, 0.5838, 0.5800, 0.6173],\n",
      "        [0.5515, 0.5487, 0.5478, 0.5283],\n",
      "        [0.5515, 0.5487, 0.5478, 0.5283],\n",
      "        [0.5516, 0.5487, 0.5478, 0.5284],\n",
      "        [0.5515, 0.5487, 0.5478, 0.5283],\n",
      "        [0.5515, 0.5487, 0.5478, 0.5283],\n",
      "        [0.5523, 0.5497, 0.5487, 0.5309],\n",
      "        [0.5515, 0.5487, 0.5478, 0.5283]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0460, 0.0124, 0.0273, 0.0113],\n",
      "        [0.0107, 0.0172, 0.0009, 0.0074],\n",
      "        [0.0257, 0.0015, 0.0268, 0.0054],\n",
      "        [0.0046, 0.0218, 0.0168, 0.0003],\n",
      "        [0.0317, 0.0204, 0.0329, 0.0004],\n",
      "        [0.0301, 0.0394, 0.0246, 0.0024],\n",
      "        [0.0437, 0.0278, 0.0033, 0.0059],\n",
      "        [0.0323, 0.0091, 0.0066, 0.0075],\n",
      "        [0.0064, 0.0074, 0.0266, 0.0171],\n",
      "        [0.0103, 0.0276, 0.0366, 0.0206],\n",
      "        [0.0304, 0.0375, 0.0400, 0.0183],\n",
      "        [0.0403, 0.0410, 0.0378, 0.0094],\n",
      "        [0.0445, 0.0397, 0.0298, 0.0006],\n",
      "        [0.0423, 0.0310, 0.0187, 0.0040],\n",
      "        [0.0433, 0.0331, 0.0260, 0.0125],\n",
      "        [0.0400, 0.0390, 0.0066, 0.0148],\n",
      "        [0.0360, 0.0020, 0.0352, 0.0137],\n",
      "        [0.0083, 0.0345, 0.0401, 0.0108],\n",
      "        [0.0350, 0.0327, 0.0270, 0.0135],\n",
      "        [0.0361, 0.0215, 0.0390, 0.0195],\n",
      "        [0.0111, 0.0190, 0.0186, 0.0083],\n",
      "        [0.0273, 0.0096, 0.0147, 0.0066],\n",
      "        [0.0242, 0.0136, 0.0214, 0.0144],\n",
      "        [0.0059, 0.0167, 0.0272, 0.0229],\n",
      "        [0.0107, 0.0205, 0.0050, 0.0604],\n",
      "        [0.0401, 0.0302, 0.0105, 0.0048],\n",
      "        [0.0263, 0.0258, 0.0351, 0.0262],\n",
      "        [0.0184, 0.0270, 0.0394, 0.0374],\n",
      "        [0.0263, 0.0270, 0.0145, 0.0408],\n",
      "        [0.0325, 0.0429, 0.0311, 0.0300],\n",
      "        [0.0364, 0.0362, 0.0363, 0.0633],\n",
      "        [0.0639, 0.0392, 0.0371, 0.0557],\n",
      "        [0.0498, 0.0667, 0.0401, 0.0566],\n",
      "        [0.0193, 0.0137, 0.0021, 0.0416],\n",
      "        [0.0544, 0.0084, 0.0331, 0.0829],\n",
      "        [0.0710, 0.0515, 0.0074, 0.0525],\n",
      "        [0.0299, 0.0404, 0.0569, 0.0626],\n",
      "        [0.0566, 0.0467, 0.0595, 0.0622],\n",
      "        [0.0883, 0.0537, 0.0458, 0.0401],\n",
      "        [0.0439, 0.0588, 0.0829, 0.0556],\n",
      "        [0.0496, 0.0605, 0.0817, 0.0532]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 17\n",
      "Number of shrink: 16\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0473,     0.0139,     0.0294,     0.0094],\n",
      "        [    0.0119,     0.0186,     0.0029,     0.0055],\n",
      "        [    0.0269,     0.0029,     0.0289,     0.0035],\n",
      "        [    0.0057,     0.0232,     0.0189,     0.0016],\n",
      "        [    0.0330,     0.0219,     0.0350,     0.0022],\n",
      "        [    0.0315,     0.0409,     0.0268,     0.0006],\n",
      "        [    0.0451,     0.0295,     0.0055,     0.0042],\n",
      "        [    0.0338,     0.0108,     0.0043,     0.0058],\n",
      "        [    0.0078,     0.0057,     0.0243,     0.0154],\n",
      "        [    0.0088,     0.0258,     0.0343,     0.0189],\n",
      "        [    0.0289,     0.0358,     0.0377,     0.0166],\n",
      "        [    0.0389,     0.0392,     0.0354,     0.0077],\n",
      "        [    0.0431,     0.0380,     0.0275,     0.0010],\n",
      "        [    0.0409,     0.0293,     0.0164,     0.0057],\n",
      "        [    0.0420,     0.0315,     0.0238,     0.0143],\n",
      "        [    0.0388,     0.0376,     0.0086,     0.0167],\n",
      "        [    0.0348,     0.0035,     0.0373,     0.0156],\n",
      "        [    0.0095,     0.0359,     0.0422,     0.0127],\n",
      "        [    0.0362,     0.0341,     0.0290,     0.0154],\n",
      "        [    0.0372,     0.0229,     0.0410,     0.0176],\n",
      "        [    0.0126,     0.0208,     0.0210,     0.0104],\n",
      "        [    0.0288,     0.0113,     0.0123,     0.0049],\n",
      "        [    0.0256,     0.0153,     0.0237,     0.0162],\n",
      "        [    0.0074,     0.0150,     0.0248,     0.0211],\n",
      "        [    0.0122,     0.0222,     0.0027,     0.0587],\n",
      "        [    0.0416,     0.0319,     0.0128,     0.0065],\n",
      "        [    0.0277,     0.0274,     0.0373,     0.0280],\n",
      "        [    0.0169,     0.0253,     0.0371,     0.0357],\n",
      "        [    0.0278,     0.0287,     0.0168,     0.0426],\n",
      "        [    0.0340,     0.0447,     0.0334,     0.0317],\n",
      "        [    0.0378,     0.0379,     0.0386,     0.0650],\n",
      "        [    0.0653,     0.0409,     0.0394,     0.0574],\n",
      "        [    0.0513,     0.0684,     0.0424,     0.0583],\n",
      "        [    0.0181,     0.0122,     0.0000,     0.0392],\n",
      "        [    0.0529,     0.0066,     0.0354,     0.0846],\n",
      "        [    0.0696,     0.0498,     0.0051,     0.0542],\n",
      "        [    0.0284,     0.0386,     0.0545,     0.0608],\n",
      "        [    0.0551,     0.0450,     0.0572,     0.0605],\n",
      "        [    0.0869,     0.0520,     0.0435,     0.0384],\n",
      "        [    0.0424,     0.0571,     0.0805,     0.0537],\n",
      "        [    0.0481,     0.0587,     0.0794,     0.0514]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.654722690582275\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 42\n",
      "X 資料 torch.Size([65, 18])\n",
      "Y 資料 torch.Size([65, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.003726489841938019, 5)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引5，y= tensor([0.4813, 0.4632, 0.4950, 0.5020])\n",
      "目前模型的Data torch.Size([42, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5676, 0.5709, 0.5674, 0.5865],\n",
      "        [0.5729, 0.5782, 0.5741, 0.6047],\n",
      "        [0.5699, 0.5741, 0.5703, 0.5944],\n",
      "        [0.5713, 0.5759, 0.5720, 0.5991],\n",
      "        [0.5662, 0.5690, 0.5657, 0.5818],\n",
      "        [0.5594, 0.5597, 0.5571, 0.5585],\n",
      "        [0.5556, 0.5545, 0.5524, 0.5455],\n",
      "        [0.5502, 0.5471, 0.5456, 0.5270],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5508, 0.5480, 0.5464, 0.5292],\n",
      "        [0.5509, 0.5482, 0.5465, 0.5295],\n",
      "        [0.5608, 0.5617, 0.5590, 0.5635],\n",
      "        [0.5689, 0.5727, 0.5691, 0.5911],\n",
      "        [0.5700, 0.5742, 0.5705, 0.5948],\n",
      "        [0.5682, 0.5718, 0.5682, 0.5887],\n",
      "        [0.5715, 0.5763, 0.5724, 0.6000],\n",
      "        [0.5731, 0.5785, 0.5744, 0.6055],\n",
      "        [0.5575, 0.5571, 0.5547, 0.5519],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5509, 0.5481, 0.5465, 0.5295],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5572, 0.5567, 0.5544, 0.5509],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5759, 0.5822, 0.5778, 0.6149],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5508, 0.5480, 0.5463, 0.5290],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266],\n",
      "        [0.5501, 0.5470, 0.5455, 0.5266]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0473,     0.0139,     0.0294,     0.0094],\n",
      "        [    0.0119,     0.0186,     0.0029,     0.0055],\n",
      "        [    0.0269,     0.0029,     0.0289,     0.0035],\n",
      "        [    0.0057,     0.0232,     0.0189,     0.0016],\n",
      "        [    0.0330,     0.0219,     0.0350,     0.0022],\n",
      "        [    0.0315,     0.0409,     0.0268,     0.0006],\n",
      "        [    0.0451,     0.0295,     0.0055,     0.0042],\n",
      "        [    0.0338,     0.0108,     0.0043,     0.0058],\n",
      "        [    0.0078,     0.0057,     0.0243,     0.0154],\n",
      "        [    0.0088,     0.0258,     0.0343,     0.0189],\n",
      "        [    0.0289,     0.0358,     0.0377,     0.0166],\n",
      "        [    0.0389,     0.0392,     0.0354,     0.0077],\n",
      "        [    0.0431,     0.0380,     0.0275,     0.0010],\n",
      "        [    0.0409,     0.0293,     0.0164,     0.0057],\n",
      "        [    0.0420,     0.0315,     0.0238,     0.0143],\n",
      "        [    0.0388,     0.0376,     0.0086,     0.0167],\n",
      "        [    0.0348,     0.0035,     0.0373,     0.0156],\n",
      "        [    0.0095,     0.0359,     0.0422,     0.0127],\n",
      "        [    0.0362,     0.0341,     0.0290,     0.0154],\n",
      "        [    0.0372,     0.0229,     0.0410,     0.0176],\n",
      "        [    0.0126,     0.0208,     0.0210,     0.0104],\n",
      "        [    0.0288,     0.0113,     0.0123,     0.0049],\n",
      "        [    0.0256,     0.0153,     0.0237,     0.0162],\n",
      "        [    0.0074,     0.0150,     0.0248,     0.0211],\n",
      "        [    0.0122,     0.0222,     0.0027,     0.0587],\n",
      "        [    0.0416,     0.0319,     0.0128,     0.0065],\n",
      "        [    0.0277,     0.0274,     0.0373,     0.0280],\n",
      "        [    0.0169,     0.0253,     0.0371,     0.0357],\n",
      "        [    0.0278,     0.0287,     0.0168,     0.0426],\n",
      "        [    0.0340,     0.0447,     0.0334,     0.0317],\n",
      "        [    0.0378,     0.0379,     0.0386,     0.0650],\n",
      "        [    0.0653,     0.0409,     0.0394,     0.0574],\n",
      "        [    0.0513,     0.0684,     0.0424,     0.0583],\n",
      "        [    0.0181,     0.0122,     0.0000,     0.0392],\n",
      "        [    0.0529,     0.0066,     0.0354,     0.0846],\n",
      "        [    0.0696,     0.0498,     0.0051,     0.0542],\n",
      "        [    0.0284,     0.0386,     0.0545,     0.0608],\n",
      "        [    0.0551,     0.0450,     0.0572,     0.0605],\n",
      "        [    0.0869,     0.0520,     0.0435,     0.0384],\n",
      "        [    0.0424,     0.0571,     0.0805,     0.0537],\n",
      "        [    0.0481,     0.0587,     0.0794,     0.0514],\n",
      "        [    0.0688,     0.0838,     0.0505,     0.0246]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"73\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"83\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 57\n",
      "Number of shrink: 36\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0469, 0.0135, 0.0281, 0.0125],\n",
      "        [0.0111, 0.0178, 0.0013, 0.0084],\n",
      "        [0.0265, 0.0026, 0.0277, 0.0059],\n",
      "        [0.0053, 0.0229, 0.0176, 0.0007],\n",
      "        [0.0330, 0.0221, 0.0343, 0.0003],\n",
      "        [0.0319, 0.0415, 0.0265, 0.0032],\n",
      "        [0.0457, 0.0301, 0.0053, 0.0072],\n",
      "        [0.0349, 0.0120, 0.0040, 0.0087],\n",
      "        [0.0103, 0.0026, 0.0222, 0.0138],\n",
      "        [0.0063, 0.0227, 0.0322, 0.0173],\n",
      "        [0.0264, 0.0327, 0.0356, 0.0150],\n",
      "        [0.0364, 0.0362, 0.0334, 0.0063],\n",
      "        [0.0422, 0.0370, 0.0274, 0.0023],\n",
      "        [0.0399, 0.0281, 0.0161, 0.0028],\n",
      "        [0.0415, 0.0310, 0.0241, 0.0121],\n",
      "        [0.0389, 0.0375, 0.0078, 0.0149],\n",
      "        [0.0349, 0.0036, 0.0365, 0.0142],\n",
      "        [0.0095, 0.0361, 0.0414, 0.0111],\n",
      "        [0.0360, 0.0341, 0.0281, 0.0142],\n",
      "        [0.0369, 0.0227, 0.0399, 0.0190],\n",
      "        [0.0149, 0.0239, 0.0230, 0.0134],\n",
      "        [0.0313, 0.0144, 0.0103, 0.0033],\n",
      "        [0.0281, 0.0184, 0.0258, 0.0177],\n",
      "        [0.0096, 0.0123, 0.0231, 0.0203],\n",
      "        [0.0147, 0.0253, 0.0006, 0.0571],\n",
      "        [0.0441, 0.0350, 0.0149, 0.0081],\n",
      "        [0.0290, 0.0290, 0.0380, 0.0276],\n",
      "        [0.0144, 0.0222, 0.0350, 0.0341],\n",
      "        [0.0303, 0.0318, 0.0189, 0.0441],\n",
      "        [0.0365, 0.0478, 0.0355, 0.0333],\n",
      "        [0.0403, 0.0410, 0.0407, 0.0666],\n",
      "        [0.0678, 0.0440, 0.0415, 0.0590],\n",
      "        [0.0538, 0.0715, 0.0445, 0.0599],\n",
      "        [0.0167, 0.0101, 0.0011, 0.0345],\n",
      "        [0.0504, 0.0035, 0.0375, 0.0862],\n",
      "        [0.0671, 0.0467, 0.0030, 0.0558],\n",
      "        [0.0260, 0.0357, 0.0526, 0.0596],\n",
      "        [0.0526, 0.0419, 0.0551, 0.0590],\n",
      "        [0.0844, 0.0489, 0.0414, 0.0368],\n",
      "        [0.0400, 0.0540, 0.0785, 0.0521],\n",
      "        [0.0456, 0.0556, 0.0773, 0.0499],\n",
      "        [0.0663, 0.0807, 0.0484, 0.0231]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 10.022589683532715\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 43\n",
      "X 資料 torch.Size([64, 18])\n",
      "Y 資料 torch.Size([64, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0037460087332874537, 9)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引9，y= tensor([0.4737, 0.4870, 0.5112, 0.5151])\n",
      "目前模型的Data torch.Size([43, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5680, 0.5713, 0.5686, 0.5895],\n",
      "        [0.5737, 0.5789, 0.5757, 0.6076],\n",
      "        [0.5703, 0.5744, 0.5715, 0.5968],\n",
      "        [0.5717, 0.5763, 0.5733, 0.6013],\n",
      "        [0.5661, 0.5688, 0.5664, 0.5837],\n",
      "        [0.5590, 0.5592, 0.5575, 0.5611],\n",
      "        [0.5550, 0.5538, 0.5526, 0.5485],\n",
      "        [0.5491, 0.5459, 0.5453, 0.5299],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5250],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5250],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5250],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5252],\n",
      "        [0.5499, 0.5470, 0.5463, 0.5325],\n",
      "        [0.5499, 0.5470, 0.5463, 0.5324],\n",
      "        [0.5604, 0.5611, 0.5593, 0.5656],\n",
      "        [0.5690, 0.5727, 0.5700, 0.5928],\n",
      "        [0.5701, 0.5741, 0.5713, 0.5961],\n",
      "        [0.5682, 0.5716, 0.5690, 0.5903],\n",
      "        [0.5717, 0.5763, 0.5732, 0.6012],\n",
      "        [0.5735, 0.5787, 0.5755, 0.6069],\n",
      "        [0.5551, 0.5540, 0.5527, 0.5489],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5250],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5250],\n",
      "        [0.5487, 0.5454, 0.5448, 0.5286],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5250],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5250],\n",
      "        [0.5559, 0.5551, 0.5537, 0.5513],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5250],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5250],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5250],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5250],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5250],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5250],\n",
      "        [0.5745, 0.5801, 0.5768, 0.6103],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5250],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5250],\n",
      "        [0.5477, 0.5440, 0.5435, 0.5254],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5250],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5250],\n",
      "        [0.5483, 0.5449, 0.5443, 0.5275],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5250],\n",
      "        [0.5476, 0.5439, 0.5434, 0.5250],\n",
      "        [0.5566, 0.5560, 0.5545, 0.5535]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0469, 0.0135, 0.0281, 0.0125],\n",
      "        [0.0111, 0.0178, 0.0013, 0.0084],\n",
      "        [0.0265, 0.0026, 0.0277, 0.0059],\n",
      "        [0.0053, 0.0229, 0.0176, 0.0007],\n",
      "        [0.0330, 0.0221, 0.0343, 0.0003],\n",
      "        [0.0319, 0.0415, 0.0265, 0.0032],\n",
      "        [0.0457, 0.0301, 0.0053, 0.0072],\n",
      "        [0.0349, 0.0120, 0.0040, 0.0087],\n",
      "        [0.0103, 0.0026, 0.0222, 0.0138],\n",
      "        [0.0063, 0.0227, 0.0322, 0.0173],\n",
      "        [0.0264, 0.0327, 0.0356, 0.0150],\n",
      "        [0.0364, 0.0362, 0.0334, 0.0063],\n",
      "        [0.0422, 0.0370, 0.0274, 0.0023],\n",
      "        [0.0399, 0.0281, 0.0161, 0.0028],\n",
      "        [0.0415, 0.0310, 0.0241, 0.0121],\n",
      "        [0.0389, 0.0375, 0.0078, 0.0149],\n",
      "        [0.0349, 0.0036, 0.0365, 0.0142],\n",
      "        [0.0095, 0.0361, 0.0414, 0.0111],\n",
      "        [0.0360, 0.0341, 0.0281, 0.0142],\n",
      "        [0.0369, 0.0227, 0.0399, 0.0190],\n",
      "        [0.0149, 0.0239, 0.0230, 0.0134],\n",
      "        [0.0313, 0.0144, 0.0103, 0.0033],\n",
      "        [0.0281, 0.0184, 0.0258, 0.0177],\n",
      "        [0.0096, 0.0123, 0.0231, 0.0203],\n",
      "        [0.0147, 0.0253, 0.0006, 0.0571],\n",
      "        [0.0441, 0.0350, 0.0149, 0.0081],\n",
      "        [0.0290, 0.0290, 0.0380, 0.0276],\n",
      "        [0.0144, 0.0222, 0.0350, 0.0341],\n",
      "        [0.0303, 0.0318, 0.0189, 0.0441],\n",
      "        [0.0365, 0.0478, 0.0355, 0.0333],\n",
      "        [0.0403, 0.0410, 0.0407, 0.0666],\n",
      "        [0.0678, 0.0440, 0.0415, 0.0590],\n",
      "        [0.0538, 0.0715, 0.0445, 0.0599],\n",
      "        [0.0167, 0.0101, 0.0011, 0.0345],\n",
      "        [0.0504, 0.0035, 0.0375, 0.0862],\n",
      "        [0.0671, 0.0467, 0.0030, 0.0558],\n",
      "        [0.0260, 0.0357, 0.0526, 0.0596],\n",
      "        [0.0526, 0.0419, 0.0551, 0.0590],\n",
      "        [0.0844, 0.0489, 0.0414, 0.0368],\n",
      "        [0.0400, 0.0540, 0.0785, 0.0521],\n",
      "        [0.0456, 0.0556, 0.0773, 0.0499],\n",
      "        [0.0663, 0.0807, 0.0484, 0.0231],\n",
      "        [0.0829, 0.0690, 0.0433, 0.0384]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 12\n",
      "Number of shrink: 13\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0487, 0.0149, 0.0290, 0.0116],\n",
      "        [0.0129, 0.0191, 0.0021, 0.0075],\n",
      "        [0.0283, 0.0040, 0.0285, 0.0050],\n",
      "        [0.0071, 0.0242, 0.0184, 0.0002],\n",
      "        [0.0349, 0.0235, 0.0352, 0.0011],\n",
      "        [0.0338, 0.0429, 0.0274, 0.0024],\n",
      "        [0.0476, 0.0317, 0.0063, 0.0064],\n",
      "        [0.0369, 0.0135, 0.0030, 0.0080],\n",
      "        [0.0123, 0.0011, 0.0212, 0.0132],\n",
      "        [0.0043, 0.0212, 0.0312, 0.0167],\n",
      "        [0.0244, 0.0312, 0.0346, 0.0144],\n",
      "        [0.0344, 0.0346, 0.0324, 0.0056],\n",
      "        [0.0402, 0.0355, 0.0264, 0.0016],\n",
      "        [0.0378, 0.0265, 0.0151, 0.0036],\n",
      "        [0.0396, 0.0295, 0.0232, 0.0130],\n",
      "        [0.0370, 0.0361, 0.0086, 0.0158],\n",
      "        [0.0331, 0.0050, 0.0373, 0.0152],\n",
      "        [0.0113, 0.0375, 0.0423, 0.0120],\n",
      "        [0.0379, 0.0355, 0.0290, 0.0152],\n",
      "        [0.0387, 0.0241, 0.0408, 0.0180],\n",
      "        [0.0170, 0.0256, 0.0242, 0.0147],\n",
      "        [0.0333, 0.0159, 0.0093, 0.0027],\n",
      "        [0.0301, 0.0199, 0.0268, 0.0183],\n",
      "        [0.0116, 0.0106, 0.0220, 0.0194],\n",
      "        [0.0167, 0.0268, 0.0004, 0.0566],\n",
      "        [0.0461, 0.0365, 0.0159, 0.0087],\n",
      "        [0.0309, 0.0305, 0.0389, 0.0284],\n",
      "        [0.0124, 0.0207, 0.0340, 0.0335],\n",
      "        [0.0323, 0.0334, 0.0199, 0.0447],\n",
      "        [0.0385, 0.0493, 0.0365, 0.0338],\n",
      "        [0.0423, 0.0425, 0.0417, 0.0672],\n",
      "        [0.0698, 0.0455, 0.0425, 0.0596],\n",
      "        [0.0558, 0.0730, 0.0455, 0.0604],\n",
      "        [0.0148, 0.0085, 0.0021, 0.0331],\n",
      "        [0.0484, 0.0020, 0.0385, 0.0868],\n",
      "        [0.0651, 0.0452, 0.0020, 0.0564],\n",
      "        [0.0239, 0.0340, 0.0515, 0.0587],\n",
      "        [0.0506, 0.0404, 0.0541, 0.0584],\n",
      "        [0.0824, 0.0474, 0.0404, 0.0362],\n",
      "        [0.0379, 0.0524, 0.0774, 0.0513],\n",
      "        [0.0436, 0.0541, 0.0763, 0.0493],\n",
      "        [0.0643, 0.0791, 0.0474, 0.0225],\n",
      "        [0.0808, 0.0672, 0.0421, 0.0370]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 10.194015741348267\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 44\n",
      "X 資料 torch.Size([63, 18])\n",
      "Y 資料 torch.Size([63, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.003664088901132345, 2)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引2，y= tensor([0.4753, 0.4796, 0.4961, 0.4813])\n",
      "目前模型的Data torch.Size([44, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5661, 0.5699, 0.5678, 0.5886],\n",
      "        [0.5719, 0.5776, 0.5749, 0.6067],\n",
      "        [0.5685, 0.5730, 0.5707, 0.5959],\n",
      "        [0.5699, 0.5750, 0.5725, 0.6005],\n",
      "        [0.5643, 0.5674, 0.5655, 0.5829],\n",
      "        [0.5571, 0.5577, 0.5566, 0.5603],\n",
      "        [0.5530, 0.5523, 0.5516, 0.5477],\n",
      "        [0.5471, 0.5444, 0.5443, 0.5291],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5244],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5244],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5244],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5245],\n",
      "        [0.5479, 0.5455, 0.5453, 0.5317],\n",
      "        [0.5479, 0.5454, 0.5452, 0.5316],\n",
      "        [0.5585, 0.5596, 0.5583, 0.5647],\n",
      "        [0.5672, 0.5713, 0.5691, 0.5919],\n",
      "        [0.5682, 0.5727, 0.5704, 0.5952],\n",
      "        [0.5664, 0.5702, 0.5681, 0.5894],\n",
      "        [0.5698, 0.5749, 0.5724, 0.6002],\n",
      "        [0.5717, 0.5773, 0.5746, 0.6059],\n",
      "        [0.5530, 0.5523, 0.5515, 0.5476],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5244],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5244],\n",
      "        [0.5466, 0.5438, 0.5437, 0.5278],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5244],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5244],\n",
      "        [0.5539, 0.5535, 0.5527, 0.5505],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5244],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5244],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5244],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5244],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5244],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5244],\n",
      "        [0.5726, 0.5786, 0.5758, 0.6089],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5244],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5244],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5245],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5244],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5244],\n",
      "        [0.5463, 0.5433, 0.5432, 0.5266],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5244],\n",
      "        [0.5456, 0.5424, 0.5424, 0.5244],\n",
      "        [0.5544, 0.5542, 0.5533, 0.5521],\n",
      "        [0.5480, 0.5456, 0.5454, 0.5321]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0487, 0.0149, 0.0290, 0.0116],\n",
      "        [0.0129, 0.0191, 0.0021, 0.0075],\n",
      "        [0.0283, 0.0040, 0.0285, 0.0050],\n",
      "        [0.0071, 0.0242, 0.0184, 0.0002],\n",
      "        [0.0349, 0.0235, 0.0352, 0.0011],\n",
      "        [0.0338, 0.0429, 0.0274, 0.0024],\n",
      "        [0.0476, 0.0317, 0.0063, 0.0064],\n",
      "        [0.0369, 0.0135, 0.0030, 0.0080],\n",
      "        [0.0123, 0.0011, 0.0212, 0.0132],\n",
      "        [0.0043, 0.0212, 0.0312, 0.0167],\n",
      "        [0.0244, 0.0312, 0.0346, 0.0144],\n",
      "        [0.0344, 0.0346, 0.0324, 0.0056],\n",
      "        [0.0402, 0.0355, 0.0264, 0.0016],\n",
      "        [0.0378, 0.0265, 0.0151, 0.0036],\n",
      "        [0.0396, 0.0295, 0.0232, 0.0130],\n",
      "        [0.0370, 0.0361, 0.0086, 0.0158],\n",
      "        [0.0331, 0.0050, 0.0373, 0.0152],\n",
      "        [0.0113, 0.0375, 0.0423, 0.0120],\n",
      "        [0.0379, 0.0355, 0.0290, 0.0152],\n",
      "        [0.0387, 0.0241, 0.0408, 0.0180],\n",
      "        [0.0170, 0.0256, 0.0242, 0.0147],\n",
      "        [0.0333, 0.0159, 0.0093, 0.0027],\n",
      "        [0.0301, 0.0199, 0.0268, 0.0183],\n",
      "        [0.0116, 0.0106, 0.0220, 0.0194],\n",
      "        [0.0167, 0.0268, 0.0004, 0.0566],\n",
      "        [0.0461, 0.0365, 0.0159, 0.0087],\n",
      "        [0.0309, 0.0305, 0.0389, 0.0284],\n",
      "        [0.0124, 0.0207, 0.0340, 0.0335],\n",
      "        [0.0323, 0.0334, 0.0199, 0.0447],\n",
      "        [0.0385, 0.0493, 0.0365, 0.0338],\n",
      "        [0.0423, 0.0425, 0.0417, 0.0672],\n",
      "        [0.0698, 0.0455, 0.0425, 0.0596],\n",
      "        [0.0558, 0.0730, 0.0455, 0.0604],\n",
      "        [0.0148, 0.0085, 0.0021, 0.0331],\n",
      "        [0.0484, 0.0020, 0.0385, 0.0868],\n",
      "        [0.0651, 0.0452, 0.0020, 0.0564],\n",
      "        [0.0239, 0.0340, 0.0515, 0.0587],\n",
      "        [0.0506, 0.0404, 0.0541, 0.0584],\n",
      "        [0.0824, 0.0474, 0.0404, 0.0362],\n",
      "        [0.0379, 0.0524, 0.0774, 0.0513],\n",
      "        [0.0436, 0.0541, 0.0763, 0.0493],\n",
      "        [0.0643, 0.0791, 0.0474, 0.0225],\n",
      "        [0.0808, 0.0672, 0.0421, 0.0370],\n",
      "        [0.0727, 0.0660, 0.0493, 0.0508]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"46\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"50\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 33\n",
      "Number of shrink: 24\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0499, 0.0159, 0.0298, 0.0103],\n",
      "        [0.0139, 0.0199, 0.0027, 0.0064],\n",
      "        [0.0295, 0.0050, 0.0294, 0.0036],\n",
      "        [0.0082, 0.0252, 0.0192, 0.0016],\n",
      "        [0.0362, 0.0247, 0.0362, 0.0027],\n",
      "        [0.0353, 0.0443, 0.0285, 0.0010],\n",
      "        [0.0492, 0.0331, 0.0075, 0.0050],\n",
      "        [0.0386, 0.0151, 0.0016, 0.0066],\n",
      "        [0.0140, 0.0004, 0.0199, 0.0122],\n",
      "        [0.0026, 0.0197, 0.0299, 0.0157],\n",
      "        [0.0228, 0.0297, 0.0333, 0.0134],\n",
      "        [0.0327, 0.0331, 0.0311, 0.0046],\n",
      "        [0.0385, 0.0340, 0.0251, 0.0004],\n",
      "        [0.0361, 0.0250, 0.0137, 0.0050],\n",
      "        [0.0381, 0.0281, 0.0220, 0.0146],\n",
      "        [0.0358, 0.0350, 0.0095, 0.0172],\n",
      "        [0.0318, 0.0061, 0.0382, 0.0167],\n",
      "        [0.0126, 0.0386, 0.0432, 0.0135],\n",
      "        [0.0390, 0.0365, 0.0298, 0.0166],\n",
      "        [0.0398, 0.0250, 0.0415, 0.0167],\n",
      "        [0.0201, 0.0290, 0.0273, 0.0207],\n",
      "        [0.0350, 0.0174, 0.0080, 0.0017],\n",
      "        [0.0318, 0.0214, 0.0281, 0.0193],\n",
      "        [0.0138, 0.0084, 0.0200, 0.0167],\n",
      "        [0.0184, 0.0283, 0.0017, 0.0555],\n",
      "        [0.0477, 0.0380, 0.0172, 0.0097],\n",
      "        [0.0326, 0.0321, 0.0403, 0.0301],\n",
      "        [0.0108, 0.0192, 0.0327, 0.0325],\n",
      "        [0.0340, 0.0348, 0.0212, 0.0457],\n",
      "        [0.0401, 0.0508, 0.0378, 0.0349],\n",
      "        [0.0440, 0.0440, 0.0430, 0.0682],\n",
      "        [0.0715, 0.0470, 0.0438, 0.0606],\n",
      "        [0.0575, 0.0745, 0.0468, 0.0615],\n",
      "        [0.0121, 0.0054, 0.0048, 0.0268],\n",
      "        [0.0467, 0.0005, 0.0398, 0.0878],\n",
      "        [0.0634, 0.0437, 0.0007, 0.0574],\n",
      "        [0.0222, 0.0325, 0.0502, 0.0576],\n",
      "        [0.0489, 0.0389, 0.0528, 0.0574],\n",
      "        [0.0807, 0.0459, 0.0391, 0.0352],\n",
      "        [0.0355, 0.0500, 0.0752, 0.0481],\n",
      "        [0.0420, 0.0526, 0.0750, 0.0483],\n",
      "        [0.0626, 0.0777, 0.0461, 0.0215],\n",
      "        [0.0778, 0.0640, 0.0392, 0.0313],\n",
      "        [0.0702, 0.0634, 0.0470, 0.0470]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 10.434880256652832\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 45\n",
      "X 資料 torch.Size([62, 18])\n",
      "Y 資料 torch.Size([62, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.003670790931209922, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.4909, 0.4658, 0.4753, 0.4796])\n",
      "目前模型的Data torch.Size([45, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5649, 0.5688, 0.5669, 0.5873],\n",
      "        [0.5709, 0.5768, 0.5743, 0.6055],\n",
      "        [0.5673, 0.5720, 0.5698, 0.5945],\n",
      "        [0.5688, 0.5740, 0.5717, 0.5991],\n",
      "        [0.5630, 0.5662, 0.5645, 0.5813],\n",
      "        [0.5556, 0.5564, 0.5554, 0.5589],\n",
      "        [0.5514, 0.5509, 0.5504, 0.5463],\n",
      "        [0.5454, 0.5428, 0.5429, 0.5278],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5235],\n",
      "        [0.5463, 0.5440, 0.5440, 0.5306],\n",
      "        [0.5461, 0.5438, 0.5438, 0.5302],\n",
      "        [0.5570, 0.5583, 0.5572, 0.5632],\n",
      "        [0.5660, 0.5702, 0.5682, 0.5905],\n",
      "        [0.5670, 0.5716, 0.5695, 0.5937],\n",
      "        [0.5651, 0.5691, 0.5672, 0.5879],\n",
      "        [0.5687, 0.5738, 0.5716, 0.5988],\n",
      "        [0.5706, 0.5764, 0.5739, 0.6046],\n",
      "        [0.5499, 0.5488, 0.5484, 0.5416],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5444, 0.5416, 0.5417, 0.5250],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5523, 0.5520, 0.5514, 0.5488],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5699, 0.5755, 0.5731, 0.6025],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234],\n",
      "        [0.5515, 0.5509, 0.5504, 0.5464],\n",
      "        [0.5455, 0.5430, 0.5430, 0.5283],\n",
      "        [0.5439, 0.5409, 0.5411, 0.5234]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0499, 0.0159, 0.0298, 0.0103],\n",
      "        [0.0139, 0.0199, 0.0027, 0.0064],\n",
      "        [0.0295, 0.0050, 0.0294, 0.0036],\n",
      "        [0.0082, 0.0252, 0.0192, 0.0016],\n",
      "        [0.0362, 0.0247, 0.0362, 0.0027],\n",
      "        [0.0353, 0.0443, 0.0285, 0.0010],\n",
      "        [0.0492, 0.0331, 0.0075, 0.0050],\n",
      "        [0.0386, 0.0151, 0.0016, 0.0066],\n",
      "        [0.0140, 0.0004, 0.0199, 0.0122],\n",
      "        [0.0026, 0.0197, 0.0299, 0.0157],\n",
      "        [0.0228, 0.0297, 0.0333, 0.0134],\n",
      "        [0.0327, 0.0331, 0.0311, 0.0046],\n",
      "        [0.0385, 0.0340, 0.0251, 0.0004],\n",
      "        [0.0361, 0.0250, 0.0137, 0.0050],\n",
      "        [0.0381, 0.0281, 0.0220, 0.0146],\n",
      "        [0.0358, 0.0350, 0.0095, 0.0172],\n",
      "        [0.0318, 0.0061, 0.0382, 0.0167],\n",
      "        [0.0126, 0.0386, 0.0432, 0.0135],\n",
      "        [0.0390, 0.0365, 0.0298, 0.0166],\n",
      "        [0.0398, 0.0250, 0.0415, 0.0167],\n",
      "        [0.0201, 0.0290, 0.0273, 0.0207],\n",
      "        [0.0350, 0.0174, 0.0080, 0.0017],\n",
      "        [0.0318, 0.0214, 0.0281, 0.0193],\n",
      "        [0.0138, 0.0084, 0.0200, 0.0167],\n",
      "        [0.0184, 0.0283, 0.0017, 0.0555],\n",
      "        [0.0477, 0.0380, 0.0172, 0.0097],\n",
      "        [0.0326, 0.0321, 0.0403, 0.0301],\n",
      "        [0.0108, 0.0192, 0.0327, 0.0325],\n",
      "        [0.0340, 0.0348, 0.0212, 0.0457],\n",
      "        [0.0401, 0.0508, 0.0378, 0.0349],\n",
      "        [0.0440, 0.0440, 0.0430, 0.0682],\n",
      "        [0.0715, 0.0470, 0.0438, 0.0606],\n",
      "        [0.0575, 0.0745, 0.0468, 0.0615],\n",
      "        [0.0121, 0.0054, 0.0048, 0.0268],\n",
      "        [0.0467, 0.0005, 0.0398, 0.0878],\n",
      "        [0.0634, 0.0437, 0.0007, 0.0574],\n",
      "        [0.0222, 0.0325, 0.0502, 0.0576],\n",
      "        [0.0489, 0.0389, 0.0528, 0.0574],\n",
      "        [0.0807, 0.0459, 0.0391, 0.0352],\n",
      "        [0.0355, 0.0500, 0.0752, 0.0481],\n",
      "        [0.0420, 0.0526, 0.0750, 0.0483],\n",
      "        [0.0626, 0.0777, 0.0461, 0.0215],\n",
      "        [0.0778, 0.0640, 0.0392, 0.0313],\n",
      "        [0.0702, 0.0634, 0.0470, 0.0470],\n",
      "        [0.0530, 0.0750, 0.0658, 0.0438]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"35\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"70\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 43\n",
      "Number of shrink: 29\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0497,     0.0159,     0.0296,     0.0123],\n",
      "        [    0.0133,     0.0196,     0.0022,     0.0085],\n",
      "        [    0.0292,     0.0051,     0.0291,     0.0053],\n",
      "        [    0.0079,     0.0252,     0.0189,     0.0002],\n",
      "        [    0.0363,     0.0251,     0.0363,     0.0014],\n",
      "        [    0.0356,     0.0449,     0.0289,     0.0024],\n",
      "        [    0.0497,     0.0338,     0.0080,     0.0066],\n",
      "        [    0.0393,     0.0161,     0.0008,     0.0081],\n",
      "        [    0.0158,     0.0029,     0.0178,     0.0104],\n",
      "        [    0.0008,     0.0172,     0.0278,     0.0139],\n",
      "        [    0.0209,     0.0272,     0.0312,     0.0116],\n",
      "        [    0.0320,     0.0321,     0.0303,     0.0061],\n",
      "        [    0.0378,     0.0330,     0.0244,     0.0017],\n",
      "        [    0.0352,     0.0237,     0.0127,     0.0041],\n",
      "        [    0.0375,     0.0272,     0.0213,     0.0140],\n",
      "        [    0.0357,     0.0346,     0.0097,     0.0164],\n",
      "        [    0.0317,     0.0066,     0.0384,     0.0159],\n",
      "        [    0.0127,     0.0391,     0.0434,     0.0126],\n",
      "        [    0.0390,     0.0368,     0.0298,     0.0156],\n",
      "        [    0.0395,     0.0250,     0.0412,     0.0182],\n",
      "        [    0.0231,     0.0330,     0.0307,     0.0262],\n",
      "        [    0.0368,     0.0199,     0.0058,     0.0000],\n",
      "        [    0.0336,     0.0239,     0.0302,     0.0211],\n",
      "        [    0.0153,     0.0065,     0.0184,     0.0160],\n",
      "        [    0.0202,     0.0308,     0.0038,     0.0538],\n",
      "        [    0.0496,     0.0405,     0.0193,     0.0115],\n",
      "        [    0.0332,     0.0329,     0.0409,     0.0290],\n",
      "        [    0.0089,     0.0167,     0.0306,     0.0307],\n",
      "        [    0.0358,     0.0373,     0.0233,     0.0475],\n",
      "        [    0.0420,     0.0533,     0.0399,     0.0366],\n",
      "        [    0.0458,     0.0465,     0.0451,     0.0700],\n",
      "        [    0.0733,     0.0495,     0.0459,     0.0624],\n",
      "        [    0.0593,     0.0770,     0.0489,     0.0632],\n",
      "        [    0.0098,     0.0020,     0.0077,     0.0208],\n",
      "        [    0.0449,     0.0020,     0.0419,     0.0896],\n",
      "        [    0.0616,     0.0412,     0.0014,     0.0592],\n",
      "        [    0.0204,     0.0300,     0.0481,     0.0558],\n",
      "        [    0.0471,     0.0364,     0.0507,     0.0556],\n",
      "        [    0.0788,     0.0434,     0.0370,     0.0334],\n",
      "        [    0.0337,     0.0475,     0.0731,     0.0463],\n",
      "        [    0.0401,     0.0501,     0.0729,     0.0465],\n",
      "        [    0.0608,     0.0752,     0.0440,     0.0197],\n",
      "        [    0.0750,     0.0602,     0.0359,     0.0260],\n",
      "        [    0.0679,     0.0603,     0.0443,     0.0438],\n",
      "        [    0.0512,     0.0725,     0.0636,     0.0420]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 10.771947383880615\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 46\n",
      "X 資料 torch.Size([61, 18])\n",
      "Y 資料 torch.Size([61, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.003490697592496872, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.4658, 0.4753, 0.4796, 0.4961])\n",
      "目前模型的Data torch.Size([46, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5652, 0.5689, 0.5672, 0.5894],\n",
      "        [0.5714, 0.5771, 0.5748, 0.6077],\n",
      "        [0.5675, 0.5719, 0.5700, 0.5962],\n",
      "        [0.5691, 0.5740, 0.5720, 0.6008],\n",
      "        [0.5629, 0.5658, 0.5644, 0.5826],\n",
      "        [0.5553, 0.5558, 0.5551, 0.5603],\n",
      "        [0.5510, 0.5502, 0.5499, 0.5478],\n",
      "        [0.5447, 0.5418, 0.5421, 0.5292],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5432, 0.5399, 0.5404, 0.5250],\n",
      "        [0.5456, 0.5430, 0.5432, 0.5319],\n",
      "        [0.5453, 0.5426, 0.5429, 0.5311],\n",
      "        [0.5564, 0.5573, 0.5565, 0.5637],\n",
      "        [0.5658, 0.5697, 0.5680, 0.5913],\n",
      "        [0.5669, 0.5712, 0.5693, 0.5945],\n",
      "        [0.5650, 0.5686, 0.5669, 0.5888],\n",
      "        [0.5687, 0.5736, 0.5716, 0.5998],\n",
      "        [0.5709, 0.5764, 0.5742, 0.6061],\n",
      "        [0.5470, 0.5449, 0.5450, 0.5360],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5430, 0.5396, 0.5401, 0.5244],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5517, 0.5511, 0.5508, 0.5499],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5676, 0.5721, 0.5702, 0.5965],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5487, 0.5472, 0.5471, 0.5411],\n",
      "        [0.5432, 0.5399, 0.5404, 0.5251],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217],\n",
      "        [0.5421, 0.5384, 0.5390, 0.5217]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0497,     0.0159,     0.0296,     0.0123],\n",
      "        [    0.0133,     0.0196,     0.0022,     0.0085],\n",
      "        [    0.0292,     0.0051,     0.0291,     0.0053],\n",
      "        [    0.0079,     0.0252,     0.0189,     0.0002],\n",
      "        [    0.0363,     0.0251,     0.0363,     0.0014],\n",
      "        [    0.0356,     0.0449,     0.0289,     0.0024],\n",
      "        [    0.0497,     0.0338,     0.0080,     0.0066],\n",
      "        [    0.0393,     0.0161,     0.0008,     0.0081],\n",
      "        [    0.0158,     0.0029,     0.0178,     0.0104],\n",
      "        [    0.0008,     0.0172,     0.0278,     0.0139],\n",
      "        [    0.0209,     0.0272,     0.0312,     0.0116],\n",
      "        [    0.0320,     0.0321,     0.0303,     0.0061],\n",
      "        [    0.0378,     0.0330,     0.0244,     0.0017],\n",
      "        [    0.0352,     0.0237,     0.0127,     0.0041],\n",
      "        [    0.0375,     0.0272,     0.0213,     0.0140],\n",
      "        [    0.0357,     0.0346,     0.0097,     0.0164],\n",
      "        [    0.0317,     0.0066,     0.0384,     0.0159],\n",
      "        [    0.0127,     0.0391,     0.0434,     0.0126],\n",
      "        [    0.0390,     0.0368,     0.0298,     0.0156],\n",
      "        [    0.0395,     0.0250,     0.0412,     0.0182],\n",
      "        [    0.0231,     0.0330,     0.0307,     0.0262],\n",
      "        [    0.0368,     0.0199,     0.0058,     0.0000],\n",
      "        [    0.0336,     0.0239,     0.0302,     0.0211],\n",
      "        [    0.0153,     0.0065,     0.0184,     0.0160],\n",
      "        [    0.0202,     0.0308,     0.0038,     0.0538],\n",
      "        [    0.0496,     0.0405,     0.0193,     0.0115],\n",
      "        [    0.0332,     0.0329,     0.0409,     0.0290],\n",
      "        [    0.0089,     0.0167,     0.0306,     0.0307],\n",
      "        [    0.0358,     0.0373,     0.0233,     0.0475],\n",
      "        [    0.0420,     0.0533,     0.0399,     0.0366],\n",
      "        [    0.0458,     0.0465,     0.0451,     0.0700],\n",
      "        [    0.0733,     0.0495,     0.0459,     0.0624],\n",
      "        [    0.0593,     0.0770,     0.0489,     0.0632],\n",
      "        [    0.0098,     0.0020,     0.0077,     0.0208],\n",
      "        [    0.0449,     0.0020,     0.0419,     0.0896],\n",
      "        [    0.0616,     0.0412,     0.0014,     0.0592],\n",
      "        [    0.0204,     0.0300,     0.0481,     0.0558],\n",
      "        [    0.0471,     0.0364,     0.0507,     0.0556],\n",
      "        [    0.0788,     0.0434,     0.0370,     0.0334],\n",
      "        [    0.0337,     0.0475,     0.0731,     0.0463],\n",
      "        [    0.0401,     0.0501,     0.0729,     0.0465],\n",
      "        [    0.0608,     0.0752,     0.0440,     0.0197],\n",
      "        [    0.0750,     0.0602,     0.0359,     0.0260],\n",
      "        [    0.0679,     0.0603,     0.0443,     0.0438],\n",
      "        [    0.0512,     0.0725,     0.0636,     0.0420],\n",
      "        [    0.0762,     0.0631,     0.0593,     0.0256]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"28\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"40\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 25\n",
      "Number of shrink: 20\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0508, 0.0166, 0.0303, 0.0126],\n",
      "        [0.0143, 0.0202, 0.0027, 0.0089],\n",
      "        [0.0304, 0.0057, 0.0298, 0.0055],\n",
      "        [0.0090, 0.0258, 0.0196, 0.0004],\n",
      "        [0.0375, 0.0258, 0.0371, 0.0013],\n",
      "        [0.0369, 0.0457, 0.0298, 0.0026],\n",
      "        [0.0510, 0.0347, 0.0090, 0.0067],\n",
      "        [0.0408, 0.0171, 0.0002, 0.0082],\n",
      "        [0.0175, 0.0042, 0.0165, 0.0100],\n",
      "        [0.0011, 0.0157, 0.0263, 0.0131],\n",
      "        [0.0193, 0.0260, 0.0300, 0.0114],\n",
      "        [0.0305, 0.0311, 0.0293, 0.0063],\n",
      "        [0.0364, 0.0320, 0.0233, 0.0019],\n",
      "        [0.0337, 0.0227, 0.0116, 0.0041],\n",
      "        [0.0362, 0.0262, 0.0204, 0.0140],\n",
      "        [0.0345, 0.0338, 0.0105, 0.0164],\n",
      "        [0.0305, 0.0073, 0.0392, 0.0159],\n",
      "        [0.0140, 0.0399, 0.0442, 0.0126],\n",
      "        [0.0401, 0.0375, 0.0305, 0.0155],\n",
      "        [0.0406, 0.0256, 0.0419, 0.0184],\n",
      "        [0.0251, 0.0347, 0.0324, 0.0277],\n",
      "        [0.0387, 0.0214, 0.0043, 0.0009],\n",
      "        [0.0355, 0.0254, 0.0317, 0.0219],\n",
      "        [0.0170, 0.0051, 0.0171, 0.0155],\n",
      "        [0.0221, 0.0323, 0.0053, 0.0530],\n",
      "        [0.0514, 0.0420, 0.0208, 0.0123],\n",
      "        [0.0346, 0.0339, 0.0419, 0.0289],\n",
      "        [0.0071, 0.0152, 0.0291, 0.0299],\n",
      "        [0.0376, 0.0388, 0.0248, 0.0483],\n",
      "        [0.0438, 0.0548, 0.0414, 0.0374],\n",
      "        [0.0477, 0.0480, 0.0466, 0.0708],\n",
      "        [0.0752, 0.0510, 0.0474, 0.0632],\n",
      "        [0.0612, 0.0785, 0.0504, 0.0640],\n",
      "        [0.0081, 0.0006, 0.0091, 0.0192],\n",
      "        [0.0430, 0.0035, 0.0434, 0.0904],\n",
      "        [0.0597, 0.0397, 0.0029, 0.0600],\n",
      "        [0.0185, 0.0285, 0.0466, 0.0550],\n",
      "        [0.0452, 0.0349, 0.0492, 0.0548],\n",
      "        [0.0770, 0.0419, 0.0355, 0.0326],\n",
      "        [0.0318, 0.0460, 0.0716, 0.0455],\n",
      "        [0.0383, 0.0486, 0.0714, 0.0457],\n",
      "        [0.0589, 0.0737, 0.0425, 0.0189],\n",
      "        [0.0730, 0.0584, 0.0341, 0.0243],\n",
      "        [0.0660, 0.0587, 0.0427, 0.0427],\n",
      "        [0.0493, 0.0710, 0.0621, 0.0412],\n",
      "        [0.0744, 0.0616, 0.0578, 0.0248]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 10.991152048110962\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 47\n",
      "X 資料 torch.Size([60, 18])\n",
      "Y 資料 torch.Size([60, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.003388230223208666, 4)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引4，y= tensor([0.4752, 0.4728, 0.4737, 0.4870])\n",
      "目前模型的Data torch.Size([47, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5640, 0.5682, 0.5665, 0.5896],\n",
      "        [0.5704, 0.5766, 0.5743, 0.6080],\n",
      "        [0.5664, 0.5713, 0.5694, 0.5964],\n",
      "        [0.5680, 0.5734, 0.5713, 0.6010],\n",
      "        [0.5617, 0.5651, 0.5636, 0.5827],\n",
      "        [0.5539, 0.5549, 0.5542, 0.5605],\n",
      "        [0.5496, 0.5492, 0.5489, 0.5480],\n",
      "        [0.5432, 0.5407, 0.5410, 0.5293],\n",
      "        [0.5404, 0.5371, 0.5376, 0.5212],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5404, 0.5372, 0.5377, 0.5215],\n",
      "        [0.5417, 0.5389, 0.5393, 0.5252],\n",
      "        [0.5441, 0.5420, 0.5422, 0.5321],\n",
      "        [0.5438, 0.5416, 0.5418, 0.5311],\n",
      "        [0.5551, 0.5564, 0.5555, 0.5637],\n",
      "        [0.5646, 0.5690, 0.5672, 0.5913],\n",
      "        [0.5657, 0.5704, 0.5685, 0.5944],\n",
      "        [0.5638, 0.5678, 0.5661, 0.5888],\n",
      "        [0.5676, 0.5729, 0.5708, 0.5999],\n",
      "        [0.5698, 0.5758, 0.5735, 0.6063],\n",
      "        [0.5450, 0.5432, 0.5433, 0.5346],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5413, 0.5383, 0.5388, 0.5239],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5503, 0.5501, 0.5498, 0.5499],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5659, 0.5706, 0.5687, 0.5949],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5467, 0.5454, 0.5453, 0.5394],\n",
      "        [0.5413, 0.5383, 0.5388, 0.5240],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208],\n",
      "        [0.5402, 0.5369, 0.5375, 0.5208]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0508, 0.0166, 0.0303, 0.0126],\n",
      "        [0.0143, 0.0202, 0.0027, 0.0089],\n",
      "        [0.0304, 0.0057, 0.0298, 0.0055],\n",
      "        [0.0090, 0.0258, 0.0196, 0.0004],\n",
      "        [0.0375, 0.0258, 0.0371, 0.0013],\n",
      "        [0.0369, 0.0457, 0.0298, 0.0026],\n",
      "        [0.0510, 0.0347, 0.0090, 0.0067],\n",
      "        [0.0408, 0.0171, 0.0002, 0.0082],\n",
      "        [0.0175, 0.0042, 0.0165, 0.0100],\n",
      "        [0.0011, 0.0157, 0.0263, 0.0131],\n",
      "        [0.0193, 0.0260, 0.0300, 0.0114],\n",
      "        [0.0305, 0.0311, 0.0293, 0.0063],\n",
      "        [0.0364, 0.0320, 0.0233, 0.0019],\n",
      "        [0.0337, 0.0227, 0.0116, 0.0041],\n",
      "        [0.0362, 0.0262, 0.0204, 0.0140],\n",
      "        [0.0345, 0.0338, 0.0105, 0.0164],\n",
      "        [0.0305, 0.0073, 0.0392, 0.0159],\n",
      "        [0.0140, 0.0399, 0.0442, 0.0126],\n",
      "        [0.0401, 0.0375, 0.0305, 0.0155],\n",
      "        [0.0406, 0.0256, 0.0419, 0.0184],\n",
      "        [0.0251, 0.0347, 0.0324, 0.0277],\n",
      "        [0.0387, 0.0214, 0.0043, 0.0009],\n",
      "        [0.0355, 0.0254, 0.0317, 0.0219],\n",
      "        [0.0170, 0.0051, 0.0171, 0.0155],\n",
      "        [0.0221, 0.0323, 0.0053, 0.0530],\n",
      "        [0.0514, 0.0420, 0.0208, 0.0123],\n",
      "        [0.0346, 0.0339, 0.0419, 0.0289],\n",
      "        [0.0071, 0.0152, 0.0291, 0.0299],\n",
      "        [0.0376, 0.0388, 0.0248, 0.0483],\n",
      "        [0.0438, 0.0548, 0.0414, 0.0374],\n",
      "        [0.0477, 0.0480, 0.0466, 0.0708],\n",
      "        [0.0752, 0.0510, 0.0474, 0.0632],\n",
      "        [0.0612, 0.0785, 0.0504, 0.0640],\n",
      "        [0.0081, 0.0006, 0.0091, 0.0192],\n",
      "        [0.0430, 0.0035, 0.0434, 0.0904],\n",
      "        [0.0597, 0.0397, 0.0029, 0.0600],\n",
      "        [0.0185, 0.0285, 0.0466, 0.0550],\n",
      "        [0.0452, 0.0349, 0.0492, 0.0548],\n",
      "        [0.0770, 0.0419, 0.0355, 0.0326],\n",
      "        [0.0318, 0.0460, 0.0716, 0.0455],\n",
      "        [0.0383, 0.0486, 0.0714, 0.0457],\n",
      "        [0.0589, 0.0737, 0.0425, 0.0189],\n",
      "        [0.0730, 0.0584, 0.0341, 0.0243],\n",
      "        [0.0660, 0.0587, 0.0427, 0.0427],\n",
      "        [0.0493, 0.0710, 0.0621, 0.0412],\n",
      "        [0.0744, 0.0616, 0.0578, 0.0248],\n",
      "        [0.0651, 0.0641, 0.0638, 0.0338]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 11\n",
      "Number of shrink: 13\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0518, 0.0176, 0.0311, 0.0127],\n",
      "        [0.0152, 0.0211, 0.0035, 0.0090],\n",
      "        [0.0313, 0.0067, 0.0306, 0.0057],\n",
      "        [0.0099, 0.0267, 0.0204, 0.0006],\n",
      "        [0.0384, 0.0268, 0.0379, 0.0010],\n",
      "        [0.0379, 0.0467, 0.0307, 0.0028],\n",
      "        [0.0521, 0.0358, 0.0099, 0.0068],\n",
      "        [0.0419, 0.0182, 0.0012, 0.0083],\n",
      "        [0.0186, 0.0053, 0.0155, 0.0103],\n",
      "        [0.0026, 0.0141, 0.0248, 0.0120],\n",
      "        [0.0182, 0.0249, 0.0290, 0.0116],\n",
      "        [0.0295, 0.0300, 0.0283, 0.0065],\n",
      "        [0.0353, 0.0309, 0.0224, 0.0021],\n",
      "        [0.0327, 0.0216, 0.0107, 0.0040],\n",
      "        [0.0352, 0.0252, 0.0195, 0.0139],\n",
      "        [0.0335, 0.0328, 0.0114, 0.0163],\n",
      "        [0.0296, 0.0083, 0.0401, 0.0159],\n",
      "        [0.0149, 0.0409, 0.0451, 0.0125],\n",
      "        [0.0410, 0.0385, 0.0314, 0.0154],\n",
      "        [0.0415, 0.0265, 0.0427, 0.0185],\n",
      "        [0.0261, 0.0359, 0.0335, 0.0277],\n",
      "        [0.0402, 0.0231, 0.0028, 0.0020],\n",
      "        [0.0370, 0.0271, 0.0332, 0.0230],\n",
      "        [0.0181, 0.0040, 0.0160, 0.0156],\n",
      "        [0.0236, 0.0340, 0.0068, 0.0519],\n",
      "        [0.0529, 0.0437, 0.0223, 0.0134],\n",
      "        [0.0356, 0.0350, 0.0428, 0.0288],\n",
      "        [0.0056, 0.0135, 0.0276, 0.0288],\n",
      "        [0.0392, 0.0405, 0.0263, 0.0494],\n",
      "        [0.0453, 0.0564, 0.0429, 0.0385],\n",
      "        [0.0492, 0.0497, 0.0481, 0.0719],\n",
      "        [0.0767, 0.0527, 0.0489, 0.0643],\n",
      "        [0.0627, 0.0802, 0.0519, 0.0651],\n",
      "        [0.0071, 0.0004, 0.0100, 0.0193],\n",
      "        [0.0415, 0.0051, 0.0449, 0.0915],\n",
      "        [0.0582, 0.0380, 0.0044, 0.0611],\n",
      "        [0.0170, 0.0269, 0.0451, 0.0540],\n",
      "        [0.0437, 0.0333, 0.0477, 0.0537],\n",
      "        [0.0755, 0.0402, 0.0340, 0.0315],\n",
      "        [0.0307, 0.0448, 0.0706, 0.0455],\n",
      "        [0.0368, 0.0470, 0.0699, 0.0446],\n",
      "        [0.0574, 0.0720, 0.0410, 0.0178],\n",
      "        [0.0718, 0.0571, 0.0330, 0.0240],\n",
      "        [0.0648, 0.0575, 0.0417, 0.0427],\n",
      "        [0.0478, 0.0694, 0.0606, 0.0401],\n",
      "        [0.0729, 0.0599, 0.0563, 0.0237],\n",
      "        [0.0635, 0.0624, 0.0623, 0.0327]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 11.145339965820312\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 48\n",
      "X 資料 torch.Size([59, 18])\n",
      "Y 資料 torch.Size([59, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.00330599257722497, 2)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引2，y= tensor([0.4882, 0.4661, 0.4752, 0.4728])\n",
      "目前模型的Data torch.Size([48, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5631, 0.5672, 0.5656, 0.5897],\n",
      "        [0.5695, 0.5757, 0.5735, 0.6082],\n",
      "        [0.5655, 0.5704, 0.5685, 0.5966],\n",
      "        [0.5671, 0.5725, 0.5705, 0.6013],\n",
      "        [0.5607, 0.5641, 0.5628, 0.5830],\n",
      "        [0.5530, 0.5539, 0.5533, 0.5607],\n",
      "        [0.5486, 0.5482, 0.5480, 0.5481],\n",
      "        [0.5421, 0.5397, 0.5401, 0.5295],\n",
      "        [0.5393, 0.5360, 0.5367, 0.5215],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5394, 0.5361, 0.5368, 0.5217],\n",
      "        [0.5407, 0.5378, 0.5383, 0.5254],\n",
      "        [0.5431, 0.5409, 0.5413, 0.5322],\n",
      "        [0.5427, 0.5405, 0.5408, 0.5312],\n",
      "        [0.5541, 0.5553, 0.5546, 0.5638],\n",
      "        [0.5637, 0.5680, 0.5663, 0.5914],\n",
      "        [0.5648, 0.5694, 0.5677, 0.5945],\n",
      "        [0.5628, 0.5668, 0.5653, 0.5889],\n",
      "        [0.5667, 0.5719, 0.5700, 0.6000],\n",
      "        [0.5689, 0.5748, 0.5727, 0.6064],\n",
      "        [0.5439, 0.5420, 0.5423, 0.5346],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5402, 0.5371, 0.5377, 0.5240],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5493, 0.5491, 0.5488, 0.5501],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5649, 0.5696, 0.5679, 0.5950],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5387, 0.5353, 0.5360, 0.5198],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5391, 0.5357, 0.5364, 0.5208],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5455, 0.5441, 0.5442, 0.5391],\n",
      "        [0.5402, 0.5371, 0.5377, 0.5239],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197],\n",
      "        [0.5387, 0.5352, 0.5360, 0.5197]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0518, 0.0176, 0.0311, 0.0127],\n",
      "        [0.0152, 0.0211, 0.0035, 0.0090],\n",
      "        [0.0313, 0.0067, 0.0306, 0.0057],\n",
      "        [0.0099, 0.0267, 0.0204, 0.0006],\n",
      "        [0.0384, 0.0268, 0.0379, 0.0010],\n",
      "        [0.0379, 0.0467, 0.0307, 0.0028],\n",
      "        [0.0521, 0.0358, 0.0099, 0.0068],\n",
      "        [0.0419, 0.0182, 0.0012, 0.0083],\n",
      "        [0.0186, 0.0053, 0.0155, 0.0103],\n",
      "        [0.0026, 0.0141, 0.0248, 0.0120],\n",
      "        [0.0182, 0.0249, 0.0290, 0.0116],\n",
      "        [0.0295, 0.0300, 0.0283, 0.0065],\n",
      "        [0.0353, 0.0309, 0.0224, 0.0021],\n",
      "        [0.0327, 0.0216, 0.0107, 0.0040],\n",
      "        [0.0352, 0.0252, 0.0195, 0.0139],\n",
      "        [0.0335, 0.0328, 0.0114, 0.0163],\n",
      "        [0.0296, 0.0083, 0.0401, 0.0159],\n",
      "        [0.0149, 0.0409, 0.0451, 0.0125],\n",
      "        [0.0410, 0.0385, 0.0314, 0.0154],\n",
      "        [0.0415, 0.0265, 0.0427, 0.0185],\n",
      "        [0.0261, 0.0359, 0.0335, 0.0277],\n",
      "        [0.0402, 0.0231, 0.0028, 0.0020],\n",
      "        [0.0370, 0.0271, 0.0332, 0.0230],\n",
      "        [0.0181, 0.0040, 0.0160, 0.0156],\n",
      "        [0.0236, 0.0340, 0.0068, 0.0519],\n",
      "        [0.0529, 0.0437, 0.0223, 0.0134],\n",
      "        [0.0356, 0.0350, 0.0428, 0.0288],\n",
      "        [0.0056, 0.0135, 0.0276, 0.0288],\n",
      "        [0.0392, 0.0405, 0.0263, 0.0494],\n",
      "        [0.0453, 0.0564, 0.0429, 0.0385],\n",
      "        [0.0492, 0.0497, 0.0481, 0.0719],\n",
      "        [0.0767, 0.0527, 0.0489, 0.0643],\n",
      "        [0.0627, 0.0802, 0.0519, 0.0651],\n",
      "        [0.0071, 0.0004, 0.0100, 0.0193],\n",
      "        [0.0415, 0.0051, 0.0449, 0.0915],\n",
      "        [0.0582, 0.0380, 0.0044, 0.0611],\n",
      "        [0.0170, 0.0269, 0.0451, 0.0540],\n",
      "        [0.0437, 0.0333, 0.0477, 0.0537],\n",
      "        [0.0755, 0.0402, 0.0340, 0.0315],\n",
      "        [0.0307, 0.0448, 0.0706, 0.0455],\n",
      "        [0.0368, 0.0470, 0.0699, 0.0446],\n",
      "        [0.0574, 0.0720, 0.0410, 0.0178],\n",
      "        [0.0718, 0.0571, 0.0330, 0.0240],\n",
      "        [0.0648, 0.0575, 0.0417, 0.0427],\n",
      "        [0.0478, 0.0694, 0.0606, 0.0401],\n",
      "        [0.0729, 0.0599, 0.0563, 0.0237],\n",
      "        [0.0635, 0.0624, 0.0623, 0.0327],\n",
      "        [0.0505, 0.0691, 0.0608, 0.0469]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"7\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"9\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"13\"回合是成功執行regularizing\n",
      "第\"15\"回合是成功執行regularizing\n",
      "第\"17\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"20\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"23\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"26\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"30\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"33\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"38\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"43\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"47\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"53\"回合是成功執行regularizing\n",
      "第\"54\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"58\"回合是成功執行regularizing\n",
      "第\"59\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"64\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"67\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"76\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"79\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"89\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"96\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0490,     0.0142,     0.0277,     0.0170],\n",
      "        [    0.0116,     0.0168,     0.0008,     0.0135],\n",
      "        [    0.0281,     0.0029,     0.0268,     0.0102],\n",
      "        [    0.0065,     0.0226,     0.0162,     0.0053],\n",
      "        [    0.0358,     0.0235,     0.0346,     0.0037],\n",
      "        [    0.0360,     0.0442,     0.0280,     0.0079],\n",
      "        [    0.0508,     0.0340,     0.0080,     0.0114],\n",
      "        [    0.0413,     0.0172,     0.0001,     0.0130],\n",
      "        [    0.0180,     0.0040,     0.0168,     0.0161],\n",
      "        [    0.0030,     0.0140,     0.0248,     0.0153],\n",
      "        [    0.0188,     0.0260,     0.0302,     0.0172],\n",
      "        [    0.0300,     0.0311,     0.0295,     0.0116],\n",
      "        [    0.0359,     0.0320,     0.0236,     0.0067],\n",
      "        [    0.0331,     0.0224,     0.0116,     0.0003],\n",
      "        [    0.0366,     0.0270,     0.0214,     0.0105],\n",
      "        [    0.0359,     0.0357,     0.0084,     0.0131],\n",
      "        [    0.0321,     0.0054,     0.0370,     0.0128],\n",
      "        [    0.0126,     0.0381,     0.0422,     0.0093],\n",
      "        [    0.0380,     0.0349,     0.0277,     0.0116],\n",
      "        [    0.0379,     0.0223,     0.0385,     0.0230],\n",
      "        [    0.0265,     0.0360,     0.0334,     0.0257],\n",
      "        [    0.0470,     0.0314,     0.0048,     0.0153],\n",
      "        [    0.0439,     0.0354,     0.0409,     0.0363],\n",
      "        [    0.0183,     0.0042,     0.0164,     0.0191],\n",
      "        [    0.0304,     0.0423,     0.0145,     0.0386],\n",
      "        [    0.0598,     0.0520,     0.0300,     0.0267],\n",
      "        [    0.0338,     0.0325,     0.0403,     0.0229],\n",
      "        [    0.0013,     0.0051,     0.0199,     0.0155],\n",
      "        [    0.0460,     0.0489,     0.0340,     0.0627],\n",
      "        [    0.0475,     0.0587,     0.0449,     0.0397],\n",
      "        [    0.0520,     0.0528,     0.0509,     0.0747],\n",
      "        [    0.0835,     0.0610,     0.0566,     0.0776],\n",
      "        [    0.0629,     0.0800,     0.0517,     0.0614],\n",
      "        [    0.0083,     0.0009,     0.0085,     0.0190],\n",
      "        [    0.0347,     0.0135,     0.0525,     0.1048],\n",
      "        [    0.0514,     0.0297,     0.0120,     0.0744],\n",
      "        [    0.0162,     0.0262,     0.0446,     0.0561],\n",
      "        [    0.0369,     0.0249,     0.0401,     0.0404],\n",
      "        [    0.0686,     0.0319,     0.0263,     0.0182],\n",
      "        [    0.0295,     0.0437,     0.0697,     0.0468],\n",
      "        [    0.0299,     0.0386,     0.0622,     0.0313],\n",
      "        [    0.0506,     0.0636,     0.0333,     0.0045],\n",
      "        [    0.0699,     0.0549,     0.0312,     0.0215],\n",
      "        [    0.0632,     0.0558,     0.0402,     0.0423],\n",
      "        [    0.0409,     0.0610,     0.0530,     0.0268],\n",
      "        [    0.0660,     0.0515,     0.0487,     0.0104],\n",
      "        [    0.0567,     0.0540,     0.0546,     0.0194],\n",
      "        [    0.0436,     0.0608,     0.0531,     0.0336]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 11.52348279953003\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 49\n",
      "X 資料 torch.Size([58, 18])\n",
      "Y 資料 torch.Size([58, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.002787499688565731, 2)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引2，y= tensor([0.4661, 0.4752, 0.4728, 0.4737])\n",
      "目前模型的Data torch.Size([49, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5659, 0.5706, 0.5691, 0.5940],\n",
      "        [0.5731, 0.5799, 0.5778, 0.6127],\n",
      "        [0.5686, 0.5741, 0.5723, 0.6011],\n",
      "        [0.5705, 0.5766, 0.5746, 0.6060],\n",
      "        [0.5634, 0.5674, 0.5661, 0.5876],\n",
      "        [0.5549, 0.5565, 0.5559, 0.5658],\n",
      "        [0.5498, 0.5500, 0.5498, 0.5527],\n",
      "        [0.5426, 0.5407, 0.5412, 0.5342],\n",
      "        [0.5399, 0.5372, 0.5380, 0.5273],\n",
      "        [0.5383, 0.5351, 0.5360, 0.5230],\n",
      "        [0.5399, 0.5372, 0.5380, 0.5272],\n",
      "        [0.5412, 0.5388, 0.5395, 0.5305],\n",
      "        [0.5437, 0.5420, 0.5425, 0.5368],\n",
      "        [0.5431, 0.5413, 0.5418, 0.5354],\n",
      "        [0.5555, 0.5572, 0.5566, 0.5672],\n",
      "        [0.5661, 0.5709, 0.5693, 0.5946],\n",
      "        [0.5672, 0.5723, 0.5707, 0.5976],\n",
      "        [0.5651, 0.5696, 0.5682, 0.5921],\n",
      "        [0.5697, 0.5755, 0.5736, 0.6038],\n",
      "        [0.5724, 0.5790, 0.5769, 0.6109],\n",
      "        [0.5435, 0.5419, 0.5423, 0.5365],\n",
      "        [0.5319, 0.5268, 0.5283, 0.5064],\n",
      "        [0.5319, 0.5268, 0.5283, 0.5064],\n",
      "        [0.5400, 0.5373, 0.5381, 0.5274],\n",
      "        [0.5319, 0.5268, 0.5283, 0.5064],\n",
      "        [0.5319, 0.5268, 0.5283, 0.5064],\n",
      "        [0.5511, 0.5516, 0.5513, 0.5559],\n",
      "        [0.5319, 0.5268, 0.5283, 0.5064],\n",
      "        [0.5319, 0.5268, 0.5283, 0.5064],\n",
      "        [0.5366, 0.5329, 0.5340, 0.5186],\n",
      "        [0.5359, 0.5321, 0.5332, 0.5169],\n",
      "        [0.5319, 0.5268, 0.5283, 0.5064],\n",
      "        [0.5385, 0.5354, 0.5362, 0.5235],\n",
      "        [0.5661, 0.5709, 0.5694, 0.5947],\n",
      "        [0.5319, 0.5268, 0.5283, 0.5064],\n",
      "        [0.5319, 0.5268, 0.5283, 0.5064],\n",
      "        [0.5379, 0.5346, 0.5355, 0.5220],\n",
      "        [0.5319, 0.5268, 0.5283, 0.5064],\n",
      "        [0.5319, 0.5268, 0.5283, 0.5064],\n",
      "        [0.5379, 0.5347, 0.5356, 0.5221],\n",
      "        [0.5319, 0.5268, 0.5283, 0.5064],\n",
      "        [0.5319, 0.5268, 0.5283, 0.5064],\n",
      "        [0.5436, 0.5419, 0.5424, 0.5367],\n",
      "        [0.5385, 0.5354, 0.5363, 0.5236],\n",
      "        [0.5319, 0.5268, 0.5283, 0.5064],\n",
      "        [0.5319, 0.5268, 0.5283, 0.5064],\n",
      "        [0.5319, 0.5268, 0.5283, 0.5064],\n",
      "        [0.5319, 0.5268, 0.5283, 0.5064],\n",
      "        [0.5319, 0.5268, 0.5283, 0.5064]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0490,     0.0142,     0.0277,     0.0170],\n",
      "        [    0.0116,     0.0168,     0.0008,     0.0135],\n",
      "        [    0.0281,     0.0029,     0.0268,     0.0102],\n",
      "        [    0.0065,     0.0226,     0.0162,     0.0053],\n",
      "        [    0.0358,     0.0235,     0.0346,     0.0037],\n",
      "        [    0.0360,     0.0442,     0.0280,     0.0079],\n",
      "        [    0.0508,     0.0340,     0.0080,     0.0114],\n",
      "        [    0.0413,     0.0172,     0.0001,     0.0130],\n",
      "        [    0.0180,     0.0040,     0.0168,     0.0161],\n",
      "        [    0.0030,     0.0140,     0.0248,     0.0153],\n",
      "        [    0.0188,     0.0260,     0.0302,     0.0172],\n",
      "        [    0.0300,     0.0311,     0.0295,     0.0116],\n",
      "        [    0.0359,     0.0320,     0.0236,     0.0067],\n",
      "        [    0.0331,     0.0224,     0.0116,     0.0003],\n",
      "        [    0.0366,     0.0270,     0.0214,     0.0105],\n",
      "        [    0.0359,     0.0357,     0.0084,     0.0131],\n",
      "        [    0.0321,     0.0054,     0.0370,     0.0128],\n",
      "        [    0.0126,     0.0381,     0.0422,     0.0093],\n",
      "        [    0.0380,     0.0349,     0.0277,     0.0116],\n",
      "        [    0.0379,     0.0223,     0.0385,     0.0230],\n",
      "        [    0.0265,     0.0360,     0.0334,     0.0257],\n",
      "        [    0.0470,     0.0314,     0.0048,     0.0153],\n",
      "        [    0.0439,     0.0354,     0.0409,     0.0363],\n",
      "        [    0.0183,     0.0042,     0.0164,     0.0191],\n",
      "        [    0.0304,     0.0423,     0.0145,     0.0386],\n",
      "        [    0.0598,     0.0520,     0.0300,     0.0267],\n",
      "        [    0.0338,     0.0325,     0.0403,     0.0229],\n",
      "        [    0.0013,     0.0051,     0.0199,     0.0155],\n",
      "        [    0.0460,     0.0489,     0.0340,     0.0627],\n",
      "        [    0.0475,     0.0587,     0.0449,     0.0397],\n",
      "        [    0.0520,     0.0528,     0.0509,     0.0747],\n",
      "        [    0.0835,     0.0610,     0.0566,     0.0776],\n",
      "        [    0.0629,     0.0800,     0.0517,     0.0614],\n",
      "        [    0.0083,     0.0009,     0.0085,     0.0190],\n",
      "        [    0.0347,     0.0135,     0.0525,     0.1048],\n",
      "        [    0.0514,     0.0297,     0.0120,     0.0744],\n",
      "        [    0.0162,     0.0262,     0.0446,     0.0561],\n",
      "        [    0.0369,     0.0249,     0.0401,     0.0404],\n",
      "        [    0.0686,     0.0319,     0.0263,     0.0182],\n",
      "        [    0.0295,     0.0437,     0.0697,     0.0468],\n",
      "        [    0.0299,     0.0386,     0.0622,     0.0313],\n",
      "        [    0.0506,     0.0636,     0.0333,     0.0045],\n",
      "        [    0.0699,     0.0549,     0.0312,     0.0215],\n",
      "        [    0.0632,     0.0558,     0.0402,     0.0423],\n",
      "        [    0.0409,     0.0610,     0.0530,     0.0268],\n",
      "        [    0.0660,     0.0515,     0.0487,     0.0104],\n",
      "        [    0.0567,     0.0540,     0.0546,     0.0194],\n",
      "        [    0.0436,     0.0608,     0.0531,     0.0336],\n",
      "        [    0.0658,     0.0517,     0.0555,     0.0328]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"1\"回合是成功執行regularizing\n",
      "第\"2\"回合是成功執行regularizing\n",
      "第\"3\"回合是成功執行regularizing\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"6\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "第\"10\"回合是成功執行regularizing\n",
      "第\"11\"回合是成功執行regularizing\n",
      "第\"12\"回合是成功執行regularizing\n",
      "第\"14\"回合是成功執行regularizing\n",
      "第\"16\"回合是成功執行regularizing\n",
      "第\"18\"回合是成功執行regularizing\n",
      "第\"19\"回合是成功執行regularizing\n",
      "第\"21\"回合是成功執行regularizing\n",
      "第\"22\"回合是成功執行regularizing\n",
      "第\"24\"回合是成功執行regularizing\n",
      "第\"25\"回合是成功執行regularizing\n",
      "第\"27\"回合是成功執行regularizing\n",
      "第\"29\"回合是成功執行regularizing\n",
      "第\"31\"回合是成功執行regularizing\n",
      "第\"32\"回合是成功執行regularizing\n",
      "第\"34\"回合是成功執行regularizing\n",
      "第\"36\"回合是成功執行regularizing\n",
      "第\"37\"回合是成功執行regularizing\n",
      "第\"39\"回合是成功執行regularizing\n",
      "第\"41\"回合是成功執行regularizing\n",
      "第\"42\"回合是成功執行regularizing\n",
      "第\"44\"回合是成功執行regularizing\n",
      "第\"45\"回合是成功執行regularizing\n",
      "第\"48\"回合是成功執行regularizing\n",
      "第\"49\"回合是成功執行regularizing\n",
      "第\"51\"回合是成功執行regularizing\n",
      "第\"52\"回合是成功執行regularizing\n",
      "第\"55\"回合是成功執行regularizing\n",
      "第\"56\"回合是成功執行regularizing\n",
      "第\"57\"回合是成功執行regularizing\n",
      "第\"60\"回合是成功執行regularizing\n",
      "第\"61\"回合是成功執行regularizing\n",
      "第\"62\"回合是成功執行regularizing\n",
      "第\"63\"回合是成功執行regularizing\n",
      "第\"65\"回合是成功執行regularizing\n",
      "第\"66\"回合是成功執行regularizing\n",
      "第\"68\"回合是成功執行regularizing\n",
      "第\"69\"回合是成功執行regularizing\n",
      "第\"71\"回合是成功執行regularizing\n",
      "第\"72\"回合是成功執行regularizing\n",
      "第\"74\"回合是成功執行regularizing\n",
      "第\"75\"回合是成功執行regularizing\n",
      "第\"77\"回合是成功執行regularizing\n",
      "第\"78\"回合是成功執行regularizing\n",
      "第\"80\"回合是成功執行regularizing\n",
      "第\"81\"回合是成功執行regularizing\n",
      "第\"82\"回合是成功執行regularizing\n",
      "第\"84\"回合是成功執行regularizing\n",
      "第\"85\"回合是成功執行regularizing\n",
      "第\"87\"回合是成功執行regularizing\n",
      "第\"88\"回合是成功執行regularizing\n",
      "第\"90\"回合是成功執行regularizing\n",
      "第\"91\"回合是成功執行regularizing\n",
      "第\"93\"回合是成功執行regularizing\n",
      "第\"94\"回合是成功執行regularizing\n",
      "第\"95\"回合是成功執行regularizing\n",
      "第\"98\"回合是成功執行regularizing\n",
      "第\"99\"回合是成功執行regularizing\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 2\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0440, 0.0080, 0.0220, 0.0223],\n",
      "        [0.0054, 0.0093, 0.0077, 0.0186],\n",
      "        [0.0223, 0.0042, 0.0203, 0.0161],\n",
      "        [0.0002, 0.0149, 0.0091, 0.0116],\n",
      "        [0.0305, 0.0168, 0.0284, 0.0107],\n",
      "        [0.0318, 0.0387, 0.0231, 0.0159],\n",
      "        [0.0479, 0.0298, 0.0044, 0.0189],\n",
      "        [0.0395, 0.0141, 0.0025, 0.0212],\n",
      "        [0.0158, 0.0006, 0.0198, 0.0259],\n",
      "        [0.0013, 0.0169, 0.0273, 0.0247],\n",
      "        [0.0212, 0.0299, 0.0335, 0.0276],\n",
      "        [0.0323, 0.0348, 0.0326, 0.0213],\n",
      "        [0.0382, 0.0356, 0.0266, 0.0153],\n",
      "        [0.0353, 0.0259, 0.0145, 0.0088],\n",
      "        [0.0405, 0.0323, 0.0261, 0.0031],\n",
      "        [0.0416, 0.0428, 0.0018, 0.0063],\n",
      "        [0.0382, 0.0021, 0.0301, 0.0057],\n",
      "        [0.0069, 0.0310, 0.0357, 0.0021],\n",
      "        [0.0307, 0.0259, 0.0194, 0.0027],\n",
      "        [0.0295, 0.0120, 0.0288, 0.0332],\n",
      "        [0.0252, 0.0337, 0.0315, 0.0193],\n",
      "        [0.0514, 0.0358, 0.0093, 0.0162],\n",
      "        [0.0531, 0.0459, 0.0511, 0.0478],\n",
      "        [0.0156, 0.0083, 0.0199, 0.0299],\n",
      "        [0.0396, 0.0528, 0.0247, 0.0271],\n",
      "        [0.0627, 0.0546, 0.0328, 0.0245],\n",
      "        [0.0278, 0.0246, 0.0332, 0.0095],\n",
      "        [0.0042, 0.0025, 0.0171, 0.0177],\n",
      "        [0.0552, 0.0594, 0.0442, 0.0742],\n",
      "        [0.0438, 0.0533, 0.0402, 0.0253],\n",
      "        [0.0473, 0.0460, 0.0448, 0.0578],\n",
      "        [0.0820, 0.0580, 0.0541, 0.0658],\n",
      "        [0.0590, 0.0743, 0.0466, 0.0472],\n",
      "        [0.0123, 0.0059, 0.0039, 0.0221],\n",
      "        [0.0255, 0.0240, 0.0628, 0.1163],\n",
      "        [0.0422, 0.0192, 0.0223, 0.0859],\n",
      "        [0.0176, 0.0289, 0.0468, 0.0653],\n",
      "        [0.0277, 0.0144, 0.0298, 0.0289],\n",
      "        [0.0594, 0.0214, 0.0161, 0.0067],\n",
      "        [0.0304, 0.0457, 0.0712, 0.0546],\n",
      "        [0.0207, 0.0281, 0.0520, 0.0198],\n",
      "        [0.0415, 0.0533, 0.0232, 0.0068],\n",
      "        [0.0696, 0.0552, 0.0311, 0.0245],\n",
      "        [0.0625, 0.0558, 0.0399, 0.0466],\n",
      "        [0.0317, 0.0505, 0.0427, 0.0153],\n",
      "        [0.0598, 0.0448, 0.0420, 0.0054],\n",
      "        [0.0476, 0.0437, 0.0445, 0.0081],\n",
      "        [0.0344, 0.0503, 0.0429, 0.0221],\n",
      "        [0.0566, 0.0412, 0.0453, 0.0213]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 11.935747146606445\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 50\n",
      "X 資料 torch.Size([57, 18])\n",
      "Y 資料 torch.Size([57, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0024085920304059982, 17)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引17，y= tensor([0.5692, 0.5428, 0.4679, 0.4297])\n",
      "目前模型的Data torch.Size([50, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5708, 0.5767, 0.5747, 0.5993],\n",
      "        [0.5794, 0.5874, 0.5847, 0.6177],\n",
      "        [0.5744, 0.5812, 0.5789, 0.6070],\n",
      "        [0.5768, 0.5842, 0.5818, 0.6123],\n",
      "        [0.5687, 0.5741, 0.5722, 0.5947],\n",
      "        [0.5590, 0.5620, 0.5609, 0.5737],\n",
      "        [0.5528, 0.5541, 0.5535, 0.5602],\n",
      "        [0.5445, 0.5438, 0.5438, 0.5423],\n",
      "        [0.5421, 0.5407, 0.5409, 0.5371],\n",
      "        [0.5400, 0.5381, 0.5385, 0.5325],\n",
      "        [0.5424, 0.5411, 0.5413, 0.5377],\n",
      "        [0.5435, 0.5425, 0.5426, 0.5401],\n",
      "        [0.5460, 0.5456, 0.5455, 0.5455],\n",
      "        [0.5453, 0.5447, 0.5447, 0.5440],\n",
      "        [0.5594, 0.5624, 0.5613, 0.5746],\n",
      "        [0.5718, 0.5780, 0.5759, 0.6014],\n",
      "        [0.5733, 0.5799, 0.5776, 0.6047],\n",
      "        [0.5708, 0.5767, 0.5747, 0.5993],\n",
      "        [0.5770, 0.5845, 0.5820, 0.6127],\n",
      "        [0.5809, 0.5893, 0.5865, 0.6211],\n",
      "        [0.5449, 0.5442, 0.5442, 0.5430],\n",
      "        [0.5275, 0.5225, 0.5238, 0.5055],\n",
      "        [0.5227, 0.5164, 0.5181, 0.4949],\n",
      "        [0.5427, 0.5415, 0.5416, 0.5383],\n",
      "        [0.5227, 0.5164, 0.5181, 0.4949],\n",
      "        [0.5290, 0.5243, 0.5255, 0.5086],\n",
      "        [0.5570, 0.5595, 0.5585, 0.5694],\n",
      "        [0.5289, 0.5242, 0.5255, 0.5086],\n",
      "        [0.5227, 0.5164, 0.5181, 0.4949],\n",
      "        [0.5402, 0.5384, 0.5387, 0.5330],\n",
      "        [0.5406, 0.5389, 0.5392, 0.5339],\n",
      "        [0.5334, 0.5299, 0.5307, 0.5183],\n",
      "        [0.5424, 0.5411, 0.5413, 0.5377],\n",
      "        [0.5702, 0.5759, 0.5739, 0.5978],\n",
      "        [0.5227, 0.5164, 0.5181, 0.4949],\n",
      "        [0.5227, 0.5164, 0.5181, 0.4949],\n",
      "        [0.5393, 0.5373, 0.5377, 0.5311],\n",
      "        [0.5227, 0.5164, 0.5181, 0.4949],\n",
      "        [0.5227, 0.5164, 0.5181, 0.4949],\n",
      "        [0.5388, 0.5366, 0.5371, 0.5299],\n",
      "        [0.5227, 0.5164, 0.5181, 0.4949],\n",
      "        [0.5227, 0.5165, 0.5182, 0.4952],\n",
      "        [0.5433, 0.5422, 0.5424, 0.5397],\n",
      "        [0.5378, 0.5354, 0.5359, 0.5278],\n",
      "        [0.5227, 0.5164, 0.5181, 0.4949],\n",
      "        [0.5257, 0.5202, 0.5216, 0.5015],\n",
      "        [0.5227, 0.5165, 0.5182, 0.4951],\n",
      "        [0.5227, 0.5164, 0.5181, 0.4949],\n",
      "        [0.5227, 0.5164, 0.5181, 0.4949],\n",
      "        [0.5227, 0.5164, 0.5181, 0.4949]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0440, 0.0080, 0.0220, 0.0223],\n",
      "        [0.0054, 0.0093, 0.0077, 0.0186],\n",
      "        [0.0223, 0.0042, 0.0203, 0.0161],\n",
      "        [0.0002, 0.0149, 0.0091, 0.0116],\n",
      "        [0.0305, 0.0168, 0.0284, 0.0107],\n",
      "        [0.0318, 0.0387, 0.0231, 0.0159],\n",
      "        [0.0479, 0.0298, 0.0044, 0.0189],\n",
      "        [0.0395, 0.0141, 0.0025, 0.0212],\n",
      "        [0.0158, 0.0006, 0.0198, 0.0259],\n",
      "        [0.0013, 0.0169, 0.0273, 0.0247],\n",
      "        [0.0212, 0.0299, 0.0335, 0.0276],\n",
      "        [0.0323, 0.0348, 0.0326, 0.0213],\n",
      "        [0.0382, 0.0356, 0.0266, 0.0153],\n",
      "        [0.0353, 0.0259, 0.0145, 0.0088],\n",
      "        [0.0405, 0.0323, 0.0261, 0.0031],\n",
      "        [0.0416, 0.0428, 0.0018, 0.0063],\n",
      "        [0.0382, 0.0021, 0.0301, 0.0057],\n",
      "        [0.0069, 0.0310, 0.0357, 0.0021],\n",
      "        [0.0307, 0.0259, 0.0194, 0.0027],\n",
      "        [0.0295, 0.0120, 0.0288, 0.0332],\n",
      "        [0.0252, 0.0337, 0.0315, 0.0193],\n",
      "        [0.0514, 0.0358, 0.0093, 0.0162],\n",
      "        [0.0531, 0.0459, 0.0511, 0.0478],\n",
      "        [0.0156, 0.0083, 0.0199, 0.0299],\n",
      "        [0.0396, 0.0528, 0.0247, 0.0271],\n",
      "        [0.0627, 0.0546, 0.0328, 0.0245],\n",
      "        [0.0278, 0.0246, 0.0332, 0.0095],\n",
      "        [0.0042, 0.0025, 0.0171, 0.0177],\n",
      "        [0.0552, 0.0594, 0.0442, 0.0742],\n",
      "        [0.0438, 0.0533, 0.0402, 0.0253],\n",
      "        [0.0473, 0.0460, 0.0448, 0.0578],\n",
      "        [0.0820, 0.0580, 0.0541, 0.0658],\n",
      "        [0.0590, 0.0743, 0.0466, 0.0472],\n",
      "        [0.0123, 0.0059, 0.0039, 0.0221],\n",
      "        [0.0255, 0.0240, 0.0628, 0.1163],\n",
      "        [0.0422, 0.0192, 0.0223, 0.0859],\n",
      "        [0.0176, 0.0289, 0.0468, 0.0653],\n",
      "        [0.0277, 0.0144, 0.0298, 0.0289],\n",
      "        [0.0594, 0.0214, 0.0161, 0.0067],\n",
      "        [0.0304, 0.0457, 0.0712, 0.0546],\n",
      "        [0.0207, 0.0281, 0.0520, 0.0198],\n",
      "        [0.0415, 0.0533, 0.0232, 0.0068],\n",
      "        [0.0696, 0.0552, 0.0311, 0.0245],\n",
      "        [0.0625, 0.0558, 0.0399, 0.0466],\n",
      "        [0.0317, 0.0505, 0.0427, 0.0153],\n",
      "        [0.0598, 0.0448, 0.0420, 0.0054],\n",
      "        [0.0476, 0.0437, 0.0445, 0.0081],\n",
      "        [0.0344, 0.0503, 0.0429, 0.0221],\n",
      "        [0.0566, 0.0412, 0.0453, 0.0213],\n",
      "        [0.0465, 0.0264, 0.0502, 0.0652]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "第\"4\"回合是成功執行regularizing\n",
      "第\"5\"回合是成功執行regularizing\n",
      "第\"8\"回合是成功執行regularizing\n",
      "Regularizing結束\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 5\n",
      "因為沒有顧好預測誤差\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.05526089668274\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 51\n",
      "X 資料 torch.Size([56, 18])\n",
      "Y 資料 torch.Size([56, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.003184720641002059, 2)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引2，y= tensor([0.4728, 0.4737, 0.4870, 0.5112])\n",
      "目前模型的Data torch.Size([51, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5707, 0.5757, 0.5729, 0.5965],\n",
      "        [0.5793, 0.5864, 0.5830, 0.6149],\n",
      "        [0.5743, 0.5802, 0.5772, 0.6042],\n",
      "        [0.5768, 0.5833, 0.5800, 0.6095],\n",
      "        [0.5686, 0.5731, 0.5705, 0.5920],\n",
      "        [0.5589, 0.5610, 0.5591, 0.5711],\n",
      "        [0.5527, 0.5531, 0.5518, 0.5576],\n",
      "        [0.5444, 0.5428, 0.5420, 0.5397],\n",
      "        [0.5420, 0.5397, 0.5392, 0.5345],\n",
      "        [0.5399, 0.5371, 0.5367, 0.5300],\n",
      "        [0.5423, 0.5401, 0.5396, 0.5352],\n",
      "        [0.5435, 0.5416, 0.5409, 0.5377],\n",
      "        [0.5459, 0.5447, 0.5438, 0.5430],\n",
      "        [0.5452, 0.5438, 0.5430, 0.5416],\n",
      "        [0.5594, 0.5616, 0.5597, 0.5722],\n",
      "        [0.5719, 0.5772, 0.5743, 0.5989],\n",
      "        [0.5734, 0.5791, 0.5761, 0.6022],\n",
      "        [0.5709, 0.5759, 0.5731, 0.5968],\n",
      "        [0.5771, 0.5837, 0.5804, 0.6102],\n",
      "        [0.5809, 0.5885, 0.5850, 0.6185],\n",
      "        [0.5446, 0.5430, 0.5422, 0.5401],\n",
      "        [0.5273, 0.5214, 0.5220, 0.5029],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5404, 0.5398, 0.5357],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5288, 0.5232, 0.5237, 0.5060],\n",
      "        [0.5570, 0.5585, 0.5568, 0.5668],\n",
      "        [0.5287, 0.5232, 0.5236, 0.5059],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5401, 0.5374, 0.5369, 0.5304],\n",
      "        [0.5405, 0.5380, 0.5375, 0.5314],\n",
      "        [0.5333, 0.5289, 0.5290, 0.5159],\n",
      "        [0.5423, 0.5402, 0.5396, 0.5352],\n",
      "        [0.5699, 0.5748, 0.5720, 0.5948],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5392, 0.5362, 0.5359, 0.5285],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5386, 0.5356, 0.5353, 0.5273],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5431, 0.5411, 0.5405, 0.5369],\n",
      "        [0.5377, 0.5343, 0.5341, 0.5252],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5255, 0.5191, 0.5198, 0.4989],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5426, 0.5405, 0.5399, 0.5358]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "因為沒有顧好預測誤差\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.154907464981079\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 52\n",
      "X 資料 torch.Size([55, 18])\n",
      "Y 資料 torch.Size([55, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.003373080398887396, 4)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引4，y= tensor([0.5151, 0.5015, 0.5018, 0.4927])\n",
      "目前模型的Data torch.Size([52, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5707, 0.5757, 0.5729, 0.5965],\n",
      "        [0.5793, 0.5864, 0.5830, 0.6149],\n",
      "        [0.5743, 0.5802, 0.5772, 0.6042],\n",
      "        [0.5768, 0.5833, 0.5800, 0.6095],\n",
      "        [0.5686, 0.5731, 0.5705, 0.5920],\n",
      "        [0.5589, 0.5610, 0.5591, 0.5711],\n",
      "        [0.5527, 0.5531, 0.5518, 0.5576],\n",
      "        [0.5444, 0.5428, 0.5420, 0.5397],\n",
      "        [0.5420, 0.5397, 0.5392, 0.5345],\n",
      "        [0.5399, 0.5371, 0.5367, 0.5300],\n",
      "        [0.5423, 0.5401, 0.5396, 0.5352],\n",
      "        [0.5435, 0.5416, 0.5409, 0.5377],\n",
      "        [0.5459, 0.5447, 0.5438, 0.5430],\n",
      "        [0.5452, 0.5438, 0.5430, 0.5416],\n",
      "        [0.5594, 0.5616, 0.5597, 0.5722],\n",
      "        [0.5719, 0.5772, 0.5743, 0.5989],\n",
      "        [0.5734, 0.5791, 0.5761, 0.6022],\n",
      "        [0.5709, 0.5759, 0.5731, 0.5968],\n",
      "        [0.5771, 0.5837, 0.5804, 0.6102],\n",
      "        [0.5809, 0.5885, 0.5850, 0.6185],\n",
      "        [0.5446, 0.5430, 0.5422, 0.5401],\n",
      "        [0.5273, 0.5214, 0.5220, 0.5029],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5404, 0.5398, 0.5357],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5288, 0.5232, 0.5237, 0.5060],\n",
      "        [0.5570, 0.5585, 0.5568, 0.5668],\n",
      "        [0.5287, 0.5232, 0.5236, 0.5059],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5401, 0.5374, 0.5369, 0.5304],\n",
      "        [0.5405, 0.5380, 0.5375, 0.5314],\n",
      "        [0.5333, 0.5289, 0.5290, 0.5159],\n",
      "        [0.5423, 0.5402, 0.5396, 0.5352],\n",
      "        [0.5699, 0.5748, 0.5720, 0.5948],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5392, 0.5362, 0.5359, 0.5285],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5386, 0.5356, 0.5353, 0.5273],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5431, 0.5411, 0.5405, 0.5369],\n",
      "        [0.5377, 0.5343, 0.5341, 0.5252],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5255, 0.5191, 0.5198, 0.4989],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5426, 0.5405, 0.5399, 0.5358],\n",
      "        [0.5569, 0.5585, 0.5567, 0.5667]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 1\n",
      "因為沒有顧好預測誤差\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.257299184799194\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 53\n",
      "X 資料 torch.Size([54, 18])\n",
      "Y 資料 torch.Size([54, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.003423043293878436, 2)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引2，y= tensor([0.4870, 0.5112, 0.5151, 0.5015])\n",
      "目前模型的Data torch.Size([53, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5707, 0.5757, 0.5729, 0.5965],\n",
      "        [0.5793, 0.5864, 0.5830, 0.6149],\n",
      "        [0.5743, 0.5802, 0.5772, 0.6042],\n",
      "        [0.5768, 0.5833, 0.5800, 0.6095],\n",
      "        [0.5686, 0.5731, 0.5705, 0.5920],\n",
      "        [0.5589, 0.5610, 0.5591, 0.5711],\n",
      "        [0.5527, 0.5531, 0.5518, 0.5576],\n",
      "        [0.5444, 0.5428, 0.5420, 0.5397],\n",
      "        [0.5420, 0.5397, 0.5392, 0.5345],\n",
      "        [0.5399, 0.5371, 0.5367, 0.5300],\n",
      "        [0.5423, 0.5401, 0.5396, 0.5352],\n",
      "        [0.5435, 0.5416, 0.5409, 0.5377],\n",
      "        [0.5459, 0.5447, 0.5438, 0.5430],\n",
      "        [0.5452, 0.5438, 0.5430, 0.5416],\n",
      "        [0.5594, 0.5616, 0.5597, 0.5722],\n",
      "        [0.5719, 0.5772, 0.5743, 0.5989],\n",
      "        [0.5734, 0.5791, 0.5761, 0.6022],\n",
      "        [0.5709, 0.5759, 0.5731, 0.5968],\n",
      "        [0.5771, 0.5837, 0.5804, 0.6102],\n",
      "        [0.5809, 0.5885, 0.5850, 0.6185],\n",
      "        [0.5446, 0.5430, 0.5422, 0.5401],\n",
      "        [0.5273, 0.5214, 0.5220, 0.5029],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5404, 0.5398, 0.5357],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5288, 0.5232, 0.5237, 0.5060],\n",
      "        [0.5570, 0.5585, 0.5568, 0.5668],\n",
      "        [0.5287, 0.5232, 0.5236, 0.5059],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5401, 0.5374, 0.5369, 0.5304],\n",
      "        [0.5405, 0.5380, 0.5375, 0.5314],\n",
      "        [0.5333, 0.5289, 0.5290, 0.5159],\n",
      "        [0.5423, 0.5402, 0.5396, 0.5352],\n",
      "        [0.5699, 0.5748, 0.5720, 0.5948],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5392, 0.5362, 0.5359, 0.5285],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5386, 0.5356, 0.5353, 0.5273],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5431, 0.5411, 0.5405, 0.5369],\n",
      "        [0.5377, 0.5343, 0.5341, 0.5252],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5255, 0.5191, 0.5198, 0.4989],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5426, 0.5405, 0.5399, 0.5358],\n",
      "        [0.5569, 0.5585, 0.5567, 0.5667],\n",
      "        [0.5578, 0.5596, 0.5578, 0.5687]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "因為沒有顧好預測誤差\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.357688665390015\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 54\n",
      "X 資料 torch.Size([53, 18])\n",
      "Y 資料 torch.Size([53, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.00374942971393466, 14)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引14，y= tensor([0.5428, 0.4679, 0.4297, 0.4331])\n",
      "目前模型的Data torch.Size([54, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5707, 0.5757, 0.5729, 0.5965],\n",
      "        [0.5793, 0.5864, 0.5830, 0.6149],\n",
      "        [0.5743, 0.5802, 0.5772, 0.6042],\n",
      "        [0.5768, 0.5833, 0.5800, 0.6095],\n",
      "        [0.5686, 0.5731, 0.5705, 0.5920],\n",
      "        [0.5589, 0.5610, 0.5591, 0.5711],\n",
      "        [0.5527, 0.5531, 0.5518, 0.5576],\n",
      "        [0.5444, 0.5428, 0.5420, 0.5397],\n",
      "        [0.5420, 0.5397, 0.5392, 0.5345],\n",
      "        [0.5399, 0.5371, 0.5367, 0.5300],\n",
      "        [0.5423, 0.5401, 0.5396, 0.5352],\n",
      "        [0.5435, 0.5416, 0.5409, 0.5377],\n",
      "        [0.5459, 0.5447, 0.5438, 0.5430],\n",
      "        [0.5452, 0.5438, 0.5430, 0.5416],\n",
      "        [0.5594, 0.5616, 0.5597, 0.5722],\n",
      "        [0.5719, 0.5772, 0.5743, 0.5989],\n",
      "        [0.5734, 0.5791, 0.5761, 0.6022],\n",
      "        [0.5709, 0.5759, 0.5731, 0.5968],\n",
      "        [0.5771, 0.5837, 0.5804, 0.6102],\n",
      "        [0.5809, 0.5885, 0.5850, 0.6185],\n",
      "        [0.5446, 0.5430, 0.5422, 0.5401],\n",
      "        [0.5273, 0.5214, 0.5220, 0.5029],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5404, 0.5398, 0.5357],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5288, 0.5232, 0.5237, 0.5060],\n",
      "        [0.5570, 0.5585, 0.5568, 0.5668],\n",
      "        [0.5287, 0.5232, 0.5236, 0.5059],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5401, 0.5374, 0.5369, 0.5304],\n",
      "        [0.5405, 0.5380, 0.5375, 0.5314],\n",
      "        [0.5333, 0.5289, 0.5290, 0.5159],\n",
      "        [0.5423, 0.5402, 0.5396, 0.5352],\n",
      "        [0.5699, 0.5748, 0.5720, 0.5948],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5392, 0.5362, 0.5359, 0.5285],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5386, 0.5356, 0.5353, 0.5273],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5431, 0.5411, 0.5405, 0.5369],\n",
      "        [0.5377, 0.5343, 0.5341, 0.5252],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5255, 0.5191, 0.5198, 0.4989],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5426, 0.5405, 0.5399, 0.5358],\n",
      "        [0.5569, 0.5585, 0.5567, 0.5667],\n",
      "        [0.5578, 0.5596, 0.5578, 0.5687],\n",
      "        [0.5248, 0.5183, 0.5191, 0.4976]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "因為沒有顧好預測誤差\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.45214295387268\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 55\n",
      "X 資料 torch.Size([52, 18])\n",
      "Y 資料 torch.Size([52, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0040088132955133915, 32)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引32，y= tensor([0.4127, 0.4805, 0.4972, 0.5403])\n",
      "目前模型的Data torch.Size([55, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5707, 0.5757, 0.5729, 0.5965],\n",
      "        [0.5793, 0.5864, 0.5830, 0.6149],\n",
      "        [0.5743, 0.5802, 0.5772, 0.6042],\n",
      "        [0.5768, 0.5833, 0.5800, 0.6095],\n",
      "        [0.5686, 0.5731, 0.5705, 0.5920],\n",
      "        [0.5589, 0.5610, 0.5591, 0.5711],\n",
      "        [0.5527, 0.5531, 0.5518, 0.5576],\n",
      "        [0.5444, 0.5428, 0.5420, 0.5397],\n",
      "        [0.5420, 0.5397, 0.5392, 0.5345],\n",
      "        [0.5399, 0.5371, 0.5367, 0.5300],\n",
      "        [0.5423, 0.5401, 0.5396, 0.5352],\n",
      "        [0.5435, 0.5416, 0.5409, 0.5377],\n",
      "        [0.5459, 0.5447, 0.5438, 0.5430],\n",
      "        [0.5452, 0.5438, 0.5430, 0.5416],\n",
      "        [0.5594, 0.5616, 0.5597, 0.5722],\n",
      "        [0.5719, 0.5772, 0.5743, 0.5989],\n",
      "        [0.5734, 0.5791, 0.5761, 0.6022],\n",
      "        [0.5709, 0.5759, 0.5731, 0.5968],\n",
      "        [0.5771, 0.5837, 0.5804, 0.6102],\n",
      "        [0.5809, 0.5885, 0.5850, 0.6185],\n",
      "        [0.5446, 0.5430, 0.5422, 0.5401],\n",
      "        [0.5273, 0.5214, 0.5220, 0.5029],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5404, 0.5398, 0.5357],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5288, 0.5232, 0.5237, 0.5060],\n",
      "        [0.5570, 0.5585, 0.5568, 0.5668],\n",
      "        [0.5287, 0.5232, 0.5236, 0.5059],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5401, 0.5374, 0.5369, 0.5304],\n",
      "        [0.5405, 0.5380, 0.5375, 0.5314],\n",
      "        [0.5333, 0.5289, 0.5290, 0.5159],\n",
      "        [0.5423, 0.5402, 0.5396, 0.5352],\n",
      "        [0.5699, 0.5748, 0.5720, 0.5948],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5392, 0.5362, 0.5359, 0.5285],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5386, 0.5356, 0.5353, 0.5273],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5431, 0.5411, 0.5405, 0.5369],\n",
      "        [0.5377, 0.5343, 0.5341, 0.5252],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5255, 0.5191, 0.5198, 0.4989],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5426, 0.5405, 0.5399, 0.5358],\n",
      "        [0.5569, 0.5585, 0.5567, 0.5667],\n",
      "        [0.5578, 0.5596, 0.5578, 0.5687],\n",
      "        [0.5248, 0.5183, 0.5191, 0.4976],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "因為沒有顧好預測誤差\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.543281555175781\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 56\n",
      "X 資料 torch.Size([51, 18])\n",
      "Y 資料 torch.Size([51, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.004813561215996742, 14)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引14，y= tensor([0.4679, 0.4297, 0.4331, 0.4531])\n",
      "目前模型的Data torch.Size([56, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5707, 0.5757, 0.5729, 0.5965],\n",
      "        [0.5793, 0.5864, 0.5830, 0.6149],\n",
      "        [0.5743, 0.5802, 0.5772, 0.6042],\n",
      "        [0.5768, 0.5833, 0.5800, 0.6095],\n",
      "        [0.5686, 0.5731, 0.5705, 0.5920],\n",
      "        [0.5589, 0.5610, 0.5591, 0.5711],\n",
      "        [0.5527, 0.5531, 0.5518, 0.5576],\n",
      "        [0.5444, 0.5428, 0.5420, 0.5397],\n",
      "        [0.5420, 0.5397, 0.5392, 0.5345],\n",
      "        [0.5399, 0.5371, 0.5367, 0.5300],\n",
      "        [0.5423, 0.5401, 0.5396, 0.5352],\n",
      "        [0.5435, 0.5416, 0.5409, 0.5377],\n",
      "        [0.5459, 0.5447, 0.5438, 0.5430],\n",
      "        [0.5452, 0.5438, 0.5430, 0.5416],\n",
      "        [0.5594, 0.5616, 0.5597, 0.5722],\n",
      "        [0.5719, 0.5772, 0.5743, 0.5989],\n",
      "        [0.5734, 0.5791, 0.5761, 0.6022],\n",
      "        [0.5709, 0.5759, 0.5731, 0.5968],\n",
      "        [0.5771, 0.5837, 0.5804, 0.6102],\n",
      "        [0.5809, 0.5885, 0.5850, 0.6185],\n",
      "        [0.5446, 0.5430, 0.5422, 0.5401],\n",
      "        [0.5273, 0.5214, 0.5220, 0.5029],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5404, 0.5398, 0.5357],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5288, 0.5232, 0.5237, 0.5060],\n",
      "        [0.5570, 0.5585, 0.5568, 0.5668],\n",
      "        [0.5287, 0.5232, 0.5236, 0.5059],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5401, 0.5374, 0.5369, 0.5304],\n",
      "        [0.5405, 0.5380, 0.5375, 0.5314],\n",
      "        [0.5333, 0.5289, 0.5290, 0.5159],\n",
      "        [0.5423, 0.5402, 0.5396, 0.5352],\n",
      "        [0.5699, 0.5748, 0.5720, 0.5948],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5392, 0.5362, 0.5359, 0.5285],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5386, 0.5356, 0.5353, 0.5273],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5431, 0.5411, 0.5405, 0.5369],\n",
      "        [0.5377, 0.5343, 0.5341, 0.5252],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5255, 0.5191, 0.5198, 0.4989],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5426, 0.5405, 0.5399, 0.5358],\n",
      "        [0.5569, 0.5585, 0.5567, 0.5667],\n",
      "        [0.5578, 0.5596, 0.5578, 0.5687],\n",
      "        [0.5248, 0.5183, 0.5191, 0.4976],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0553, 0.0865, 0.0840, 0.0409]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "因為沒有顧好預測誤差\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0553, 0.0865, 0.0840, 0.0409]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.636930227279663\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 57\n",
      "X 資料 torch.Size([50, 18])\n",
      "Y 資料 torch.Size([50, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.005145553965121508, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引1，y= tensor([0.4961, 0.4813, 0.4632, 0.4950])\n",
      "目前模型的Data torch.Size([57, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5707, 0.5757, 0.5729, 0.5965],\n",
      "        [0.5793, 0.5864, 0.5830, 0.6149],\n",
      "        [0.5743, 0.5802, 0.5772, 0.6042],\n",
      "        [0.5768, 0.5833, 0.5800, 0.6095],\n",
      "        [0.5686, 0.5731, 0.5705, 0.5920],\n",
      "        [0.5589, 0.5610, 0.5591, 0.5711],\n",
      "        [0.5527, 0.5531, 0.5518, 0.5576],\n",
      "        [0.5444, 0.5428, 0.5420, 0.5397],\n",
      "        [0.5420, 0.5397, 0.5392, 0.5345],\n",
      "        [0.5399, 0.5371, 0.5367, 0.5300],\n",
      "        [0.5423, 0.5401, 0.5396, 0.5352],\n",
      "        [0.5435, 0.5416, 0.5409, 0.5377],\n",
      "        [0.5459, 0.5447, 0.5438, 0.5430],\n",
      "        [0.5452, 0.5438, 0.5430, 0.5416],\n",
      "        [0.5594, 0.5616, 0.5597, 0.5722],\n",
      "        [0.5719, 0.5772, 0.5743, 0.5989],\n",
      "        [0.5734, 0.5791, 0.5761, 0.6022],\n",
      "        [0.5709, 0.5759, 0.5731, 0.5968],\n",
      "        [0.5771, 0.5837, 0.5804, 0.6102],\n",
      "        [0.5809, 0.5885, 0.5850, 0.6185],\n",
      "        [0.5446, 0.5430, 0.5422, 0.5401],\n",
      "        [0.5273, 0.5214, 0.5220, 0.5029],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5404, 0.5398, 0.5357],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5288, 0.5232, 0.5237, 0.5060],\n",
      "        [0.5570, 0.5585, 0.5568, 0.5668],\n",
      "        [0.5287, 0.5232, 0.5236, 0.5059],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5401, 0.5374, 0.5369, 0.5304],\n",
      "        [0.5405, 0.5380, 0.5375, 0.5314],\n",
      "        [0.5333, 0.5289, 0.5290, 0.5159],\n",
      "        [0.5423, 0.5402, 0.5396, 0.5352],\n",
      "        [0.5699, 0.5748, 0.5720, 0.5948],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5392, 0.5362, 0.5359, 0.5285],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5386, 0.5356, 0.5353, 0.5273],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5431, 0.5411, 0.5405, 0.5369],\n",
      "        [0.5377, 0.5343, 0.5341, 0.5252],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5255, 0.5191, 0.5198, 0.4989],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5426, 0.5405, 0.5399, 0.5358],\n",
      "        [0.5569, 0.5585, 0.5567, 0.5667],\n",
      "        [0.5578, 0.5596, 0.5578, 0.5687],\n",
      "        [0.5248, 0.5183, 0.5191, 0.4976],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5533, 0.5539, 0.5524, 0.5589]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0553, 0.0865, 0.0840, 0.0409],\n",
      "        [0.0572, 0.0726, 0.0892, 0.0639]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "因為沒有顧好預測誤差\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0553, 0.0865, 0.0840, 0.0409],\n",
      "        [0.0572, 0.0726, 0.0892, 0.0639]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.731756687164307\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 58\n",
      "X 資料 torch.Size([49, 18])\n",
      "Y 資料 torch.Size([49, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.006004948168992996, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引1，y= tensor([0.5112, 0.5151, 0.5015, 0.5018])\n",
      "目前模型的Data torch.Size([58, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5707, 0.5757, 0.5729, 0.5965],\n",
      "        [0.5793, 0.5864, 0.5830, 0.6149],\n",
      "        [0.5743, 0.5802, 0.5772, 0.6042],\n",
      "        [0.5768, 0.5833, 0.5800, 0.6095],\n",
      "        [0.5686, 0.5731, 0.5705, 0.5920],\n",
      "        [0.5589, 0.5610, 0.5591, 0.5711],\n",
      "        [0.5527, 0.5531, 0.5518, 0.5576],\n",
      "        [0.5444, 0.5428, 0.5420, 0.5397],\n",
      "        [0.5420, 0.5397, 0.5392, 0.5345],\n",
      "        [0.5399, 0.5371, 0.5367, 0.5300],\n",
      "        [0.5423, 0.5401, 0.5396, 0.5352],\n",
      "        [0.5435, 0.5416, 0.5409, 0.5377],\n",
      "        [0.5459, 0.5447, 0.5438, 0.5430],\n",
      "        [0.5452, 0.5438, 0.5430, 0.5416],\n",
      "        [0.5594, 0.5616, 0.5597, 0.5722],\n",
      "        [0.5719, 0.5772, 0.5743, 0.5989],\n",
      "        [0.5734, 0.5791, 0.5761, 0.6022],\n",
      "        [0.5709, 0.5759, 0.5731, 0.5968],\n",
      "        [0.5771, 0.5837, 0.5804, 0.6102],\n",
      "        [0.5809, 0.5885, 0.5850, 0.6185],\n",
      "        [0.5446, 0.5430, 0.5422, 0.5401],\n",
      "        [0.5273, 0.5214, 0.5220, 0.5029],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5404, 0.5398, 0.5357],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5288, 0.5232, 0.5237, 0.5060],\n",
      "        [0.5570, 0.5585, 0.5568, 0.5668],\n",
      "        [0.5287, 0.5232, 0.5236, 0.5059],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5401, 0.5374, 0.5369, 0.5304],\n",
      "        [0.5405, 0.5380, 0.5375, 0.5314],\n",
      "        [0.5333, 0.5289, 0.5290, 0.5159],\n",
      "        [0.5423, 0.5402, 0.5396, 0.5352],\n",
      "        [0.5699, 0.5748, 0.5720, 0.5948],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5392, 0.5362, 0.5359, 0.5285],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5386, 0.5356, 0.5353, 0.5273],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5431, 0.5411, 0.5405, 0.5369],\n",
      "        [0.5377, 0.5343, 0.5341, 0.5252],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5255, 0.5191, 0.5198, 0.4989],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5426, 0.5405, 0.5399, 0.5358],\n",
      "        [0.5569, 0.5585, 0.5567, 0.5667],\n",
      "        [0.5578, 0.5596, 0.5578, 0.5687],\n",
      "        [0.5248, 0.5183, 0.5191, 0.4976],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5533, 0.5539, 0.5524, 0.5589],\n",
      "        [0.5738, 0.5797, 0.5766, 0.6032]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0553, 0.0865, 0.0840, 0.0409],\n",
      "        [0.0572, 0.0726, 0.0892, 0.0639],\n",
      "        [0.0626, 0.0645, 0.0751, 0.1014]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "因為沒有顧好預測誤差\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0553, 0.0865, 0.0840, 0.0409],\n",
      "        [0.0572, 0.0726, 0.0892, 0.0639],\n",
      "        [0.0626, 0.0645, 0.0751, 0.1014]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.828304767608643\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 59\n",
      "X 資料 torch.Size([48, 18])\n",
      "Y 資料 torch.Size([48, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.006050816737115383, 12)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引12，y= tensor([0.4297, 0.4331, 0.4531, 0.4271])\n",
      "目前模型的Data torch.Size([59, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5707, 0.5757, 0.5729, 0.5965],\n",
      "        [0.5793, 0.5864, 0.5830, 0.6149],\n",
      "        [0.5743, 0.5802, 0.5772, 0.6042],\n",
      "        [0.5768, 0.5833, 0.5800, 0.6095],\n",
      "        [0.5686, 0.5731, 0.5705, 0.5920],\n",
      "        [0.5589, 0.5610, 0.5591, 0.5711],\n",
      "        [0.5527, 0.5531, 0.5518, 0.5576],\n",
      "        [0.5444, 0.5428, 0.5420, 0.5397],\n",
      "        [0.5420, 0.5397, 0.5392, 0.5345],\n",
      "        [0.5399, 0.5371, 0.5367, 0.5300],\n",
      "        [0.5423, 0.5401, 0.5396, 0.5352],\n",
      "        [0.5435, 0.5416, 0.5409, 0.5377],\n",
      "        [0.5459, 0.5447, 0.5438, 0.5430],\n",
      "        [0.5452, 0.5438, 0.5430, 0.5416],\n",
      "        [0.5594, 0.5616, 0.5597, 0.5722],\n",
      "        [0.5719, 0.5772, 0.5743, 0.5989],\n",
      "        [0.5734, 0.5791, 0.5761, 0.6022],\n",
      "        [0.5709, 0.5759, 0.5731, 0.5968],\n",
      "        [0.5771, 0.5837, 0.5804, 0.6102],\n",
      "        [0.5809, 0.5885, 0.5850, 0.6185],\n",
      "        [0.5446, 0.5430, 0.5422, 0.5401],\n",
      "        [0.5273, 0.5214, 0.5220, 0.5029],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5404, 0.5398, 0.5357],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5288, 0.5232, 0.5237, 0.5060],\n",
      "        [0.5570, 0.5585, 0.5568, 0.5668],\n",
      "        [0.5287, 0.5232, 0.5236, 0.5059],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5401, 0.5374, 0.5369, 0.5304],\n",
      "        [0.5405, 0.5380, 0.5375, 0.5314],\n",
      "        [0.5333, 0.5289, 0.5290, 0.5159],\n",
      "        [0.5423, 0.5402, 0.5396, 0.5352],\n",
      "        [0.5699, 0.5748, 0.5720, 0.5948],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5392, 0.5362, 0.5359, 0.5285],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5386, 0.5356, 0.5353, 0.5273],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5431, 0.5411, 0.5405, 0.5369],\n",
      "        [0.5377, 0.5343, 0.5341, 0.5252],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5255, 0.5191, 0.5198, 0.4989],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5426, 0.5405, 0.5399, 0.5358],\n",
      "        [0.5569, 0.5585, 0.5567, 0.5667],\n",
      "        [0.5578, 0.5596, 0.5578, 0.5687],\n",
      "        [0.5248, 0.5183, 0.5191, 0.4976],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5533, 0.5539, 0.5524, 0.5589],\n",
      "        [0.5738, 0.5797, 0.5766, 0.6032],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0553, 0.0865, 0.0840, 0.0409],\n",
      "        [0.0572, 0.0726, 0.0892, 0.0639],\n",
      "        [0.0626, 0.0645, 0.0751, 0.1014],\n",
      "        [0.0934, 0.0831, 0.0640, 0.0669]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "因為沒有顧好預測誤差\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0553, 0.0865, 0.0840, 0.0409],\n",
      "        [0.0572, 0.0726, 0.0892, 0.0639],\n",
      "        [0.0626, 0.0645, 0.0751, 0.1014],\n",
      "        [0.0934, 0.0831, 0.0640, 0.0669]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.927461385726929\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 60\n",
      "X 資料 torch.Size([47, 18])\n",
      "Y 資料 torch.Size([47, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0066384440287947655, 12)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引12，y= tensor([0.4331, 0.4531, 0.4271, 0.4142])\n",
      "目前模型的Data torch.Size([60, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5707, 0.5757, 0.5729, 0.5965],\n",
      "        [0.5793, 0.5864, 0.5830, 0.6149],\n",
      "        [0.5743, 0.5802, 0.5772, 0.6042],\n",
      "        [0.5768, 0.5833, 0.5800, 0.6095],\n",
      "        [0.5686, 0.5731, 0.5705, 0.5920],\n",
      "        [0.5589, 0.5610, 0.5591, 0.5711],\n",
      "        [0.5527, 0.5531, 0.5518, 0.5576],\n",
      "        [0.5444, 0.5428, 0.5420, 0.5397],\n",
      "        [0.5420, 0.5397, 0.5392, 0.5345],\n",
      "        [0.5399, 0.5371, 0.5367, 0.5300],\n",
      "        [0.5423, 0.5401, 0.5396, 0.5352],\n",
      "        [0.5435, 0.5416, 0.5409, 0.5377],\n",
      "        [0.5459, 0.5447, 0.5438, 0.5430],\n",
      "        [0.5452, 0.5438, 0.5430, 0.5416],\n",
      "        [0.5594, 0.5616, 0.5597, 0.5722],\n",
      "        [0.5719, 0.5772, 0.5743, 0.5989],\n",
      "        [0.5734, 0.5791, 0.5761, 0.6022],\n",
      "        [0.5709, 0.5759, 0.5731, 0.5968],\n",
      "        [0.5771, 0.5837, 0.5804, 0.6102],\n",
      "        [0.5809, 0.5885, 0.5850, 0.6185],\n",
      "        [0.5446, 0.5430, 0.5422, 0.5401],\n",
      "        [0.5273, 0.5214, 0.5220, 0.5029],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5404, 0.5398, 0.5357],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5288, 0.5232, 0.5237, 0.5060],\n",
      "        [0.5570, 0.5585, 0.5568, 0.5668],\n",
      "        [0.5287, 0.5232, 0.5236, 0.5059],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5401, 0.5374, 0.5369, 0.5304],\n",
      "        [0.5405, 0.5380, 0.5375, 0.5314],\n",
      "        [0.5333, 0.5289, 0.5290, 0.5159],\n",
      "        [0.5423, 0.5402, 0.5396, 0.5352],\n",
      "        [0.5699, 0.5748, 0.5720, 0.5948],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5392, 0.5362, 0.5359, 0.5285],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5386, 0.5356, 0.5353, 0.5273],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5431, 0.5411, 0.5405, 0.5369],\n",
      "        [0.5377, 0.5343, 0.5341, 0.5252],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5255, 0.5191, 0.5198, 0.4989],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5426, 0.5405, 0.5399, 0.5358],\n",
      "        [0.5569, 0.5585, 0.5567, 0.5667],\n",
      "        [0.5578, 0.5596, 0.5578, 0.5687],\n",
      "        [0.5248, 0.5183, 0.5191, 0.4976],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5533, 0.5539, 0.5524, 0.5589],\n",
      "        [0.5738, 0.5797, 0.5766, 0.6032],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0553, 0.0865, 0.0840, 0.0409],\n",
      "        [0.0572, 0.0726, 0.0892, 0.0639],\n",
      "        [0.0626, 0.0645, 0.0751, 0.1014],\n",
      "        [0.0934, 0.0831, 0.0640, 0.0669],\n",
      "        [0.0901, 0.0631, 0.0900, 0.0797]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "因為沒有顧好預測誤差\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0553, 0.0865, 0.0840, 0.0409],\n",
      "        [0.0572, 0.0726, 0.0892, 0.0639],\n",
      "        [0.0626, 0.0645, 0.0751, 0.1014],\n",
      "        [0.0934, 0.0831, 0.0640, 0.0669],\n",
      "        [0.0901, 0.0631, 0.0900, 0.0797]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.017590999603271\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 61\n",
      "X 資料 torch.Size([46, 18])\n",
      "Y 資料 torch.Size([46, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.007046426646411419, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.4796, 0.4961, 0.4813, 0.4632])\n",
      "目前模型的Data torch.Size([61, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5707, 0.5757, 0.5729, 0.5965],\n",
      "        [0.5793, 0.5864, 0.5830, 0.6149],\n",
      "        [0.5743, 0.5802, 0.5772, 0.6042],\n",
      "        [0.5768, 0.5833, 0.5800, 0.6095],\n",
      "        [0.5686, 0.5731, 0.5705, 0.5920],\n",
      "        [0.5589, 0.5610, 0.5591, 0.5711],\n",
      "        [0.5527, 0.5531, 0.5518, 0.5576],\n",
      "        [0.5444, 0.5428, 0.5420, 0.5397],\n",
      "        [0.5420, 0.5397, 0.5392, 0.5345],\n",
      "        [0.5399, 0.5371, 0.5367, 0.5300],\n",
      "        [0.5423, 0.5401, 0.5396, 0.5352],\n",
      "        [0.5435, 0.5416, 0.5409, 0.5377],\n",
      "        [0.5459, 0.5447, 0.5438, 0.5430],\n",
      "        [0.5452, 0.5438, 0.5430, 0.5416],\n",
      "        [0.5594, 0.5616, 0.5597, 0.5722],\n",
      "        [0.5719, 0.5772, 0.5743, 0.5989],\n",
      "        [0.5734, 0.5791, 0.5761, 0.6022],\n",
      "        [0.5709, 0.5759, 0.5731, 0.5968],\n",
      "        [0.5771, 0.5837, 0.5804, 0.6102],\n",
      "        [0.5809, 0.5885, 0.5850, 0.6185],\n",
      "        [0.5446, 0.5430, 0.5422, 0.5401],\n",
      "        [0.5273, 0.5214, 0.5220, 0.5029],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5404, 0.5398, 0.5357],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5288, 0.5232, 0.5237, 0.5060],\n",
      "        [0.5570, 0.5585, 0.5568, 0.5668],\n",
      "        [0.5287, 0.5232, 0.5236, 0.5059],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5401, 0.5374, 0.5369, 0.5304],\n",
      "        [0.5405, 0.5380, 0.5375, 0.5314],\n",
      "        [0.5333, 0.5289, 0.5290, 0.5159],\n",
      "        [0.5423, 0.5402, 0.5396, 0.5352],\n",
      "        [0.5699, 0.5748, 0.5720, 0.5948],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5392, 0.5362, 0.5359, 0.5285],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5386, 0.5356, 0.5353, 0.5273],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5431, 0.5411, 0.5405, 0.5369],\n",
      "        [0.5377, 0.5343, 0.5341, 0.5252],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5255, 0.5191, 0.5198, 0.4989],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5426, 0.5405, 0.5399, 0.5358],\n",
      "        [0.5569, 0.5585, 0.5567, 0.5667],\n",
      "        [0.5578, 0.5596, 0.5578, 0.5687],\n",
      "        [0.5248, 0.5183, 0.5191, 0.4976],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5533, 0.5539, 0.5524, 0.5589],\n",
      "        [0.5738, 0.5797, 0.5766, 0.6032],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5589, 0.5610, 0.5591, 0.5711]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0553, 0.0865, 0.0840, 0.0409],\n",
      "        [0.0572, 0.0726, 0.0892, 0.0639],\n",
      "        [0.0626, 0.0645, 0.0751, 0.1014],\n",
      "        [0.0934, 0.0831, 0.0640, 0.0669],\n",
      "        [0.0901, 0.0631, 0.0900, 0.0797],\n",
      "        [0.0793, 0.0649, 0.0778, 0.1078]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "因為沒有顧好預測誤差\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0553, 0.0865, 0.0840, 0.0409],\n",
      "        [0.0572, 0.0726, 0.0892, 0.0639],\n",
      "        [0.0626, 0.0645, 0.0751, 0.1014],\n",
      "        [0.0934, 0.0831, 0.0640, 0.0669],\n",
      "        [0.0901, 0.0631, 0.0900, 0.0797],\n",
      "        [0.0793, 0.0649, 0.0778, 0.1078]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.107937574386597\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 62\n",
      "X 資料 torch.Size([45, 18])\n",
      "Y 資料 torch.Size([45, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.007970936596393585, 10)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引10，y= tensor([0.5046, 0.5578, 0.5700, 0.5779])\n",
      "目前模型的Data torch.Size([62, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5707, 0.5757, 0.5729, 0.5965],\n",
      "        [0.5793, 0.5864, 0.5830, 0.6149],\n",
      "        [0.5743, 0.5802, 0.5772, 0.6042],\n",
      "        [0.5768, 0.5833, 0.5800, 0.6095],\n",
      "        [0.5686, 0.5731, 0.5705, 0.5920],\n",
      "        [0.5589, 0.5610, 0.5591, 0.5711],\n",
      "        [0.5527, 0.5531, 0.5518, 0.5576],\n",
      "        [0.5444, 0.5428, 0.5420, 0.5397],\n",
      "        [0.5420, 0.5397, 0.5392, 0.5345],\n",
      "        [0.5399, 0.5371, 0.5367, 0.5300],\n",
      "        [0.5423, 0.5401, 0.5396, 0.5352],\n",
      "        [0.5435, 0.5416, 0.5409, 0.5377],\n",
      "        [0.5459, 0.5447, 0.5438, 0.5430],\n",
      "        [0.5452, 0.5438, 0.5430, 0.5416],\n",
      "        [0.5594, 0.5616, 0.5597, 0.5722],\n",
      "        [0.5719, 0.5772, 0.5743, 0.5989],\n",
      "        [0.5734, 0.5791, 0.5761, 0.6022],\n",
      "        [0.5709, 0.5759, 0.5731, 0.5968],\n",
      "        [0.5771, 0.5837, 0.5804, 0.6102],\n",
      "        [0.5809, 0.5885, 0.5850, 0.6185],\n",
      "        [0.5446, 0.5430, 0.5422, 0.5401],\n",
      "        [0.5273, 0.5214, 0.5220, 0.5029],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5404, 0.5398, 0.5357],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5288, 0.5232, 0.5237, 0.5060],\n",
      "        [0.5570, 0.5585, 0.5568, 0.5668],\n",
      "        [0.5287, 0.5232, 0.5236, 0.5059],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5401, 0.5374, 0.5369, 0.5304],\n",
      "        [0.5405, 0.5380, 0.5375, 0.5314],\n",
      "        [0.5333, 0.5289, 0.5290, 0.5159],\n",
      "        [0.5423, 0.5402, 0.5396, 0.5352],\n",
      "        [0.5699, 0.5748, 0.5720, 0.5948],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5392, 0.5362, 0.5359, 0.5285],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5386, 0.5356, 0.5353, 0.5273],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5431, 0.5411, 0.5405, 0.5369],\n",
      "        [0.5377, 0.5343, 0.5341, 0.5252],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5255, 0.5191, 0.5198, 0.4989],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5426, 0.5405, 0.5399, 0.5358],\n",
      "        [0.5569, 0.5585, 0.5567, 0.5667],\n",
      "        [0.5578, 0.5596, 0.5578, 0.5687],\n",
      "        [0.5248, 0.5183, 0.5191, 0.4976],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5533, 0.5539, 0.5524, 0.5589],\n",
      "        [0.5738, 0.5797, 0.5766, 0.6032],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5589, 0.5610, 0.5591, 0.5711],\n",
      "        [0.6133, 0.6291, 0.6230, 0.6883]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0553, 0.0865, 0.0840, 0.0409],\n",
      "        [0.0572, 0.0726, 0.0892, 0.0639],\n",
      "        [0.0626, 0.0645, 0.0751, 0.1014],\n",
      "        [0.0934, 0.0831, 0.0640, 0.0669],\n",
      "        [0.0901, 0.0631, 0.0900, 0.0797],\n",
      "        [0.0793, 0.0649, 0.0778, 0.1078],\n",
      "        [0.1087, 0.0712, 0.0530, 0.1104]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "因為沒有顧好預測誤差\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "我成功了\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 0\n",
      "是不是可以不要你: True\n",
      "Cannot drop out the nero number: 1 / 1\n",
      "Reorganizing result: The final number of neuro is  1\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0553, 0.0865, 0.0840, 0.0409],\n",
      "        [0.0572, 0.0726, 0.0892, 0.0639],\n",
      "        [0.0626, 0.0645, 0.0751, 0.1014],\n",
      "        [0.0934, 0.0831, 0.0640, 0.0669],\n",
      "        [0.0901, 0.0631, 0.0900, 0.0797],\n",
      "        [0.0793, 0.0649, 0.0778, 0.1078],\n",
      "        [0.1087, 0.0712, 0.0530, 0.1104]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.199331045150757\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 63\n",
      "X 資料 torch.Size([44, 18])\n",
      "Y 資料 torch.Size([44, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.008232295513153076, 24)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引24，y= tensor([0.3787, 0.4127, 0.4805, 0.4972])\n",
      "目前模型的Data torch.Size([63, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5707, 0.5757, 0.5729, 0.5965],\n",
      "        [0.5793, 0.5864, 0.5830, 0.6149],\n",
      "        [0.5743, 0.5802, 0.5772, 0.6042],\n",
      "        [0.5768, 0.5833, 0.5800, 0.6095],\n",
      "        [0.5686, 0.5731, 0.5705, 0.5920],\n",
      "        [0.5589, 0.5610, 0.5591, 0.5711],\n",
      "        [0.5527, 0.5531, 0.5518, 0.5576],\n",
      "        [0.5444, 0.5428, 0.5420, 0.5397],\n",
      "        [0.5420, 0.5397, 0.5392, 0.5345],\n",
      "        [0.5399, 0.5371, 0.5367, 0.5300],\n",
      "        [0.5423, 0.5401, 0.5396, 0.5352],\n",
      "        [0.5435, 0.5416, 0.5409, 0.5377],\n",
      "        [0.5459, 0.5447, 0.5438, 0.5430],\n",
      "        [0.5452, 0.5438, 0.5430, 0.5416],\n",
      "        [0.5594, 0.5616, 0.5597, 0.5722],\n",
      "        [0.5719, 0.5772, 0.5743, 0.5989],\n",
      "        [0.5734, 0.5791, 0.5761, 0.6022],\n",
      "        [0.5709, 0.5759, 0.5731, 0.5968],\n",
      "        [0.5771, 0.5837, 0.5804, 0.6102],\n",
      "        [0.5809, 0.5885, 0.5850, 0.6185],\n",
      "        [0.5446, 0.5430, 0.5422, 0.5401],\n",
      "        [0.5273, 0.5214, 0.5220, 0.5029],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5404, 0.5398, 0.5357],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5288, 0.5232, 0.5237, 0.5060],\n",
      "        [0.5570, 0.5585, 0.5568, 0.5668],\n",
      "        [0.5287, 0.5232, 0.5236, 0.5059],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5401, 0.5374, 0.5369, 0.5304],\n",
      "        [0.5405, 0.5380, 0.5375, 0.5314],\n",
      "        [0.5333, 0.5289, 0.5290, 0.5159],\n",
      "        [0.5423, 0.5402, 0.5396, 0.5352],\n",
      "        [0.5699, 0.5748, 0.5720, 0.5948],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5392, 0.5362, 0.5359, 0.5285],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5386, 0.5356, 0.5353, 0.5273],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5431, 0.5411, 0.5405, 0.5369],\n",
      "        [0.5377, 0.5343, 0.5341, 0.5252],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5255, 0.5191, 0.5198, 0.4989],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5426, 0.5405, 0.5399, 0.5358],\n",
      "        [0.5569, 0.5585, 0.5567, 0.5667],\n",
      "        [0.5578, 0.5596, 0.5578, 0.5687],\n",
      "        [0.5248, 0.5183, 0.5191, 0.4976],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5533, 0.5539, 0.5524, 0.5589],\n",
      "        [0.5738, 0.5797, 0.5766, 0.6032],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5589, 0.5610, 0.5591, 0.5711],\n",
      "        [0.6133, 0.6291, 0.6230, 0.6883],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0553, 0.0865, 0.0840, 0.0409],\n",
      "        [0.0572, 0.0726, 0.0892, 0.0639],\n",
      "        [0.0626, 0.0645, 0.0751, 0.1014],\n",
      "        [0.0934, 0.0831, 0.0640, 0.0669],\n",
      "        [0.0901, 0.0631, 0.0900, 0.0797],\n",
      "        [0.0793, 0.0649, 0.0778, 0.1078],\n",
      "        [0.1087, 0.0712, 0.0530, 0.1104],\n",
      "        [0.1444, 0.1035, 0.0366, 0.0032]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 439\n",
      "Number of shrink: 231\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[0.0441, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0225, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0480, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0396, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0159, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0322, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0069, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0307, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0391, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0629, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0440, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0821, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0591, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0121, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0596, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0571, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0460, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0698, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0708, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0553, 0.0865, 0.0840, 0.0409],\n",
      "        [0.0572, 0.0726, 0.0892, 0.0639],\n",
      "        [0.0626, 0.0645, 0.0751, 0.1014],\n",
      "        [0.0934, 0.0831, 0.0640, 0.0669],\n",
      "        [0.0901, 0.0631, 0.0900, 0.0797],\n",
      "        [0.0793, 0.0649, 0.0778, 0.1078],\n",
      "        [0.1087, 0.0712, 0.0530, 0.1104],\n",
      "        [0.1444, 0.1035, 0.0366, 0.0032]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.11750881 0.11750881 0.11750881 0.11750881]\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "The index of the undesired data: tensor([[62,  0]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[0.0442, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0224, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0481, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0397, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0158, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0323, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0068, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0306, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0392, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0628, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0439, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0820, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0590, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0122, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0597, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0570, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0459, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0697, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0709, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0552, 0.0865, 0.0840, 0.0409],\n",
      "        [0.0572, 0.0726, 0.0892, 0.0639],\n",
      "        [0.0627, 0.0645, 0.0751, 0.1014],\n",
      "        [0.0935, 0.0831, 0.0640, 0.0669],\n",
      "        [0.0900, 0.0631, 0.0900, 0.0797],\n",
      "        [0.0793, 0.0649, 0.0778, 0.1078],\n",
      "        [0.1086, 0.0712, 0.0530, 0.1104],\n",
      "        [0.0005, 0.1035, 0.0366, 0.0032]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 4\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 659\n",
      "Number of shrink: 341\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 2 / 4\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 660\n",
      "Number of shrink: 340\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 3 / 4\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 658\n",
      "Number of shrink: 342\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 4 / 4\n",
      "Reorganizing result: The final number of neuro is  4\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0442, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0224, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0481, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0397, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0158, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0323, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0068, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0306, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0392, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0628, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0439, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0820, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0590, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0122, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0597, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0570, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0459, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0697, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0709, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0552, 0.0865, 0.0840, 0.0409],\n",
      "        [0.0572, 0.0726, 0.0892, 0.0639],\n",
      "        [0.0627, 0.0645, 0.0751, 0.1014],\n",
      "        [0.0935, 0.0831, 0.0640, 0.0669],\n",
      "        [0.0900, 0.0631, 0.0900, 0.0797],\n",
      "        [0.0793, 0.0649, 0.0778, 0.1078],\n",
      "        [0.1086, 0.0712, 0.0530, 0.1104],\n",
      "        [0.0005, 0.1035, 0.0366, 0.0032]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 23.6375789642334\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 64\n",
      "X 資料 torch.Size([43, 18])\n",
      "Y 資料 torch.Size([43, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.010432403534650803, 10)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引10，y= tensor([0.4531, 0.4271, 0.4142, 0.3588])\n",
      "目前模型的Data torch.Size([64, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5707, 0.5757, 0.5729, 0.5965],\n",
      "        [0.5792, 0.5864, 0.5830, 0.6149],\n",
      "        [0.5744, 0.5802, 0.5772, 0.6042],\n",
      "        [0.5768, 0.5833, 0.5800, 0.6095],\n",
      "        [0.5686, 0.5731, 0.5705, 0.5920],\n",
      "        [0.5590, 0.5610, 0.5591, 0.5711],\n",
      "        [0.5526, 0.5531, 0.5518, 0.5576],\n",
      "        [0.5443, 0.5428, 0.5420, 0.5397],\n",
      "        [0.5421, 0.5397, 0.5392, 0.5345],\n",
      "        [0.5399, 0.5371, 0.5367, 0.5300],\n",
      "        [0.5422, 0.5401, 0.5396, 0.5352],\n",
      "        [0.5435, 0.5416, 0.5409, 0.5377],\n",
      "        [0.5459, 0.5447, 0.5438, 0.5430],\n",
      "        [0.5452, 0.5438, 0.5430, 0.5416],\n",
      "        [0.5595, 0.5616, 0.5597, 0.5722],\n",
      "        [0.5719, 0.5772, 0.5743, 0.5989],\n",
      "        [0.5734, 0.5791, 0.5761, 0.6022],\n",
      "        [0.5709, 0.5759, 0.5731, 0.5968],\n",
      "        [0.5771, 0.5837, 0.5804, 0.6102],\n",
      "        [0.5810, 0.5885, 0.5850, 0.6185],\n",
      "        [0.5445, 0.5430, 0.5422, 0.5401],\n",
      "        [0.5273, 0.5214, 0.5220, 0.5029],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5404, 0.5398, 0.5357],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5288, 0.5232, 0.5237, 0.5060],\n",
      "        [0.5569, 0.5585, 0.5568, 0.5668],\n",
      "        [0.5287, 0.5232, 0.5236, 0.5059],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5401, 0.5374, 0.5369, 0.5304],\n",
      "        [0.5405, 0.5380, 0.5375, 0.5314],\n",
      "        [0.5334, 0.5289, 0.5290, 0.5159],\n",
      "        [0.5424, 0.5402, 0.5396, 0.5352],\n",
      "        [0.5700, 0.5748, 0.5720, 0.5948],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5392, 0.5362, 0.5359, 0.5285],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5386, 0.5356, 0.5353, 0.5273],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5431, 0.5411, 0.5405, 0.5369],\n",
      "        [0.5376, 0.5343, 0.5341, 0.5252],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5255, 0.5191, 0.5198, 0.4989],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5405, 0.5399, 0.5358],\n",
      "        [0.5569, 0.5585, 0.5567, 0.5667],\n",
      "        [0.5579, 0.5596, 0.5578, 0.5687],\n",
      "        [0.5249, 0.5183, 0.5191, 0.4976],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5230, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5533, 0.5539, 0.5524, 0.5589],\n",
      "        [0.5739, 0.5797, 0.5766, 0.6032],\n",
      "        [0.5233, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5590, 0.5610, 0.5591, 0.5711],\n",
      "        [0.6132, 0.6291, 0.6230, 0.6883],\n",
      "        [0.3793, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0442, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0224, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0481, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0397, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0158, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0323, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0068, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0306, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0392, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0628, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0439, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0820, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0590, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0122, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0597, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0570, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0459, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0697, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0709, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0552, 0.0865, 0.0840, 0.0409],\n",
      "        [0.0572, 0.0726, 0.0892, 0.0639],\n",
      "        [0.0627, 0.0645, 0.0751, 0.1014],\n",
      "        [0.0935, 0.0831, 0.0640, 0.0669],\n",
      "        [0.0900, 0.0631, 0.0900, 0.0797],\n",
      "        [0.0793, 0.0649, 0.0778, 0.1078],\n",
      "        [0.1086, 0.0712, 0.0530, 0.1104],\n",
      "        [0.0005, 0.1035, 0.0366, 0.0032],\n",
      "        [0.0701, 0.0891, 0.1029, 0.1352]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[0.0442, 0.0090, 0.0238, 0.0195],\n",
      "        [0.0055, 0.0103, 0.0060, 0.0157],\n",
      "        [0.0224, 0.0032, 0.0220, 0.0133],\n",
      "        [0.0003, 0.0159, 0.0108, 0.0088],\n",
      "        [0.0306, 0.0178, 0.0302, 0.0080],\n",
      "        [0.0319, 0.0397, 0.0249, 0.0132],\n",
      "        [0.0481, 0.0308, 0.0061, 0.0163],\n",
      "        [0.0397, 0.0151, 0.0007, 0.0186],\n",
      "        [0.0158, 0.0015, 0.0180, 0.0233],\n",
      "        [0.0014, 0.0160, 0.0255, 0.0222],\n",
      "        [0.0211, 0.0289, 0.0318, 0.0252],\n",
      "        [0.0323, 0.0338, 0.0309, 0.0188],\n",
      "        [0.0382, 0.0347, 0.0249, 0.0129],\n",
      "        [0.0352, 0.0250, 0.0129, 0.0064],\n",
      "        [0.0406, 0.0314, 0.0245, 0.0056],\n",
      "        [0.0417, 0.0420, 0.0034, 0.0088],\n",
      "        [0.0382, 0.0013, 0.0316, 0.0082],\n",
      "        [0.0068, 0.0318, 0.0373, 0.0046],\n",
      "        [0.0306, 0.0267, 0.0210, 0.0052],\n",
      "        [0.0294, 0.0128, 0.0304, 0.0306],\n",
      "        [0.0255, 0.0349, 0.0335, 0.0222],\n",
      "        [0.0516, 0.0369, 0.0112, 0.0188],\n",
      "        [0.0526, 0.0461, 0.0521, 0.0488],\n",
      "        [0.0158, 0.0073, 0.0181, 0.0273],\n",
      "        [0.0392, 0.0530, 0.0257, 0.0261],\n",
      "        [0.0628, 0.0557, 0.0346, 0.0271],\n",
      "        [0.0279, 0.0255, 0.0349, 0.0121],\n",
      "        [0.0044, 0.0015, 0.0152, 0.0150],\n",
      "        [0.0547, 0.0595, 0.0452, 0.0752],\n",
      "        [0.0439, 0.0543, 0.0419, 0.0279],\n",
      "        [0.0474, 0.0469, 0.0466, 0.0602],\n",
      "        [0.0820, 0.0590, 0.0559, 0.0682],\n",
      "        [0.0590, 0.0752, 0.0483, 0.0496],\n",
      "        [0.0122, 0.0047, 0.0058, 0.0191],\n",
      "        [0.0260, 0.0242, 0.0638, 0.1173],\n",
      "        [0.0427, 0.0190, 0.0233, 0.0869],\n",
      "        [0.0175, 0.0278, 0.0450, 0.0626],\n",
      "        [0.0282, 0.0142, 0.0288, 0.0279],\n",
      "        [0.0599, 0.0212, 0.0151, 0.0057],\n",
      "        [0.0303, 0.0446, 0.0694, 0.0520],\n",
      "        [0.0212, 0.0279, 0.0510, 0.0188],\n",
      "        [0.0419, 0.0530, 0.0221, 0.0080],\n",
      "        [0.0694, 0.0541, 0.0293, 0.0218],\n",
      "        [0.0623, 0.0547, 0.0380, 0.0439],\n",
      "        [0.0323, 0.0503, 0.0418, 0.0143],\n",
      "        [0.0597, 0.0437, 0.0401, 0.0028],\n",
      "        [0.0480, 0.0434, 0.0434, 0.0070],\n",
      "        [0.0349, 0.0501, 0.0419, 0.0211],\n",
      "        [0.0570, 0.0410, 0.0443, 0.0203],\n",
      "        [0.0459, 0.0266, 0.0492, 0.0642],\n",
      "        [0.0697, 0.0668, 0.0529, 0.0246],\n",
      "        [0.0418, 0.0570, 0.0549, 0.0741],\n",
      "        [0.0709, 0.0484, 0.0427, 0.0672],\n",
      "        [0.0179, 0.0504, 0.0893, 0.0645],\n",
      "        [0.1105, 0.0357, 0.0199, 0.0464],\n",
      "        [0.0552, 0.0865, 0.0840, 0.0409],\n",
      "        [0.0572, 0.0726, 0.0892, 0.0639],\n",
      "        [0.0627, 0.0645, 0.0751, 0.1014],\n",
      "        [0.0935, 0.0831, 0.0640, 0.0669],\n",
      "        [0.0900, 0.0631, 0.0900, 0.0797],\n",
      "        [0.0793, 0.0649, 0.0778, 0.1078],\n",
      "        [0.1086, 0.0712, 0.0530, 0.1104],\n",
      "        [0.0005, 0.1035, 0.0366, 0.0032],\n",
      "        [0.0701, 0.0891, 0.1029, 0.1352]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.11750881 0.11750881 0.11750881 0.11750881]\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "The index of the undesired data: tensor([[63,  3]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0442,     0.0090,     0.0238,     0.0195],\n",
      "        [    0.0055,     0.0103,     0.0060,     0.0157],\n",
      "        [    0.0224,     0.0032,     0.0220,     0.0133],\n",
      "        [    0.0003,     0.0159,     0.0108,     0.0088],\n",
      "        [    0.0306,     0.0178,     0.0302,     0.0080],\n",
      "        [    0.0319,     0.0397,     0.0249,     0.0132],\n",
      "        [    0.0481,     0.0308,     0.0061,     0.0163],\n",
      "        [    0.0397,     0.0151,     0.0007,     0.0186],\n",
      "        [    0.0158,     0.0015,     0.0180,     0.0233],\n",
      "        [    0.0014,     0.0160,     0.0255,     0.0222],\n",
      "        [    0.0211,     0.0289,     0.0318,     0.0252],\n",
      "        [    0.0323,     0.0338,     0.0309,     0.0188],\n",
      "        [    0.0382,     0.0347,     0.0249,     0.0129],\n",
      "        [    0.0352,     0.0250,     0.0129,     0.0064],\n",
      "        [    0.0406,     0.0314,     0.0245,     0.0056],\n",
      "        [    0.0417,     0.0420,     0.0034,     0.0088],\n",
      "        [    0.0382,     0.0013,     0.0316,     0.0082],\n",
      "        [    0.0068,     0.0318,     0.0373,     0.0046],\n",
      "        [    0.0306,     0.0267,     0.0210,     0.0052],\n",
      "        [    0.0294,     0.0128,     0.0304,     0.0306],\n",
      "        [    0.0255,     0.0349,     0.0335,     0.0222],\n",
      "        [    0.0516,     0.0369,     0.0112,     0.0188],\n",
      "        [    0.0526,     0.0461,     0.0521,     0.0488],\n",
      "        [    0.0158,     0.0073,     0.0181,     0.0273],\n",
      "        [    0.0392,     0.0530,     0.0257,     0.0261],\n",
      "        [    0.0628,     0.0557,     0.0346,     0.0271],\n",
      "        [    0.0279,     0.0255,     0.0349,     0.0121],\n",
      "        [    0.0044,     0.0015,     0.0152,     0.0150],\n",
      "        [    0.0547,     0.0595,     0.0452,     0.0752],\n",
      "        [    0.0439,     0.0543,     0.0419,     0.0279],\n",
      "        [    0.0474,     0.0469,     0.0466,     0.0602],\n",
      "        [    0.0820,     0.0590,     0.0559,     0.0682],\n",
      "        [    0.0590,     0.0752,     0.0483,     0.0496],\n",
      "        [    0.0122,     0.0047,     0.0058,     0.0191],\n",
      "        [    0.0260,     0.0242,     0.0638,     0.1173],\n",
      "        [    0.0427,     0.0190,     0.0233,     0.0869],\n",
      "        [    0.0175,     0.0278,     0.0450,     0.0626],\n",
      "        [    0.0282,     0.0142,     0.0288,     0.0279],\n",
      "        [    0.0599,     0.0212,     0.0151,     0.0057],\n",
      "        [    0.0303,     0.0446,     0.0694,     0.0520],\n",
      "        [    0.0212,     0.0279,     0.0510,     0.0188],\n",
      "        [    0.0419,     0.0530,     0.0221,     0.0080],\n",
      "        [    0.0694,     0.0541,     0.0293,     0.0218],\n",
      "        [    0.0623,     0.0547,     0.0380,     0.0439],\n",
      "        [    0.0323,     0.0503,     0.0418,     0.0143],\n",
      "        [    0.0597,     0.0437,     0.0401,     0.0028],\n",
      "        [    0.0480,     0.0434,     0.0434,     0.0070],\n",
      "        [    0.0349,     0.0501,     0.0419,     0.0211],\n",
      "        [    0.0570,     0.0410,     0.0443,     0.0203],\n",
      "        [    0.0459,     0.0266,     0.0492,     0.0642],\n",
      "        [    0.0697,     0.0668,     0.0529,     0.0246],\n",
      "        [    0.0418,     0.0570,     0.0549,     0.0741],\n",
      "        [    0.0709,     0.0484,     0.0427,     0.0672],\n",
      "        [    0.0179,     0.0504,     0.0893,     0.0645],\n",
      "        [    0.1105,     0.0357,     0.0199,     0.0464],\n",
      "        [    0.0552,     0.0865,     0.0840,     0.0409],\n",
      "        [    0.0572,     0.0726,     0.0892,     0.0639],\n",
      "        [    0.0627,     0.0645,     0.0751,     0.1014],\n",
      "        [    0.0935,     0.0831,     0.0640,     0.0669],\n",
      "        [    0.0900,     0.0631,     0.0900,     0.0797],\n",
      "        [    0.0793,     0.0649,     0.0778,     0.1078],\n",
      "        [    0.1086,     0.0712,     0.0530,     0.1104],\n",
      "        [    0.0005,     0.1035,     0.0366,     0.0032],\n",
      "        [    0.0701,     0.0891,     0.1029,     0.0000]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 659\n",
      "Number of shrink: 341\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 2 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 36\n",
      "Number of shrink: 25\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 3 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 658\n",
      "Number of shrink: 342\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 4 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 5 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 6 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 7 / 7\n",
      "Reorganizing result: The final number of neuro is  7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0442,     0.0090,     0.0238,     0.0195],\n",
      "        [    0.0055,     0.0103,     0.0060,     0.0157],\n",
      "        [    0.0224,     0.0032,     0.0220,     0.0133],\n",
      "        [    0.0003,     0.0159,     0.0108,     0.0088],\n",
      "        [    0.0306,     0.0178,     0.0302,     0.0080],\n",
      "        [    0.0319,     0.0397,     0.0249,     0.0132],\n",
      "        [    0.0481,     0.0308,     0.0061,     0.0163],\n",
      "        [    0.0397,     0.0151,     0.0007,     0.0186],\n",
      "        [    0.0158,     0.0015,     0.0180,     0.0233],\n",
      "        [    0.0014,     0.0160,     0.0255,     0.0222],\n",
      "        [    0.0211,     0.0289,     0.0318,     0.0252],\n",
      "        [    0.0323,     0.0338,     0.0309,     0.0188],\n",
      "        [    0.0382,     0.0347,     0.0249,     0.0129],\n",
      "        [    0.0352,     0.0250,     0.0129,     0.0064],\n",
      "        [    0.0406,     0.0314,     0.0245,     0.0056],\n",
      "        [    0.0417,     0.0420,     0.0034,     0.0088],\n",
      "        [    0.0382,     0.0013,     0.0316,     0.0082],\n",
      "        [    0.0068,     0.0318,     0.0373,     0.0046],\n",
      "        [    0.0306,     0.0267,     0.0210,     0.0052],\n",
      "        [    0.0294,     0.0128,     0.0304,     0.0306],\n",
      "        [    0.0255,     0.0349,     0.0335,     0.0222],\n",
      "        [    0.0516,     0.0369,     0.0112,     0.0188],\n",
      "        [    0.0526,     0.0461,     0.0521,     0.0488],\n",
      "        [    0.0158,     0.0073,     0.0181,     0.0273],\n",
      "        [    0.0392,     0.0530,     0.0257,     0.0261],\n",
      "        [    0.0628,     0.0557,     0.0346,     0.0271],\n",
      "        [    0.0279,     0.0255,     0.0349,     0.0121],\n",
      "        [    0.0044,     0.0015,     0.0152,     0.0150],\n",
      "        [    0.0547,     0.0595,     0.0452,     0.0752],\n",
      "        [    0.0439,     0.0543,     0.0419,     0.0279],\n",
      "        [    0.0474,     0.0469,     0.0466,     0.0602],\n",
      "        [    0.0820,     0.0590,     0.0559,     0.0682],\n",
      "        [    0.0590,     0.0752,     0.0483,     0.0496],\n",
      "        [    0.0122,     0.0047,     0.0058,     0.0191],\n",
      "        [    0.0260,     0.0242,     0.0638,     0.1173],\n",
      "        [    0.0427,     0.0190,     0.0233,     0.0869],\n",
      "        [    0.0175,     0.0278,     0.0450,     0.0626],\n",
      "        [    0.0282,     0.0142,     0.0288,     0.0279],\n",
      "        [    0.0599,     0.0212,     0.0151,     0.0057],\n",
      "        [    0.0303,     0.0446,     0.0694,     0.0520],\n",
      "        [    0.0212,     0.0279,     0.0510,     0.0188],\n",
      "        [    0.0419,     0.0530,     0.0221,     0.0080],\n",
      "        [    0.0694,     0.0541,     0.0293,     0.0218],\n",
      "        [    0.0623,     0.0547,     0.0380,     0.0439],\n",
      "        [    0.0323,     0.0503,     0.0418,     0.0143],\n",
      "        [    0.0597,     0.0437,     0.0401,     0.0028],\n",
      "        [    0.0480,     0.0434,     0.0434,     0.0070],\n",
      "        [    0.0349,     0.0501,     0.0419,     0.0211],\n",
      "        [    0.0570,     0.0410,     0.0443,     0.0203],\n",
      "        [    0.0459,     0.0266,     0.0492,     0.0642],\n",
      "        [    0.0697,     0.0668,     0.0529,     0.0246],\n",
      "        [    0.0418,     0.0570,     0.0549,     0.0741],\n",
      "        [    0.0709,     0.0484,     0.0427,     0.0672],\n",
      "        [    0.0179,     0.0504,     0.0893,     0.0645],\n",
      "        [    0.1105,     0.0357,     0.0199,     0.0464],\n",
      "        [    0.0552,     0.0865,     0.0840,     0.0409],\n",
      "        [    0.0572,     0.0726,     0.0892,     0.0639],\n",
      "        [    0.0627,     0.0645,     0.0751,     0.1014],\n",
      "        [    0.0935,     0.0831,     0.0640,     0.0669],\n",
      "        [    0.0900,     0.0631,     0.0900,     0.0797],\n",
      "        [    0.0793,     0.0649,     0.0778,     0.1078],\n",
      "        [    0.1086,     0.0712,     0.0530,     0.1104],\n",
      "        [    0.0005,     0.1035,     0.0366,     0.0032],\n",
      "        [    0.0701,     0.0891,     0.1029,     0.0000]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 30.297393321990967\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 65\n",
      "X 資料 torch.Size([42, 18])\n",
      "Y 資料 torch.Size([42, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.010950877331197262, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.5015, 0.5018, 0.4927, 0.4902])\n",
      "目前模型的Data torch.Size([65, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5707, 0.5757, 0.5729, 0.5965],\n",
      "        [0.5792, 0.5864, 0.5830, 0.6149],\n",
      "        [0.5744, 0.5802, 0.5772, 0.6042],\n",
      "        [0.5768, 0.5833, 0.5800, 0.6095],\n",
      "        [0.5686, 0.5731, 0.5705, 0.5920],\n",
      "        [0.5590, 0.5610, 0.5591, 0.5711],\n",
      "        [0.5526, 0.5531, 0.5518, 0.5576],\n",
      "        [0.5443, 0.5428, 0.5420, 0.5397],\n",
      "        [0.5421, 0.5397, 0.5392, 0.5345],\n",
      "        [0.5399, 0.5371, 0.5367, 0.5300],\n",
      "        [0.5422, 0.5401, 0.5396, 0.5352],\n",
      "        [0.5435, 0.5416, 0.5409, 0.5377],\n",
      "        [0.5459, 0.5447, 0.5438, 0.5430],\n",
      "        [0.5452, 0.5438, 0.5430, 0.5416],\n",
      "        [0.5595, 0.5616, 0.5597, 0.5722],\n",
      "        [0.5719, 0.5772, 0.5743, 0.5989],\n",
      "        [0.5734, 0.5791, 0.5761, 0.6022],\n",
      "        [0.5709, 0.5759, 0.5731, 0.5968],\n",
      "        [0.5771, 0.5837, 0.5804, 0.6102],\n",
      "        [0.5810, 0.5885, 0.5850, 0.6185],\n",
      "        [0.5445, 0.5430, 0.5422, 0.5401],\n",
      "        [0.5273, 0.5214, 0.5220, 0.5029],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5404, 0.5398, 0.5357],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5288, 0.5232, 0.5237, 0.5060],\n",
      "        [0.5569, 0.5585, 0.5568, 0.5668],\n",
      "        [0.5287, 0.5232, 0.5236, 0.5059],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5401, 0.5374, 0.5369, 0.5304],\n",
      "        [0.5405, 0.5380, 0.5375, 0.5314],\n",
      "        [0.5334, 0.5289, 0.5290, 0.5159],\n",
      "        [0.5424, 0.5402, 0.5396, 0.5352],\n",
      "        [0.5700, 0.5748, 0.5720, 0.5948],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5392, 0.5362, 0.5359, 0.5285],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5386, 0.5356, 0.5353, 0.5273],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5431, 0.5411, 0.5405, 0.5369],\n",
      "        [0.5376, 0.5343, 0.5341, 0.5252],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5255, 0.5191, 0.5198, 0.4989],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5405, 0.5399, 0.5358],\n",
      "        [0.5569, 0.5585, 0.5567, 0.5667],\n",
      "        [0.5579, 0.5596, 0.5578, 0.5687],\n",
      "        [0.5249, 0.5183, 0.5191, 0.4976],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5230, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5533, 0.5539, 0.5524, 0.5589],\n",
      "        [0.5739, 0.5797, 0.5766, 0.6032],\n",
      "        [0.5233, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5590, 0.5610, 0.5591, 0.5711],\n",
      "        [0.6132, 0.6291, 0.6230, 0.6883],\n",
      "        [0.3793, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.3588],\n",
      "        [0.5852, 0.5938, 0.5900, 0.6277]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0442,     0.0090,     0.0238,     0.0195],\n",
      "        [    0.0055,     0.0103,     0.0060,     0.0157],\n",
      "        [    0.0224,     0.0032,     0.0220,     0.0133],\n",
      "        [    0.0003,     0.0159,     0.0108,     0.0088],\n",
      "        [    0.0306,     0.0178,     0.0302,     0.0080],\n",
      "        [    0.0319,     0.0397,     0.0249,     0.0132],\n",
      "        [    0.0481,     0.0308,     0.0061,     0.0163],\n",
      "        [    0.0397,     0.0151,     0.0007,     0.0186],\n",
      "        [    0.0158,     0.0015,     0.0180,     0.0233],\n",
      "        [    0.0014,     0.0160,     0.0255,     0.0222],\n",
      "        [    0.0211,     0.0289,     0.0318,     0.0252],\n",
      "        [    0.0323,     0.0338,     0.0309,     0.0188],\n",
      "        [    0.0382,     0.0347,     0.0249,     0.0129],\n",
      "        [    0.0352,     0.0250,     0.0129,     0.0064],\n",
      "        [    0.0406,     0.0314,     0.0245,     0.0056],\n",
      "        [    0.0417,     0.0420,     0.0034,     0.0088],\n",
      "        [    0.0382,     0.0013,     0.0316,     0.0082],\n",
      "        [    0.0068,     0.0318,     0.0373,     0.0046],\n",
      "        [    0.0306,     0.0267,     0.0210,     0.0052],\n",
      "        [    0.0294,     0.0128,     0.0304,     0.0306],\n",
      "        [    0.0255,     0.0349,     0.0335,     0.0222],\n",
      "        [    0.0516,     0.0369,     0.0112,     0.0188],\n",
      "        [    0.0526,     0.0461,     0.0521,     0.0488],\n",
      "        [    0.0158,     0.0073,     0.0181,     0.0273],\n",
      "        [    0.0392,     0.0530,     0.0257,     0.0261],\n",
      "        [    0.0628,     0.0557,     0.0346,     0.0271],\n",
      "        [    0.0279,     0.0255,     0.0349,     0.0121],\n",
      "        [    0.0044,     0.0015,     0.0152,     0.0150],\n",
      "        [    0.0547,     0.0595,     0.0452,     0.0752],\n",
      "        [    0.0439,     0.0543,     0.0419,     0.0279],\n",
      "        [    0.0474,     0.0469,     0.0466,     0.0602],\n",
      "        [    0.0820,     0.0590,     0.0559,     0.0682],\n",
      "        [    0.0590,     0.0752,     0.0483,     0.0496],\n",
      "        [    0.0122,     0.0047,     0.0058,     0.0191],\n",
      "        [    0.0260,     0.0242,     0.0638,     0.1173],\n",
      "        [    0.0427,     0.0190,     0.0233,     0.0869],\n",
      "        [    0.0175,     0.0278,     0.0450,     0.0626],\n",
      "        [    0.0282,     0.0142,     0.0288,     0.0279],\n",
      "        [    0.0599,     0.0212,     0.0151,     0.0057],\n",
      "        [    0.0303,     0.0446,     0.0694,     0.0520],\n",
      "        [    0.0212,     0.0279,     0.0510,     0.0188],\n",
      "        [    0.0419,     0.0530,     0.0221,     0.0080],\n",
      "        [    0.0694,     0.0541,     0.0293,     0.0218],\n",
      "        [    0.0623,     0.0547,     0.0380,     0.0439],\n",
      "        [    0.0323,     0.0503,     0.0418,     0.0143],\n",
      "        [    0.0597,     0.0437,     0.0401,     0.0028],\n",
      "        [    0.0480,     0.0434,     0.0434,     0.0070],\n",
      "        [    0.0349,     0.0501,     0.0419,     0.0211],\n",
      "        [    0.0570,     0.0410,     0.0443,     0.0203],\n",
      "        [    0.0459,     0.0266,     0.0492,     0.0642],\n",
      "        [    0.0697,     0.0668,     0.0529,     0.0246],\n",
      "        [    0.0418,     0.0570,     0.0549,     0.0741],\n",
      "        [    0.0709,     0.0484,     0.0427,     0.0672],\n",
      "        [    0.0179,     0.0504,     0.0893,     0.0645],\n",
      "        [    0.1105,     0.0357,     0.0199,     0.0464],\n",
      "        [    0.0552,     0.0865,     0.0840,     0.0409],\n",
      "        [    0.0572,     0.0726,     0.0892,     0.0639],\n",
      "        [    0.0627,     0.0645,     0.0751,     0.1014],\n",
      "        [    0.0935,     0.0831,     0.0640,     0.0669],\n",
      "        [    0.0900,     0.0631,     0.0900,     0.0797],\n",
      "        [    0.0793,     0.0649,     0.0778,     0.1078],\n",
      "        [    0.1086,     0.0712,     0.0530,     0.1104],\n",
      "        [    0.0005,     0.1035,     0.0366,     0.0032],\n",
      "        [    0.0701,     0.0891,     0.1029,     0.0000],\n",
      "        [    0.0837,     0.0920,     0.0973,     0.1375]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0442,     0.0090,     0.0238,     0.0195],\n",
      "        [    0.0055,     0.0103,     0.0060,     0.0157],\n",
      "        [    0.0224,     0.0032,     0.0220,     0.0133],\n",
      "        [    0.0003,     0.0159,     0.0108,     0.0088],\n",
      "        [    0.0306,     0.0178,     0.0302,     0.0080],\n",
      "        [    0.0319,     0.0397,     0.0249,     0.0132],\n",
      "        [    0.0481,     0.0308,     0.0061,     0.0163],\n",
      "        [    0.0397,     0.0151,     0.0007,     0.0186],\n",
      "        [    0.0158,     0.0015,     0.0180,     0.0233],\n",
      "        [    0.0014,     0.0160,     0.0255,     0.0222],\n",
      "        [    0.0211,     0.0289,     0.0318,     0.0252],\n",
      "        [    0.0323,     0.0338,     0.0309,     0.0188],\n",
      "        [    0.0382,     0.0347,     0.0249,     0.0129],\n",
      "        [    0.0352,     0.0250,     0.0129,     0.0064],\n",
      "        [    0.0406,     0.0314,     0.0245,     0.0056],\n",
      "        [    0.0417,     0.0420,     0.0034,     0.0088],\n",
      "        [    0.0382,     0.0013,     0.0316,     0.0082],\n",
      "        [    0.0068,     0.0318,     0.0373,     0.0046],\n",
      "        [    0.0306,     0.0267,     0.0210,     0.0052],\n",
      "        [    0.0294,     0.0128,     0.0304,     0.0306],\n",
      "        [    0.0255,     0.0349,     0.0335,     0.0222],\n",
      "        [    0.0516,     0.0369,     0.0112,     0.0188],\n",
      "        [    0.0526,     0.0461,     0.0521,     0.0488],\n",
      "        [    0.0158,     0.0073,     0.0181,     0.0273],\n",
      "        [    0.0392,     0.0530,     0.0257,     0.0261],\n",
      "        [    0.0628,     0.0557,     0.0346,     0.0271],\n",
      "        [    0.0279,     0.0255,     0.0349,     0.0121],\n",
      "        [    0.0044,     0.0015,     0.0152,     0.0150],\n",
      "        [    0.0547,     0.0595,     0.0452,     0.0752],\n",
      "        [    0.0439,     0.0543,     0.0419,     0.0279],\n",
      "        [    0.0474,     0.0469,     0.0466,     0.0602],\n",
      "        [    0.0820,     0.0590,     0.0559,     0.0682],\n",
      "        [    0.0590,     0.0752,     0.0483,     0.0496],\n",
      "        [    0.0122,     0.0047,     0.0058,     0.0191],\n",
      "        [    0.0260,     0.0242,     0.0638,     0.1173],\n",
      "        [    0.0427,     0.0190,     0.0233,     0.0869],\n",
      "        [    0.0175,     0.0278,     0.0450,     0.0626],\n",
      "        [    0.0282,     0.0142,     0.0288,     0.0279],\n",
      "        [    0.0599,     0.0212,     0.0151,     0.0057],\n",
      "        [    0.0303,     0.0446,     0.0694,     0.0520],\n",
      "        [    0.0212,     0.0279,     0.0510,     0.0188],\n",
      "        [    0.0419,     0.0530,     0.0221,     0.0080],\n",
      "        [    0.0694,     0.0541,     0.0293,     0.0218],\n",
      "        [    0.0623,     0.0547,     0.0380,     0.0439],\n",
      "        [    0.0323,     0.0503,     0.0418,     0.0143],\n",
      "        [    0.0597,     0.0437,     0.0401,     0.0028],\n",
      "        [    0.0480,     0.0434,     0.0434,     0.0070],\n",
      "        [    0.0349,     0.0501,     0.0419,     0.0211],\n",
      "        [    0.0570,     0.0410,     0.0443,     0.0203],\n",
      "        [    0.0459,     0.0266,     0.0492,     0.0642],\n",
      "        [    0.0697,     0.0668,     0.0529,     0.0246],\n",
      "        [    0.0418,     0.0570,     0.0549,     0.0741],\n",
      "        [    0.0709,     0.0484,     0.0427,     0.0672],\n",
      "        [    0.0179,     0.0504,     0.0893,     0.0645],\n",
      "        [    0.1105,     0.0357,     0.0199,     0.0464],\n",
      "        [    0.0552,     0.0865,     0.0840,     0.0409],\n",
      "        [    0.0572,     0.0726,     0.0892,     0.0639],\n",
      "        [    0.0627,     0.0645,     0.0751,     0.1014],\n",
      "        [    0.0935,     0.0831,     0.0640,     0.0669],\n",
      "        [    0.0900,     0.0631,     0.0900,     0.0797],\n",
      "        [    0.0793,     0.0649,     0.0778,     0.1078],\n",
      "        [    0.1086,     0.0712,     0.0530,     0.1104],\n",
      "        [    0.0005,     0.1035,     0.0366,     0.0032],\n",
      "        [    0.0701,     0.0891,     0.1029,     0.0000],\n",
      "        [    0.0837,     0.0920,     0.0973,     0.1375]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.11750881 0.11750881 0.11750881 0.11750881]\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "The index of the undesired data: tensor([[64,  3]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0442,     0.0090,     0.0238,     0.0195],\n",
      "        [    0.0055,     0.0103,     0.0060,     0.0157],\n",
      "        [    0.0224,     0.0032,     0.0220,     0.0133],\n",
      "        [    0.0003,     0.0159,     0.0108,     0.0088],\n",
      "        [    0.0306,     0.0178,     0.0302,     0.0080],\n",
      "        [    0.0319,     0.0397,     0.0249,     0.0132],\n",
      "        [    0.0481,     0.0308,     0.0061,     0.0163],\n",
      "        [    0.0397,     0.0151,     0.0007,     0.0186],\n",
      "        [    0.0158,     0.0015,     0.0180,     0.0233],\n",
      "        [    0.0014,     0.0160,     0.0255,     0.0222],\n",
      "        [    0.0211,     0.0289,     0.0318,     0.0252],\n",
      "        [    0.0323,     0.0338,     0.0309,     0.0188],\n",
      "        [    0.0382,     0.0347,     0.0249,     0.0129],\n",
      "        [    0.0352,     0.0250,     0.0129,     0.0064],\n",
      "        [    0.0406,     0.0314,     0.0245,     0.0056],\n",
      "        [    0.0417,     0.0420,     0.0034,     0.0088],\n",
      "        [    0.0382,     0.0013,     0.0316,     0.0082],\n",
      "        [    0.0068,     0.0318,     0.0373,     0.0046],\n",
      "        [    0.0306,     0.0267,     0.0210,     0.0052],\n",
      "        [    0.0294,     0.0128,     0.0304,     0.0306],\n",
      "        [    0.0255,     0.0349,     0.0335,     0.0222],\n",
      "        [    0.0516,     0.0369,     0.0112,     0.0188],\n",
      "        [    0.0526,     0.0461,     0.0521,     0.0488],\n",
      "        [    0.0158,     0.0073,     0.0181,     0.0273],\n",
      "        [    0.0392,     0.0530,     0.0257,     0.0261],\n",
      "        [    0.0628,     0.0557,     0.0346,     0.0271],\n",
      "        [    0.0279,     0.0255,     0.0349,     0.0121],\n",
      "        [    0.0044,     0.0015,     0.0152,     0.0150],\n",
      "        [    0.0547,     0.0595,     0.0452,     0.0752],\n",
      "        [    0.0439,     0.0543,     0.0419,     0.0279],\n",
      "        [    0.0474,     0.0469,     0.0466,     0.0602],\n",
      "        [    0.0820,     0.0590,     0.0559,     0.0682],\n",
      "        [    0.0590,     0.0752,     0.0483,     0.0496],\n",
      "        [    0.0122,     0.0047,     0.0058,     0.0191],\n",
      "        [    0.0260,     0.0242,     0.0638,     0.1173],\n",
      "        [    0.0427,     0.0190,     0.0233,     0.0869],\n",
      "        [    0.0175,     0.0278,     0.0450,     0.0626],\n",
      "        [    0.0282,     0.0142,     0.0288,     0.0279],\n",
      "        [    0.0599,     0.0212,     0.0151,     0.0057],\n",
      "        [    0.0303,     0.0446,     0.0694,     0.0520],\n",
      "        [    0.0212,     0.0279,     0.0510,     0.0188],\n",
      "        [    0.0419,     0.0530,     0.0221,     0.0080],\n",
      "        [    0.0694,     0.0541,     0.0293,     0.0218],\n",
      "        [    0.0623,     0.0547,     0.0380,     0.0439],\n",
      "        [    0.0323,     0.0503,     0.0418,     0.0143],\n",
      "        [    0.0597,     0.0437,     0.0401,     0.0028],\n",
      "        [    0.0480,     0.0434,     0.0434,     0.0070],\n",
      "        [    0.0349,     0.0501,     0.0419,     0.0211],\n",
      "        [    0.0570,     0.0410,     0.0443,     0.0203],\n",
      "        [    0.0459,     0.0266,     0.0492,     0.0642],\n",
      "        [    0.0697,     0.0668,     0.0529,     0.0246],\n",
      "        [    0.0418,     0.0570,     0.0549,     0.0741],\n",
      "        [    0.0709,     0.0484,     0.0427,     0.0672],\n",
      "        [    0.0179,     0.0504,     0.0893,     0.0645],\n",
      "        [    0.1105,     0.0357,     0.0199,     0.0464],\n",
      "        [    0.0552,     0.0865,     0.0840,     0.0409],\n",
      "        [    0.0572,     0.0726,     0.0892,     0.0639],\n",
      "        [    0.0627,     0.0645,     0.0751,     0.1014],\n",
      "        [    0.0935,     0.0831,     0.0640,     0.0669],\n",
      "        [    0.0900,     0.0631,     0.0900,     0.0797],\n",
      "        [    0.0793,     0.0649,     0.0778,     0.1078],\n",
      "        [    0.1086,     0.0712,     0.0530,     0.1104],\n",
      "        [    0.0005,     0.1035,     0.0366,     0.0032],\n",
      "        [    0.0701,     0.0891,     0.1029,     0.0000],\n",
      "        [    0.0837,     0.0920,     0.0973,     0.0000]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 658\n",
      "Number of shrink: 342\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 30\n",
      "Number of shrink: 22\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 659\n",
      "Number of shrink: 341\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0442,     0.0090,     0.0238,     0.0195],\n",
      "        [    0.0055,     0.0103,     0.0060,     0.0157],\n",
      "        [    0.0224,     0.0032,     0.0220,     0.0133],\n",
      "        [    0.0003,     0.0159,     0.0108,     0.0088],\n",
      "        [    0.0306,     0.0178,     0.0302,     0.0080],\n",
      "        [    0.0319,     0.0397,     0.0249,     0.0132],\n",
      "        [    0.0481,     0.0308,     0.0061,     0.0163],\n",
      "        [    0.0397,     0.0151,     0.0007,     0.0186],\n",
      "        [    0.0158,     0.0015,     0.0180,     0.0233],\n",
      "        [    0.0014,     0.0160,     0.0255,     0.0222],\n",
      "        [    0.0211,     0.0289,     0.0318,     0.0252],\n",
      "        [    0.0323,     0.0338,     0.0309,     0.0188],\n",
      "        [    0.0382,     0.0347,     0.0249,     0.0129],\n",
      "        [    0.0352,     0.0250,     0.0129,     0.0064],\n",
      "        [    0.0406,     0.0314,     0.0245,     0.0056],\n",
      "        [    0.0417,     0.0420,     0.0034,     0.0088],\n",
      "        [    0.0382,     0.0013,     0.0316,     0.0082],\n",
      "        [    0.0068,     0.0318,     0.0373,     0.0046],\n",
      "        [    0.0306,     0.0267,     0.0210,     0.0052],\n",
      "        [    0.0294,     0.0128,     0.0304,     0.0306],\n",
      "        [    0.0255,     0.0349,     0.0335,     0.0222],\n",
      "        [    0.0516,     0.0369,     0.0112,     0.0188],\n",
      "        [    0.0526,     0.0461,     0.0521,     0.0488],\n",
      "        [    0.0158,     0.0073,     0.0181,     0.0273],\n",
      "        [    0.0392,     0.0530,     0.0257,     0.0261],\n",
      "        [    0.0628,     0.0557,     0.0346,     0.0271],\n",
      "        [    0.0279,     0.0255,     0.0349,     0.0121],\n",
      "        [    0.0044,     0.0015,     0.0152,     0.0150],\n",
      "        [    0.0547,     0.0595,     0.0452,     0.0752],\n",
      "        [    0.0439,     0.0543,     0.0419,     0.0279],\n",
      "        [    0.0474,     0.0469,     0.0466,     0.0602],\n",
      "        [    0.0820,     0.0590,     0.0559,     0.0682],\n",
      "        [    0.0590,     0.0752,     0.0483,     0.0496],\n",
      "        [    0.0122,     0.0047,     0.0058,     0.0191],\n",
      "        [    0.0260,     0.0242,     0.0638,     0.1173],\n",
      "        [    0.0427,     0.0190,     0.0233,     0.0869],\n",
      "        [    0.0175,     0.0278,     0.0450,     0.0626],\n",
      "        [    0.0282,     0.0142,     0.0288,     0.0279],\n",
      "        [    0.0599,     0.0212,     0.0151,     0.0057],\n",
      "        [    0.0303,     0.0446,     0.0694,     0.0520],\n",
      "        [    0.0212,     0.0279,     0.0510,     0.0188],\n",
      "        [    0.0419,     0.0530,     0.0221,     0.0080],\n",
      "        [    0.0694,     0.0541,     0.0293,     0.0218],\n",
      "        [    0.0623,     0.0547,     0.0380,     0.0439],\n",
      "        [    0.0323,     0.0503,     0.0418,     0.0143],\n",
      "        [    0.0597,     0.0437,     0.0401,     0.0028],\n",
      "        [    0.0480,     0.0434,     0.0434,     0.0070],\n",
      "        [    0.0349,     0.0501,     0.0419,     0.0211],\n",
      "        [    0.0570,     0.0410,     0.0443,     0.0203],\n",
      "        [    0.0459,     0.0266,     0.0492,     0.0642],\n",
      "        [    0.0697,     0.0668,     0.0529,     0.0246],\n",
      "        [    0.0418,     0.0570,     0.0549,     0.0741],\n",
      "        [    0.0709,     0.0484,     0.0427,     0.0672],\n",
      "        [    0.0179,     0.0504,     0.0893,     0.0645],\n",
      "        [    0.1105,     0.0357,     0.0199,     0.0464],\n",
      "        [    0.0552,     0.0865,     0.0840,     0.0409],\n",
      "        [    0.0572,     0.0726,     0.0892,     0.0639],\n",
      "        [    0.0627,     0.0645,     0.0751,     0.1014],\n",
      "        [    0.0935,     0.0831,     0.0640,     0.0669],\n",
      "        [    0.0900,     0.0631,     0.0900,     0.0797],\n",
      "        [    0.0793,     0.0649,     0.0778,     0.1078],\n",
      "        [    0.1086,     0.0712,     0.0530,     0.1104],\n",
      "        [    0.0005,     0.1035,     0.0366,     0.0032],\n",
      "        [    0.0701,     0.0891,     0.1029,     0.0000],\n",
      "        [    0.0837,     0.0920,     0.0973,     0.0000]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 36.00832676887512\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 66\n",
      "X 資料 torch.Size([41, 18])\n",
      "Y 資料 torch.Size([41, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.013031808659434319, 21)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引21，y= tensor([0.3743, 0.3787, 0.4127, 0.4805])\n",
      "目前模型的Data torch.Size([66, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5707, 0.5757, 0.5729, 0.5965],\n",
      "        [0.5792, 0.5864, 0.5830, 0.6149],\n",
      "        [0.5744, 0.5802, 0.5772, 0.6042],\n",
      "        [0.5768, 0.5833, 0.5800, 0.6095],\n",
      "        [0.5686, 0.5731, 0.5705, 0.5920],\n",
      "        [0.5590, 0.5610, 0.5591, 0.5711],\n",
      "        [0.5526, 0.5531, 0.5518, 0.5576],\n",
      "        [0.5443, 0.5428, 0.5420, 0.5397],\n",
      "        [0.5421, 0.5397, 0.5392, 0.5345],\n",
      "        [0.5399, 0.5371, 0.5367, 0.5300],\n",
      "        [0.5422, 0.5401, 0.5396, 0.5352],\n",
      "        [0.5435, 0.5416, 0.5409, 0.5377],\n",
      "        [0.5459, 0.5447, 0.5438, 0.5430],\n",
      "        [0.5452, 0.5438, 0.5430, 0.5416],\n",
      "        [0.5595, 0.5616, 0.5597, 0.5722],\n",
      "        [0.5719, 0.5772, 0.5743, 0.5989],\n",
      "        [0.5734, 0.5791, 0.5761, 0.6022],\n",
      "        [0.5709, 0.5759, 0.5731, 0.5968],\n",
      "        [0.5771, 0.5837, 0.5804, 0.6102],\n",
      "        [0.5810, 0.5885, 0.5850, 0.6185],\n",
      "        [0.5445, 0.5430, 0.5422, 0.5401],\n",
      "        [0.5273, 0.5214, 0.5220, 0.5029],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5404, 0.5398, 0.5357],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4940],\n",
      "        [0.5288, 0.5232, 0.5237, 0.5060],\n",
      "        [0.5569, 0.5585, 0.5568, 0.5668],\n",
      "        [0.5287, 0.5232, 0.5236, 0.5059],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5401, 0.5374, 0.5369, 0.5304],\n",
      "        [0.5405, 0.5380, 0.5375, 0.5314],\n",
      "        [0.5334, 0.5289, 0.5290, 0.5159],\n",
      "        [0.5424, 0.5402, 0.5396, 0.5352],\n",
      "        [0.5700, 0.5748, 0.5720, 0.5948],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5392, 0.5362, 0.5359, 0.5285],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5386, 0.5356, 0.5353, 0.5273],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5431, 0.5411, 0.5405, 0.5369],\n",
      "        [0.5376, 0.5343, 0.5341, 0.5252],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5255, 0.5191, 0.5198, 0.4989],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5405, 0.5399, 0.5358],\n",
      "        [0.5569, 0.5585, 0.5567, 0.5667],\n",
      "        [0.5579, 0.5596, 0.5578, 0.5687],\n",
      "        [0.5249, 0.5183, 0.5191, 0.4976],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5230, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5533, 0.5539, 0.5524, 0.5589],\n",
      "        [0.5739, 0.5797, 0.5766, 0.6032],\n",
      "        [0.5233, 0.5162, 0.5171, 0.4940],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5590, 0.5610, 0.5591, 0.5711],\n",
      "        [0.6132, 0.6291, 0.6230, 0.6883],\n",
      "        [0.3793, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.3588],\n",
      "        [0.5852, 0.5938, 0.5900, 0.4902],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0442,     0.0090,     0.0238,     0.0195],\n",
      "        [    0.0055,     0.0103,     0.0060,     0.0157],\n",
      "        [    0.0224,     0.0032,     0.0220,     0.0133],\n",
      "        [    0.0003,     0.0159,     0.0108,     0.0088],\n",
      "        [    0.0306,     0.0178,     0.0302,     0.0080],\n",
      "        [    0.0319,     0.0397,     0.0249,     0.0132],\n",
      "        [    0.0481,     0.0308,     0.0061,     0.0163],\n",
      "        [    0.0397,     0.0151,     0.0007,     0.0186],\n",
      "        [    0.0158,     0.0015,     0.0180,     0.0233],\n",
      "        [    0.0014,     0.0160,     0.0255,     0.0222],\n",
      "        [    0.0211,     0.0289,     0.0318,     0.0252],\n",
      "        [    0.0323,     0.0338,     0.0309,     0.0188],\n",
      "        [    0.0382,     0.0347,     0.0249,     0.0129],\n",
      "        [    0.0352,     0.0250,     0.0129,     0.0064],\n",
      "        [    0.0406,     0.0314,     0.0245,     0.0056],\n",
      "        [    0.0417,     0.0420,     0.0034,     0.0088],\n",
      "        [    0.0382,     0.0013,     0.0316,     0.0082],\n",
      "        [    0.0068,     0.0318,     0.0373,     0.0046],\n",
      "        [    0.0306,     0.0267,     0.0210,     0.0052],\n",
      "        [    0.0294,     0.0128,     0.0304,     0.0306],\n",
      "        [    0.0255,     0.0349,     0.0335,     0.0222],\n",
      "        [    0.0516,     0.0369,     0.0112,     0.0188],\n",
      "        [    0.0526,     0.0461,     0.0521,     0.0488],\n",
      "        [    0.0158,     0.0073,     0.0181,     0.0273],\n",
      "        [    0.0392,     0.0530,     0.0257,     0.0261],\n",
      "        [    0.0628,     0.0557,     0.0346,     0.0271],\n",
      "        [    0.0279,     0.0255,     0.0349,     0.0121],\n",
      "        [    0.0044,     0.0015,     0.0152,     0.0150],\n",
      "        [    0.0547,     0.0595,     0.0452,     0.0752],\n",
      "        [    0.0439,     0.0543,     0.0419,     0.0279],\n",
      "        [    0.0474,     0.0469,     0.0466,     0.0602],\n",
      "        [    0.0820,     0.0590,     0.0559,     0.0682],\n",
      "        [    0.0590,     0.0752,     0.0483,     0.0496],\n",
      "        [    0.0122,     0.0047,     0.0058,     0.0191],\n",
      "        [    0.0260,     0.0242,     0.0638,     0.1173],\n",
      "        [    0.0427,     0.0190,     0.0233,     0.0869],\n",
      "        [    0.0175,     0.0278,     0.0450,     0.0626],\n",
      "        [    0.0282,     0.0142,     0.0288,     0.0279],\n",
      "        [    0.0599,     0.0212,     0.0151,     0.0057],\n",
      "        [    0.0303,     0.0446,     0.0694,     0.0520],\n",
      "        [    0.0212,     0.0279,     0.0510,     0.0188],\n",
      "        [    0.0419,     0.0530,     0.0221,     0.0080],\n",
      "        [    0.0694,     0.0541,     0.0293,     0.0218],\n",
      "        [    0.0623,     0.0547,     0.0380,     0.0439],\n",
      "        [    0.0323,     0.0503,     0.0418,     0.0143],\n",
      "        [    0.0597,     0.0437,     0.0401,     0.0028],\n",
      "        [    0.0480,     0.0434,     0.0434,     0.0070],\n",
      "        [    0.0349,     0.0501,     0.0419,     0.0211],\n",
      "        [    0.0570,     0.0410,     0.0443,     0.0203],\n",
      "        [    0.0459,     0.0266,     0.0492,     0.0642],\n",
      "        [    0.0697,     0.0668,     0.0529,     0.0246],\n",
      "        [    0.0418,     0.0570,     0.0549,     0.0741],\n",
      "        [    0.0709,     0.0484,     0.0427,     0.0672],\n",
      "        [    0.0179,     0.0504,     0.0893,     0.0645],\n",
      "        [    0.1105,     0.0357,     0.0199,     0.0464],\n",
      "        [    0.0552,     0.0865,     0.0840,     0.0409],\n",
      "        [    0.0572,     0.0726,     0.0892,     0.0639],\n",
      "        [    0.0627,     0.0645,     0.0751,     0.1014],\n",
      "        [    0.0935,     0.0831,     0.0640,     0.0669],\n",
      "        [    0.0900,     0.0631,     0.0900,     0.0797],\n",
      "        [    0.0793,     0.0649,     0.0778,     0.1078],\n",
      "        [    0.1086,     0.0712,     0.0530,     0.1104],\n",
      "        [    0.0005,     0.1035,     0.0366,     0.0032],\n",
      "        [    0.0701,     0.0891,     0.1029,     0.0000],\n",
      "        [    0.0837,     0.0920,     0.0973,     0.0000],\n",
      "        [    0.1488,     0.1375,     0.1044,     0.0135]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0442,     0.0090,     0.0238,     0.0195],\n",
      "        [    0.0055,     0.0103,     0.0060,     0.0157],\n",
      "        [    0.0224,     0.0032,     0.0220,     0.0133],\n",
      "        [    0.0003,     0.0159,     0.0108,     0.0088],\n",
      "        [    0.0306,     0.0178,     0.0302,     0.0080],\n",
      "        [    0.0319,     0.0397,     0.0249,     0.0132],\n",
      "        [    0.0481,     0.0308,     0.0061,     0.0163],\n",
      "        [    0.0397,     0.0151,     0.0007,     0.0186],\n",
      "        [    0.0158,     0.0015,     0.0180,     0.0233],\n",
      "        [    0.0014,     0.0160,     0.0255,     0.0222],\n",
      "        [    0.0211,     0.0289,     0.0318,     0.0252],\n",
      "        [    0.0323,     0.0338,     0.0309,     0.0188],\n",
      "        [    0.0382,     0.0347,     0.0249,     0.0129],\n",
      "        [    0.0352,     0.0250,     0.0129,     0.0064],\n",
      "        [    0.0406,     0.0314,     0.0245,     0.0056],\n",
      "        [    0.0417,     0.0420,     0.0034,     0.0088],\n",
      "        [    0.0382,     0.0013,     0.0316,     0.0082],\n",
      "        [    0.0068,     0.0318,     0.0373,     0.0046],\n",
      "        [    0.0306,     0.0267,     0.0210,     0.0052],\n",
      "        [    0.0294,     0.0128,     0.0304,     0.0306],\n",
      "        [    0.0255,     0.0349,     0.0335,     0.0222],\n",
      "        [    0.0516,     0.0369,     0.0112,     0.0188],\n",
      "        [    0.0526,     0.0461,     0.0521,     0.0488],\n",
      "        [    0.0158,     0.0073,     0.0181,     0.0273],\n",
      "        [    0.0392,     0.0530,     0.0257,     0.0261],\n",
      "        [    0.0628,     0.0557,     0.0346,     0.0271],\n",
      "        [    0.0279,     0.0255,     0.0349,     0.0121],\n",
      "        [    0.0044,     0.0015,     0.0152,     0.0150],\n",
      "        [    0.0547,     0.0595,     0.0452,     0.0752],\n",
      "        [    0.0439,     0.0543,     0.0419,     0.0279],\n",
      "        [    0.0474,     0.0469,     0.0466,     0.0602],\n",
      "        [    0.0820,     0.0590,     0.0559,     0.0682],\n",
      "        [    0.0590,     0.0752,     0.0483,     0.0496],\n",
      "        [    0.0122,     0.0047,     0.0058,     0.0191],\n",
      "        [    0.0260,     0.0242,     0.0638,     0.1173],\n",
      "        [    0.0427,     0.0190,     0.0233,     0.0869],\n",
      "        [    0.0175,     0.0278,     0.0450,     0.0626],\n",
      "        [    0.0282,     0.0142,     0.0288,     0.0279],\n",
      "        [    0.0599,     0.0212,     0.0151,     0.0057],\n",
      "        [    0.0303,     0.0446,     0.0694,     0.0520],\n",
      "        [    0.0212,     0.0279,     0.0510,     0.0188],\n",
      "        [    0.0419,     0.0530,     0.0221,     0.0080],\n",
      "        [    0.0694,     0.0541,     0.0293,     0.0218],\n",
      "        [    0.0623,     0.0547,     0.0380,     0.0439],\n",
      "        [    0.0323,     0.0503,     0.0418,     0.0143],\n",
      "        [    0.0597,     0.0437,     0.0401,     0.0028],\n",
      "        [    0.0480,     0.0434,     0.0434,     0.0070],\n",
      "        [    0.0349,     0.0501,     0.0419,     0.0211],\n",
      "        [    0.0570,     0.0410,     0.0443,     0.0203],\n",
      "        [    0.0459,     0.0266,     0.0492,     0.0642],\n",
      "        [    0.0697,     0.0668,     0.0529,     0.0246],\n",
      "        [    0.0418,     0.0570,     0.0549,     0.0741],\n",
      "        [    0.0709,     0.0484,     0.0427,     0.0672],\n",
      "        [    0.0179,     0.0504,     0.0893,     0.0645],\n",
      "        [    0.1105,     0.0357,     0.0199,     0.0464],\n",
      "        [    0.0552,     0.0865,     0.0840,     0.0409],\n",
      "        [    0.0572,     0.0726,     0.0892,     0.0639],\n",
      "        [    0.0627,     0.0645,     0.0751,     0.1014],\n",
      "        [    0.0935,     0.0831,     0.0640,     0.0669],\n",
      "        [    0.0900,     0.0631,     0.0900,     0.0797],\n",
      "        [    0.0793,     0.0649,     0.0778,     0.1078],\n",
      "        [    0.1086,     0.0712,     0.0530,     0.1104],\n",
      "        [    0.0005,     0.1035,     0.0366,     0.0032],\n",
      "        [    0.0701,     0.0891,     0.1029,     0.0000],\n",
      "        [    0.0837,     0.0920,     0.0973,     0.0000],\n",
      "        [    0.1488,     0.1375,     0.1044,     0.0135]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.11750881 0.11750881 0.11750881 0.11750881]\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "The index of the undesired data: tensor([[65,  0],\n",
      "        [65,  1]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0442,     0.0090,     0.0238,     0.0195],\n",
      "        [    0.0055,     0.0103,     0.0060,     0.0157],\n",
      "        [    0.0224,     0.0032,     0.0220,     0.0133],\n",
      "        [    0.0003,     0.0159,     0.0108,     0.0088],\n",
      "        [    0.0306,     0.0178,     0.0302,     0.0080],\n",
      "        [    0.0319,     0.0397,     0.0249,     0.0132],\n",
      "        [    0.0481,     0.0308,     0.0061,     0.0163],\n",
      "        [    0.0397,     0.0151,     0.0007,     0.0186],\n",
      "        [    0.0158,     0.0015,     0.0180,     0.0233],\n",
      "        [    0.0014,     0.0160,     0.0255,     0.0222],\n",
      "        [    0.0211,     0.0289,     0.0318,     0.0252],\n",
      "        [    0.0323,     0.0338,     0.0309,     0.0188],\n",
      "        [    0.0382,     0.0347,     0.0249,     0.0129],\n",
      "        [    0.0352,     0.0250,     0.0129,     0.0064],\n",
      "        [    0.0406,     0.0314,     0.0245,     0.0056],\n",
      "        [    0.0417,     0.0420,     0.0034,     0.0088],\n",
      "        [    0.0382,     0.0013,     0.0316,     0.0082],\n",
      "        [    0.0068,     0.0318,     0.0373,     0.0046],\n",
      "        [    0.0306,     0.0267,     0.0210,     0.0052],\n",
      "        [    0.0294,     0.0128,     0.0304,     0.0306],\n",
      "        [    0.0255,     0.0349,     0.0335,     0.0222],\n",
      "        [    0.0516,     0.0369,     0.0112,     0.0188],\n",
      "        [    0.0526,     0.0461,     0.0521,     0.0488],\n",
      "        [    0.0158,     0.0073,     0.0181,     0.0273],\n",
      "        [    0.0392,     0.0530,     0.0257,     0.0261],\n",
      "        [    0.0628,     0.0557,     0.0346,     0.0271],\n",
      "        [    0.0279,     0.0255,     0.0349,     0.0121],\n",
      "        [    0.0044,     0.0015,     0.0152,     0.0150],\n",
      "        [    0.0547,     0.0595,     0.0452,     0.0752],\n",
      "        [    0.0439,     0.0543,     0.0419,     0.0279],\n",
      "        [    0.0474,     0.0469,     0.0466,     0.0602],\n",
      "        [    0.0820,     0.0590,     0.0559,     0.0682],\n",
      "        [    0.0590,     0.0752,     0.0483,     0.0496],\n",
      "        [    0.0122,     0.0047,     0.0058,     0.0191],\n",
      "        [    0.0260,     0.0242,     0.0638,     0.1173],\n",
      "        [    0.0427,     0.0190,     0.0233,     0.0869],\n",
      "        [    0.0175,     0.0278,     0.0450,     0.0626],\n",
      "        [    0.0282,     0.0142,     0.0288,     0.0279],\n",
      "        [    0.0599,     0.0212,     0.0151,     0.0057],\n",
      "        [    0.0303,     0.0446,     0.0694,     0.0520],\n",
      "        [    0.0212,     0.0279,     0.0510,     0.0188],\n",
      "        [    0.0419,     0.0530,     0.0221,     0.0080],\n",
      "        [    0.0694,     0.0541,     0.0293,     0.0218],\n",
      "        [    0.0623,     0.0547,     0.0380,     0.0439],\n",
      "        [    0.0323,     0.0503,     0.0418,     0.0143],\n",
      "        [    0.0597,     0.0437,     0.0401,     0.0028],\n",
      "        [    0.0480,     0.0434,     0.0434,     0.0070],\n",
      "        [    0.0349,     0.0501,     0.0419,     0.0211],\n",
      "        [    0.0570,     0.0410,     0.0443,     0.0203],\n",
      "        [    0.0459,     0.0266,     0.0492,     0.0642],\n",
      "        [    0.0697,     0.0668,     0.0529,     0.0246],\n",
      "        [    0.0418,     0.0570,     0.0549,     0.0741],\n",
      "        [    0.0709,     0.0484,     0.0427,     0.0672],\n",
      "        [    0.0179,     0.0504,     0.0893,     0.0645],\n",
      "        [    0.1105,     0.0357,     0.0199,     0.0464],\n",
      "        [    0.0552,     0.0865,     0.0840,     0.0409],\n",
      "        [    0.0572,     0.0726,     0.0892,     0.0639],\n",
      "        [    0.0627,     0.0645,     0.0751,     0.1014],\n",
      "        [    0.0935,     0.0831,     0.0640,     0.0669],\n",
      "        [    0.0900,     0.0631,     0.0900,     0.0797],\n",
      "        [    0.0793,     0.0649,     0.0778,     0.1078],\n",
      "        [    0.1086,     0.0712,     0.0530,     0.1104],\n",
      "        [    0.0005,     0.1035,     0.0366,     0.0032],\n",
      "        [    0.0701,     0.0891,     0.1029,     0.0000],\n",
      "        [    0.0837,     0.0920,     0.0973,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.1044,     0.0135]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 658\n",
      "Number of shrink: 342\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 2 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 255\n",
      "Number of shrink: 137\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 3 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 658\n",
      "Number of shrink: 342\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 4 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 5 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 6 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 7 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 8 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 9 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 10 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 1\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 11 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 2\n",
      "Number of shrink: 8\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 12 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 1\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 13 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 14 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 15 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 16 / 16\n",
      "Reorganizing result: The final number of neuro is  16\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0442,     0.0090,     0.0238,     0.0195],\n",
      "        [    0.0055,     0.0103,     0.0060,     0.0157],\n",
      "        [    0.0224,     0.0032,     0.0220,     0.0133],\n",
      "        [    0.0003,     0.0159,     0.0108,     0.0088],\n",
      "        [    0.0306,     0.0178,     0.0302,     0.0080],\n",
      "        [    0.0319,     0.0397,     0.0249,     0.0132],\n",
      "        [    0.0481,     0.0308,     0.0061,     0.0163],\n",
      "        [    0.0397,     0.0151,     0.0007,     0.0186],\n",
      "        [    0.0158,     0.0015,     0.0180,     0.0233],\n",
      "        [    0.0014,     0.0160,     0.0255,     0.0222],\n",
      "        [    0.0211,     0.0289,     0.0318,     0.0252],\n",
      "        [    0.0323,     0.0338,     0.0309,     0.0188],\n",
      "        [    0.0382,     0.0347,     0.0249,     0.0129],\n",
      "        [    0.0352,     0.0250,     0.0129,     0.0064],\n",
      "        [    0.0406,     0.0314,     0.0245,     0.0056],\n",
      "        [    0.0417,     0.0420,     0.0034,     0.0088],\n",
      "        [    0.0382,     0.0013,     0.0316,     0.0082],\n",
      "        [    0.0068,     0.0318,     0.0373,     0.0046],\n",
      "        [    0.0306,     0.0267,     0.0210,     0.0052],\n",
      "        [    0.0294,     0.0128,     0.0304,     0.0306],\n",
      "        [    0.0255,     0.0349,     0.0335,     0.0222],\n",
      "        [    0.0516,     0.0369,     0.0112,     0.0188],\n",
      "        [    0.0526,     0.0461,     0.0521,     0.0488],\n",
      "        [    0.0158,     0.0073,     0.0181,     0.0273],\n",
      "        [    0.0392,     0.0530,     0.0257,     0.0261],\n",
      "        [    0.0628,     0.0557,     0.0346,     0.0271],\n",
      "        [    0.0279,     0.0255,     0.0349,     0.0121],\n",
      "        [    0.0044,     0.0015,     0.0152,     0.0150],\n",
      "        [    0.0547,     0.0595,     0.0452,     0.0752],\n",
      "        [    0.0439,     0.0543,     0.0419,     0.0279],\n",
      "        [    0.0474,     0.0469,     0.0466,     0.0602],\n",
      "        [    0.0820,     0.0590,     0.0559,     0.0682],\n",
      "        [    0.0590,     0.0752,     0.0483,     0.0496],\n",
      "        [    0.0122,     0.0047,     0.0058,     0.0191],\n",
      "        [    0.0260,     0.0242,     0.0638,     0.1173],\n",
      "        [    0.0427,     0.0190,     0.0233,     0.0869],\n",
      "        [    0.0175,     0.0278,     0.0450,     0.0626],\n",
      "        [    0.0282,     0.0142,     0.0288,     0.0279],\n",
      "        [    0.0599,     0.0212,     0.0151,     0.0057],\n",
      "        [    0.0303,     0.0446,     0.0694,     0.0520],\n",
      "        [    0.0212,     0.0279,     0.0510,     0.0188],\n",
      "        [    0.0419,     0.0530,     0.0221,     0.0080],\n",
      "        [    0.0694,     0.0541,     0.0293,     0.0218],\n",
      "        [    0.0623,     0.0547,     0.0380,     0.0439],\n",
      "        [    0.0323,     0.0503,     0.0418,     0.0143],\n",
      "        [    0.0597,     0.0437,     0.0401,     0.0028],\n",
      "        [    0.0480,     0.0434,     0.0434,     0.0070],\n",
      "        [    0.0349,     0.0501,     0.0419,     0.0211],\n",
      "        [    0.0570,     0.0410,     0.0443,     0.0203],\n",
      "        [    0.0459,     0.0266,     0.0492,     0.0642],\n",
      "        [    0.0697,     0.0668,     0.0529,     0.0246],\n",
      "        [    0.0418,     0.0570,     0.0549,     0.0741],\n",
      "        [    0.0709,     0.0484,     0.0427,     0.0672],\n",
      "        [    0.0179,     0.0504,     0.0893,     0.0645],\n",
      "        [    0.1105,     0.0357,     0.0199,     0.0464],\n",
      "        [    0.0552,     0.0865,     0.0840,     0.0409],\n",
      "        [    0.0572,     0.0726,     0.0892,     0.0639],\n",
      "        [    0.0627,     0.0645,     0.0751,     0.1014],\n",
      "        [    0.0935,     0.0831,     0.0640,     0.0669],\n",
      "        [    0.0900,     0.0631,     0.0900,     0.0797],\n",
      "        [    0.0793,     0.0649,     0.0778,     0.1078],\n",
      "        [    0.1086,     0.0712,     0.0530,     0.1104],\n",
      "        [    0.0005,     0.1035,     0.0366,     0.0032],\n",
      "        [    0.0701,     0.0891,     0.1029,     0.0000],\n",
      "        [    0.0837,     0.0920,     0.0973,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.1044,     0.0135]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 43.822471618652344\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 67\n",
      "X 資料 torch.Size([40, 18])\n",
      "Y 資料 torch.Size([40, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.008251756429672241, 20)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引20，y= tensor([0.3566, 0.3743, 0.3787, 0.4127])\n",
      "目前模型的Data torch.Size([67, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5707, 0.5757, 0.5729, 0.5965],\n",
      "        [0.5792, 0.5864, 0.5830, 0.6149],\n",
      "        [0.5744, 0.5802, 0.5772, 0.6042],\n",
      "        [0.5768, 0.5833, 0.5800, 0.6095],\n",
      "        [0.5686, 0.5731, 0.5705, 0.5920],\n",
      "        [0.5590, 0.5610, 0.5591, 0.5711],\n",
      "        [0.5526, 0.5531, 0.5518, 0.5576],\n",
      "        [0.5443, 0.5428, 0.5420, 0.5397],\n",
      "        [0.5421, 0.5397, 0.5392, 0.5345],\n",
      "        [0.5399, 0.5371, 0.5367, 0.5300],\n",
      "        [0.5422, 0.5401, 0.5396, 0.5352],\n",
      "        [0.5435, 0.5416, 0.5409, 0.5377],\n",
      "        [0.5459, 0.5447, 0.5438, 0.5430],\n",
      "        [0.5452, 0.5438, 0.5430, 0.5416],\n",
      "        [0.5595, 0.5616, 0.5597, 0.5722],\n",
      "        [0.5719, 0.5772, 0.5743, 0.5989],\n",
      "        [0.5734, 0.5791, 0.5761, 0.6022],\n",
      "        [0.5709, 0.5759, 0.5731, 0.5968],\n",
      "        [0.5771, 0.5837, 0.5804, 0.6102],\n",
      "        [0.5810, 0.5885, 0.5850, 0.6185],\n",
      "        [0.5445, 0.5430, 0.5422, 0.5401],\n",
      "        [0.5273, 0.5214, 0.5220, 0.5029],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5404, 0.5398, 0.5357],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4940],\n",
      "        [0.5288, 0.5232, 0.5237, 0.5060],\n",
      "        [0.5569, 0.5585, 0.5568, 0.5668],\n",
      "        [0.5287, 0.5232, 0.5236, 0.5059],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5401, 0.5374, 0.5369, 0.5304],\n",
      "        [0.5405, 0.5380, 0.5375, 0.5314],\n",
      "        [0.5334, 0.5289, 0.5290, 0.5159],\n",
      "        [0.5424, 0.5402, 0.5396, 0.5352],\n",
      "        [0.5700, 0.5748, 0.5720, 0.5948],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5392, 0.5362, 0.5359, 0.5285],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5386, 0.5356, 0.5353, 0.5273],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5431, 0.5411, 0.5405, 0.5369],\n",
      "        [0.5376, 0.5343, 0.5341, 0.5252],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5255, 0.5191, 0.5198, 0.4989],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5405, 0.5399, 0.5358],\n",
      "        [0.5569, 0.5585, 0.5567, 0.5667],\n",
      "        [0.5579, 0.5596, 0.5578, 0.5687],\n",
      "        [0.5249, 0.5183, 0.5191, 0.4976],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5230, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5533, 0.5539, 0.5524, 0.5589],\n",
      "        [0.5739, 0.5797, 0.5766, 0.6032],\n",
      "        [0.5233, 0.5162, 0.5171, 0.4940],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5590, 0.5610, 0.5591, 0.5711],\n",
      "        [0.6132, 0.6291, 0.6230, 0.6883],\n",
      "        [0.3793, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.3588],\n",
      "        [0.5852, 0.5938, 0.5900, 0.4902],\n",
      "        [0.3743, 0.3787, 0.5171, 0.4939],\n",
      "        [0.4248, 0.4253, 0.5171, 0.4939]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0442,     0.0090,     0.0238,     0.0195],\n",
      "        [    0.0055,     0.0103,     0.0060,     0.0157],\n",
      "        [    0.0224,     0.0032,     0.0220,     0.0133],\n",
      "        [    0.0003,     0.0159,     0.0108,     0.0088],\n",
      "        [    0.0306,     0.0178,     0.0302,     0.0080],\n",
      "        [    0.0319,     0.0397,     0.0249,     0.0132],\n",
      "        [    0.0481,     0.0308,     0.0061,     0.0163],\n",
      "        [    0.0397,     0.0151,     0.0007,     0.0186],\n",
      "        [    0.0158,     0.0015,     0.0180,     0.0233],\n",
      "        [    0.0014,     0.0160,     0.0255,     0.0222],\n",
      "        [    0.0211,     0.0289,     0.0318,     0.0252],\n",
      "        [    0.0323,     0.0338,     0.0309,     0.0188],\n",
      "        [    0.0382,     0.0347,     0.0249,     0.0129],\n",
      "        [    0.0352,     0.0250,     0.0129,     0.0064],\n",
      "        [    0.0406,     0.0314,     0.0245,     0.0056],\n",
      "        [    0.0417,     0.0420,     0.0034,     0.0088],\n",
      "        [    0.0382,     0.0013,     0.0316,     0.0082],\n",
      "        [    0.0068,     0.0318,     0.0373,     0.0046],\n",
      "        [    0.0306,     0.0267,     0.0210,     0.0052],\n",
      "        [    0.0294,     0.0128,     0.0304,     0.0306],\n",
      "        [    0.0255,     0.0349,     0.0335,     0.0222],\n",
      "        [    0.0516,     0.0369,     0.0112,     0.0188],\n",
      "        [    0.0526,     0.0461,     0.0521,     0.0488],\n",
      "        [    0.0158,     0.0073,     0.0181,     0.0273],\n",
      "        [    0.0392,     0.0530,     0.0257,     0.0261],\n",
      "        [    0.0628,     0.0557,     0.0346,     0.0271],\n",
      "        [    0.0279,     0.0255,     0.0349,     0.0121],\n",
      "        [    0.0044,     0.0015,     0.0152,     0.0150],\n",
      "        [    0.0547,     0.0595,     0.0452,     0.0752],\n",
      "        [    0.0439,     0.0543,     0.0419,     0.0279],\n",
      "        [    0.0474,     0.0469,     0.0466,     0.0602],\n",
      "        [    0.0820,     0.0590,     0.0559,     0.0682],\n",
      "        [    0.0590,     0.0752,     0.0483,     0.0496],\n",
      "        [    0.0122,     0.0047,     0.0058,     0.0191],\n",
      "        [    0.0260,     0.0242,     0.0638,     0.1173],\n",
      "        [    0.0427,     0.0190,     0.0233,     0.0869],\n",
      "        [    0.0175,     0.0278,     0.0450,     0.0626],\n",
      "        [    0.0282,     0.0142,     0.0288,     0.0279],\n",
      "        [    0.0599,     0.0212,     0.0151,     0.0057],\n",
      "        [    0.0303,     0.0446,     0.0694,     0.0520],\n",
      "        [    0.0212,     0.0279,     0.0510,     0.0188],\n",
      "        [    0.0419,     0.0530,     0.0221,     0.0080],\n",
      "        [    0.0694,     0.0541,     0.0293,     0.0218],\n",
      "        [    0.0623,     0.0547,     0.0380,     0.0439],\n",
      "        [    0.0323,     0.0503,     0.0418,     0.0143],\n",
      "        [    0.0597,     0.0437,     0.0401,     0.0028],\n",
      "        [    0.0480,     0.0434,     0.0434,     0.0070],\n",
      "        [    0.0349,     0.0501,     0.0419,     0.0211],\n",
      "        [    0.0570,     0.0410,     0.0443,     0.0203],\n",
      "        [    0.0459,     0.0266,     0.0492,     0.0642],\n",
      "        [    0.0697,     0.0668,     0.0529,     0.0246],\n",
      "        [    0.0418,     0.0570,     0.0549,     0.0741],\n",
      "        [    0.0709,     0.0484,     0.0427,     0.0672],\n",
      "        [    0.0179,     0.0504,     0.0893,     0.0645],\n",
      "        [    0.1105,     0.0357,     0.0199,     0.0464],\n",
      "        [    0.0552,     0.0865,     0.0840,     0.0409],\n",
      "        [    0.0572,     0.0726,     0.0892,     0.0639],\n",
      "        [    0.0627,     0.0645,     0.0751,     0.1014],\n",
      "        [    0.0935,     0.0831,     0.0640,     0.0669],\n",
      "        [    0.0900,     0.0631,     0.0900,     0.0797],\n",
      "        [    0.0793,     0.0649,     0.0778,     0.1078],\n",
      "        [    0.1086,     0.0712,     0.0530,     0.1104],\n",
      "        [    0.0005,     0.1035,     0.0366,     0.0032],\n",
      "        [    0.0701,     0.0891,     0.1029,     0.0000],\n",
      "        [    0.0837,     0.0920,     0.0973,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.1044,     0.0135],\n",
      "        [    0.0682,     0.0510,     0.1383,     0.0813]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0442,     0.0090,     0.0238,     0.0195],\n",
      "        [    0.0055,     0.0103,     0.0060,     0.0157],\n",
      "        [    0.0224,     0.0032,     0.0220,     0.0133],\n",
      "        [    0.0003,     0.0159,     0.0108,     0.0088],\n",
      "        [    0.0306,     0.0178,     0.0302,     0.0080],\n",
      "        [    0.0319,     0.0397,     0.0249,     0.0132],\n",
      "        [    0.0481,     0.0308,     0.0061,     0.0163],\n",
      "        [    0.0397,     0.0151,     0.0007,     0.0186],\n",
      "        [    0.0158,     0.0015,     0.0180,     0.0233],\n",
      "        [    0.0014,     0.0160,     0.0255,     0.0222],\n",
      "        [    0.0211,     0.0289,     0.0318,     0.0252],\n",
      "        [    0.0323,     0.0338,     0.0309,     0.0188],\n",
      "        [    0.0382,     0.0347,     0.0249,     0.0129],\n",
      "        [    0.0352,     0.0250,     0.0129,     0.0064],\n",
      "        [    0.0406,     0.0314,     0.0245,     0.0056],\n",
      "        [    0.0417,     0.0420,     0.0034,     0.0088],\n",
      "        [    0.0382,     0.0013,     0.0316,     0.0082],\n",
      "        [    0.0068,     0.0318,     0.0373,     0.0046],\n",
      "        [    0.0306,     0.0267,     0.0210,     0.0052],\n",
      "        [    0.0294,     0.0128,     0.0304,     0.0306],\n",
      "        [    0.0255,     0.0349,     0.0335,     0.0222],\n",
      "        [    0.0516,     0.0369,     0.0112,     0.0188],\n",
      "        [    0.0526,     0.0461,     0.0521,     0.0488],\n",
      "        [    0.0158,     0.0073,     0.0181,     0.0273],\n",
      "        [    0.0392,     0.0530,     0.0257,     0.0261],\n",
      "        [    0.0628,     0.0557,     0.0346,     0.0271],\n",
      "        [    0.0279,     0.0255,     0.0349,     0.0121],\n",
      "        [    0.0044,     0.0015,     0.0152,     0.0150],\n",
      "        [    0.0547,     0.0595,     0.0452,     0.0752],\n",
      "        [    0.0439,     0.0543,     0.0419,     0.0279],\n",
      "        [    0.0474,     0.0469,     0.0466,     0.0602],\n",
      "        [    0.0820,     0.0590,     0.0559,     0.0682],\n",
      "        [    0.0590,     0.0752,     0.0483,     0.0496],\n",
      "        [    0.0122,     0.0047,     0.0058,     0.0191],\n",
      "        [    0.0260,     0.0242,     0.0638,     0.1173],\n",
      "        [    0.0427,     0.0190,     0.0233,     0.0869],\n",
      "        [    0.0175,     0.0278,     0.0450,     0.0626],\n",
      "        [    0.0282,     0.0142,     0.0288,     0.0279],\n",
      "        [    0.0599,     0.0212,     0.0151,     0.0057],\n",
      "        [    0.0303,     0.0446,     0.0694,     0.0520],\n",
      "        [    0.0212,     0.0279,     0.0510,     0.0188],\n",
      "        [    0.0419,     0.0530,     0.0221,     0.0080],\n",
      "        [    0.0694,     0.0541,     0.0293,     0.0218],\n",
      "        [    0.0623,     0.0547,     0.0380,     0.0439],\n",
      "        [    0.0323,     0.0503,     0.0418,     0.0143],\n",
      "        [    0.0597,     0.0437,     0.0401,     0.0028],\n",
      "        [    0.0480,     0.0434,     0.0434,     0.0070],\n",
      "        [    0.0349,     0.0501,     0.0419,     0.0211],\n",
      "        [    0.0570,     0.0410,     0.0443,     0.0203],\n",
      "        [    0.0459,     0.0266,     0.0492,     0.0642],\n",
      "        [    0.0697,     0.0668,     0.0529,     0.0246],\n",
      "        [    0.0418,     0.0570,     0.0549,     0.0741],\n",
      "        [    0.0709,     0.0484,     0.0427,     0.0672],\n",
      "        [    0.0179,     0.0504,     0.0893,     0.0645],\n",
      "        [    0.1105,     0.0357,     0.0199,     0.0464],\n",
      "        [    0.0552,     0.0865,     0.0840,     0.0409],\n",
      "        [    0.0572,     0.0726,     0.0892,     0.0639],\n",
      "        [    0.0627,     0.0645,     0.0751,     0.1014],\n",
      "        [    0.0935,     0.0831,     0.0640,     0.0669],\n",
      "        [    0.0900,     0.0631,     0.0900,     0.0797],\n",
      "        [    0.0793,     0.0649,     0.0778,     0.1078],\n",
      "        [    0.1086,     0.0712,     0.0530,     0.1104],\n",
      "        [    0.0005,     0.1035,     0.0366,     0.0032],\n",
      "        [    0.0701,     0.0891,     0.1029,     0.0000],\n",
      "        [    0.0837,     0.0920,     0.0973,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.1044,     0.0135],\n",
      "        [    0.0682,     0.0510,     0.1383,     0.0813]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.11750881 0.11750881 0.11750881 0.11750881]\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "The index of the undesired data: tensor([[66,  2]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0442,     0.0090,     0.0238,     0.0195],\n",
      "        [    0.0055,     0.0103,     0.0060,     0.0157],\n",
      "        [    0.0224,     0.0032,     0.0220,     0.0133],\n",
      "        [    0.0003,     0.0159,     0.0108,     0.0088],\n",
      "        [    0.0306,     0.0178,     0.0302,     0.0080],\n",
      "        [    0.0319,     0.0397,     0.0249,     0.0132],\n",
      "        [    0.0481,     0.0308,     0.0061,     0.0163],\n",
      "        [    0.0397,     0.0151,     0.0007,     0.0186],\n",
      "        [    0.0158,     0.0015,     0.0180,     0.0233],\n",
      "        [    0.0014,     0.0160,     0.0255,     0.0222],\n",
      "        [    0.0211,     0.0289,     0.0318,     0.0252],\n",
      "        [    0.0323,     0.0338,     0.0309,     0.0188],\n",
      "        [    0.0382,     0.0347,     0.0249,     0.0129],\n",
      "        [    0.0352,     0.0250,     0.0129,     0.0064],\n",
      "        [    0.0406,     0.0314,     0.0245,     0.0056],\n",
      "        [    0.0417,     0.0420,     0.0034,     0.0088],\n",
      "        [    0.0382,     0.0013,     0.0316,     0.0082],\n",
      "        [    0.0068,     0.0318,     0.0373,     0.0046],\n",
      "        [    0.0306,     0.0267,     0.0210,     0.0052],\n",
      "        [    0.0294,     0.0128,     0.0304,     0.0306],\n",
      "        [    0.0255,     0.0349,     0.0335,     0.0222],\n",
      "        [    0.0516,     0.0369,     0.0112,     0.0188],\n",
      "        [    0.0526,     0.0461,     0.0521,     0.0488],\n",
      "        [    0.0158,     0.0073,     0.0181,     0.0273],\n",
      "        [    0.0392,     0.0530,     0.0257,     0.0261],\n",
      "        [    0.0628,     0.0557,     0.0346,     0.0271],\n",
      "        [    0.0279,     0.0255,     0.0349,     0.0121],\n",
      "        [    0.0044,     0.0015,     0.0152,     0.0150],\n",
      "        [    0.0547,     0.0595,     0.0452,     0.0752],\n",
      "        [    0.0439,     0.0543,     0.0419,     0.0279],\n",
      "        [    0.0474,     0.0469,     0.0466,     0.0602],\n",
      "        [    0.0820,     0.0590,     0.0558,     0.0682],\n",
      "        [    0.0590,     0.0752,     0.0483,     0.0496],\n",
      "        [    0.0122,     0.0047,     0.0058,     0.0191],\n",
      "        [    0.0260,     0.0242,     0.0638,     0.1173],\n",
      "        [    0.0427,     0.0190,     0.0233,     0.0869],\n",
      "        [    0.0175,     0.0278,     0.0450,     0.0626],\n",
      "        [    0.0282,     0.0142,     0.0288,     0.0279],\n",
      "        [    0.0599,     0.0212,     0.0151,     0.0057],\n",
      "        [    0.0303,     0.0446,     0.0694,     0.0520],\n",
      "        [    0.0212,     0.0279,     0.0510,     0.0188],\n",
      "        [    0.0419,     0.0530,     0.0221,     0.0080],\n",
      "        [    0.0694,     0.0541,     0.0293,     0.0218],\n",
      "        [    0.0623,     0.0547,     0.0380,     0.0439],\n",
      "        [    0.0323,     0.0503,     0.0418,     0.0143],\n",
      "        [    0.0597,     0.0437,     0.0401,     0.0028],\n",
      "        [    0.0480,     0.0434,     0.0434,     0.0070],\n",
      "        [    0.0349,     0.0501,     0.0419,     0.0211],\n",
      "        [    0.0570,     0.0410,     0.0443,     0.0203],\n",
      "        [    0.0459,     0.0266,     0.0492,     0.0642],\n",
      "        [    0.0697,     0.0668,     0.0529,     0.0246],\n",
      "        [    0.0418,     0.0570,     0.0549,     0.0741],\n",
      "        [    0.0709,     0.0484,     0.0427,     0.0672],\n",
      "        [    0.0179,     0.0504,     0.0893,     0.0645],\n",
      "        [    0.1105,     0.0357,     0.0199,     0.0464],\n",
      "        [    0.0552,     0.0865,     0.0840,     0.0409],\n",
      "        [    0.0572,     0.0726,     0.0892,     0.0639],\n",
      "        [    0.0627,     0.0645,     0.0752,     0.1014],\n",
      "        [    0.0935,     0.0831,     0.0640,     0.0669],\n",
      "        [    0.0900,     0.0631,     0.0900,     0.0797],\n",
      "        [    0.0793,     0.0649,     0.0778,     0.1078],\n",
      "        [    0.1086,     0.0712,     0.0530,     0.1104],\n",
      "        [    0.0005,     0.1035,     0.0366,     0.0032],\n",
      "        [    0.0701,     0.0891,     0.1029,     0.0000],\n",
      "        [    0.0837,     0.0920,     0.0973,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.1044,     0.0135],\n",
      "        [    0.0682,     0.0510,     0.0000,     0.0813]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 658\n",
      "Number of shrink: 342\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 2 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 181\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 3 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 659\n",
      "Number of shrink: 341\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 4 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 5 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 6 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 7 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 8 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 9 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 10 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 1\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 11 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 2\n",
      "Number of shrink: 8\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 12 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 1\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 13 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 14 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 15 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 16 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 85\n",
      "Number of shrink: 50\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 17 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 243\n",
      "Number of shrink: 131\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 18 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 85\n",
      "Number of shrink: 50\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 19 / 19\n",
      "Reorganizing result: The final number of neuro is  19\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0442,     0.0090,     0.0238,     0.0195],\n",
      "        [    0.0055,     0.0103,     0.0060,     0.0157],\n",
      "        [    0.0224,     0.0032,     0.0220,     0.0133],\n",
      "        [    0.0003,     0.0159,     0.0108,     0.0088],\n",
      "        [    0.0306,     0.0178,     0.0302,     0.0080],\n",
      "        [    0.0319,     0.0397,     0.0249,     0.0132],\n",
      "        [    0.0481,     0.0308,     0.0061,     0.0163],\n",
      "        [    0.0397,     0.0151,     0.0007,     0.0186],\n",
      "        [    0.0158,     0.0015,     0.0180,     0.0233],\n",
      "        [    0.0014,     0.0160,     0.0255,     0.0222],\n",
      "        [    0.0211,     0.0289,     0.0318,     0.0252],\n",
      "        [    0.0323,     0.0338,     0.0309,     0.0188],\n",
      "        [    0.0382,     0.0347,     0.0249,     0.0129],\n",
      "        [    0.0352,     0.0250,     0.0129,     0.0064],\n",
      "        [    0.0406,     0.0314,     0.0245,     0.0056],\n",
      "        [    0.0417,     0.0420,     0.0034,     0.0088],\n",
      "        [    0.0382,     0.0013,     0.0316,     0.0082],\n",
      "        [    0.0068,     0.0318,     0.0373,     0.0046],\n",
      "        [    0.0306,     0.0267,     0.0210,     0.0052],\n",
      "        [    0.0294,     0.0128,     0.0304,     0.0306],\n",
      "        [    0.0255,     0.0349,     0.0335,     0.0222],\n",
      "        [    0.0516,     0.0369,     0.0112,     0.0188],\n",
      "        [    0.0526,     0.0461,     0.0521,     0.0488],\n",
      "        [    0.0158,     0.0073,     0.0181,     0.0273],\n",
      "        [    0.0392,     0.0530,     0.0257,     0.0261],\n",
      "        [    0.0628,     0.0557,     0.0346,     0.0271],\n",
      "        [    0.0279,     0.0255,     0.0349,     0.0121],\n",
      "        [    0.0044,     0.0015,     0.0152,     0.0150],\n",
      "        [    0.0547,     0.0595,     0.0452,     0.0752],\n",
      "        [    0.0439,     0.0543,     0.0419,     0.0279],\n",
      "        [    0.0474,     0.0469,     0.0466,     0.0602],\n",
      "        [    0.0820,     0.0590,     0.0558,     0.0682],\n",
      "        [    0.0590,     0.0752,     0.0483,     0.0496],\n",
      "        [    0.0122,     0.0047,     0.0058,     0.0191],\n",
      "        [    0.0260,     0.0242,     0.0638,     0.1173],\n",
      "        [    0.0427,     0.0190,     0.0233,     0.0869],\n",
      "        [    0.0175,     0.0278,     0.0450,     0.0626],\n",
      "        [    0.0282,     0.0142,     0.0288,     0.0279],\n",
      "        [    0.0599,     0.0212,     0.0151,     0.0057],\n",
      "        [    0.0303,     0.0446,     0.0694,     0.0520],\n",
      "        [    0.0212,     0.0279,     0.0510,     0.0188],\n",
      "        [    0.0419,     0.0530,     0.0221,     0.0080],\n",
      "        [    0.0694,     0.0541,     0.0293,     0.0218],\n",
      "        [    0.0623,     0.0547,     0.0380,     0.0439],\n",
      "        [    0.0323,     0.0503,     0.0418,     0.0143],\n",
      "        [    0.0597,     0.0437,     0.0401,     0.0028],\n",
      "        [    0.0480,     0.0434,     0.0434,     0.0070],\n",
      "        [    0.0349,     0.0501,     0.0419,     0.0211],\n",
      "        [    0.0570,     0.0410,     0.0443,     0.0203],\n",
      "        [    0.0459,     0.0266,     0.0492,     0.0642],\n",
      "        [    0.0697,     0.0668,     0.0529,     0.0246],\n",
      "        [    0.0418,     0.0570,     0.0549,     0.0741],\n",
      "        [    0.0709,     0.0484,     0.0427,     0.0672],\n",
      "        [    0.0179,     0.0504,     0.0893,     0.0645],\n",
      "        [    0.1105,     0.0357,     0.0199,     0.0464],\n",
      "        [    0.0552,     0.0865,     0.0840,     0.0409],\n",
      "        [    0.0572,     0.0726,     0.0892,     0.0639],\n",
      "        [    0.0627,     0.0645,     0.0752,     0.1014],\n",
      "        [    0.0935,     0.0831,     0.0640,     0.0669],\n",
      "        [    0.0900,     0.0631,     0.0900,     0.0797],\n",
      "        [    0.0793,     0.0649,     0.0778,     0.1078],\n",
      "        [    0.1086,     0.0712,     0.0530,     0.1104],\n",
      "        [    0.0005,     0.1035,     0.0366,     0.0032],\n",
      "        [    0.0701,     0.0891,     0.1029,     0.0000],\n",
      "        [    0.0837,     0.0920,     0.0973,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.1044,     0.0135],\n",
      "        [    0.0682,     0.0510,     0.0000,     0.0813]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 53.65152168273926\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 68\n",
      "X 資料 torch.Size([39, 18])\n",
      "Y 資料 torch.Size([39, 4])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.013693788088858128, 20)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引20，y= tensor([0.5403, 0.5808, 0.6112, 0.6975])\n",
      "目前模型的Data torch.Size([68, 18])\n",
      "<<預測值>>\n",
      "tensor([[0.5707, 0.5757, 0.5729, 0.5965],\n",
      "        [0.5792, 0.5864, 0.5830, 0.6149],\n",
      "        [0.5744, 0.5802, 0.5772, 0.6042],\n",
      "        [0.5768, 0.5833, 0.5801, 0.6095],\n",
      "        [0.5686, 0.5731, 0.5705, 0.5920],\n",
      "        [0.5590, 0.5610, 0.5591, 0.5711],\n",
      "        [0.5526, 0.5531, 0.5518, 0.5576],\n",
      "        [0.5443, 0.5428, 0.5420, 0.5397],\n",
      "        [0.5421, 0.5397, 0.5392, 0.5345],\n",
      "        [0.5399, 0.5371, 0.5367, 0.5300],\n",
      "        [0.5422, 0.5401, 0.5396, 0.5352],\n",
      "        [0.5435, 0.5416, 0.5409, 0.5377],\n",
      "        [0.5459, 0.5447, 0.5438, 0.5430],\n",
      "        [0.5452, 0.5438, 0.5430, 0.5416],\n",
      "        [0.5595, 0.5616, 0.5597, 0.5722],\n",
      "        [0.5719, 0.5772, 0.5743, 0.5989],\n",
      "        [0.5734, 0.5791, 0.5761, 0.6022],\n",
      "        [0.5709, 0.5759, 0.5731, 0.5968],\n",
      "        [0.5771, 0.5837, 0.5804, 0.6102],\n",
      "        [0.5810, 0.5885, 0.5850, 0.6185],\n",
      "        [0.5445, 0.5430, 0.5422, 0.5401],\n",
      "        [0.5273, 0.5214, 0.5220, 0.5029],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5404, 0.5398, 0.5357],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4940],\n",
      "        [0.5288, 0.5232, 0.5237, 0.5060],\n",
      "        [0.5569, 0.5585, 0.5568, 0.5668],\n",
      "        [0.5287, 0.5232, 0.5236, 0.5059],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5401, 0.5374, 0.5370, 0.5304],\n",
      "        [0.5405, 0.5380, 0.5375, 0.5314],\n",
      "        [0.5334, 0.5289, 0.5290, 0.5159],\n",
      "        [0.5424, 0.5402, 0.5396, 0.5352],\n",
      "        [0.5700, 0.5748, 0.5720, 0.5948],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5392, 0.5362, 0.5359, 0.5285],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5386, 0.5356, 0.5353, 0.5273],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5431, 0.5411, 0.5405, 0.5369],\n",
      "        [0.5376, 0.5343, 0.5341, 0.5252],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5255, 0.5191, 0.5198, 0.4989],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5425, 0.5405, 0.5399, 0.5358],\n",
      "        [0.5569, 0.5585, 0.5568, 0.5667],\n",
      "        [0.5579, 0.5596, 0.5578, 0.5687],\n",
      "        [0.5249, 0.5183, 0.5190, 0.4976],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5230, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5533, 0.5539, 0.5525, 0.5589],\n",
      "        [0.5739, 0.5797, 0.5766, 0.6032],\n",
      "        [0.5233, 0.5162, 0.5171, 0.4940],\n",
      "        [0.5231, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5590, 0.5610, 0.5591, 0.5711],\n",
      "        [0.6132, 0.6291, 0.6230, 0.6883],\n",
      "        [0.3793, 0.5162, 0.5171, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.3588],\n",
      "        [0.5852, 0.5938, 0.5899, 0.4902],\n",
      "        [0.3743, 0.3787, 0.5171, 0.4939],\n",
      "        [0.4248, 0.4253, 0.3787, 0.4939],\n",
      "        [0.5232, 0.5162, 0.5171, 0.4939]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0442,     0.0090,     0.0238,     0.0195],\n",
      "        [    0.0055,     0.0103,     0.0060,     0.0157],\n",
      "        [    0.0224,     0.0032,     0.0220,     0.0133],\n",
      "        [    0.0003,     0.0159,     0.0108,     0.0088],\n",
      "        [    0.0306,     0.0178,     0.0302,     0.0080],\n",
      "        [    0.0319,     0.0397,     0.0249,     0.0132],\n",
      "        [    0.0481,     0.0308,     0.0061,     0.0163],\n",
      "        [    0.0397,     0.0151,     0.0007,     0.0186],\n",
      "        [    0.0158,     0.0015,     0.0180,     0.0233],\n",
      "        [    0.0014,     0.0160,     0.0255,     0.0222],\n",
      "        [    0.0211,     0.0289,     0.0318,     0.0252],\n",
      "        [    0.0323,     0.0338,     0.0309,     0.0188],\n",
      "        [    0.0382,     0.0347,     0.0249,     0.0129],\n",
      "        [    0.0352,     0.0250,     0.0129,     0.0064],\n",
      "        [    0.0406,     0.0314,     0.0245,     0.0056],\n",
      "        [    0.0417,     0.0420,     0.0034,     0.0088],\n",
      "        [    0.0382,     0.0013,     0.0316,     0.0082],\n",
      "        [    0.0068,     0.0318,     0.0373,     0.0046],\n",
      "        [    0.0306,     0.0267,     0.0210,     0.0052],\n",
      "        [    0.0294,     0.0128,     0.0304,     0.0306],\n",
      "        [    0.0255,     0.0349,     0.0335,     0.0222],\n",
      "        [    0.0516,     0.0369,     0.0112,     0.0188],\n",
      "        [    0.0526,     0.0461,     0.0521,     0.0488],\n",
      "        [    0.0158,     0.0073,     0.0181,     0.0273],\n",
      "        [    0.0392,     0.0530,     0.0257,     0.0261],\n",
      "        [    0.0628,     0.0557,     0.0346,     0.0271],\n",
      "        [    0.0279,     0.0255,     0.0349,     0.0121],\n",
      "        [    0.0044,     0.0015,     0.0152,     0.0150],\n",
      "        [    0.0547,     0.0595,     0.0452,     0.0752],\n",
      "        [    0.0439,     0.0543,     0.0419,     0.0279],\n",
      "        [    0.0474,     0.0469,     0.0466,     0.0602],\n",
      "        [    0.0820,     0.0590,     0.0558,     0.0682],\n",
      "        [    0.0590,     0.0752,     0.0483,     0.0496],\n",
      "        [    0.0122,     0.0047,     0.0058,     0.0191],\n",
      "        [    0.0260,     0.0242,     0.0638,     0.1173],\n",
      "        [    0.0427,     0.0190,     0.0233,     0.0869],\n",
      "        [    0.0175,     0.0278,     0.0450,     0.0626],\n",
      "        [    0.0282,     0.0142,     0.0288,     0.0279],\n",
      "        [    0.0599,     0.0212,     0.0151,     0.0057],\n",
      "        [    0.0303,     0.0446,     0.0694,     0.0520],\n",
      "        [    0.0212,     0.0279,     0.0510,     0.0188],\n",
      "        [    0.0419,     0.0530,     0.0221,     0.0080],\n",
      "        [    0.0694,     0.0541,     0.0293,     0.0218],\n",
      "        [    0.0623,     0.0547,     0.0380,     0.0439],\n",
      "        [    0.0323,     0.0503,     0.0418,     0.0143],\n",
      "        [    0.0597,     0.0437,     0.0401,     0.0028],\n",
      "        [    0.0480,     0.0434,     0.0434,     0.0070],\n",
      "        [    0.0349,     0.0501,     0.0419,     0.0211],\n",
      "        [    0.0570,     0.0410,     0.0443,     0.0203],\n",
      "        [    0.0459,     0.0266,     0.0492,     0.0642],\n",
      "        [    0.0697,     0.0668,     0.0529,     0.0246],\n",
      "        [    0.0418,     0.0570,     0.0549,     0.0741],\n",
      "        [    0.0709,     0.0484,     0.0427,     0.0672],\n",
      "        [    0.0179,     0.0504,     0.0893,     0.0645],\n",
      "        [    0.1105,     0.0357,     0.0199,     0.0464],\n",
      "        [    0.0552,     0.0865,     0.0840,     0.0409],\n",
      "        [    0.0572,     0.0726,     0.0892,     0.0639],\n",
      "        [    0.0627,     0.0645,     0.0752,     0.1014],\n",
      "        [    0.0935,     0.0831,     0.0640,     0.0669],\n",
      "        [    0.0900,     0.0631,     0.0900,     0.0797],\n",
      "        [    0.0793,     0.0649,     0.0778,     0.1078],\n",
      "        [    0.1086,     0.0712,     0.0530,     0.1104],\n",
      "        [    0.0005,     0.1035,     0.0366,     0.0032],\n",
      "        [    0.0701,     0.0891,     0.1029,     0.0000],\n",
      "        [    0.0837,     0.0920,     0.0973,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.1044,     0.0135],\n",
      "        [    0.0682,     0.0510,     0.0000,     0.0813],\n",
      "        [    0.0172,     0.0647,     0.0942,     0.2035]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Loss值\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0442,     0.0090,     0.0238,     0.0195],\n",
      "        [    0.0055,     0.0103,     0.0060,     0.0157],\n",
      "        [    0.0224,     0.0032,     0.0220,     0.0133],\n",
      "        [    0.0003,     0.0159,     0.0108,     0.0088],\n",
      "        [    0.0306,     0.0178,     0.0302,     0.0080],\n",
      "        [    0.0319,     0.0397,     0.0249,     0.0132],\n",
      "        [    0.0481,     0.0308,     0.0061,     0.0163],\n",
      "        [    0.0397,     0.0151,     0.0007,     0.0186],\n",
      "        [    0.0158,     0.0015,     0.0180,     0.0233],\n",
      "        [    0.0014,     0.0160,     0.0255,     0.0222],\n",
      "        [    0.0211,     0.0289,     0.0318,     0.0252],\n",
      "        [    0.0323,     0.0338,     0.0309,     0.0188],\n",
      "        [    0.0382,     0.0347,     0.0249,     0.0129],\n",
      "        [    0.0352,     0.0250,     0.0129,     0.0064],\n",
      "        [    0.0406,     0.0314,     0.0245,     0.0056],\n",
      "        [    0.0417,     0.0420,     0.0034,     0.0088],\n",
      "        [    0.0382,     0.0013,     0.0316,     0.0082],\n",
      "        [    0.0068,     0.0318,     0.0373,     0.0046],\n",
      "        [    0.0306,     0.0267,     0.0210,     0.0052],\n",
      "        [    0.0294,     0.0128,     0.0304,     0.0306],\n",
      "        [    0.0255,     0.0349,     0.0335,     0.0222],\n",
      "        [    0.0516,     0.0369,     0.0112,     0.0188],\n",
      "        [    0.0526,     0.0461,     0.0521,     0.0488],\n",
      "        [    0.0158,     0.0073,     0.0181,     0.0273],\n",
      "        [    0.0392,     0.0530,     0.0257,     0.0261],\n",
      "        [    0.0628,     0.0557,     0.0346,     0.0271],\n",
      "        [    0.0279,     0.0255,     0.0349,     0.0121],\n",
      "        [    0.0044,     0.0015,     0.0152,     0.0150],\n",
      "        [    0.0547,     0.0595,     0.0452,     0.0752],\n",
      "        [    0.0439,     0.0543,     0.0419,     0.0279],\n",
      "        [    0.0474,     0.0469,     0.0466,     0.0602],\n",
      "        [    0.0820,     0.0590,     0.0558,     0.0682],\n",
      "        [    0.0590,     0.0752,     0.0483,     0.0496],\n",
      "        [    0.0122,     0.0047,     0.0058,     0.0191],\n",
      "        [    0.0260,     0.0242,     0.0638,     0.1173],\n",
      "        [    0.0427,     0.0190,     0.0233,     0.0869],\n",
      "        [    0.0175,     0.0278,     0.0450,     0.0626],\n",
      "        [    0.0282,     0.0142,     0.0288,     0.0279],\n",
      "        [    0.0599,     0.0212,     0.0151,     0.0057],\n",
      "        [    0.0303,     0.0446,     0.0694,     0.0520],\n",
      "        [    0.0212,     0.0279,     0.0510,     0.0188],\n",
      "        [    0.0419,     0.0530,     0.0221,     0.0080],\n",
      "        [    0.0694,     0.0541,     0.0293,     0.0218],\n",
      "        [    0.0623,     0.0547,     0.0380,     0.0439],\n",
      "        [    0.0323,     0.0503,     0.0418,     0.0143],\n",
      "        [    0.0597,     0.0437,     0.0401,     0.0028],\n",
      "        [    0.0480,     0.0434,     0.0434,     0.0070],\n",
      "        [    0.0349,     0.0501,     0.0419,     0.0211],\n",
      "        [    0.0570,     0.0410,     0.0443,     0.0203],\n",
      "        [    0.0459,     0.0266,     0.0492,     0.0642],\n",
      "        [    0.0697,     0.0668,     0.0529,     0.0246],\n",
      "        [    0.0418,     0.0570,     0.0549,     0.0741],\n",
      "        [    0.0709,     0.0484,     0.0427,     0.0672],\n",
      "        [    0.0179,     0.0504,     0.0893,     0.0645],\n",
      "        [    0.1105,     0.0357,     0.0199,     0.0464],\n",
      "        [    0.0552,     0.0865,     0.0840,     0.0409],\n",
      "        [    0.0572,     0.0726,     0.0892,     0.0639],\n",
      "        [    0.0627,     0.0645,     0.0752,     0.1014],\n",
      "        [    0.0935,     0.0831,     0.0640,     0.0669],\n",
      "        [    0.0900,     0.0631,     0.0900,     0.0797],\n",
      "        [    0.0793,     0.0649,     0.0778,     0.1078],\n",
      "        [    0.1086,     0.0712,     0.0530,     0.1104],\n",
      "        [    0.0005,     0.1035,     0.0366,     0.0032],\n",
      "        [    0.0701,     0.0891,     0.1029,     0.0000],\n",
      "        [    0.0837,     0.0920,     0.0973,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.1044,     0.0135],\n",
      "        [    0.0682,     0.0510,     0.0000,     0.0813],\n",
      "        [    0.0172,     0.0647,     0.0942,     0.2035]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.11750881 0.11750881 0.11750881 0.11750881]\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "The index of the undesired data: tensor([[67,  3]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0442,     0.0090,     0.0238,     0.0195],\n",
      "        [    0.0055,     0.0103,     0.0060,     0.0157],\n",
      "        [    0.0224,     0.0032,     0.0220,     0.0133],\n",
      "        [    0.0003,     0.0159,     0.0108,     0.0088],\n",
      "        [    0.0306,     0.0178,     0.0302,     0.0080],\n",
      "        [    0.0319,     0.0397,     0.0249,     0.0132],\n",
      "        [    0.0481,     0.0308,     0.0061,     0.0163],\n",
      "        [    0.0397,     0.0151,     0.0007,     0.0186],\n",
      "        [    0.0158,     0.0015,     0.0180,     0.0233],\n",
      "        [    0.0014,     0.0160,     0.0255,     0.0222],\n",
      "        [    0.0211,     0.0289,     0.0318,     0.0252],\n",
      "        [    0.0323,     0.0338,     0.0309,     0.0188],\n",
      "        [    0.0382,     0.0347,     0.0249,     0.0129],\n",
      "        [    0.0352,     0.0250,     0.0129,     0.0064],\n",
      "        [    0.0406,     0.0314,     0.0245,     0.0056],\n",
      "        [    0.0417,     0.0420,     0.0034,     0.0088],\n",
      "        [    0.0382,     0.0013,     0.0316,     0.0082],\n",
      "        [    0.0068,     0.0318,     0.0373,     0.0046],\n",
      "        [    0.0306,     0.0267,     0.0210,     0.0052],\n",
      "        [    0.0294,     0.0128,     0.0304,     0.0306],\n",
      "        [    0.0255,     0.0349,     0.0335,     0.0222],\n",
      "        [    0.0516,     0.0369,     0.0112,     0.0188],\n",
      "        [    0.0526,     0.0461,     0.0521,     0.0488],\n",
      "        [    0.0158,     0.0073,     0.0181,     0.0273],\n",
      "        [    0.0392,     0.0530,     0.0257,     0.0261],\n",
      "        [    0.0628,     0.0557,     0.0346,     0.0271],\n",
      "        [    0.0279,     0.0255,     0.0349,     0.0121],\n",
      "        [    0.0044,     0.0015,     0.0152,     0.0150],\n",
      "        [    0.0547,     0.0595,     0.0452,     0.0752],\n",
      "        [    0.0439,     0.0543,     0.0419,     0.0279],\n",
      "        [    0.0474,     0.0469,     0.0466,     0.0602],\n",
      "        [    0.0820,     0.0590,     0.0558,     0.0682],\n",
      "        [    0.0590,     0.0752,     0.0483,     0.0496],\n",
      "        [    0.0122,     0.0047,     0.0058,     0.0191],\n",
      "        [    0.0260,     0.0242,     0.0638,     0.1173],\n",
      "        [    0.0427,     0.0190,     0.0233,     0.0869],\n",
      "        [    0.0175,     0.0278,     0.0450,     0.0626],\n",
      "        [    0.0282,     0.0142,     0.0288,     0.0279],\n",
      "        [    0.0599,     0.0212,     0.0151,     0.0057],\n",
      "        [    0.0303,     0.0446,     0.0694,     0.0520],\n",
      "        [    0.0212,     0.0279,     0.0510,     0.0188],\n",
      "        [    0.0419,     0.0530,     0.0221,     0.0080],\n",
      "        [    0.0694,     0.0541,     0.0293,     0.0218],\n",
      "        [    0.0623,     0.0547,     0.0380,     0.0439],\n",
      "        [    0.0323,     0.0503,     0.0418,     0.0143],\n",
      "        [    0.0597,     0.0437,     0.0401,     0.0028],\n",
      "        [    0.0480,     0.0434,     0.0434,     0.0070],\n",
      "        [    0.0349,     0.0501,     0.0419,     0.0211],\n",
      "        [    0.0570,     0.0410,     0.0443,     0.0203],\n",
      "        [    0.0459,     0.0266,     0.0492,     0.0642],\n",
      "        [    0.0697,     0.0668,     0.0529,     0.0246],\n",
      "        [    0.0418,     0.0570,     0.0549,     0.0741],\n",
      "        [    0.0709,     0.0484,     0.0427,     0.0672],\n",
      "        [    0.0179,     0.0504,     0.0893,     0.0645],\n",
      "        [    0.1105,     0.0357,     0.0199,     0.0464],\n",
      "        [    0.0552,     0.0865,     0.0840,     0.0409],\n",
      "        [    0.0572,     0.0726,     0.0892,     0.0639],\n",
      "        [    0.0627,     0.0645,     0.0752,     0.1014],\n",
      "        [    0.0935,     0.0831,     0.0640,     0.0669],\n",
      "        [    0.0900,     0.0631,     0.0900,     0.0797],\n",
      "        [    0.0793,     0.0649,     0.0778,     0.1078],\n",
      "        [    0.1086,     0.0712,     0.0530,     0.1104],\n",
      "        [    0.0005,     0.1035,     0.0366,     0.0032],\n",
      "        [    0.0701,     0.0891,     0.1029,     0.0000],\n",
      "        [    0.0837,     0.0920,     0.0973,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.1044,     0.0135],\n",
      "        [    0.0682,     0.0510,     0.0000,     0.0813],\n",
      "        [    0.0172,     0.0647,     0.0942,     0.0000]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要你: False\n",
      "Cannot drop out the nero number: 1 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.11750881316098707\n",
      "Regularizing結束\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "因為Learning不能這麼小啦\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.11750881316098707\n"
     ]
    }
   ],
   "source": [
    "x_data, y_data = get_data(4)\n",
    "x_data = sc.fit_transform(x_data)\n",
    "y_data = sc.fit_transform(y_data)\n",
    "threshold_for_error = 3000/(sc.data_max_-sc.data_min_)\n",
    "\n",
    "\n",
    "data = range(x_data.shape[0])\n",
    "# window_size => the length of training block\n",
    "window_size = 106\n",
    "# step_window => step size of each window\n",
    "step_window = 4\n",
    "# the split data\n",
    "splits = []\n",
    "\n",
    "## Moving window mechnism\n",
    "for i in range(window_size, len(data), step_window):\n",
    "    train = np.array(data[i-window_size:i])\n",
    "    test = np.array(data[i-window_size:i+step_window])\n",
    "#     test = np.array(data[i:i+step_window])\n",
    "    splits.append(('TRAIN:', train, 'TEST:', test))\n",
    "\n",
    "## Record program start time\n",
    "start = time.time()\n",
    "# for i_block in range(len(splits)):\n",
    "for i_block in range(-2,0,1):\n",
    "    block_start = time.time()\n",
    "    ## Record the number of each step\n",
    "    nb_step4 = 0\n",
    "    nb_step6_1 = 0\n",
    "    nb_step6_2 = 0\n",
    "#     print(\"The <<%d>> Block\" %(i_block+1))\n",
    "    print(\"The <<%d>> Block\" %(len(splits)+i_block+1))\n",
    "#     print(\"The training block\\n\", y_data[splits[i_block][1]])\n",
    "#     print(\"The testing block\\n\", y_data[splits[i_block][3]])\n",
    "    \n",
    "    x_train = x_data[splits[i_block][1]]\n",
    "    x_test = x_data[splits[i_block][3]]\n",
    "    y_train = y_data[splits[i_block][1]]\n",
    "    y_test = y_data[splits[i_block][3]]\n",
    "    \n",
    "    x_train_scaled = torch.FloatTensor(x_train)\n",
    "    x_test_scaled = torch.FloatTensor(x_test)\n",
    "    y_train_scaled = torch.FloatTensor(y_train)\n",
    "    y_test = sc.inverse_transform(y_test)\n",
    "#     x_train_scaled = torch.FloatTensor(sc.fit_transform(x_train))\n",
    "#     x_test_scaled = torch.FloatTensor(sc.transform(x_test))\n",
    "#     y_train_scaled = torch.FloatTensor(sc.fit_transform(y_train))\n",
    "    \n",
    "#     threshold_for_error = 3000/(sc.data_max_-sc.data_min_)\n",
    "#     threshold_for_error = threshold_for_error[0]\n",
    "#     print(\"確認threshold_for_error:\",threshold_for_error)\n",
    "    # 如果是第一個 Block的話\n",
    "    if i_block == -2:\n",
    "#     if i_block == 0:\n",
    "        initial_x = torch.FloatTensor(x_train_scaled[:x_train_scaled.shape[1]+1])\n",
    "        initial_y = torch.FloatTensor(y_train_scaled[:x_train_scaled.shape[1]+1])\n",
    "        \n",
    "        x_train_scaled = torch.FloatTensor(x_train_scaled[x_train_scaled.shape[1]+1:])\n",
    "        y_train_scaled = torch.FloatTensor(y_train_scaled[x_train_scaled.shape[1]+1:])\n",
    "#         print(initial_x.shape[0])\n",
    "        \n",
    "        network = Network(4,initial_x,initial_y)\n",
    "        network.nb_node_acceptable = torch.IntTensor([4 for _ in range(initial_x.shape[0])])\n",
    "        network.threshold_for_error = threshold_for_error[0]\n",
    "        initializing(network, initial_x, initial_y)\n",
    "        print(\"<<Initializing後看一下差異>>\")\n",
    "        yo,loss = network.forward()\n",
    "        print(torch.abs(network.y-yo))\n",
    "        print(\"threshold_for_error:\",threshold_for_error)\n",
    "    \n",
    "#     print(\"(後)確認threshold_for_error:\",network.threshold_for_error)\n",
    "#     print(\"看一下模型\")\n",
    "#     print(network.state_dict())\n",
    "    \n",
    "    for i in range(int(x_train_scaled.shape[0]*0.9624)):\n",
    "#     for i in range(3):\n",
    "        \n",
    "        if i_block == -2:\n",
    "#         if i_block == 0:\n",
    "            print(\"現在訓練到第幾筆資料: %d\"%(i+x_train_scaled.shape[1]+2))\n",
    "        \n",
    "        else:\n",
    "            print(\"現在訓練到第幾筆資料: %d\"%(i+1))\n",
    "        \n",
    "        print(\"X 資料\",x_train_scaled.shape)\n",
    "        print(\"Y 資料\",y_train_scaled.shape)\n",
    "        \n",
    "        sorted_index = selecting(network, x_train_scaled, y_train_scaled)\n",
    "        \n",
    "        if i==0 and i_block > -2:\n",
    "#         if i==0 and i_block > 0:\n",
    "            print(\"除了N=0外，第一筆資料\")\n",
    "            network.setData(x_train_scaled[sorted_index[0]].reshape(1,-1), y_train_scaled[sorted_index[0]].reshape(1,-1))\n",
    "            network.nb_node_acceptable = torch.IntTensor([])\n",
    "        \n",
    "        else:    \n",
    "        ## Add new data for training\n",
    "            network.addData(x_train_scaled[sorted_index[0]], y_train_scaled[sorted_index[0]])\n",
    "        \n",
    "        print(\"現在要進去模型的數據，索引%d，y=\"%(sorted_index[0]),y_train_scaled[sorted_index[0]].data)\n",
    "        print(\"目前模型的Data\",network.x.shape)\n",
    "        \n",
    "        x_train_scaled = np.delete(x_train_scaled, sorted_index[0], 0)\n",
    "        y_train_scaled = np.delete(y_train_scaled, sorted_index[0], 0)\n",
    "\n",
    "        \n",
    "        yo,loss = network.forward()\n",
    "        print(\"<<預測值>>\")\n",
    "        print(yo)\n",
    "        print(\"<<差異>>\")\n",
    "        print(torch.abs(yo-network.y))\n",
    "        print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "        print(\"Loss值\")\n",
    "        print(loss)\n",
    "\n",
    "        pre_network = copy.deepcopy(network)\n",
    "        \n",
    "        if not torch.all(torch.abs(network.y-yo)<network.threshold_for_error):\n",
    "\n",
    "            network.acceptable = False\n",
    "            network = matching(network)\n",
    "            \n",
    "            print(\"<<Matching後看一下差異>>\")\n",
    "            yo,loss = network.forward()\n",
    "            print(torch.abs(yo-network.y))\n",
    "            print(\"threshold_for_error:\",threshold_for_error)\n",
    "            if network.acceptable == False:\n",
    "                \n",
    "                network = pre_network\n",
    "                cramming(network)\n",
    "\n",
    "                print(\"<<Cramming後看一下差異>>\")\n",
    "                yo,loss = network.forward()\n",
    "                print(torch.abs(yo-network.y))\n",
    "                print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "                nb_step6_2 += 1\n",
    "\n",
    "            else:\n",
    "                nb_step6_1 += 1\n",
    "\n",
    "        else:\n",
    "            nb_step4 += 1\n",
    "\n",
    "        network = reorganizing(network)\n",
    "#         print(\"看一下 hidden node\")\n",
    "#         print(network.nb_node_acceptable)\n",
    "        network.nb_node_acceptable = torch.cat([network.nb_node_acceptable, torch.IntTensor([network.linear1.bias.data.shape[0]])],0)\n",
    "#         print(\"看一下 hidden node\")\n",
    "#         print(network.nb_node_acceptable)\n",
    "        print(\"<<Reorganizing後看一下差異>>\")\n",
    "        yo,loss = network.forward()\n",
    "        print(torch.abs(yo-network.y))\n",
    "        print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "        print(\"使用裝置\",(list(network.parameters())[0].device))\n",
    "        print(\"累計時間(s)\",time.time()-start)\n",
    "        print(\"-\"*90)\n",
    "\n",
    "    \n",
    "    block_end = time.time()\n",
    "#     print(\"到第 %d 個區塊累積花費時間(s)\"%(i_block+1),block_end-block_start)\n",
    "    print(\"到第 %d 個區塊累積花費時間(s)\"%(len(splits)+i_block+1),block_end-block_start)\n",
    "#     print(\"<<The performance of %d block>>\"%(i_block+1))\n",
    "    print(\"<<The performance of %d block>>\"%(len(splits)+i_block+1))\n",
    "    \n",
    "#     validation(network, nb_step4, nb_step6_1, nb_step6_2, x_test_scaled, y_test, block_start, block_end,i_block+1)\n",
    "    validation(network, nb_step4, nb_step6_1, nb_step6_2, x_test_scaled, y_test, block_start, block_end,(len(splits)+i_block+1))\n",
    "    end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
